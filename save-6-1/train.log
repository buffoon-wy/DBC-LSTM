{"episode_reward": 0.0, "episode": 1.0, "duration": 51.87424111366272, "step": 24}
{"episode_reward": -9.0280207664094, "episode": 2.0, "duration": 9.163941144943237, "step": 73}
{"episode_reward": -25.19311023493172, "episode": 3.0, "batch_reward": -0.561868143769411, "critic_loss": 0.16509595362899396, "ae_transition_loss": -1.0320691699878528, "ae_encoder_loss": 0.04215406787653382, "actor_loss": 0.6349839017941401, "actor_target_entropy": -2.0, "actor_entropy": -0.2320458416182261, "alpha_loss": 0.010332921161114847, "alpha_value": 0.00986080809816746, "duration": 25.523651361465454, "step": 122}
{"episode_reward": -18.785149057906835, "episode": 4.0, "batch_reward": -0.4497808516025543, "critic_loss": 0.021264791954308748, "ae_transition_loss": -2.2954336404800415, "ae_encoder_loss": 0.0288517028093338, "actor_loss": 0.4699960947036743, "actor_target_entropy": -2.0, "actor_entropy": -1.3181309700012207, "alpha_loss": 0.004928175127133727, "alpha_value": 0.009677065800659553, "duration": 4.934351921081543, "step": 146}
{"episode_reward": -2.9174981410777914, "episode": 5.0, "batch_reward": -0.34817710518836975, "critic_loss": 0.01243289764970541, "ae_transition_loss": -1.6343697786331177, "ae_encoder_loss": 0.03588970638811588, "actor_loss": 0.36788261532783506, "actor_target_entropy": -2.0, "actor_entropy": -1.811373805999756, "alpha_loss": 0.002255466568749398, "alpha_value": 0.0096649393978949, "duration": 10.025190830230713, "step": 195}
{"episode_reward": -4.1566338684475115, "episode": 6.0, "batch_reward": -0.2889065146446228, "critic_loss": 0.010182679165154696, "ae_transition_loss": -1.4890235662460327, "ae_encoder_loss": 0.03362710028886795, "actor_loss": 0.37013159692287445, "actor_target_entropy": -2.0, "actor_entropy": -1.6984197497367859, "alpha_loss": 0.0009803671855479479, "alpha_value": 0.009654413776966804, "duration": 5.099930763244629, "step": 219}
{"episode_reward": -4.305976257295191, "episode": 7.0, "batch_reward": -0.26112056771914166, "critic_loss": 0.00761015589038531, "ae_transition_loss": -1.913001815478007, "ae_encoder_loss": 0.033155192310611405, "actor_loss": 0.37366148829460144, "actor_target_entropy": -2.0, "actor_entropy": -1.6802966197331746, "alpha_loss": 0.0026270211286221943, "alpha_value": 0.009647778435249433, "duration": 4.958749771118164, "step": 243}
{"episode_reward": -4.894204551029094, "episode": 8.0, "batch_reward": -0.22508090734481812, "critic_loss": 0.00792256062850356, "ae_transition_loss": -1.9892643213272094, "ae_encoder_loss": 0.03036244697868824, "actor_loss": 0.36392284631729127, "actor_target_entropy": -2.0, "actor_entropy": -1.5734235286712646, "alpha_loss": 0.0030763063114136457, "alpha_value": 0.009638088757192449, "duration": 9.893666505813599, "step": 292}
{"episode_reward": -5.967493678973192, "episode": 9.0, "batch_reward": -0.19230905175209045, "critic_loss": 0.010375317186117172, "ae_transition_loss": -2.0221356323787143, "ae_encoder_loss": 0.022559770715555975, "actor_loss": 0.3564436307975224, "actor_target_entropy": -2.0, "actor_entropy": -1.8785909414291382, "alpha_loss": 0.00038596835968616815, "alpha_value": 0.009625263640010076, "duration": 14.726886510848999, "step": 366}
{"episode_reward": -6.872735445462127, "episode": 10.0, "batch_reward": -0.15886219143867492, "critic_loss": 0.008653209451586008, "ae_transition_loss": -2.2119991302490236, "ae_encoder_loss": 0.018561098165810107, "actor_loss": 0.36306309700012207, "actor_target_entropy": -2.0, "actor_entropy": -1.5476106643676757, "alpha_loss": 0.0026276808697730304, "alpha_value": 0.009616012727741534, "duration": 9.919894695281982, "step": 415}
{"episode_reward": -6.283760885497041, "episode": 11.0, "batch_reward": -0.17686161994934083, "critic_loss": 0.010213790275156499, "ae_transition_loss": -1.8882079601287842, "ae_encoder_loss": 0.024176956992596386, "actor_loss": 0.37184221148490904, "actor_target_entropy": -2.0, "actor_entropy": -1.1171126246452332, "alpha_loss": 0.006796510051935911, "alpha_value": 0.00960579312295555, "duration": 56.762454986572266, "step": 464}
{"episode_reward": -7.699277165935537, "episode": 12.0, "batch_reward": -0.15847023129463195, "critic_loss": 0.012147351074963808, "ae_transition_loss": -2.3012065410614015, "ae_encoder_loss": 0.01655083615332842, "actor_loss": 0.3831411600112915, "actor_target_entropy": -2.0, "actor_entropy": -1.718367099761963, "alpha_loss": 0.0018793641589581966, "alpha_value": 0.009589580390988508, "duration": 10.119496822357178, "step": 513}
{"episode_reward": -4.953870056210376, "episode": 13.0, "batch_reward": -0.14585124850273132, "critic_loss": 0.009246671246364713, "ae_transition_loss": -2.0023276090621946, "ae_encoder_loss": 0.019658115319907667, "actor_loss": 0.362816721200943, "actor_target_entropy": -2.0, "actor_entropy": -1.684322476387024, "alpha_loss": 0.0022998429369181393, "alpha_value": 0.009573872332238467, "duration": 10.366458177566528, "step": 562}
{"episode_reward": -3.806061720798834, "episode": 14.0, "batch_reward": -0.11949130594730377, "critic_loss": 0.014428135752677918, "ae_transition_loss": -2.0265359401702883, "ae_encoder_loss": 0.016052011400461197, "actor_loss": 0.3775829434394836, "actor_target_entropy": -2.0, "actor_entropy": -1.8279253959655761, "alpha_loss": 0.0005853546550497413, "alpha_value": 0.009560496595618183, "duration": 10.055729150772095, "step": 611}
{"episode_reward": -4.276638065533549, "episode": 15.0, "batch_reward": -0.1560043804347515, "critic_loss": 0.011722489260137081, "ae_transition_loss": -2.095906913280487, "ae_encoder_loss": 0.02020835690200329, "actor_loss": 0.3968736380338669, "actor_target_entropy": -2.0, "actor_entropy": -1.6766712665557861, "alpha_loss": 0.0028714729996863753, "alpha_value": 0.00955356989500155, "duration": 5.062767267227173, "step": 635}
{"episode_reward": -4.0453546352516465, "episode": 16.0, "batch_reward": -0.11293818801641464, "critic_loss": 0.01541566802188754, "ae_transition_loss": -1.968708336353302, "ae_encoder_loss": 0.012413785327225924, "actor_loss": 0.3720029145479202, "actor_target_entropy": -2.0, "actor_entropy": -1.4182140827178955, "alpha_loss": 0.0038195594679564238, "alpha_value": 0.00954990974001463, "duration": 5.027797222137451, "step": 659}
{"episode_reward": -2.7288318580176556, "episode": 17.0, "batch_reward": -0.1595149040222168, "critic_loss": 0.010210792689273754, "ae_transition_loss": -2.2234514554341636, "ae_encoder_loss": 0.026051472251613934, "actor_loss": 0.4030224184195201, "actor_target_entropy": -2.0, "actor_entropy": -1.3788413604100545, "alpha_loss": 0.004985181304315726, "alpha_value": 0.009544126185113662, "duration": 5.124583721160889, "step": 683}
{"episode_reward": -3.8926259639186602, "episode": 18.0, "batch_reward": -0.10526970028877258, "critic_loss": 0.012524524703621864, "ae_transition_loss": -2.3585071563720703, "ae_encoder_loss": 0.012051512952893972, "actor_loss": 0.3451506942510605, "actor_target_entropy": -2.0, "actor_entropy": -1.3419267535209656, "alpha_loss": 0.006360039347782731, "alpha_value": 0.009536888211495047, "duration": 5.031179666519165, "step": 707}
{"episode_reward": -2.36873858401842, "episode": 19.0, "batch_reward": -0.1098204106092453, "critic_loss": 0.007808714949836333, "ae_transition_loss": -2.4170384407043457, "ae_encoder_loss": 0.01127806530954937, "actor_loss": 0.38802728056907654, "actor_target_entropy": -2.0, "actor_entropy": -1.542370319366455, "alpha_loss": 0.003524534326667587, "alpha_value": 0.009527967095728562, "duration": 5.216501235961914, "step": 731}
{"episode_reward": -3.0326519938145364, "episode": 20.0, "batch_reward": -0.11064766719937325, "critic_loss": 0.007320311851799488, "ae_transition_loss": -2.3659502267837524, "ae_encoder_loss": 0.015226482413709164, "actor_loss": 0.33706724643707275, "actor_target_entropy": -2.0, "actor_entropy": -1.5154290199279785, "alpha_loss": 0.003567572683095932, "alpha_value": 0.009518875893233006, "duration": 4.915074110031128, "step": 755}
{"episode_reward": -2.4613207405915856, "episode": 21.0, "batch_reward": -0.12077078968286514, "critic_loss": 0.010409874375909567, "ae_transition_loss": -2.5067631006240845, "ae_encoder_loss": 0.007875584298744798, "actor_loss": 0.3953707069158554, "actor_target_entropy": -2.0, "actor_entropy": -1.5510284900665283, "alpha_loss": 0.002695939561817795, "alpha_value": 0.00951170721701391, "duration": 52.12763571739197, "step": 779}
{"episode_reward": -2.433019407650732, "episode": 22.0, "batch_reward": -0.10527267058690389, "critic_loss": 0.009096394293010235, "ae_transition_loss": -2.0994881788889566, "ae_encoder_loss": 0.012963409690807262, "actor_loss": 0.3617820342381795, "actor_target_entropy": -2.0, "actor_entropy": -1.7280457019805908, "alpha_loss": 0.0018606696394272149, "alpha_value": 0.009503015754929593, "duration": 5.150712966918945, "step": 804}
{"episode_reward": -1.8407971682596858, "episode": 23.0, "batch_reward": -0.11587909981608391, "critic_loss": 0.010821034200489521, "ae_transition_loss": -1.4229950308799744, "ae_encoder_loss": 0.013114097993820906, "actor_loss": 0.36468009650707245, "actor_target_entropy": -2.0, "actor_entropy": -2.1643600463867188, "alpha_loss": -0.0030087389750406146, "alpha_value": 0.00949534665991636, "duration": 5.004918098449707, "step": 828}
{"episode_reward": -3.1832906231788596, "episode": 24.0, "batch_reward": -0.09537239372730255, "critic_loss": 0.013999300387998423, "ae_transition_loss": -2.1646583875020347, "ae_encoder_loss": 0.005990242430319388, "actor_loss": 0.376634806394577, "actor_target_entropy": -2.0, "actor_entropy": -2.107651948928833, "alpha_loss": -0.002047959812140713, "alpha_value": 0.009490954669834526, "duration": 5.2988440990448, "step": 852}
{"episode_reward": -2.202928927293838, "episode": 25.0, "batch_reward": -0.09670891612768173, "critic_loss": 0.01067596986623747, "ae_transition_loss": -2.341458967753819, "ae_encoder_loss": 0.010396499985030718, "actor_loss": 0.34649157524108887, "actor_target_entropy": -2.0, "actor_entropy": -1.5144323791776384, "alpha_loss": 0.003327591610806329, "alpha_value": 0.00948494894533242, "duration": 15.128039836883545, "step": 926}
{"episode_reward": -4.815467351411815, "episode": 26.0, "batch_reward": -0.09414791688323021, "critic_loss": 0.007418877445161343, "ae_transition_loss": -2.5082030296325684, "ae_encoder_loss": 0.014158900128677487, "actor_loss": 0.40073545277118683, "actor_target_entropy": -2.0, "actor_entropy": -1.8293220400810242, "alpha_loss": 0.0015739806112833321, "alpha_value": 0.00947643959860341, "duration": 5.032503843307495, "step": 950}
{"episode_reward": -3.3159277525339443, "episode": 27.0, "batch_reward": -0.0951244334379832, "critic_loss": 0.006650019126633803, "ae_transition_loss": -2.436558485031128, "ae_encoder_loss": 0.00994496326893568, "actor_loss": 0.355309118827184, "actor_target_entropy": -2.0, "actor_entropy": -1.8850955963134766, "alpha_loss": 0.00078789455195268, "alpha_value": 0.009471312780187945, "duration": 5.35243034362793, "step": 974}
{"episode_reward": -2.343753187524389, "episode": 28.0, "batch_reward": -0.08320485055446625, "critic_loss": 0.008333512116223574, "ae_transition_loss": -2.280765473842621, "ae_encoder_loss": 0.00810329825617373, "actor_loss": 0.33420832455158234, "actor_target_entropy": -2.0, "actor_entropy": -1.6989635229110718, "alpha_loss": 0.002999638207256794, "alpha_value": 0.009466610061762429, "duration": 4.8714423179626465, "step": 998}
{"episode_reward": -2.3126813476648906, "episode": 29.0, "batch_reward": -0.09331647083163261, "critic_loss": 0.009501851443201304, "ae_transition_loss": -2.365244197845459, "ae_encoder_loss": 0.013079126970842481, "actor_loss": 0.35238046050071714, "actor_target_entropy": -2.0, "actor_entropy": -1.5045533418655395, "alpha_loss": 0.0037501007318496704, "alpha_value": 0.009458681441586122, "duration": 9.871487855911255, "step": 1047}
{"episode_reward": -4.059482447749648, "episode": 30.0, "batch_reward": -0.08699570099512736, "critic_loss": 0.010475379414856434, "ae_transition_loss": -2.6614155769348145, "ae_encoder_loss": 0.008137245080433786, "actor_loss": 0.35023807485898334, "actor_target_entropy": -2.0, "actor_entropy": -1.5371691385904949, "alpha_loss": 0.00392646505497396, "alpha_value": 0.00944757860465834, "duration": 5.209203243255615, "step": 1071}
{"episode_reward": -3.1063074307819485, "episode": 31.0, "duration": 42.15032696723938, "step": 1072}
{"episode_reward": -0.26405349132736655, "episode": 32.0, "batch_reward": -0.11076963692903519, "critic_loss": 0.009357109665870667, "ae_transition_loss": -1.9591701030731201, "ae_encoder_loss": 0.013714843429625034, "actor_loss": 0.3729633241891861, "actor_target_entropy": -2.0, "actor_entropy": -1.7497628331184387, "alpha_loss": 0.0009986710065277293, "alpha_value": 0.009439558740082277, "duration": 4.799931526184082, "step": 1096}
{"episode_reward": -1.2684814964066644, "episode": 33.0, "batch_reward": -0.09527470171451569, "critic_loss": 0.00458801444619894, "ae_transition_loss": -1.7826462388038635, "ae_encoder_loss": 0.010759057011455297, "actor_loss": 0.3507382571697235, "actor_target_entropy": -2.0, "actor_entropy": -1.7440962195396423, "alpha_loss": 0.0013293128431541845, "alpha_value": 0.009433626310760189, "duration": 4.691741943359375, "step": 1120}
{"episode_reward": -3.295540202285455, "episode": 34.0, "batch_reward": -0.08440126478672028, "critic_loss": 0.005549561651423574, "ae_transition_loss": -1.9653443574905396, "ae_encoder_loss": 0.010897859930992126, "actor_loss": 0.3459647178649902, "actor_target_entropy": -2.0, "actor_entropy": -1.543754768371582, "alpha_loss": 0.0024080862989649177, "alpha_value": 0.009424309134222732, "duration": 9.779727697372437, "step": 1169}
{"episode_reward": -3.6182279080576034, "episode": 35.0, "batch_reward": -0.06602261836330096, "critic_loss": 0.00827501326178511, "ae_transition_loss": -2.302239735921224, "ae_encoder_loss": 0.006499382633289012, "actor_loss": 0.330705205599467, "actor_target_entropy": -2.0, "actor_entropy": -1.4765246311823528, "alpha_loss": 0.003813751662770907, "alpha_value": 0.009413051841796945, "duration": 4.961878299713135, "step": 1193}
{"episode_reward": -2.0529087518211964, "episode": 36.0, "batch_reward": -0.09403610676527023, "critic_loss": 0.006827940419316292, "ae_transition_loss": -2.329668712615967, "ae_encoder_loss": 0.012611892900895327, "actor_loss": 0.35047307014465334, "actor_target_entropy": -2.0, "actor_entropy": -1.6480219125747682, "alpha_loss": 0.001967477489961311, "alpha_value": 0.00940056811355183, "duration": 10.157067775726318, "step": 1242}
{"episode_reward": -4.214643758267779, "episode": 37.0, "batch_reward": -0.10310382395982742, "critic_loss": 0.006876899395138025, "ae_transition_loss": -2.4305814504623413, "ae_encoder_loss": 0.012559293769299984, "actor_loss": 0.3457799553871155, "actor_target_entropy": -2.0, "actor_entropy": -1.7704460620880127, "alpha_loss": 0.0011386639234842733, "alpha_value": 0.009390417525883158, "duration": 4.888500213623047, "step": 1266}
{"episode_reward": -3.20313075052297, "episode": 38.0, "batch_reward": -0.08715790882706642, "critic_loss": 0.009438771288841963, "ae_transition_loss": -2.0298829674720764, "ae_encoder_loss": 0.017521418631076813, "actor_loss": 0.3320145756006241, "actor_target_entropy": -2.0, "actor_entropy": -1.8637428879737854, "alpha_loss": -0.0004356957506388426, "alpha_value": 0.009385257095314589, "duration": 4.959956884384155, "step": 1290}
{"episode_reward": -3.0752023079993576, "episode": 39.0, "batch_reward": -0.09339892367521922, "critic_loss": 0.005637328916539748, "ae_transition_loss": -2.02857236067454, "ae_encoder_loss": 0.011767674547930559, "actor_loss": 0.3526869515577952, "actor_target_entropy": -2.0, "actor_entropy": -1.798279603322347, "alpha_loss": 0.00129375575731198, "alpha_value": 0.00938003236439923, "duration": 4.9179346561431885, "step": 1314}
{"episode_reward": -2.9960036541751123, "episode": 40.0, "batch_reward": -0.07242265716195107, "critic_loss": 0.006078721256926656, "ae_transition_loss": -2.3480608463287354, "ae_encoder_loss": 0.00535773835144937, "actor_loss": 0.3422837108373642, "actor_target_entropy": -2.0, "actor_entropy": -1.7280457019805908, "alpha_loss": 0.0012187798274680972, "alpha_value": 0.009375260280689315, "duration": 4.805387258529663, "step": 1338}
{"episode_reward": -3.2440593179508004, "episode": 41.0, "batch_reward": -0.08226322382688522, "critic_loss": 0.007342242480566104, "ae_transition_loss": -2.3212504386901855, "ae_encoder_loss": 0.007520122143129508, "actor_loss": 0.346607764561971, "actor_target_entropy": -2.0, "actor_entropy": -1.628224531809489, "alpha_loss": 0.0008265067202349504, "alpha_value": 0.009371011049828857, "duration": 47.391053676605225, "step": 1362}
{"episode_reward": -4.1707338163390855, "episode": 42.0, "duration": 0.18247008323669434, "step": 1363}
{"episode_reward": -0.1600255724825557, "episode": 43.0, "duration": 0.21753191947937012, "step": 1364}
{"episode_reward": -0.9568127999726078, "episode": 44.0, "batch_reward": -0.07662255795938629, "critic_loss": 0.010692658168928964, "ae_transition_loss": -2.3727239881243025, "ae_encoder_loss": 0.007612153829541057, "actor_loss": 0.34884503909519743, "actor_target_entropy": -2.0, "actor_entropy": -1.326242446899414, "alpha_loss": 0.005083288298919797, "alpha_value": 0.009359837347308223, "duration": 14.832088947296143, "step": 1438}
{"episode_reward": -6.38524501026228, "episode": 45.0, "batch_reward": -0.07084789127111435, "critic_loss": 0.00835975476851066, "ae_transition_loss": -1.509627143541972, "ae_encoder_loss": 0.003366189368534833, "actor_loss": 0.3459539512793223, "actor_target_entropy": -2.0, "actor_entropy": -1.642572561899821, "alpha_loss": 0.002546620167170962, "alpha_value": 0.009341860942211346, "duration": 5.080911874771118, "step": 1462}
{"episode_reward": -2.5085486515927493, "episode": 46.0, "batch_reward": -0.06928353682160378, "critic_loss": 0.009440648928284645, "ae_transition_loss": -2.0266417503356933, "ae_encoder_loss": 0.006444986443966627, "actor_loss": 0.3324751853942871, "actor_target_entropy": -2.0, "actor_entropy": -1.4102965116500854, "alpha_loss": 0.004879289027303457, "alpha_value": 0.009326622631295339, "duration": 10.030365467071533, "step": 1511}
{"episode_reward": -3.5675554583055344, "episode": 47.0, "batch_reward": -0.07580108089106423, "critic_loss": 0.007461646970893655, "ae_transition_loss": -2.243485689163208, "ae_encoder_loss": 0.0066209361622376105, "actor_loss": 0.32916514362607685, "actor_target_entropy": -2.0, "actor_entropy": -1.3551286458969116, "alpha_loss": 0.004425319959409535, "alpha_value": 0.009297502184093037, "duration": 14.5440354347229, "step": 1585}
{"episode_reward": -6.030854139238103, "episode": 48.0, "batch_reward": -0.07285891100764275, "critic_loss": 0.007455934537574649, "ae_transition_loss": -2.385196805000305, "ae_encoder_loss": 0.008804391603916883, "actor_loss": 0.29586538672447205, "actor_target_entropy": -2.0, "actor_entropy": -1.5305640697479248, "alpha_loss": 0.00343251449521631, "alpha_value": 0.009273965212980677, "duration": 5.007871150970459, "step": 1609}
{"episode_reward": -4.020537622033437, "episode": 49.0, "batch_reward": -0.07944139589866002, "critic_loss": 0.0075954655185341835, "ae_transition_loss": -2.4210774103800454, "ae_encoder_loss": 0.008772477507591248, "actor_loss": 0.3336483637491862, "actor_target_entropy": -2.0, "actor_entropy": -1.4128062725067139, "alpha_loss": 0.003390013783549269, "alpha_value": 0.009262259113545912, "duration": 5.293749570846558, "step": 1633}
{"episode_reward": -2.9473115749956906, "episode": 50.0, "batch_reward": -0.0633871927857399, "critic_loss": 0.007085836259648204, "ae_transition_loss": -2.5499377250671387, "ae_encoder_loss": 0.005522997351363301, "actor_loss": 0.3119365721940994, "actor_target_entropy": -2.0, "actor_entropy": -1.566244661808014, "alpha_loss": 0.004317393759265542, "alpha_value": 0.009250629920485434, "duration": 5.109692573547363, "step": 1657}
{"episode_reward": -2.660262286212872, "episode": 51.0, "batch_reward": -0.07472279667854309, "critic_loss": 0.0059207660766939325, "ae_transition_loss": -2.6279966831207275, "ae_encoder_loss": 0.005301247108339642, "actor_loss": 0.3188345730304718, "actor_target_entropy": -2.0, "actor_entropy": -1.972133755683899, "alpha_loss": -0.0011182456898192565, "alpha_value": 0.009239257699986562, "duration": 43.3556854724884, "step": 1681}
{"episode_reward": -2.7256166233795946, "episode": 52.0, "duration": 0.1972489356994629, "step": 1682}
{"episode_reward": -0.2065199494635973, "episode": 53.0, "batch_reward": -0.08798898756504059, "critic_loss": 0.009038036689162254, "ae_transition_loss": -2.6165660619735718, "ae_encoder_loss": 0.010825529228895903, "actor_loss": 0.3376525342464447, "actor_target_entropy": -2.0, "actor_entropy": -1.9216381311416626, "alpha_loss": -5.273247370496392e-05, "alpha_value": 0.009230932815923392, "duration": 4.99847936630249, "step": 1706}
{"episode_reward": -3.1659908392384093, "episode": 54.0, "duration": 0.2197275161743164, "step": 1707}
{"episode_reward": -0.019114287570118904, "episode": 55.0, "batch_reward": -0.054580980290969215, "critic_loss": 0.006742409275223811, "ae_transition_loss": -1.9021345774332683, "ae_encoder_loss": 0.005790905716518561, "actor_loss": 0.3197366992632548, "actor_target_entropy": -2.0, "actor_entropy": -1.7865070104599, "alpha_loss": 0.0023047673360755048, "alpha_value": 0.009224585787772563, "duration": 5.392675161361694, "step": 1731}
{"episode_reward": -2.174677191650023, "episode": 56.0, "batch_reward": -0.06026618182659149, "critic_loss": 0.004467618535272777, "ae_transition_loss": -2.2003846168518066, "ae_encoder_loss": 0.002260812558233738, "actor_loss": 0.34205180406570435, "actor_target_entropy": -2.0, "actor_entropy": -1.8052439093589783, "alpha_loss": 0.0003509240341372788, "alpha_value": 0.009218200366517623, "duration": 4.939266204833984, "step": 1755}
{"episode_reward": -3.8135959302135967, "episode": 57.0, "batch_reward": -0.05921970680356026, "critic_loss": 0.008474433328956366, "ae_transition_loss": -2.4611541032791138, "ae_encoder_loss": 0.003369993413798511, "actor_loss": 0.3135867416858673, "actor_target_entropy": -2.0, "actor_entropy": -1.576685607433319, "alpha_loss": 0.0010733257804531604, "alpha_value": 0.009213696691409416, "duration": 5.083520889282227, "step": 1779}
{"episode_reward": -3.121229360589769, "episode": 58.0, "batch_reward": -0.08754522105058034, "critic_loss": 0.009591915179044008, "ae_transition_loss": -2.5636069774627686, "ae_encoder_loss": 0.014297548991938433, "actor_loss": 0.3251927097638448, "actor_target_entropy": -2.0, "actor_entropy": -1.2193618615468342, "alpha_loss": 0.003987946159516771, "alpha_value": 0.009208051578021093, "duration": 5.20568323135376, "step": 1803}
{"episode_reward": -4.04291648228676, "episode": 59.0, "batch_reward": -0.0768298365175724, "critic_loss": 0.007738953712396324, "ae_transition_loss": -2.5819941759109497, "ae_encoder_loss": 0.007455141967511736, "actor_loss": 0.32251212298870086, "actor_target_entropy": -2.0, "actor_entropy": -1.4508476853370667, "alpha_loss": 0.0038930349750444294, "alpha_value": 0.009185934537716725, "duration": 19.62214946746826, "step": 1902}
{"episode_reward": -6.008025403297236, "episode": 60.0, "batch_reward": -0.05860215611755848, "critic_loss": 0.0055520907044410706, "ae_transition_loss": -2.5963258743286133, "ae_encoder_loss": 0.00856045470573008, "actor_loss": 0.3304649889469147, "actor_target_entropy": -2.0, "actor_entropy": -1.1179859042167664, "alpha_loss": 0.004557900247164071, "alpha_value": 0.009162128224488607, "duration": 4.923567295074463, "step": 1926}
{"episode_reward": -3.232826281597775, "episode": 61.0, "batch_reward": -0.050810281187295914, "critic_loss": 0.008141943952068686, "ae_transition_loss": -2.7381597757339478, "ae_encoder_loss": 0.001641308408579789, "actor_loss": 0.3120836615562439, "actor_target_entropy": -2.0, "actor_entropy": -1.1614446640014648, "alpha_loss": 0.005262656137347221, "alpha_value": 0.009152729383819832, "duration": 42.928014039993286, "step": 1950}
{"episode_reward": -2.3764829577878275, "episode": 62.0, "batch_reward": -0.06900535399715106, "critic_loss": 0.008519760798662901, "ae_transition_loss": -2.804382801055908, "ae_encoder_loss": 0.007528454453373949, "actor_loss": 0.3280070622762044, "actor_target_entropy": -2.0, "actor_entropy": -1.6300193071365356, "alpha_loss": 0.0016736096004024148, "alpha_value": 0.009140160212233977, "duration": 5.102633953094482, "step": 1974}
{"episode_reward": -3.342782710755134, "episode": 63.0, "batch_reward": -0.06174887903034687, "critic_loss": 0.006262935232371092, "ae_transition_loss": -2.846290946006775, "ae_encoder_loss": 0.005116206117236288, "actor_loss": 0.3049558252096176, "actor_target_entropy": -2.0, "actor_entropy": -1.925558865070343, "alpha_loss": -0.00011466759315226227, "alpha_value": 0.009129094714431725, "duration": 4.920741081237793, "step": 1998}
{"episode_reward": -2.5473220945365034, "episode": 64.0, "batch_reward": -0.06946802064776421, "critic_loss": 0.004275796911679208, "ae_transition_loss": -2.7100522994995115, "ae_encoder_loss": 0.007541396608576179, "actor_loss": 0.32446030974388124, "actor_target_entropy": -2.0, "actor_entropy": -1.6307013034820557, "alpha_loss": 0.002593907807022333, "alpha_value": 0.009117144226827129, "duration": 9.771854639053345, "step": 2047}
{"episode_reward": -4.115993536161867, "episode": 65.0, "batch_reward": -0.061453609416882195, "critic_loss": 0.007613661388556163, "ae_transition_loss": -2.426485220591227, "ae_encoder_loss": 0.005777667819832762, "actor_loss": 0.3012181520462036, "actor_target_entropy": -2.0, "actor_entropy": -1.2848987579345703, "alpha_loss": 0.004090372084950407, "alpha_value": 0.009103269283754238, "duration": 5.181512355804443, "step": 2071}
{"episode_reward": -2.826091784490278, "episode": 66.0, "batch_reward": -0.04864948429167271, "critic_loss": 0.00721650430932641, "ae_transition_loss": -2.7792809009552, "ae_encoder_loss": 0.0045259865000844, "actor_loss": 0.34104759991168976, "actor_target_entropy": -2.0, "actor_entropy": -1.4322795867919922, "alpha_loss": 0.003391472273506224, "alpha_value": 0.009093272128223655, "duration": 4.754138946533203, "step": 2095}
{"episode_reward": -3.103773600537242, "episode": 67.0, "batch_reward": -0.0793716199696064, "critic_loss": 0.005891990847885609, "ae_transition_loss": -2.71082079410553, "ae_encoder_loss": 0.006469564585131593, "actor_loss": 0.29626530408859253, "actor_target_entropy": -2.0, "actor_entropy": -1.613037347793579, "alpha_loss": 0.002078310411889106, "alpha_value": 0.009085057692925808, "duration": 4.779738664627075, "step": 2119}
{"episode_reward": -2.4155273672490076, "episode": 68.0, "batch_reward": -0.044907725105683007, "critic_loss": 0.004343286816341181, "ae_transition_loss": -2.8054396311442056, "ae_encoder_loss": 0.0010114037516662695, "actor_loss": 0.31251753369967145, "actor_target_entropy": -2.0, "actor_entropy": -1.5241003433863323, "alpha_loss": 0.0023141054747005305, "alpha_value": 0.009075594029825653, "duration": 5.034686088562012, "step": 2143}
{"episode_reward": -2.524386013644265, "episode": 69.0, "batch_reward": -0.04934212006628513, "critic_loss": 0.005881511606276035, "ae_transition_loss": -2.862157702445984, "ae_encoder_loss": 0.004336701142165111, "actor_loss": 0.28872354328632355, "actor_target_entropy": -2.0, "actor_entropy": -1.2654310464859009, "alpha_loss": 0.003950852551497519, "alpha_value": 0.009066386455996975, "duration": 4.885096788406372, "step": 2167}
{"episode_reward": -2.9686363823182544, "episode": 70.0, "batch_reward": -0.06633192052443822, "critic_loss": 0.007052364914367597, "ae_transition_loss": -2.841110944747925, "ae_encoder_loss": 0.008868610486388206, "actor_loss": 0.30756670236587524, "actor_target_entropy": -2.0, "actor_entropy": -1.1251553297042847, "alpha_loss": 0.005219565083583196, "alpha_value": 0.009056162211576643, "duration": 5.181718826293945, "step": 2191}
{"episode_reward": -1.8859138145911325, "episode": 71.0, "batch_reward": -0.058091215789318085, "critic_loss": 0.008624627022072673, "ae_transition_loss": -2.7007606625556946, "ae_encoder_loss": 0.005507799670795066, "actor_loss": 0.30360381305217743, "actor_target_entropy": -2.0, "actor_entropy": -1.4324262142181396, "alpha_loss": 0.003536746895406395, "alpha_value": 0.009039289505392656, "duration": 51.86166477203369, "step": 2240}
{"episode_reward": -2.8597281059787973, "episode": 72.0, "batch_reward": -0.06270377114415168, "critic_loss": 0.007674943935126066, "ae_transition_loss": -2.6673912525177004, "ae_encoder_loss": 0.0054830288048833605, "actor_loss": 0.299347460269928, "actor_target_entropy": -2.0, "actor_entropy": -1.2281128764152527, "alpha_loss": 0.004623188404366374, "alpha_value": 0.009017455919424131, "duration": 9.71584963798523, "step": 2289}
{"episode_reward": -5.137869404421593, "episode": 73.0, "batch_reward": -0.06805757060647011, "critic_loss": 0.0071608129267891245, "ae_transition_loss": -2.6340221563975015, "ae_encoder_loss": 0.009262981669356426, "actor_loss": 0.32801828781763714, "actor_target_entropy": -2.0, "actor_entropy": -0.9054964383443197, "alpha_loss": 0.007540628003577392, "alpha_value": 0.00899612374507606, "duration": 5.239026069641113, "step": 2313}
{"episode_reward": -2.703114365841747, "episode": 74.0, "batch_reward": -0.03682496026158333, "critic_loss": 0.011261047795414925, "ae_transition_loss": -2.465479612350464, "ae_encoder_loss": 0.0006798893718951149, "actor_loss": 0.2731662690639496, "actor_target_entropy": -2.0, "actor_entropy": -1.2292692065238953, "alpha_loss": 0.005224853754043579, "alpha_value": 0.008979612508319652, "duration": 5.043999195098877, "step": 2337}
{"episode_reward": -3.250828161184437, "episode": 75.0, "batch_reward": -0.07364966198801995, "critic_loss": 0.008647742960602046, "ae_transition_loss": -2.4570858478546143, "ae_encoder_loss": 0.011620665807276965, "actor_loss": 0.29893157482147215, "actor_target_entropy": -2.0, "actor_entropy": -1.4049527883529662, "alpha_loss": 0.0046866308897733685, "alpha_value": 0.00895601095851013, "duration": 10.119928359985352, "step": 2386}
{"episode_reward": -4.153773909093794, "episode": 76.0, "batch_reward": -0.05917973071336746, "critic_loss": 0.004416344687342644, "ae_transition_loss": -2.515656590461731, "ae_encoder_loss": 0.005773460725322366, "actor_loss": 0.3102564364671707, "actor_target_entropy": -2.0, "actor_entropy": -1.278997540473938, "alpha_loss": 0.004934475990012288, "alpha_value": 0.008932812953298907, "duration": 5.031630039215088, "step": 2410}
{"episode_reward": -1.4150879651631867, "episode": 77.0, "batch_reward": -0.044766382314264774, "critic_loss": 0.007849552086554468, "ae_transition_loss": -2.5925267338752747, "ae_encoder_loss": 0.0020576982619786577, "actor_loss": 0.2855820022523403, "actor_target_entropy": -2.0, "actor_entropy": -1.3385591059923172, "alpha_loss": 0.004109963861992583, "alpha_value": 0.008899480758149662, "duration": 15.361402034759521, "step": 2484}
{"episode_reward": -4.890075270983392, "episode": 78.0, "batch_reward": -0.04584932327270508, "critic_loss": 0.00513881491497159, "ae_transition_loss": -2.601935625076294, "ae_encoder_loss": 0.0015500169392907992, "actor_loss": 0.2854432463645935, "actor_target_entropy": -2.0, "actor_entropy": -1.9085614681243896, "alpha_loss": -0.00010626818402670324, "alpha_value": 0.008868512784275698, "duration": 4.9623143672943115, "step": 2508}
{"episode_reward": -2.0540228149302013, "episode": 79.0, "batch_reward": -0.05526851341128349, "critic_loss": 0.006722950609400868, "ae_transition_loss": -2.3896864891052245, "ae_encoder_loss": 0.0042593816440785305, "actor_loss": 0.2821743369102478, "actor_target_entropy": -2.0, "actor_entropy": -1.7735501050949096, "alpha_loss": 0.0004341740859672427, "alpha_value": 0.008853875409250245, "duration": 10.139679193496704, "step": 2557}
{"episode_reward": -3.0789878276324596, "episode": 80.0, "batch_reward": -0.06258977800607682, "critic_loss": 0.004472157871350646, "ae_transition_loss": -2.7218743801116942, "ae_encoder_loss": 0.0073800074169412255, "actor_loss": 0.28631256222724916, "actor_target_entropy": -2.0, "actor_entropy": -1.270474648475647, "alpha_loss": 0.0030528641771525146, "alpha_value": 0.008836943366001085, "duration": 9.94778299331665, "step": 2606}
{"episode_reward": -2.731352893774608, "episode": 81.0, "batch_reward": -0.06369677931070328, "critic_loss": 0.007053906796500087, "ae_transition_loss": -2.3221999406814575, "ae_encoder_loss": 0.008646483067423105, "actor_loss": 0.28879182040691376, "actor_target_entropy": -2.0, "actor_entropy": -1.698231279850006, "alpha_loss": 0.00039551773807033896, "alpha_value": 0.008824732683863766, "duration": 47.44772219657898, "step": 2630}
{"episode_reward": -3.255460569257551, "episode": 82.0, "batch_reward": -0.05233236153920492, "critic_loss": 0.0034027414318795004, "ae_transition_loss": -2.7487191359202066, "ae_encoder_loss": 0.004775119966022127, "actor_loss": 0.2881981035073598, "actor_target_entropy": -2.0, "actor_entropy": -1.6210796038309734, "alpha_loss": 0.0011118090284677844, "alpha_value": 0.00881759134509001, "duration": 5.204020738601685, "step": 2654}
{"episode_reward": -2.999962236038187, "episode": 83.0, "batch_reward": -0.047298991680145265, "critic_loss": 0.00525677683763206, "ae_transition_loss": -2.8103450775146483, "ae_encoder_loss": 0.002282698031922337, "actor_loss": 0.28092814683914186, "actor_target_entropy": -2.0, "actor_entropy": -1.140435028076172, "alpha_loss": 0.004793152399361134, "alpha_value": 0.008805682837773658, "duration": 10.55757188796997, "step": 2703}
{"episode_reward": -4.398385975715054, "episode": 84.0, "batch_reward": -0.055671630427241325, "critic_loss": 0.0069775888696312904, "ae_transition_loss": -2.8997437953948975, "ae_encoder_loss": 0.004570187069475651, "actor_loss": 0.28062063455581665, "actor_target_entropy": -2.0, "actor_entropy": -1.37136971950531, "alpha_loss": 0.003114720690064132, "alpha_value": 0.008791671062898444, "duration": 5.097849607467651, "step": 2727}
{"episode_reward": -2.6483480858777777, "episode": 85.0, "batch_reward": -0.04193780447045962, "critic_loss": 0.004147030723591645, "ae_transition_loss": -2.7785772482554116, "ae_encoder_loss": 0.0005959737585120214, "actor_loss": 0.2841745416323344, "actor_target_entropy": -2.0, "actor_entropy": -1.5985489686330159, "alpha_loss": 0.0015072157936325918, "alpha_value": 0.008781129115000487, "duration": 5.334665298461914, "step": 2751}
{"episode_reward": -3.903808880363456, "episode": 86.0, "batch_reward": -0.07041264325380325, "critic_loss": 0.008234045002609491, "ae_transition_loss": -2.416839838027954, "ae_encoder_loss": 0.01188460597768426, "actor_loss": 0.24885421991348267, "actor_target_entropy": -2.0, "actor_entropy": -1.67275071144104, "alpha_loss": 0.00028241361724212766, "alpha_value": 0.008771666406940966, "duration": 4.98885703086853, "step": 2775}
{"episode_reward": -2.0187968103994764, "episode": 87.0, "duration": 0.22373580932617188, "step": 2776}
{"episode_reward": -1.0263970959894024, "episode": 88.0, "duration": 0.22024059295654297, "step": 2777}
{"episode_reward": -1.2919966238233647, "episode": 89.0, "batch_reward": -0.03893545518318812, "critic_loss": 0.006328233362485965, "ae_transition_loss": -2.7000250021616616, "ae_encoder_loss": 0.0006618482014649393, "actor_loss": 0.2950520118077596, "actor_target_entropy": -2.0, "actor_entropy": -1.5862133900324504, "alpha_loss": 8.951404985661308e-05, "alpha_value": 0.008764256293865338, "duration": 5.44757866859436, "step": 2801}
{"episode_reward": -2.8682329017360333, "episode": 90.0, "duration": 0.19977903366088867, "step": 2802}
{"episode_reward": -0.6135005558610965, "episode": 91.0, "batch_reward": -0.05956418253481388, "critic_loss": 0.0034290474141016603, "ae_transition_loss": -2.8380995988845825, "ae_encoder_loss": 0.00381289841607213, "actor_loss": 0.2667624354362488, "actor_target_entropy": -2.0, "actor_entropy": -1.4723982214927673, "alpha_loss": 0.0010408989037387073, "alpha_value": 0.008758304186750547, "duration": 53.03987169265747, "step": 2826}
{"episode_reward": -3.0385300179901806, "episode": 92.0, "batch_reward": -0.046858424320816994, "critic_loss": 0.006397896446287632, "ae_transition_loss": -2.828684687614441, "ae_encoder_loss": 0.00302305756486021, "actor_loss": 0.28482596576213837, "actor_target_entropy": -2.0, "actor_entropy": -1.5962011814117432, "alpha_loss": 0.002090222726110369, "alpha_value": 0.008753863608952965, "duration": 5.115908145904541, "step": 2850}
{"episode_reward": -1.839275452037631, "episode": 93.0, "batch_reward": -0.048264291137456894, "critic_loss": 0.0036716224276460707, "ae_transition_loss": -2.823850631713867, "ae_encoder_loss": 0.003967980631159662, "actor_loss": 0.2828795053064823, "actor_target_entropy": -2.0, "actor_entropy": -1.7675385177135468, "alpha_loss": -4.789379636349622e-05, "alpha_value": 0.00874499318446543, "duration": 15.080623865127563, "step": 2924}
{"episode_reward": -3.071445993578594, "episode": 94.0, "batch_reward": -0.0429663147777319, "critic_loss": 0.005155044980347157, "ae_transition_loss": -2.7159119129180906, "ae_encoder_loss": 0.0018962756599648855, "actor_loss": 0.2753386378288269, "actor_target_entropy": -2.0, "actor_entropy": -0.9877088189125061, "alpha_loss": 0.00488876448944211, "alpha_value": 0.008735794332781984, "duration": 10.294444561004639, "step": 2973}
{"episode_reward": -3.075373922198683, "episode": 95.0, "duration": 0.2045750617980957, "step": 2974}
{"episode_reward": -0.3883548493095206, "episode": 96.0, "batch_reward": -0.0440932922065258, "critic_loss": 0.004599716980010271, "ae_transition_loss": -2.7099510431289673, "ae_encoder_loss": 0.0012981009012946743, "actor_loss": 0.28411106765270233, "actor_target_entropy": -2.0, "actor_entropy": -1.3118573427200317, "alpha_loss": 0.004265590221621096, "alpha_value": 0.008725123709086976, "duration": 5.039529800415039, "step": 2998}
{"episode_reward": -1.1352009358309145, "episode": 97.0, "batch_reward": -0.04522431890169779, "critic_loss": 0.005395019038890799, "ae_transition_loss": -2.812213102976481, "ae_encoder_loss": 0.001031649186188588, "actor_loss": 0.26419977347056073, "actor_target_entropy": -2.0, "actor_entropy": -1.623495062192281, "alpha_loss": 0.0011239843637061615, "alpha_value": 0.008715278684829216, "duration": 5.050409317016602, "step": 3022}
{"episode_reward": -3.0319973213656044, "episode": 98.0, "batch_reward": -0.04266137257218361, "critic_loss": 0.003030169173143804, "ae_transition_loss": -2.818947672843933, "ae_encoder_loss": 0.0010594416817184538, "actor_loss": 0.29453714191913605, "actor_target_entropy": -2.0, "actor_entropy": -1.5271022319793701, "alpha_loss": 0.0019736820831894875, "alpha_value": 0.008706566290974417, "duration": 4.868990421295166, "step": 3046}
{"episode_reward": -2.588133845997734, "episode": 99.0, "batch_reward": -0.060307618230581284, "critic_loss": 0.0038504997501149774, "ae_transition_loss": -2.88251793384552, "ae_encoder_loss": 0.004207156700431369, "actor_loss": 0.2642640769481659, "actor_target_entropy": -2.0, "actor_entropy": -1.133683204650879, "alpha_loss": 0.0038361281622201204, "alpha_value": 0.008699968090987307, "duration": 4.787884712219238, "step": 3070}
{"episode_reward": -3.1682392050193537, "episode": 100.0, "batch_reward": -0.039318982511758804, "critic_loss": 0.003459385751436154, "ae_transition_loss": -2.858938376108805, "ae_encoder_loss": 0.0018253577794287896, "actor_loss": 0.2864678005377452, "actor_target_entropy": -2.0, "actor_entropy": -0.8595358530680338, "alpha_loss": 0.005263399953643481, "alpha_value": 0.008690394190452129, "duration": 4.82160210609436, "step": 3094}
{"episode_reward": -2.9687976574408745, "episode": 101.0, "batch_reward": -0.03882945887744427, "critic_loss": 0.00750915496610105, "ae_transition_loss": -2.895216226577759, "ae_encoder_loss": 0.0013414097847999074, "actor_loss": 0.24938495457172394, "actor_target_entropy": -2.0, "actor_entropy": -1.0161810517311096, "alpha_loss": 0.003356772824190557, "alpha_value": 0.00867892616052179, "duration": 47.94456934928894, "step": 3118}
{"episode_reward": -2.677806229337905, "episode": 102.0, "batch_reward": -0.03939265261093775, "critic_loss": 0.007669943384826183, "ae_transition_loss": -2.8569584687550864, "ae_encoder_loss": 0.0011404225770093035, "actor_loss": 0.2727954387664795, "actor_target_entropy": -2.0, "actor_entropy": -1.30508553981781, "alpha_loss": 0.0025582624754558005, "alpha_value": 0.008667007692394051, "duration": 5.199671506881714, "step": 3142}
{"episode_reward": -3.013044345647188, "episode": 103.0, "batch_reward": -0.0650910884141922, "critic_loss": 0.004301217617467046, "ae_transition_loss": -2.8824942111968994, "ae_encoder_loss": 0.010996800847351551, "actor_loss": 0.2592290937900543, "actor_target_entropy": -2.0, "actor_entropy": -1.4956207871437073, "alpha_loss": 0.0013016879674978554, "alpha_value": 0.008655715069638078, "duration": 5.05389928817749, "step": 3166}
{"episode_reward": -3.425155232966715, "episode": 104.0, "duration": 0.21924805641174316, "step": 3167}
{"episode_reward": -0.09379116917180164, "episode": 105.0, "batch_reward": -0.031458377838134766, "critic_loss": 0.0056425100192427635, "ae_transition_loss": -2.9039371808369956, "ae_encoder_loss": 0.0003788820061648342, "actor_loss": 0.264958788951238, "actor_target_entropy": -2.0, "actor_entropy": -1.482338786125183, "alpha_loss": 0.002048152770536641, "alpha_value": 0.008645790795272428, "duration": 5.29978084564209, "step": 3191}
{"episode_reward": -2.0819495410833957, "episode": 106.0, "batch_reward": -0.03749910369515419, "critic_loss": 0.007002396741881967, "ae_transition_loss": -2.8228607177734375, "ae_encoder_loss": 0.0028695953624264803, "actor_loss": 0.2586360573768616, "actor_target_entropy": -2.0, "actor_entropy": -1.4453790783882141, "alpha_loss": 0.0022479805629700422, "alpha_value": 0.008636405213982887, "duration": 4.787771463394165, "step": 3215}
{"episode_reward": -3.590180891750681, "episode": 107.0, "batch_reward": -0.04665176756680012, "critic_loss": 0.004096115822903812, "ae_transition_loss": -2.578284978866577, "ae_encoder_loss": 0.0011594282696023583, "actor_loss": 0.28696319460868835, "actor_target_entropy": -2.0, "actor_entropy": -1.3889027833938599, "alpha_loss": 0.00137507967883721, "alpha_value": 0.008629127216577116, "duration": 4.875709533691406, "step": 3239}
{"episode_reward": -3.1999489026784387, "episode": 108.0, "batch_reward": -0.04360930770635605, "critic_loss": 0.004889194387942553, "ae_transition_loss": -2.772737216949463, "ae_encoder_loss": 0.0023201887281175003, "actor_loss": 0.26971948742866514, "actor_target_entropy": -2.0, "actor_entropy": -1.411000633239746, "alpha_loss": 0.002404456492513418, "alpha_value": 0.008617347168152484, "duration": 9.599968194961548, "step": 3288}
{"episode_reward": -4.3322858108123485, "episode": 109.0, "batch_reward": -0.029122749343514442, "critic_loss": 0.0037338363472372293, "ae_transition_loss": -2.919519821802775, "ae_encoder_loss": 2.538109462572417e-05, "actor_loss": 0.26183916131655377, "actor_target_entropy": -2.0, "actor_entropy": -1.4686034520467122, "alpha_loss": 0.0011994581048687298, "alpha_value": 0.008603804529335108, "duration": 4.972179889678955, "step": 3312}
{"episode_reward": -2.2279683558322794, "episode": 110.0, "batch_reward": -0.04241247475147247, "critic_loss": 0.0029089987510815263, "ae_transition_loss": -2.9279955625534058, "ae_encoder_loss": 0.001110768469516188, "actor_loss": 0.2854594886302948, "actor_target_entropy": -2.0, "actor_entropy": -1.4739784002304077, "alpha_loss": 0.0011870356393046677, "alpha_value": 0.008596087248712513, "duration": 4.843564748764038, "step": 3336}
{"episode_reward": -4.539225164022719, "episode": 111.0, "batch_reward": -0.05651488602161407, "critic_loss": 0.004228007257916033, "ae_transition_loss": -2.905183792114258, "ae_encoder_loss": 0.005297250536023057, "actor_loss": 0.27093291878700254, "actor_target_entropy": -2.0, "actor_entropy": -1.404003667831421, "alpha_loss": 0.0017068388289771975, "alpha_value": 0.008586407238325757, "duration": 56.74374556541443, "step": 3385}
{"episode_reward": -3.0679237544186733, "episode": 112.0, "batch_reward": -0.03325159288942814, "critic_loss": 0.0045749080600216985, "ae_transition_loss": -2.835886240005493, "ae_encoder_loss": 0.0022116617365099955, "actor_loss": 0.2537132352590561, "actor_target_entropy": -2.0, "actor_entropy": -1.0775744915008545, "alpha_loss": 0.003958799177780747, "alpha_value": 0.008576834648970222, "duration": 5.067877292633057, "step": 3409}
{"episode_reward": -2.5163581399356456, "episode": 113.0, "batch_reward": -0.057175094882647194, "critic_loss": 0.003656557993963361, "ae_transition_loss": -2.9204982121785483, "ae_encoder_loss": 0.008751078819235166, "actor_loss": 0.27000181873639423, "actor_target_entropy": -2.0, "actor_entropy": -1.2516562938690186, "alpha_loss": 0.004798228930061062, "alpha_value": 0.008568434740874917, "duration": 4.932723522186279, "step": 3433}
{"episode_reward": -3.4395470361181406, "episode": 114.0, "batch_reward": -0.05122427232563496, "critic_loss": 0.005690380232408643, "ae_transition_loss": -3.019303035736084, "ae_encoder_loss": 0.005729248642455787, "actor_loss": 0.2657772660255432, "actor_target_entropy": -2.0, "actor_entropy": -1.6354330778121948, "alpha_loss": 0.0017518946551717818, "alpha_value": 0.008552333410522597, "duration": 10.09552264213562, "step": 3482}
{"episode_reward": -3.2396296546331205, "episode": 115.0, "batch_reward": -0.03422818426042795, "critic_loss": 0.0054313677828758955, "ae_transition_loss": -2.711259126663208, "ae_encoder_loss": 0.0034032559087791014, "actor_loss": 0.2721537947654724, "actor_target_entropy": -2.0, "actor_entropy": -1.4418952465057373, "alpha_loss": 0.001182555701234378, "alpha_value": 0.008539152941710931, "duration": 4.906958103179932, "step": 3506}
{"episode_reward": -3.553562667567409, "episode": 116.0, "batch_reward": -0.04098057933151722, "critic_loss": 0.006403770996257663, "ae_transition_loss": -2.800174188613892, "ae_encoder_loss": 0.00405169302084687, "actor_loss": 0.28911563456058503, "actor_target_entropy": -2.0, "actor_entropy": -0.8856056928634644, "alpha_loss": 0.003434664523229003, "alpha_value": 0.008526742707362794, "duration": 9.791718006134033, "step": 3555}
{"episode_reward": -4.89052881631334, "episode": 117.0, "batch_reward": -0.05374837480485439, "critic_loss": 0.011475951177999377, "ae_transition_loss": -2.877600908279419, "ae_encoder_loss": 0.0026620455901138484, "actor_loss": 0.2626658231019974, "actor_target_entropy": -2.0, "actor_entropy": -1.2319297194480896, "alpha_loss": 0.0036665869411081076, "alpha_value": 0.008512878977822994, "duration": 4.811855316162109, "step": 3579}
{"episode_reward": -2.4992648081707087, "episode": 118.0, "batch_reward": -0.049020770192146304, "critic_loss": 0.007250394020229578, "ae_transition_loss": -2.976111078262329, "ae_encoder_loss": 0.006001070558340871, "actor_loss": 0.2879615664482117, "actor_target_entropy": -2.0, "actor_entropy": -0.7924407035112381, "alpha_loss": 0.00495607047341764, "alpha_value": 0.008496518970737577, "duration": 9.687922954559326, "step": 3628}
{"episode_reward": -3.477668451390365, "episode": 119.0, "batch_reward": -0.03781061470508575, "critic_loss": 0.007210550783202052, "ae_transition_loss": -2.937680983543396, "ae_encoder_loss": 0.0015402995984914014, "actor_loss": 0.2770352244377136, "actor_target_entropy": -2.0, "actor_entropy": -1.0116314262151718, "alpha_loss": 0.004154718026984483, "alpha_value": 0.008456754333815977, "duration": 19.406400442123413, "step": 3727}
{"episode_reward": -6.588815565454909, "episode": 120.0, "batch_reward": -0.050900384038686755, "critic_loss": 0.007334972359240055, "ae_transition_loss": -2.884280490875244, "ae_encoder_loss": 0.005661265177332097, "actor_loss": 0.27956215143203733, "actor_target_entropy": -2.0, "actor_entropy": -0.6613660275936126, "alpha_loss": 0.00789679428562522, "alpha_value": 0.008411222275950102, "duration": 9.951393365859985, "step": 3776}
{"episode_reward": -2.8035473645894586, "episode": 121.0, "batch_reward": -0.03563355654478073, "critic_loss": 0.00509223248809576, "ae_transition_loss": -2.8936585187911987, "ae_encoder_loss": 0.0008732242913538357, "actor_loss": 0.2726464718580246, "actor_target_entropy": -2.0, "actor_entropy": -1.1379902958869934, "alpha_loss": 0.004104109015315771, "alpha_value": 0.00838337032541633, "duration": 48.79364252090454, "step": 3800}
{"episode_reward": -1.7208202324247406, "episode": 122.0, "batch_reward": -0.03805577754974365, "critic_loss": 0.0034186565317213535, "ae_transition_loss": -2.768509864807129, "ae_encoder_loss": 0.005230944603681564, "actor_loss": 0.25875723361968994, "actor_target_entropy": -2.0, "actor_entropy": -1.0925897359848022, "alpha_loss": 0.006726144813001156, "alpha_value": 0.008370869029999195, "duration": 0.5304913520812988, "step": 3801}
{"episode_reward": -0.48824387788772583, "episode": 123.0, "batch_reward": -0.033892794512212276, "critic_loss": 0.005506415385752916, "ae_transition_loss": -2.8678590059280396, "ae_encoder_loss": 0.0005068626905995188, "actor_loss": 0.25905656814575195, "actor_target_entropy": -2.0, "actor_entropy": -0.7836733162403107, "alpha_loss": 0.0061310764867812395, "alpha_value": 0.008358345966847692, "duration": 5.032945156097412, "step": 3825}
{"episode_reward": -2.6640994158237326, "episode": 124.0, "batch_reward": -0.03057675715535879, "critic_loss": 0.005719107575714588, "ae_transition_loss": -2.8135318756103516, "ae_encoder_loss": 0.002051561152256909, "actor_loss": 0.25937478244304657, "actor_target_entropy": -2.0, "actor_entropy": -0.6294980645179749, "alpha_loss": 0.006154779810458422, "alpha_value": 0.008341493617731916, "duration": 5.031692266464233, "step": 3849}
{"episode_reward": -3.549386197594814, "episode": 125.0, "duration": 0.219588041305542, "step": 3850}
{"episode_reward": -0.22725825733463662, "episode": 126.0, "batch_reward": -0.051961500197649, "critic_loss": 0.005156723161538442, "ae_transition_loss": -2.8260260423024497, "ae_encoder_loss": 0.0035981867088897466, "actor_loss": 0.2633068263530731, "actor_target_entropy": -2.0, "actor_entropy": -1.109140674273173, "alpha_loss": 0.0027230453367034593, "alpha_value": 0.008320763017063295, "duration": 5.216031789779663, "step": 3874}
{"episode_reward": -3.242476354764744, "episode": 127.0, "batch_reward": -0.03735079589698996, "critic_loss": 0.003907383253265705, "ae_transition_loss": -3.001575469970703, "ae_encoder_loss": 0.001986043327113813, "actor_loss": 0.261285628591265, "actor_target_entropy": -2.0, "actor_entropy": -1.14409111227308, "alpha_loss": 0.003145909053273499, "alpha_value": 0.008284478229721035, "duration": 15.091859340667725, "step": 3948}
{"episode_reward": -3.8047574188381796, "episode": 128.0, "batch_reward": -0.04993363469839096, "critic_loss": 0.003951172227971256, "ae_transition_loss": -3.0883323351542153, "ae_encoder_loss": 0.0033467383667205772, "actor_loss": 0.2756493389606476, "actor_target_entropy": -2.0, "actor_entropy": -1.5509783426920574, "alpha_loss": 0.0008355365425813943, "alpha_value": 0.008254072872962573, "duration": 5.145850658416748, "step": 3972}
{"episode_reward": -3.3760511883788067, "episode": 129.0, "batch_reward": -0.04290176369249821, "critic_loss": 0.004423809936270118, "ae_transition_loss": -3.196731686592102, "ae_encoder_loss": 0.001390934032315272, "actor_loss": 0.260025292634964, "actor_target_entropy": -2.0, "actor_entropy": -1.6294596195220947, "alpha_loss": 4.793799598701298e-05, "alpha_value": 0.00824240449715163, "duration": 4.948088645935059, "step": 3996}
{"episode_reward": -2.6206030630048405, "episode": 130.0, "batch_reward": -0.03718538582324982, "critic_loss": 0.004462650045752525, "ae_transition_loss": -3.1790409088134766, "ae_encoder_loss": 0.001489377289544791, "actor_loss": 0.25519928336143494, "actor_target_entropy": -2.0, "actor_entropy": -1.5017037391662598, "alpha_loss": 9.08596302906517e-05, "alpha_value": 0.00823487682693943, "duration": 5.2173988819122314, "step": 4020}
{"episode_reward": -2.6824132165231833, "episode": 131.0, "batch_reward": -0.04027630132623017, "critic_loss": 0.005046815174864605, "ae_transition_loss": -2.46893148124218, "ae_encoder_loss": 0.0033536945720697986, "actor_loss": 0.2573797535151243, "actor_target_entropy": -2.0, "actor_entropy": -1.3233138769865036, "alpha_loss": 0.002345271554077044, "alpha_value": 0.00821873001357776, "duration": 44.263471364974976, "step": 4094}
{"episode_reward": -5.241970734725583, "episode": 132.0, "batch_reward": -0.03983335383236408, "critic_loss": 0.008566818432882428, "ae_transition_loss": -2.4933871030807495, "ae_encoder_loss": 0.00315700095052307, "actor_loss": 0.2677938640117645, "actor_target_entropy": -2.0, "actor_entropy": -1.2831941843032837, "alpha_loss": 0.0021240757778286934, "alpha_value": 0.008202053922152452, "duration": 4.896259069442749, "step": 4118}
{"episode_reward": -3.7214564131221635, "episode": 133.0, "batch_reward": -0.04249009738365809, "critic_loss": 0.004588777975489696, "ae_transition_loss": -2.2488315105438232, "ae_encoder_loss": 0.0057581554671439035, "actor_loss": 0.25585641463597614, "actor_target_entropy": -2.0, "actor_entropy": -1.0561333497365315, "alpha_loss": 0.0029993917948255935, "alpha_value": 0.00819391827490406, "duration": 5.1561279296875, "step": 4142}
{"episode_reward": -2.4741422627787415, "episode": 134.0, "batch_reward": -0.02446296066045761, "critic_loss": 0.004330172901973128, "ae_transition_loss": -2.2000561952590942, "ae_encoder_loss": 0.00013863832282368094, "actor_loss": 0.25658464431762695, "actor_target_entropy": -2.0, "actor_entropy": -1.053578495979309, "alpha_loss": 0.00407211238052696, "alpha_value": 0.008185158867486282, "duration": 4.803355932235718, "step": 4166}
{"episode_reward": -2.517932323371928, "episode": 135.0, "batch_reward": -0.0323010440915823, "critic_loss": 0.0028023546328768134, "ae_transition_loss": -2.126138925552368, "ae_encoder_loss": 0.0003679469919006806, "actor_loss": 0.2515987157821655, "actor_target_entropy": -2.0, "actor_entropy": -1.0897683501243591, "alpha_loss": 0.005655364599078894, "alpha_value": 0.008176944928098492, "duration": 4.899864435195923, "step": 4190}
{"episode_reward": -2.496979664902188, "episode": 136.0, "batch_reward": -0.032116467133164406, "critic_loss": 0.005493381371100743, "ae_transition_loss": -2.280316193898519, "ae_encoder_loss": 0.002369149908190593, "actor_loss": 0.24930253624916077, "actor_target_entropy": -2.0, "actor_entropy": -1.0053515434265137, "alpha_loss": 0.004659933503717184, "alpha_value": 0.008164635489248161, "duration": 5.1063621044158936, "step": 4214}
{"episode_reward": -1.5516577517114594, "episode": 137.0, "batch_reward": -0.03529974818229675, "critic_loss": 0.005521469051018357, "ae_transition_loss": -2.3536739349365234, "ae_encoder_loss": 0.0008885508505045436, "actor_loss": 0.2547088712453842, "actor_target_entropy": -2.0, "actor_entropy": -0.9707403779029846, "alpha_loss": 0.004946782253682613, "alpha_value": 0.00815114292476564, "duration": 4.917223215103149, "step": 4238}
{"episode_reward": -3.3271047820906317, "episode": 138.0, "batch_reward": -0.05016851673523585, "critic_loss": 0.004839157996078332, "ae_transition_loss": -2.4241095383961997, "ae_encoder_loss": 0.005307250268136461, "actor_loss": 0.2571369707584381, "actor_target_entropy": -2.0, "actor_entropy": -1.065297524134318, "alpha_loss": 0.004515131625036399, "alpha_value": 0.008136555630460972, "duration": 5.050754547119141, "step": 4262}
{"episode_reward": -3.5276848864641437, "episode": 139.0, "batch_reward": -0.04041336476802826, "critic_loss": 0.0064523061737418175, "ae_transition_loss": -2.4278502464294434, "ae_encoder_loss": 0.004117534714168869, "actor_loss": 0.2504886984825134, "actor_target_entropy": -2.0, "actor_entropy": -1.0484290719032288, "alpha_loss": 0.0043259336380288005, "alpha_value": 0.008121583814924392, "duration": 4.8728179931640625, "step": 4286}
{"episode_reward": -3.0410621981916917, "episode": 140.0, "batch_reward": -0.04109732620418072, "critic_loss": 0.004205411672592163, "ae_transition_loss": -2.4855719089508055, "ae_encoder_loss": 0.0018224364845082163, "actor_loss": 0.2595147848129272, "actor_target_entropy": -2.0, "actor_entropy": -1.2710203647613525, "alpha_loss": 0.0038728078361600637, "alpha_value": 0.008099670746958675, "duration": 10.039774894714355, "step": 4335}
{"episode_reward": -3.8574745296548154, "episode": 141.0, "batch_reward": -0.04615956507623196, "critic_loss": 0.005977787543088198, "ae_transition_loss": -1.9039992332458495, "ae_encoder_loss": 0.00540923792286776, "actor_loss": 0.2677884131669998, "actor_target_entropy": -2.0, "actor_entropy": -1.3980462074279785, "alpha_loss": 0.0019233135972172022, "alpha_value": 0.00807049374976235, "duration": 52.68031644821167, "step": 4384}
{"episode_reward": -3.479334644106139, "episode": 142.0, "batch_reward": -0.03671136498451233, "critic_loss": 0.026057136245071888, "ae_transition_loss": -1.1847719848155975, "ae_encoder_loss": 0.0017046089051291347, "actor_loss": 0.2789001539349556, "actor_target_entropy": -2.0, "actor_entropy": -1.3491621017456055, "alpha_loss": 0.003102162154391408, "alpha_value": 0.008053315788954466, "duration": 4.903043031692505, "step": 4408}
{"episode_reward": -2.3510741198115634, "episode": 143.0, "batch_reward": -0.04389673620462418, "critic_loss": 0.027536237612366676, "ae_transition_loss": -0.9183451890945434, "ae_encoder_loss": 0.004214021540246904, "actor_loss": 0.25851869881153106, "actor_target_entropy": -2.0, "actor_entropy": -1.1674816131591796, "alpha_loss": 0.003714817063882947, "alpha_value": 0.008037643744775318, "duration": 9.771731615066528, "step": 4457}
{"episode_reward": -3.885660186082584, "episode": 144.0, "batch_reward": -0.04590548276901245, "critic_loss": 0.012648088298738003, "ae_transition_loss": -1.8271668195724486, "ae_encoder_loss": 0.004758365399902686, "actor_loss": 0.2724754959344864, "actor_target_entropy": -2.0, "actor_entropy": -0.5010289669036865, "alpha_loss": 0.007028063945472241, "alpha_value": 0.008011395453193917, "duration": 9.935684442520142, "step": 4506}
{"episode_reward": -2.6117576975166332, "episode": 145.0, "duration": 0.23139643669128418, "step": 4507}
{"episode_reward": 0.049800388065872614, "episode": 146.0, "batch_reward": -0.03323361277580261, "critic_loss": 0.006954860718299945, "ae_transition_loss": -1.8542555173238118, "ae_encoder_loss": 0.0015722694467209901, "actor_loss": 0.25825680295626324, "actor_target_entropy": -2.0, "actor_entropy": -0.7685389717419943, "alpha_loss": 0.007263267723222573, "alpha_value": 0.007983514787184244, "duration": 5.302040100097656, "step": 4531}
{"episode_reward": -1.6259544939652246, "episode": 147.0, "batch_reward": -0.030064912512898445, "critic_loss": 0.006747074890881777, "ae_transition_loss": -1.9910537004470825, "ae_encoder_loss": 0.00022167110728332773, "actor_loss": 0.27288857102394104, "actor_target_entropy": -2.0, "actor_entropy": -0.5941724479198456, "alpha_loss": 0.007652976317331195, "alpha_value": 0.007963443770180028, "duration": 4.665891885757446, "step": 4555}
{"episode_reward": -4.334100683707153, "episode": 148.0, "batch_reward": -0.05405941605567932, "critic_loss": 0.01104738051071763, "ae_transition_loss": -2.093960404396057, "ae_encoder_loss": 0.006168596912175417, "actor_loss": 0.25557124614715576, "actor_target_entropy": -2.0, "actor_entropy": -0.36110055446624756, "alpha_loss": 0.009533192496746778, "alpha_value": 0.007945869547384792, "duration": 4.869041919708252, "step": 4579}
{"episode_reward": -3.1434513348101043, "episode": 149.0, "batch_reward": -0.034141836067040764, "critic_loss": 0.008548787329345942, "ae_transition_loss": -2.2299036979675293, "ae_encoder_loss": 0.00026791219230896485, "actor_loss": 0.23554271956284842, "actor_target_entropy": -2.0, "actor_entropy": -0.9231308102607727, "alpha_loss": 0.00708086509257555, "alpha_value": 0.007921673076158375, "duration": 5.103631258010864, "step": 4603}
{"episode_reward": -3.483061183392096, "episode": 150.0, "batch_reward": -0.031606617383658886, "critic_loss": 0.006378880934789777, "ae_transition_loss": -2.4144145250320435, "ae_encoder_loss": 0.00025808940699789673, "actor_loss": 0.27705132961273193, "actor_target_entropy": -2.0, "actor_entropy": -1.0985822677612305, "alpha_loss": 0.005014842841774225, "alpha_value": 0.007897369255725074, "duration": 4.762912750244141, "step": 4627}
{"episode_reward": -2.9094782695944525, "episode": 151.0, "batch_reward": -0.04522470633188883, "critic_loss": 0.00661540466050307, "ae_transition_loss": -2.4916770458221436, "ae_encoder_loss": 0.0051666695314149065, "actor_loss": 0.22199400266011557, "actor_target_entropy": -2.0, "actor_entropy": -0.9533220728238424, "alpha_loss": 0.004927219512561957, "alpha_value": 0.00787441345840151, "duration": 47.850972175598145, "step": 4651}
{"episode_reward": -2.8294429864553745, "episode": 152.0, "batch_reward": -0.050701722502708435, "critic_loss": 0.007837554963771254, "ae_transition_loss": -1.5805218368768692, "ae_encoder_loss": 0.0060480039137473796, "actor_loss": 0.23137273266911507, "actor_target_entropy": -2.0, "actor_entropy": -0.6983014345169067, "alpha_loss": 0.007231554249301553, "alpha_value": 0.007843558832615154, "duration": 9.760463953018188, "step": 4700}
{"episode_reward": -4.553469671770709, "episode": 153.0, "batch_reward": -0.049014799296855927, "critic_loss": 0.0058856019750237465, "ae_transition_loss": -1.866939902305603, "ae_encoder_loss": 0.006663429085165262, "actor_loss": 0.2386309653520584, "actor_target_entropy": -2.0, "actor_entropy": -0.6316580176353455, "alpha_loss": 0.006551749538630247, "alpha_value": 0.007820977829361366, "duration": 0.5448493957519531, "step": 4701}
{"episode_reward": 0.0028870433381062988, "episode": 154.0, "batch_reward": -0.0453416109085083, "critic_loss": 0.0066518227104097605, "ae_transition_loss": -2.006094217300415, "ae_encoder_loss": 0.004524224088527262, "actor_loss": 0.22237496078014374, "actor_target_entropy": -2.0, "actor_entropy": -0.58362977206707, "alpha_loss": 0.007547049666754901, "alpha_value": 0.007797751800618809, "duration": 9.7706139087677, "step": 4750}
{"episode_reward": -2.704488522327436, "episode": 155.0, "batch_reward": -0.03184801712632179, "critic_loss": 0.003592126537114382, "ae_transition_loss": -2.0450515747070312, "ae_encoder_loss": 0.00046390644274652004, "actor_loss": 0.23600637912750244, "actor_target_entropy": -2.0, "actor_entropy": -0.6851517558097839, "alpha_loss": 0.006220458075404167, "alpha_value": 0.007774075942828282, "duration": 0.5262932777404785, "step": 4751}
{"episode_reward": -0.4356864944321903, "episode": 156.0, "batch_reward": -0.028578979894518852, "critic_loss": 0.006637301295995712, "ae_transition_loss": -2.056103229522705, "ae_encoder_loss": 0.0019568372663343325, "actor_loss": 0.20633519440889359, "actor_target_entropy": -2.0, "actor_entropy": -0.8493735790252686, "alpha_loss": 0.005749884760007262, "alpha_value": 0.007759899383460243, "duration": 4.961410760879517, "step": 4775}
{"episode_reward": -3.138963190020615, "episode": 157.0, "batch_reward": -0.03718540817499161, "critic_loss": 0.005284108687192202, "ae_transition_loss": -2.095627546310425, "ae_encoder_loss": 0.003412584359466564, "actor_loss": 0.22168470919132233, "actor_target_entropy": -2.0, "actor_entropy": -1.054955244064331, "alpha_loss": 0.00428576476406306, "alpha_value": 0.007741593888878028, "duration": 4.911747694015503, "step": 4799}
{"episode_reward": -4.024491552280644, "episode": 158.0, "batch_reward": -0.042618077248334885, "critic_loss": 0.0064086139512558775, "ae_transition_loss": -2.208605686823527, "ae_encoder_loss": 0.002870265733993923, "actor_loss": 0.22396833697954813, "actor_target_entropy": -2.0, "actor_entropy": -0.9304672280947367, "alpha_loss": 0.005391354362169902, "alpha_value": 0.007720144454441605, "duration": 5.221121072769165, "step": 4823}
{"episode_reward": -2.8734584698816517, "episode": 159.0, "batch_reward": -0.03434070944786072, "critic_loss": 0.004456538939848542, "ae_transition_loss": -2.443309116363525, "ae_encoder_loss": 0.002354874071897939, "actor_loss": 0.21898104548454284, "actor_target_entropy": -2.0, "actor_entropy": -1.1670923233032227, "alpha_loss": 0.004177601356059313, "alpha_value": 0.0076873826401683085, "duration": 9.996256351470947, "step": 4872}
{"episode_reward": -3.2077352133834047, "episode": 160.0, "batch_reward": -0.03973137028515339, "critic_loss": 0.004319265950471163, "ae_transition_loss": -2.6520999670028687, "ae_encoder_loss": 0.003991494813817553, "actor_loss": 0.2193208634853363, "actor_target_entropy": -2.0, "actor_entropy": -1.5742489695549011, "alpha_loss": 0.0018898532143794, "alpha_value": 0.007661110900049405, "duration": 5.038017511367798, "step": 4896}
{"episode_reward": -2.242795491304645, "episode": 161.0, "batch_reward": -0.04586842097342014, "critic_loss": 0.004252967005595565, "ae_transition_loss": -2.717987298965454, "ae_encoder_loss": 0.004860717139672488, "actor_loss": 0.22430554628372193, "actor_target_entropy": -2.0, "actor_entropy": -1.3679659843444825, "alpha_loss": 0.003188839228823781, "alpha_value": 0.007639953269563816, "duration": 44.2558376789093, "step": 4945}
{"episode_reward": -4.670642616179594, "episode": 162.0, "batch_reward": -0.05022394843399525, "critic_loss": 0.006463529076427221, "ae_transition_loss": -2.3850038051605225, "ae_encoder_loss": 0.003951540682464838, "actor_loss": 0.191527858376503, "actor_target_entropy": -2.0, "actor_entropy": -1.2007149457931519, "alpha_loss": 0.0037356701213866472, "alpha_value": 0.007620382094329442, "duration": 5.0639894008636475, "step": 4969}
{"episode_reward": -3.3218059059222256, "episode": 163.0, "batch_reward": -0.032526531567176185, "critic_loss": 0.004852694924920797, "ae_transition_loss": -2.374570846557617, "ae_encoder_loss": 0.0013171394627230863, "actor_loss": 0.2226931850115458, "actor_target_entropy": -2.0, "actor_entropy": -1.1615734895070393, "alpha_loss": 0.0036054872131596007, "alpha_value": 0.007606635064036076, "duration": 5.436650991439819, "step": 4993}
{"episode_reward": -2.593713161535654, "episode": 164.0, "batch_reward": -0.04118313640356064, "critic_loss": 0.004458834184333682, "ae_transition_loss": -2.535642981529236, "ae_encoder_loss": 0.0038017030456103384, "actor_loss": 0.23952385038137436, "actor_target_entropy": -2.0, "actor_entropy": -1.0938893556594849, "alpha_loss": 0.0024528236826881766, "alpha_value": 0.007593161635221217, "duration": 5.062876224517822, "step": 5017}
{"episode_reward": -1.842779314059056, "episode": 165.0, "duration": 0.22762608528137207, "step": 5018}
{"episode_reward": -0.4798715661690538, "episode": 166.0, "batch_reward": -0.028722925732533138, "critic_loss": 0.006017329326520364, "ae_transition_loss": -2.4286776383717856, "ae_encoder_loss": 0.001810261494635294, "actor_loss": 0.2110867847998937, "actor_target_entropy": -2.0, "actor_entropy": -1.0154186288515727, "alpha_loss": 0.004439245443791151, "alpha_value": 0.007580244451018167, "duration": 5.663177013397217, "step": 5042}
{"episode_reward": -3.878101241380496, "episode": 167.0, "batch_reward": -0.04475780390202999, "critic_loss": 0.005504808202385902, "ae_transition_loss": -2.4910786867141725, "ae_encoder_loss": 0.005136483628302812, "actor_loss": 0.21578995734453202, "actor_target_entropy": -2.0, "actor_entropy": -1.0215956628322602, "alpha_loss": 0.004622325534000993, "alpha_value": 0.007543369335425193, "duration": 20.25827121734619, "step": 5141}
{"episode_reward": -5.4466364449624365, "episode": 168.0, "batch_reward": -0.03580077551305294, "critic_loss": 0.0037500213366001844, "ae_transition_loss": -2.5861464738845825, "ae_encoder_loss": 0.0035478833015076816, "actor_loss": 0.21993396431207657, "actor_target_entropy": -2.0, "actor_entropy": -1.123902678489685, "alpha_loss": 0.003956474480219185, "alpha_value": 0.007507800706293994, "duration": 4.806276798248291, "step": 5165}
{"episode_reward": -3.4567049704153936, "episode": 169.0, "duration": 0.22318434715270996, "step": 5166}
{"episode_reward": -0.16470300446036285, "episode": 170.0, "batch_reward": -0.03368114307522774, "critic_loss": 0.004438887303695083, "ae_transition_loss": -2.4161885261535643, "ae_encoder_loss": 0.0064177864231169226, "actor_loss": 0.21112467646598815, "actor_target_entropy": -2.0, "actor_entropy": -1.3129323244094848, "alpha_loss": 0.0030475072446279226, "alpha_value": 0.007487685206499527, "duration": 9.896159172058105, "step": 5215}
{"episode_reward": -3.265640482774225, "episode": 171.0, "batch_reward": -0.03666922077536583, "critic_loss": 0.002982338657602668, "ae_transition_loss": -2.292888641357422, "ae_encoder_loss": 0.013545427937060595, "actor_loss": 0.2188566029071808, "actor_target_entropy": -2.0, "actor_entropy": -1.3980109691619873, "alpha_loss": 0.0027837418019771576, "alpha_value": 0.007469016039245907, "duration": 38.607829093933105, "step": 5239}
{"episode_reward": -2.3006732131583605, "episode": 172.0, "batch_reward": -0.034426579251885414, "critic_loss": 0.0054038939997553825, "ae_transition_loss": -1.8998572031656902, "ae_encoder_loss": 0.022396476318438847, "actor_loss": 0.19743471841017404, "actor_target_entropy": -2.0, "actor_entropy": -1.2721529801686604, "alpha_loss": 0.002931251268212994, "alpha_value": 0.007456735939497652, "duration": 4.934844493865967, "step": 5263}
{"episode_reward": -2.4699194955180044, "episode": 173.0, "batch_reward": -0.03470746520906687, "critic_loss": 0.004777383990585804, "ae_transition_loss": -2.0308451056480408, "ae_encoder_loss": 0.021787989884614944, "actor_loss": 0.22471392899751663, "actor_target_entropy": -2.0, "actor_entropy": -1.048099309206009, "alpha_loss": 0.0032332775881513953, "alpha_value": 0.00744495536983315, "duration": 5.021124362945557, "step": 5287}
{"episode_reward": -4.0279452241436395, "episode": 174.0, "batch_reward": -0.05038897693157196, "critic_loss": 0.003456055729960402, "ae_transition_loss": -2.2012979984283447, "ae_encoder_loss": 0.02932478052874406, "actor_loss": 0.2030749519666036, "actor_target_entropy": -2.0, "actor_entropy": -0.8031406998634338, "alpha_loss": 0.005365993361920118, "alpha_value": 0.007433101810963241, "duration": 5.116964101791382, "step": 5311}
{"episode_reward": -2.9397486390419516, "episode": 175.0, "duration": 0.1961994171142578, "step": 5312}
{"episode_reward": -0.9063907188321465, "episode": 176.0, "batch_reward": -0.02599259279668331, "critic_loss": 0.004182513453997672, "ae_transition_loss": -2.273221015930176, "ae_encoder_loss": 0.010241995565593243, "actor_loss": 0.20605211704969406, "actor_target_entropy": -2.0, "actor_entropy": -0.666902482509613, "alpha_loss": 0.0036892166826874018, "alpha_value": 0.007420097038870574, "duration": 4.925974607467651, "step": 5336}
{"episode_reward": -2.183967409153355, "episode": 177.0, "batch_reward": -0.05022856593132019, "critic_loss": 0.003912209765985608, "ae_transition_loss": -2.2778329849243164, "ae_encoder_loss": 0.01443398930132389, "actor_loss": 0.21408025920391083, "actor_target_entropy": -2.0, "actor_entropy": -0.5766088366508484, "alpha_loss": 0.004486676189117134, "alpha_value": 0.007409456551520527, "duration": 4.8157219886779785, "step": 5360}
{"episode_reward": -1.5011789891478087, "episode": 178.0, "batch_reward": -0.03910684337218603, "critic_loss": 0.003767334157600999, "ae_transition_loss": -2.3038221995035806, "ae_encoder_loss": 0.009330060333013535, "actor_loss": 0.2028421312570572, "actor_target_entropy": -2.0, "actor_entropy": -0.6840450763702393, "alpha_loss": 0.0036528175696730614, "alpha_value": 0.007395763962574996, "duration": 4.988255739212036, "step": 5384}
{"episode_reward": -2.972032740721355, "episode": 179.0, "batch_reward": -0.03728443570435047, "critic_loss": 0.0035472027957439423, "ae_transition_loss": -2.3990901708602905, "ae_encoder_loss": 0.009962290758267045, "actor_loss": 0.20359674096107483, "actor_target_entropy": -2.0, "actor_entropy": -0.8159212172031403, "alpha_loss": 0.0035640904679894447, "alpha_value": 0.007382268068514842, "duration": 4.851396083831787, "step": 5408}
{"episode_reward": -2.5631753448680694, "episode": 180.0, "batch_reward": -0.02830275148153305, "critic_loss": 0.0028246025710056224, "ae_transition_loss": -2.520880142847697, "ae_encoder_loss": 0.004011474239329497, "actor_loss": 0.20655652383963266, "actor_target_entropy": -2.0, "actor_entropy": -0.9477246801058451, "alpha_loss": 0.0029999516749133668, "alpha_value": 0.00736913808048284, "duration": 5.129239559173584, "step": 5432}
{"episode_reward": -3.171918294650758, "episode": 181.0, "batch_reward": -0.03104694001376629, "critic_loss": 0.0029997002566233277, "ae_transition_loss": -2.691505193710327, "ae_encoder_loss": 0.0074172536842525005, "actor_loss": 0.20194237679243088, "actor_target_entropy": -2.0, "actor_entropy": -1.071910321712494, "alpha_loss": 0.0032158648828044534, "alpha_value": 0.007356632677097524, "duration": 47.5943386554718, "step": 5456}
{"episode_reward": -2.4624887154542314, "episode": 182.0, "batch_reward": -0.03629657360059874, "critic_loss": 0.004251148335502616, "ae_transition_loss": -2.6670544488089427, "ae_encoder_loss": 0.005266574377726231, "actor_loss": 0.20114073370184218, "actor_target_entropy": -2.0, "actor_entropy": -1.2737997600010462, "alpha_loss": 0.0025337846018373966, "alpha_value": 0.007336119379805957, "duration": 14.815436363220215, "step": 5530}
{"episode_reward": -3.998506923963751, "episode": 183.0, "batch_reward": -0.04720791392028332, "critic_loss": 0.004834970179945231, "ae_transition_loss": -2.854621982574463, "ae_encoder_loss": 0.00887653708923608, "actor_loss": 0.20238544344902037, "actor_target_entropy": -2.0, "actor_entropy": -1.2872328996658324, "alpha_loss": 0.002143493387848139, "alpha_value": 0.007311280817970429, "duration": 9.95169973373413, "step": 5579}
{"episode_reward": -1.872678450409229, "episode": 184.0, "batch_reward": -0.04589072987437248, "critic_loss": 0.0025181833188980818, "ae_transition_loss": -2.8366431395212808, "ae_encoder_loss": 0.00404596421867609, "actor_loss": 0.20969553788503012, "actor_target_entropy": -2.0, "actor_entropy": -1.164144515991211, "alpha_loss": 0.0033137778906772533, "alpha_value": 0.007296134045226482, "duration": 5.132577657699585, "step": 5603}
{"episode_reward": -3.3370366275998298, "episode": 185.0, "batch_reward": -0.03253744635730982, "critic_loss": 0.005454442580230534, "ae_transition_loss": -2.8920024633407593, "ae_encoder_loss": 0.005644562654197216, "actor_loss": 0.18807081133127213, "actor_target_entropy": -2.0, "actor_entropy": -1.1283337473869324, "alpha_loss": 0.00294297409709543, "alpha_value": 0.007286403756348496, "duration": 4.846929311752319, "step": 5627}
{"episode_reward": -3.061420743092337, "episode": 186.0, "batch_reward": -0.024452530468503635, "critic_loss": 0.0027451057297488055, "ae_transition_loss": -2.8404365380605063, "ae_encoder_loss": 0.0018082448126127322, "actor_loss": 0.19942837953567505, "actor_target_entropy": -2.0, "actor_entropy": -1.093342383702596, "alpha_loss": 0.002667339751496911, "alpha_value": 0.007276371400272592, "duration": 5.064922571182251, "step": 5651}
{"episode_reward": -2.530521443386383, "episode": 187.0, "batch_reward": -0.0394112691283226, "critic_loss": 0.0020987199968658388, "ae_transition_loss": -2.8492146730422974, "ae_encoder_loss": 0.003433854435570538, "actor_loss": 0.20252955332398415, "actor_target_entropy": -2.0, "actor_entropy": -1.0868678987026215, "alpha_loss": 0.002694274764508009, "alpha_value": 0.007262712806188342, "duration": 9.55492115020752, "step": 5700}
{"episode_reward": -2.167541474292371, "episode": 188.0, "batch_reward": -0.04838550339142481, "critic_loss": 0.0016823430778458714, "ae_transition_loss": -2.9087642828623452, "ae_encoder_loss": 0.006701587854574124, "actor_loss": 0.20563040673732758, "actor_target_entropy": -2.0, "actor_entropy": -1.13908052444458, "alpha_loss": 0.001991039685284098, "alpha_value": 0.007249458381279249, "duration": 5.1377198696136475, "step": 5724}
{"episode_reward": -3.2612331661803706, "episode": 189.0, "batch_reward": -0.02868917863816023, "critic_loss": 0.001987073919735849, "ae_transition_loss": -2.8826266527175903, "ae_encoder_loss": 0.002559344284236431, "actor_loss": 0.19810309261083603, "actor_target_entropy": -2.0, "actor_entropy": -1.1334450244903564, "alpha_loss": 0.0012818677350878716, "alpha_value": 0.007240486323841987, "duration": 4.889672040939331, "step": 5748}
{"episode_reward": -2.1451933347670424, "episode": 190.0, "batch_reward": -0.034116261173039675, "critic_loss": 0.0030110812367638573, "ae_transition_loss": -2.90590101480484, "ae_encoder_loss": 0.004839712230022997, "actor_loss": 0.19616287015378475, "actor_target_entropy": -2.0, "actor_entropy": -1.2173012793064117, "alpha_loss": 0.0016032969433581457, "alpha_value": 0.007225091108361987, "duration": 15.027021169662476, "step": 5822}
{"episode_reward": -2.506617697626631, "episode": 191.0, "batch_reward": -0.04626449756324291, "critic_loss": 0.0022512637078762054, "ae_transition_loss": -2.9922053813934326, "ae_encoder_loss": 0.011650657746940851, "actor_loss": 0.1882028430700302, "actor_target_entropy": -2.0, "actor_entropy": -1.2874451279640198, "alpha_loss": 0.0003810757916653529, "alpha_value": 0.007211298949038665, "duration": 47.19680714607239, "step": 5846}
{"episode_reward": -2.264254320038945, "episode": 192.0, "batch_reward": -0.02829265035688877, "critic_loss": 0.0022711354540660977, "ae_transition_loss": -3.0072526931762695, "ae_encoder_loss": 0.00446725485380739, "actor_loss": 0.19680602848529816, "actor_target_entropy": -2.0, "actor_entropy": -1.2791637778282166, "alpha_loss": 0.0010232024942524731, "alpha_value": 0.007206676044450444, "duration": 4.863516807556152, "step": 5870}
{"episode_reward": -2.6119394006029477, "episode": 193.0, "batch_reward": -0.04779410858949026, "critic_loss": 0.0026618437453483543, "ae_transition_loss": -2.9101592699686685, "ae_encoder_loss": 0.010361254991342625, "actor_loss": 0.19471856951713562, "actor_target_entropy": -2.0, "actor_entropy": -1.272135575612386, "alpha_loss": 0.0012623680716690917, "alpha_value": 0.00720133502125118, "duration": 5.284712314605713, "step": 5894}
{"episode_reward": -3.0447326877233323, "episode": 194.0, "batch_reward": -0.019936591386795044, "critic_loss": 0.0034264337737113237, "ae_transition_loss": -2.9506293535232544, "ae_encoder_loss": 0.003629672690294683, "actor_loss": 0.17522259056568146, "actor_target_entropy": -2.0, "actor_entropy": -1.2641921639442444, "alpha_loss": 0.001783446001354605, "alpha_value": 0.007196185978151713, "duration": 4.911020994186401, "step": 5918}
{"episode_reward": -2.4741922179713445, "episode": 195.0, "batch_reward": -0.03384184595197439, "critic_loss": 0.0031682501547038557, "ae_transition_loss": -2.8419667720794677, "ae_encoder_loss": 0.008169973269104958, "actor_loss": 0.19902934730052949, "actor_target_entropy": -2.0, "actor_entropy": -1.2157328844070434, "alpha_loss": 0.001748671755194664, "alpha_value": 0.007188865072323927, "duration": 9.935912609100342, "step": 5967}
{"episode_reward": -3.400252838488953, "episode": 196.0, "batch_reward": -0.03673795089125633, "critic_loss": 0.0028934717876836656, "ae_transition_loss": -2.700860023498535, "ae_encoder_loss": 0.010961819067597389, "actor_loss": 0.19318684041500092, "actor_target_entropy": -2.0, "actor_entropy": -1.1141242980957031, "alpha_loss": 0.0015856619225814938, "alpha_value": 0.007177500223930197, "duration": 10.027784585952759, "step": 6016}
{"episode_reward": -3.4672873135600515, "episode": 197.0, "batch_reward": -0.03645328991115093, "critic_loss": 0.0011810989817604423, "ae_transition_loss": -2.5839744806289673, "ae_encoder_loss": 0.01590882893651724, "actor_loss": 0.20405463874340057, "actor_target_entropy": -2.0, "actor_entropy": -1.1225838661193848, "alpha_loss": 0.0008491195912938565, "alpha_value": 0.007169466856119917, "duration": 4.9635467529296875, "step": 6040}
{"episode_reward": -3.0448843913494263, "episode": 198.0, "batch_reward": -0.029702521860599518, "critic_loss": 0.0033602656330913305, "ae_transition_loss": -2.408787727355957, "ae_encoder_loss": 0.016546547412872314, "actor_loss": 0.19197024405002594, "actor_target_entropy": -2.0, "actor_entropy": -1.1550768613815308, "alpha_loss": 0.001019935472868383, "alpha_value": 0.0071663176534413455, "duration": 0.5517280101776123, "step": 6041}
{"episode_reward": -0.19907264387956042, "episode": 199.0, "batch_reward": -0.027339134365320206, "critic_loss": 0.0025984476087614894, "ae_transition_loss": -1.6749421954154968, "ae_encoder_loss": 0.03160919714719057, "actor_loss": 0.1954096294939518, "actor_target_entropy": -2.0, "actor_entropy": -1.2528147995471954, "alpha_loss": 0.0007733992897556163, "alpha_value": 0.007161575907690694, "duration": 9.668413639068604, "step": 6090}
{"episode_reward": -2.5168188994166676, "episode": 200.0, "batch_reward": -0.0356768270333608, "critic_loss": 0.0025869328916693726, "ae_transition_loss": -1.8514504432678223, "ae_encoder_loss": 0.04473661631345749, "actor_loss": 0.1989345302184423, "actor_target_entropy": -2.0, "actor_entropy": -1.413920799891154, "alpha_loss": 0.0004860345604053388, "alpha_value": 0.007155680518819735, "duration": 5.263598918914795, "step": 6115}
{"episode_reward": -1.8134905026154633, "episode": 201.0, "batch_reward": -0.02693222276866436, "critic_loss": 0.0021932406816631556, "ae_transition_loss": -2.01706063747406, "ae_encoder_loss": 0.036156121641397476, "actor_loss": 0.19168057292699814, "actor_target_entropy": -2.0, "actor_entropy": -1.4634636044502258, "alpha_loss": 0.00024980484158731997, "alpha_value": 0.00715201548961902, "duration": 43.98770070075989, "step": 6139}
{"episode_reward": -2.2170240568709767, "episode": 202.0, "batch_reward": -0.029846034198999404, "critic_loss": 0.0041295869275927545, "ae_transition_loss": -2.026476240158081, "ae_encoder_loss": 0.033114572241902354, "actor_loss": 0.18597729206085206, "actor_target_entropy": -2.0, "actor_entropy": -1.3720179796218872, "alpha_loss": 0.0010567439370788635, "alpha_value": 0.007147724825066736, "duration": 10.215702533721924, "step": 6188}
{"episode_reward": -1.710426831776871, "episode": 203.0, "batch_reward": -0.024940891812245052, "critic_loss": 0.0031422902829945087, "ae_transition_loss": -2.0562419096628823, "ae_encoder_loss": 0.031489426270127296, "actor_loss": 0.19463079671065012, "actor_target_entropy": -2.0, "actor_entropy": -1.024513840675354, "alpha_loss": 0.0014515701138104002, "alpha_value": 0.007142456016170207, "duration": 5.32065749168396, "step": 6212}
{"episode_reward": -1.725453522504307, "episode": 204.0, "batch_reward": -0.037552186846733095, "critic_loss": 0.0018537700176239013, "ae_transition_loss": -2.065446901321411, "ae_encoder_loss": 0.03555368781089783, "actor_loss": 0.19806447327136995, "actor_target_entropy": -2.0, "actor_entropy": -0.9569940447807312, "alpha_loss": 0.002584659866988659, "alpha_value": 0.007135429555718146, "duration": 10.39039158821106, "step": 6261}
{"episode_reward": -3.637778348201036, "episode": 205.0, "batch_reward": -0.04864049702882767, "critic_loss": 0.003952513914555311, "ae_transition_loss": -2.1222176551818848, "ae_encoder_loss": 0.05436357110738754, "actor_loss": 0.18981292098760605, "actor_target_entropy": -2.0, "actor_entropy": -0.9925006926059723, "alpha_loss": 0.002468606922775507, "alpha_value": 0.007127420724145951, "duration": 5.228276968002319, "step": 6285}
{"episode_reward": -1.84597770325372, "episode": 206.0, "batch_reward": -0.03257586833621774, "critic_loss": 0.0037240714633039068, "ae_transition_loss": -2.077533653804234, "ae_encoder_loss": 0.045792579650878906, "actor_loss": 0.19542683873857772, "actor_target_entropy": -2.0, "actor_entropy": -0.7449860828263419, "alpha_loss": 0.0034908129434500423, "alpha_value": 0.007114474466261537, "duration": 15.152026891708374, "step": 6359}
{"episode_reward": -3.575061357397423, "episode": 207.0, "batch_reward": -0.03630758747458458, "critic_loss": 0.005055448971688747, "ae_transition_loss": -2.0127922534942626, "ae_encoder_loss": 0.05227584987878799, "actor_loss": 0.20717288851737975, "actor_target_entropy": -2.0, "actor_entropy": -0.9958237171173095, "alpha_loss": 0.002853733766824007, "alpha_value": 0.00709160521225873, "duration": 10.151511907577515, "step": 6408}
{"episode_reward": -3.1192710354091226, "episode": 208.0, "batch_reward": -0.03300591123600801, "critic_loss": 0.0033313528013726077, "ae_transition_loss": -1.850528399149577, "ae_encoder_loss": 0.05596400424838066, "actor_loss": 0.21188666423161825, "actor_target_entropy": -2.0, "actor_entropy": -1.2079871495564778, "alpha_loss": 0.0028248069187005362, "alpha_value": 0.007075100489079594, "duration": 5.157802104949951, "step": 6432}
{"episode_reward": -3.6001691778156104, "episode": 209.0, "batch_reward": -0.030329856276512145, "critic_loss": 0.002594347856938839, "ae_transition_loss": -2.0371078968048097, "ae_encoder_loss": 0.04865182712674141, "actor_loss": 0.19743151366710662, "actor_target_entropy": -2.0, "actor_entropy": -0.8025764107704163, "alpha_loss": 0.003014325862750411, "alpha_value": 0.0070585649863658655, "duration": 10.058917999267578, "step": 6481}
{"episode_reward": -0.9156076022533584, "episode": 210.0, "batch_reward": -0.03601874345365692, "critic_loss": 0.003398395862485118, "ae_transition_loss": -2.0970576931448544, "ae_encoder_loss": 0.061999886789742636, "actor_loss": 0.20036941065507777, "actor_target_entropy": -2.0, "actor_entropy": -1.0976603381774004, "alpha_loss": 0.0024535624200806897, "alpha_value": 0.007015786729452103, "duration": 34.32691144943237, "step": 6655}
{"episode_reward": -3.8433415318988957, "episode": 211.0, "batch_reward": -0.033158653415739536, "critic_loss": 0.010838408023118973, "ae_transition_loss": -1.8507798314094543, "ae_encoder_loss": 0.06817871332168579, "actor_loss": 0.15396981686353683, "actor_target_entropy": -2.0, "actor_entropy": -1.1029061675071716, "alpha_loss": 0.001460347673855722, "alpha_value": 0.006980430139749708, "duration": 43.03548073768616, "step": 6679}
{"episode_reward": -3.345319406027604, "episode": 212.0, "batch_reward": -0.030486437305808068, "critic_loss": 0.005002338252961635, "ae_transition_loss": -2.1103031158447267, "ae_encoder_loss": 0.038449167460203174, "actor_loss": 0.2190407395362854, "actor_target_entropy": -2.0, "actor_entropy": -1.0623881578445435, "alpha_loss": 0.0015123275108635426, "alpha_value": 0.006968993351875841, "duration": 9.956133604049683, "step": 6728}
{"episode_reward": -2.795976669731492, "episode": 213.0, "batch_reward": -0.033526403130963445, "critic_loss": 0.003909462597221136, "ae_transition_loss": -2.3310095965862274, "ae_encoder_loss": 0.014561864314600825, "actor_loss": 0.19835523143410683, "actor_target_entropy": -2.0, "actor_entropy": -1.0320263653993607, "alpha_loss": 0.001305334131757263, "alpha_value": 0.0069510523449691, "duration": 15.221193075180054, "step": 6803}
{"episode_reward": -0.8302896263323117, "episode": 214.0, "batch_reward": -0.02788454480469227, "critic_loss": 0.004378535086289048, "ae_transition_loss": -2.6418840885162354, "ae_encoder_loss": 0.009170481003820896, "actor_loss": 0.22371474653482437, "actor_target_entropy": -2.0, "actor_entropy": -1.060602605342865, "alpha_loss": 0.001744949957355857, "alpha_value": 0.006939033008682739, "duration": 4.854247570037842, "step": 6827}
{"episode_reward": -3.151621389747347, "episode": 215.0, "batch_reward": -0.03598650172352791, "critic_loss": 0.0038438843039330095, "ae_transition_loss": -2.567325532436371, "ae_encoder_loss": 0.013012872077524662, "actor_loss": 0.19833377934992313, "actor_target_entropy": -2.0, "actor_entropy": -0.9987829253077507, "alpha_loss": 0.002946182736195624, "alpha_value": 0.006925426765017404, "duration": 15.302561283111572, "step": 6901}
{"episode_reward": -1.7638879148481357, "episode": 216.0, "duration": 0.19860124588012695, "step": 6902}
{"episode_reward": -0.6769129051840607, "episode": 217.0, "batch_reward": -0.029031584039330482, "critic_loss": 0.004079677746631205, "ae_transition_loss": -2.575760006904602, "ae_encoder_loss": 0.011609560810029507, "actor_loss": 0.19131281971931458, "actor_target_entropy": -2.0, "actor_entropy": -0.7870161831378937, "alpha_loss": 0.002914372947998345, "alpha_value": 0.006909117744115782, "duration": 5.022143602371216, "step": 6926}
{"episode_reward": -1.2901106458064637, "episode": 218.0, "batch_reward": -0.03520579822361469, "critic_loss": 0.0028668002923950553, "ae_transition_loss": -2.7924039363861084, "ae_encoder_loss": 0.013750698417425156, "actor_loss": 0.20253876596689224, "actor_target_entropy": -2.0, "actor_entropy": -0.8297465443611145, "alpha_loss": 0.0027868980541825294, "alpha_value": 0.006901714464841285, "duration": 4.7516865730285645, "step": 6950}
{"episode_reward": -2.9035117417419176, "episode": 219.0, "batch_reward": -0.028252166882157325, "critic_loss": 0.002765902376268059, "ae_transition_loss": -2.8260231733322145, "ae_encoder_loss": 0.010572265461087227, "actor_loss": 0.1982102945446968, "actor_target_entropy": -2.0, "actor_entropy": -1.2280553698539733, "alpha_loss": 0.0011807979317381978, "alpha_value": 0.0068817108318590765, "duration": 19.715818881988525, "step": 7049}
{"episode_reward": -2.221897391429366, "episode": 220.0, "batch_reward": -0.028844329295679927, "critic_loss": 0.003629700659075752, "ae_transition_loss": -2.82010754942894, "ae_encoder_loss": 0.012512168032117188, "actor_loss": 0.1919234450906515, "actor_target_entropy": -2.0, "actor_entropy": -0.8642076104879379, "alpha_loss": 0.0015013268348411657, "alpha_value": 0.00685820288738545, "duration": 14.57788634300232, "step": 7123}
{"episode_reward": -2.1405353445836988, "episode": 221.0, "duration": 33.877768993377686, "step": 7124}
{"episode_reward": -0.7519955162773518, "episode": 222.0, "batch_reward": -0.024590077623724938, "critic_loss": 0.002332088607363403, "ae_transition_loss": -2.7216463565826414, "ae_encoder_loss": 0.01265405397862196, "actor_loss": 0.19829328656196593, "actor_target_entropy": -2.0, "actor_entropy": -1.0370441913604735, "alpha_loss": 0.0014345713192597032, "alpha_value": 0.006843282521560151, "duration": 10.131820440292358, "step": 7173}
{"episode_reward": -1.6734979985451286, "episode": 223.0, "batch_reward": -0.03179281111806631, "critic_loss": 0.002892094780690968, "ae_transition_loss": -2.6982887983322144, "ae_encoder_loss": 0.015013989061117172, "actor_loss": 0.19261564314365387, "actor_target_entropy": -2.0, "actor_entropy": -1.1315808296203613, "alpha_loss": 0.0015563565539196134, "alpha_value": 0.006835382559083871, "duration": 5.22433066368103, "step": 7197}
{"episode_reward": -2.675006429457119, "episode": 224.0, "batch_reward": -0.024997377023100852, "critic_loss": 0.0030202466994524004, "ae_transition_loss": -2.5949480056762697, "ae_encoder_loss": 0.01572951301932335, "actor_loss": 0.19016860723495482, "actor_target_entropy": -2.0, "actor_entropy": -1.0894619464874267, "alpha_loss": 0.0017118655843660236, "alpha_value": 0.006827498147287748, "duration": 10.355370998382568, "step": 7246}
{"episode_reward": -2.553719978763751, "episode": 225.0, "batch_reward": -0.030193741898983717, "critic_loss": 0.0039185978239402175, "ae_transition_loss": -2.5361571311950684, "ae_encoder_loss": 0.020547034218907356, "actor_loss": 0.18695873022079468, "actor_target_entropy": -2.0, "actor_entropy": -1.0128424167633057, "alpha_loss": 0.0018497584969736636, "alpha_value": 0.006819257096889252, "duration": 4.913666486740112, "step": 7270}
{"episode_reward": -2.4085683079885993, "episode": 226.0, "batch_reward": -0.026832459960132837, "critic_loss": 0.0037348043406382203, "ae_transition_loss": -2.505494326353073, "ae_encoder_loss": 0.031532353488728404, "actor_loss": 0.18973658420145512, "actor_target_entropy": -2.0, "actor_entropy": -1.22405207157135, "alpha_loss": 0.0002162963864975609, "alpha_value": 0.006808872382158267, "duration": 15.645328521728516, "step": 7344}
{"episode_reward": -1.7911987791072157, "episode": 227.0, "batch_reward": -0.022977152746170758, "critic_loss": 0.0036952081602066754, "ae_transition_loss": -2.2822161316871643, "ae_encoder_loss": 0.04231214337050915, "actor_loss": 0.19128819555044174, "actor_target_entropy": -2.0, "actor_entropy": -1.0894486486911774, "alpha_loss": 0.00037337008980102836, "alpha_value": 0.006797314292585876, "duration": 20.89626121520996, "step": 7443}
{"episode_reward": -1.4738517238029247, "episode": 228.0, "batch_reward": -0.030208137817680836, "critic_loss": 0.003251918125897646, "ae_transition_loss": -2.1847853660583496, "ae_encoder_loss": 0.054468367248773575, "actor_loss": 0.1925867646932602, "actor_target_entropy": -2.0, "actor_entropy": -1.0147517323493958, "alpha_loss": 0.0015752905746921897, "alpha_value": 0.0067914932413003625, "duration": 4.955839395523071, "step": 7467}
{"episode_reward": -0.36052420976577115, "episode": 229.0, "batch_reward": -0.027910321330030758, "critic_loss": 0.0036720548135538897, "ae_transition_loss": -1.7971351146697998, "ae_encoder_loss": 0.05029374361038208, "actor_loss": 0.19852295021216074, "actor_target_entropy": -2.0, "actor_entropy": -1.2045254309972127, "alpha_loss": 0.0006556225610741725, "alpha_value": 0.006789027192277014, "duration": 5.566087484359741, "step": 7491}
{"episode_reward": -1.9639850148149565, "episode": 230.0, "batch_reward": -0.03497842140495777, "critic_loss": 0.003490996197797358, "ae_transition_loss": -1.8441867232322693, "ae_encoder_loss": 0.06718483567237854, "actor_loss": 0.1890728995203972, "actor_target_entropy": -2.0, "actor_entropy": -1.4862037897109985, "alpha_loss": 0.0006310211683739908, "alpha_value": 0.0067865722666691775, "duration": 4.829714775085449, "step": 7515}
{"episode_reward": -2.0181114484785563, "episode": 231.0, "batch_reward": -0.026759316492825747, "critic_loss": 0.004719895788002759, "ae_transition_loss": -1.3460103511810302, "ae_encoder_loss": 0.06772550493478775, "actor_loss": 0.19821503311395644, "actor_target_entropy": -2.0, "actor_entropy": -0.9512439846992493, "alpha_loss": 0.001580950862262398, "alpha_value": 0.0067783628118379055, "duration": 58.60252833366394, "step": 7614}
{"episode_reward": -2.2423429497154945, "episode": 232.0, "batch_reward": -0.03511238843202591, "critic_loss": 0.006556898355484009, "ae_transition_loss": -1.4297593832015991, "ae_encoder_loss": 0.05451584979891777, "actor_loss": 0.18537122011184692, "actor_target_entropy": -2.0, "actor_entropy": -1.0907962322235107, "alpha_loss": 0.0028932118439115584, "alpha_value": 0.006768206514115584, "duration": 5.208920955657959, "step": 7638}
{"episode_reward": -2.5500631056328755, "episode": 233.0, "batch_reward": -0.030641427263617516, "critic_loss": 0.004333898948971182, "ae_transition_loss": -1.4478859156370163, "ae_encoder_loss": 0.039828161243349314, "actor_loss": 0.20388584211468697, "actor_target_entropy": -2.0, "actor_entropy": -0.9014955908060074, "alpha_loss": 0.0024232400173787028, "alpha_value": 0.00675532623119841, "duration": 15.014917135238647, "step": 7712}
{"episode_reward": -2.023595153323065, "episode": 234.0, "batch_reward": -0.03084472455084324, "critic_loss": 0.004660822823643685, "ae_transition_loss": -1.4875586748123169, "ae_encoder_loss": 0.028946224600076675, "actor_loss": 0.19201959669589996, "actor_target_entropy": -2.0, "actor_entropy": -0.8384945511817932, "alpha_loss": 0.0025836320128291845, "alpha_value": 0.006735369752485743, "duration": 9.87230920791626, "step": 7761}
{"episode_reward": -3.1695497535199384, "episode": 235.0, "batch_reward": -0.03515070956200361, "critic_loss": 0.004690830362960696, "ae_transition_loss": -1.5884045660495758, "ae_encoder_loss": 0.037540310993790627, "actor_loss": 0.1994730643928051, "actor_target_entropy": -2.0, "actor_entropy": -0.7790012359619141, "alpha_loss": 0.0024249578709714115, "alpha_value": 0.006719827129959912, "duration": 9.860297679901123, "step": 7810}
{"episode_reward": -2.032004310638778, "episode": 236.0, "batch_reward": -0.03235191976030668, "critic_loss": 0.005421356996521354, "ae_transition_loss": -1.7468306223551433, "ae_encoder_loss": 0.05053772901495298, "actor_loss": 0.22493565579255423, "actor_target_entropy": -2.0, "actor_entropy": -0.7816471656163534, "alpha_loss": 0.003446991555392742, "alpha_value": 0.006707137626819663, "duration": 4.829335927963257, "step": 7834}
{"episode_reward": -2.111704920490789, "episode": 237.0, "batch_reward": -0.03873894549906254, "critic_loss": 0.0039625579956918955, "ae_transition_loss": -1.7717424035072327, "ae_encoder_loss": 0.07935639843344688, "actor_loss": 0.2044067606329918, "actor_target_entropy": -2.0, "actor_entropy": -0.8717225790023804, "alpha_loss": 0.003096619388088584, "alpha_value": 0.006697181257469255, "duration": 5.017910718917847, "step": 7858}
{"episode_reward": -2.8093716003951843, "episode": 238.0, "duration": 0.1828019618988037, "step": 7859}
{"episode_reward": -0.17587107530106277, "episode": 239.0, "batch_reward": -0.023811512316266697, "critic_loss": 0.0037304842844605446, "ae_transition_loss": -1.7880125443140666, "ae_encoder_loss": 0.06999993075927098, "actor_loss": 0.22392159700393677, "actor_target_entropy": -2.0, "actor_entropy": -0.9804677367210388, "alpha_loss": 0.003542453981935978, "alpha_value": 0.006686713593351345, "duration": 5.137386083602905, "step": 7883}
{"episode_reward": -3.1392962863874394, "episode": 240.0, "batch_reward": -0.029109876602888107, "critic_loss": 0.0055753670167177916, "ae_transition_loss": -1.8599533438682556, "ae_encoder_loss": 0.058796871453523636, "actor_loss": 0.19724349677562714, "actor_target_entropy": -2.0, "actor_entropy": -1.0822980403900146, "alpha_loss": 0.0028870815876871347, "alpha_value": 0.006675573517030211, "duration": 4.87931489944458, "step": 7907}
{"episode_reward": -2.201768558302398, "episode": 241.0, "batch_reward": -0.019786972412839533, "critic_loss": 0.004271022183820606, "ae_transition_loss": -1.828176164627075, "ae_encoder_loss": 0.06193870455026627, "actor_loss": 0.20285018682479858, "actor_target_entropy": -2.0, "actor_entropy": -0.7275083869695663, "alpha_loss": 0.003735188744030893, "alpha_value": 0.006648063972049699, "duration": 67.19186067581177, "step": 8006}
{"episode_reward": -3.0490005883039752, "episode": 242.0, "batch_reward": -0.02856998108327389, "critic_loss": 0.004139691824093461, "ae_transition_loss": -1.8228506326675415, "ae_encoder_loss": 0.07250816971063614, "actor_loss": 0.20292408466339112, "actor_target_entropy": -2.0, "actor_entropy": -0.40322344899177553, "alpha_loss": 0.004777716938406229, "alpha_value": 0.0066095511045815725, "duration": 10.123773574829102, "step": 8055}
{"episode_reward": -0.938337673652469, "episode": 243.0, "duration": 0.22738146781921387, "step": 8056}
{"episode_reward": -0.5307424068450928, "episode": 244.0, "batch_reward": -0.02889837045222521, "critic_loss": 0.0033872833009809256, "ae_transition_loss": -1.8054884672164917, "ae_encoder_loss": 0.05452829599380493, "actor_loss": 0.20862305909395218, "actor_target_entropy": -2.0, "actor_entropy": -0.5240903496742249, "alpha_loss": 0.0047386514488607645, "alpha_value": 0.00658881859655841, "duration": 5.062558174133301, "step": 8080}
{"episode_reward": -3.1784909825008456, "episode": 245.0, "batch_reward": -0.023041025114556152, "critic_loss": 0.0050183756587406, "ae_transition_loss": -1.8518759806950886, "ae_encoder_loss": 0.052559678753217064, "actor_loss": 0.19324867924054465, "actor_target_entropy": -2.0, "actor_entropy": -0.5479657848676046, "alpha_loss": 0.00488499707231919, "alpha_value": 0.0065729083862568335, "duration": 5.113387107849121, "step": 8104}
{"episode_reward": -2.82188075418411, "episode": 246.0, "batch_reward": -0.02581473719328642, "critic_loss": 0.00478016585111618, "ae_transition_loss": -1.9402709603309631, "ae_encoder_loss": 0.057011501863598824, "actor_loss": 0.1979411393404007, "actor_target_entropy": -2.0, "actor_entropy": -0.6361803114414215, "alpha_loss": 0.004940343555063009, "alpha_value": 0.006556493178246715, "duration": 5.1638712882995605, "step": 8128}
{"episode_reward": -2.462462645676969, "episode": 247.0, "batch_reward": -0.02591695450246334, "critic_loss": 0.0026775413813690343, "ae_transition_loss": -2.0123183727264404, "ae_encoder_loss": 0.06185691679517428, "actor_loss": 0.21679867804050446, "actor_target_entropy": -2.0, "actor_entropy": -0.7613006830215454, "alpha_loss": 0.004991986944029729, "alpha_value": 0.0065397154278182415, "duration": 5.262256145477295, "step": 8152}
{"episode_reward": -3.2094952230856904, "episode": 248.0, "batch_reward": -0.03066038340330124, "critic_loss": 0.00355477596167475, "ae_transition_loss": -2.038504481315613, "ae_encoder_loss": 0.06293193995952606, "actor_loss": 0.21106494963169098, "actor_target_entropy": -2.0, "actor_entropy": -0.7645825147628784, "alpha_loss": 0.0037194867618381977, "alpha_value": 0.006522633777973522, "duration": 4.861492156982422, "step": 8176}
{"episode_reward": -2.309300590762618, "episode": 249.0, "batch_reward": -0.02224634388195617, "critic_loss": 0.004658308146255357, "ae_transition_loss": -1.9363165753228324, "ae_encoder_loss": 0.06697676650115422, "actor_loss": 0.19436363875865936, "actor_target_entropy": -2.0, "actor_entropy": -0.6920726299285889, "alpha_loss": 0.004435453430882522, "alpha_value": 0.0064928339993529805, "duration": 14.804975032806396, "step": 8250}
{"episode_reward": -3.307912430906226, "episode": 250.0, "batch_reward": -0.020464948564767837, "critic_loss": 0.004433138761669397, "ae_transition_loss": -2.0123468399047852, "ae_encoder_loss": 0.06331663802266121, "actor_loss": 0.20164126753807068, "actor_target_entropy": -2.0, "actor_entropy": -0.7680372595787048, "alpha_loss": 0.00277423863299191, "alpha_value": 0.006454417911031908, "duration": 9.898504972457886, "step": 8299}
{"episode_reward": -1.704798782880503, "episode": 251.0, "batch_reward": -0.01920154256125291, "critic_loss": 0.004793646900604169, "ae_transition_loss": -2.00705885887146, "ae_encoder_loss": 0.058153084168831505, "actor_loss": 0.19699073334534964, "actor_target_entropy": -2.0, "actor_entropy": -0.7618856430053711, "alpha_loss": 0.0039146508400638895, "alpha_value": 0.00643167112836527, "duration": 47.45972776412964, "step": 8323}
{"episode_reward": -4.473272742619101, "episode": 252.0, "batch_reward": -0.032122896052896976, "critic_loss": 0.002591283177025616, "ae_transition_loss": -2.0525351762771606, "ae_encoder_loss": 0.06347582302987576, "actor_loss": 0.2017923668026924, "actor_target_entropy": -2.0, "actor_entropy": -0.7588367164134979, "alpha_loss": 0.0036861300468444824, "alpha_value": 0.006417800507230954, "duration": 5.0198142528533936, "step": 8347}
{"episode_reward": -1.615549761000546, "episode": 253.0, "batch_reward": -0.02331359436114629, "critic_loss": 0.004302982318525513, "ae_transition_loss": -2.126485506693522, "ae_encoder_loss": 0.049708619713783264, "actor_loss": 0.20432478686173758, "actor_target_entropy": -2.0, "actor_entropy": -0.7720600167910258, "alpha_loss": 0.003827141753087441, "alpha_value": 0.006403926148942693, "duration": 5.27335000038147, "step": 8371}
{"episode_reward": -2.290215252012447, "episode": 254.0, "batch_reward": -0.033897342160344124, "critic_loss": 0.0027835245709866285, "ae_transition_loss": -2.175815224647522, "ae_encoder_loss": 0.0560371745377779, "actor_loss": 0.20332733541727066, "actor_target_entropy": -2.0, "actor_entropy": -0.8247149288654327, "alpha_loss": 0.004108925350010395, "alpha_value": 0.006390037304786525, "duration": 4.858545303344727, "step": 8395}
{"episode_reward": -4.351298490987349, "episode": 255.0, "batch_reward": -0.022466115653514862, "critic_loss": 0.00394772388972342, "ae_transition_loss": -2.2212785482406616, "ae_encoder_loss": 0.05772371031343937, "actor_loss": 0.19698207825422287, "actor_target_entropy": -2.0, "actor_entropy": -0.8857299089431763, "alpha_loss": 0.003978476859629154, "alpha_value": 0.006378764662701537, "duration": 4.9431586265563965, "step": 8419}
{"episode_reward": -2.2707805500493334, "episode": 256.0, "batch_reward": -0.03708777762949467, "critic_loss": 0.003471574435631434, "ae_transition_loss": -2.080952843030294, "ae_encoder_loss": 0.07470980783303578, "actor_loss": 0.20878082513809204, "actor_target_entropy": -2.0, "actor_entropy": -0.9404582579930624, "alpha_loss": 0.0029431452664236226, "alpha_value": 0.00636481436738115, "duration": 5.284185171127319, "step": 8443}
{"episode_reward": -2.5885258629061525, "episode": 257.0, "batch_reward": -0.03350558690726757, "critic_loss": 0.0042671432020142674, "ae_transition_loss": -1.8822457790374756, "ae_encoder_loss": 0.07465386390686035, "actor_loss": 0.201014906167984, "actor_target_entropy": -2.0, "actor_entropy": -0.9413799941539764, "alpha_loss": 0.00344738329295069, "alpha_value": 0.006351510864205802, "duration": 5.09948468208313, "step": 8467}
{"episode_reward": -2.4140072840640014, "episode": 258.0, "batch_reward": -0.018526032877465088, "critic_loss": 0.0046099939694007235, "ae_transition_loss": -1.1287981271743774, "ae_encoder_loss": 0.08713970084985097, "actor_loss": 0.19528103868166605, "actor_target_entropy": -2.0, "actor_entropy": -0.8838152885437012, "alpha_loss": 0.0022303751902654767, "alpha_value": 0.0063386430077475445, "duration": 5.248096227645874, "step": 8491}
{"episode_reward": -3.3606811175788, "episode": 259.0, "batch_reward": -0.022970934864133596, "critic_loss": 0.0044065366382710636, "ae_transition_loss": -0.5350547097623348, "ae_encoder_loss": 0.053252354729920626, "actor_loss": 0.21233119815587997, "actor_target_entropy": -2.0, "actor_entropy": -1.1981627941131592, "alpha_loss": 0.003148762392811477, "alpha_value": 0.006322028531120531, "duration": 9.763376951217651, "step": 8540}
{"episode_reward": -3.5551011032669186, "episode": 260.0, "batch_reward": -0.016500533403207857, "critic_loss": 0.0034011651296168566, "ae_transition_loss": -1.143298347791036, "ae_encoder_loss": 0.01925064902752638, "actor_loss": 0.20709107319513956, "actor_target_entropy": -2.0, "actor_entropy": -1.0062965552012126, "alpha_loss": 0.002504967929174503, "alpha_value": 0.006305860708640071, "duration": 5.036139249801636, "step": 8564}
{"episode_reward": -4.119161761293893, "episode": 261.0, "batch_reward": -0.022500761784613132, "critic_loss": 0.0055922020226717, "ae_transition_loss": -1.2305400609970092, "ae_encoder_loss": 0.008509280439466239, "actor_loss": 0.19318189918994905, "actor_target_entropy": -2.0, "actor_entropy": -0.8891110062599182, "alpha_loss": 0.002226631110534072, "alpha_value": 0.006288344036167089, "duration": 44.524691343307495, "step": 8613}
{"episode_reward": -0.3158311990517802, "episode": 262.0, "batch_reward": -0.023690599415983473, "critic_loss": 0.005552283288644893, "ae_transition_loss": -1.215204187801906, "ae_encoder_loss": 0.0038713272993585895, "actor_loss": 0.20443001176629746, "actor_target_entropy": -2.0, "actor_entropy": -0.861626786845071, "alpha_loss": 0.0021929441718384624, "alpha_value": 0.006265079003710485, "duration": 15.04665756225586, "step": 8687}
{"episode_reward": -2.0296146796359413, "episode": 263.0, "duration": 0.22373366355895996, "step": 8688}
{"episode_reward": -0.8527443547735852, "episode": 264.0, "batch_reward": -0.02589486613869667, "critic_loss": 0.004608154296875, "ae_transition_loss": -1.2581186056137086, "ae_encoder_loss": 0.0033987488131970167, "actor_loss": 0.2088531255722046, "actor_target_entropy": -2.0, "actor_entropy": -1.0981547594070435, "alpha_loss": 0.0018579350435175002, "alpha_value": 0.006243935658671228, "duration": 9.971991062164307, "step": 8737}
{"episode_reward": -2.2744976034516284, "episode": 265.0, "duration": 0.23143744468688965, "step": 8738}
{"episode_reward": -0.7014641242261236, "episode": 266.0, "batch_reward": -0.021584842912852766, "critic_loss": 0.0054613335756585005, "ae_transition_loss": -1.4586938261985778, "ae_encoder_loss": 0.0020025248086312786, "actor_loss": 0.21355321258306503, "actor_target_entropy": -2.0, "actor_entropy": -1.0391730546951294, "alpha_loss": 0.0015133774664718657, "alpha_value": 0.006221092600591287, "duration": 20.468026638031006, "step": 8837}
{"episode_reward": -3.0976210678721086, "episode": 267.0, "batch_reward": -0.024074978712532256, "critic_loss": 0.005968947429209948, "ae_transition_loss": -1.7761254641744826, "ae_encoder_loss": 0.0023259668523678556, "actor_loss": 0.21166070799032846, "actor_target_entropy": -2.0, "actor_entropy": -1.038481096426646, "alpha_loss": 0.0018753273244429794, "alpha_value": 0.006184980884741174, "duration": 36.07248020172119, "step": 9011}
{"episode_reward": 0.488161678371107, "episode": 268.0, "batch_reward": -0.021765773317643573, "critic_loss": 0.005157131868015442, "ae_transition_loss": -2.055547152246748, "ae_encoder_loss": 0.0016675449151080102, "actor_loss": 0.2051279672554561, "actor_target_entropy": -2.0, "actor_entropy": -0.6910099131720406, "alpha_loss": 0.0027576675971171687, "alpha_value": 0.006150585037126288, "duration": 15.294746160507202, "step": 9085}
{"episode_reward": -0.25729570041819827, "episode": 269.0, "batch_reward": -0.026298126205801964, "critic_loss": 0.006235061679035425, "ae_transition_loss": -1.9141751527786255, "ae_encoder_loss": 0.006195602240040898, "actor_loss": 0.19398260116577148, "actor_target_entropy": -2.0, "actor_entropy": -0.5101657658815384, "alpha_loss": 0.0031661586835980415, "alpha_value": 0.006135660983632775, "duration": 4.848110675811768, "step": 9109}
{"episode_reward": -1.3217648206393378, "episode": 270.0, "batch_reward": -0.027503544837236403, "critic_loss": 0.0041913824621587995, "ae_transition_loss": -2.1220044136047362, "ae_encoder_loss": 0.0028153370134532452, "actor_loss": 0.20749641358852386, "actor_target_entropy": -2.0, "actor_entropy": -0.6521053194999695, "alpha_loss": 0.0034427518025040627, "alpha_value": 0.006122356718754564, "duration": 10.008141040802002, "step": 9158}
{"episode_reward": -2.8671567294136073, "episode": 271.0, "batch_reward": -0.021525877807289363, "critic_loss": 0.004856719775125385, "ae_transition_loss": -1.8677494049072265, "ae_encoder_loss": 0.003963958285748958, "actor_loss": 0.20692960619926454, "actor_target_entropy": -2.0, "actor_entropy": -0.896324098110199, "alpha_loss": 0.002579414937645197, "alpha_value": 0.0061016334072925334, "duration": 47.827716588974, "step": 9207}
{"episode_reward": -1.3447306454511962, "episode": 272.0, "batch_reward": -0.026378200461085025, "critic_loss": 0.005837217080765045, "ae_transition_loss": -1.2787139874238234, "ae_encoder_loss": 0.009660049932650648, "actor_loss": 0.21112451071922594, "actor_target_entropy": -2.0, "actor_entropy": -0.9022131103735703, "alpha_loss": 0.002406354035394123, "alpha_value": 0.0060660776131436925, "duration": 24.82949447631836, "step": 9331}
{"episode_reward": 2.566013264097897, "episode": 273.0, "batch_reward": -0.020192041993141174, "critic_loss": 0.006341149332001805, "ae_transition_loss": -1.318361222743988, "ae_encoder_loss": 0.013494499726220965, "actor_loss": 0.20930127054452896, "actor_target_entropy": -2.0, "actor_entropy": -0.9477499127388, "alpha_loss": 0.0020783551735803485, "alpha_value": 0.0060382353169334164, "duration": 4.769953966140747, "step": 9355}
{"episode_reward": -2.764558215225494, "episode": 274.0, "batch_reward": -0.014051723293960094, "critic_loss": 0.0068187874276191, "ae_transition_loss": -1.3358315825462341, "ae_encoder_loss": 0.011579820420593023, "actor_loss": 0.20718743652105331, "actor_target_entropy": -2.0, "actor_entropy": -0.795211672782898, "alpha_loss": 0.0017554345540702343, "alpha_value": 0.006031331955153671, "duration": 4.820058107376099, "step": 9379}
{"episode_reward": -0.8731288812802026, "episode": 275.0, "batch_reward": -0.023266091321905453, "critic_loss": 0.006693670370926459, "ae_transition_loss": -1.1395066380500793, "ae_encoder_loss": 0.016806321839491527, "actor_loss": 0.21284050742785135, "actor_target_entropy": -2.0, "actor_entropy": -0.5825198690096537, "alpha_loss": 0.0021073566749691963, "alpha_value": 0.006023118449345665, "duration": 4.86091160774231, "step": 9403}
{"episode_reward": -2.0781603542096727, "episode": 276.0, "batch_reward": -0.038080403581261635, "critic_loss": 0.005453143501654267, "ae_transition_loss": -1.4348238110542297, "ae_encoder_loss": 0.013008934445679188, "actor_loss": 0.2110709249973297, "actor_target_entropy": -2.0, "actor_entropy": -0.7807918190956116, "alpha_loss": 0.0029960989486426115, "alpha_value": 0.0060149297991612515, "duration": 4.81838321685791, "step": 9427}
{"episode_reward": -2.5721991165493625, "episode": 277.0, "batch_reward": -0.026180871451894443, "critic_loss": 0.005789938848465681, "ae_transition_loss": -1.4873308738072712, "ae_encoder_loss": 0.010806709217528502, "actor_loss": 0.22267471253871918, "actor_target_entropy": -2.0, "actor_entropy": -0.8401718338330587, "alpha_loss": 0.002189099400614699, "alpha_value": 0.006006407082235218, "duration": 5.33693265914917, "step": 9451}
{"episode_reward": -2.510140708084891, "episode": 278.0, "batch_reward": -0.01915685774292797, "critic_loss": 0.0062133255996741354, "ae_transition_loss": -1.7699862718582153, "ae_encoder_loss": 0.007612317393068224, "actor_loss": 0.21087330393493176, "actor_target_entropy": -2.0, "actor_entropy": -0.8438908457756042, "alpha_loss": 0.001998909196117893, "alpha_value": 0.0059882555046813085, "duration": 17.006829738616943, "step": 9538}
{"episode_reward": -1.3635775856096335, "episode": 279.0, "batch_reward": -0.021642588182455964, "critic_loss": 0.00525735590296487, "ae_transition_loss": -1.5805085036489699, "ae_encoder_loss": 0.029932116106566455, "actor_loss": 0.21220480899016061, "actor_target_entropy": -2.0, "actor_entropy": -0.9849878880712721, "alpha_loss": 0.0017988579865131113, "alpha_value": 0.005949731355669306, "duration": 35.34437680244446, "step": 9712}
{"episode_reward": 2.6261854982081902, "episode": 280.0, "batch_reward": -0.023284037652261117, "critic_loss": 0.0057466837906223886, "ae_transition_loss": -1.3241398755241842, "ae_encoder_loss": 0.07188978111919235, "actor_loss": 0.20984971610938802, "actor_target_entropy": -2.0, "actor_entropy": -0.8622082857524648, "alpha_loss": 0.0018330113962292671, "alpha_value": 0.005903961776925371, "duration": 35.09511756896973, "step": 9886}
{"episode_reward": 0.42025166058176994, "episode": 281.0, "batch_reward": -0.015708106926039737, "critic_loss": 0.006702321198056726, "ae_transition_loss": -1.3316509443170883, "ae_encoder_loss": 0.058696411111775565, "actor_loss": 0.20459986171301672, "actor_target_entropy": -2.0, "actor_entropy": -0.8475903833613676, "alpha_loss": 0.002993741853381781, "alpha_value": 0.0058509997668585645, "duration": 499.2637951374054, "step": 10060}
{"episode_reward": 3.478057507612502, "episode": 282.0, "batch_reward": -0.02232499063635866, "critic_loss": 0.006292574340477586, "ae_transition_loss": -1.362134834130605, "ae_encoder_loss": 0.06447969066600005, "actor_loss": 0.20108558237552643, "actor_target_entropy": -2.0, "actor_entropy": -0.8458584447701772, "alpha_loss": 0.0022099807780856886, "alpha_value": 0.005794838197547899, "duration": 24.139737367630005, "step": 10180}
{"episode_reward": 3.4178471516507565, "episode": 283.0, "batch_reward": -0.01851440316531807, "critic_loss": 0.006137604103423655, "ae_transition_loss": -1.6421949326992036, "ae_encoder_loss": 0.019851886620745062, "actor_loss": 0.19757074639201164, "actor_target_entropy": -2.0, "actor_entropy": -0.7775886446237564, "alpha_loss": 0.0013202195521444082, "alpha_value": 0.005743997461267055, "duration": 39.77881669998169, "step": 10372}
{"episode_reward": 13.264090690768663, "episode": 284.0, "batch_reward": -0.018007960077375172, "critic_loss": 0.013345341919921339, "ae_transition_loss": -0.9190802469849586, "ae_encoder_loss": 0.021829564310610294, "actor_loss": 0.2320994630455971, "actor_target_entropy": -2.0, "actor_entropy": -1.0597349643707275, "alpha_loss": 0.0019292782060801982, "alpha_value": 0.005710562083573291, "duration": 20.904754400253296, "step": 10476}
{"episode_reward": 4.602915691060665, "episode": 285.0, "batch_reward": -0.012920380119650968, "critic_loss": 0.008933745839289929, "ae_transition_loss": -0.646183646038959, "ae_encoder_loss": 0.017808571261794942, "actor_loss": 0.1927665722997565, "actor_target_entropy": -2.0, "actor_entropy": -0.6638163437968806, "alpha_loss": 0.003051923453121593, "alpha_value": 0.005668669364826506, "duration": 38.62378668785095, "step": 10669}
{"episode_reward": 14.128554780866951, "episode": 286.0, "batch_reward": -0.013958656636532396, "critic_loss": 0.008190136170014739, "ae_transition_loss": -0.7683970183134079, "ae_encoder_loss": 0.057540301233530045, "actor_loss": 0.18921728990972042, "actor_target_entropy": -2.0, "actor_entropy": -0.6435629576444626, "alpha_loss": 0.0038858866319060326, "alpha_value": 0.005613761814265606, "duration": 14.956404209136963, "step": 10743}
{"episode_reward": 1.2794105131653353, "episode": 287.0, "batch_reward": -0.010783561528660357, "critic_loss": 0.006957393535412848, "ae_transition_loss": -0.7338358581066131, "ae_encoder_loss": 0.08290134146809577, "actor_loss": 0.18442828357219695, "actor_target_entropy": -2.0, "actor_entropy": -0.5358711242675781, "alpha_loss": 0.00396893797442317, "alpha_value": 0.005567594737395194, "duration": 20.245367527008057, "step": 10842}
{"episode_reward": 6.826368707652924, "episode": 288.0, "batch_reward": -0.01304853559387001, "critic_loss": 0.008194266310469671, "ae_transition_loss": -1.1082035140557722, "ae_encoder_loss": 0.04608358544382182, "actor_loss": 0.17286777360872788, "actor_target_entropy": -2.0, "actor_entropy": -0.7211750095540826, "alpha_loss": 0.0031755267092111435, "alpha_value": 0.0055122367446017164, "duration": 23.257776021957397, "step": 10958}
{"episode_reward": 14.527007149226892, "episode": 289.0, "batch_reward": -0.01094505850536128, "critic_loss": 0.007951710010982223, "ae_transition_loss": -1.4501222901874118, "ae_encoder_loss": 0.04891411835948626, "actor_loss": 0.18292525741789076, "actor_target_entropy": -2.0, "actor_entropy": -0.628259367412991, "alpha_loss": 0.002703681445887519, "alpha_value": 0.005464376053263894, "duration": 17.858973503112793, "step": 11044}
{"episode_reward": 8.880014554149229, "episode": 290.0, "batch_reward": -0.004592102632159367, "critic_loss": 0.010473883536178619, "ae_transition_loss": -1.3086496591567993, "ae_encoder_loss": 0.05830600671470165, "actor_loss": 0.16986767761409283, "actor_target_entropy": -2.0, "actor_entropy": -0.9215361624956131, "alpha_loss": 0.0006607151153730229, "alpha_value": 0.005429281720996025, "duration": 16.832409381866455, "step": 11130}
{"episode_reward": 12.681865256309136, "episode": 291.0, "batch_reward": -0.00899393088184297, "critic_loss": 0.010919488267973065, "ae_transition_loss": -1.2467137277126312, "ae_encoder_loss": 0.06365072727203369, "actor_loss": 0.1705319583415985, "actor_target_entropy": -2.0, "actor_entropy": -1.320861279964447, "alpha_loss": -0.00141215740586631, "alpha_value": 0.005413851970331657, "duration": 138.1355757713318, "step": 11168}
{"episode_reward": 7.9235925971451815, "episode": 292.0, "duration": 0.23669981956481934, "step": 11169}
{"episode_reward": 0.05078597004084345, "episode": 293.0, "batch_reward": -0.008333086435283934, "critic_loss": 0.009487426573676723, "ae_transition_loss": -1.0899288654327393, "ae_encoder_loss": 0.05751256165759904, "actor_loss": 0.17073032047067369, "actor_target_entropy": -2.0, "actor_entropy": -0.8727382251194545, "alpha_loss": -0.00047380880901723037, "alpha_value": 0.005410888846473243, "duration": 14.354874610900879, "step": 11240}
{"episode_reward": 18.39764193781599, "episode": 294.0, "batch_reward": -0.0028855111449956894, "critic_loss": 0.0066279456950724125, "ae_transition_loss": -1.0684279203414917, "ae_encoder_loss": 0.06378266215324402, "actor_loss": 0.15584635734558105, "actor_target_entropy": -2.0, "actor_entropy": -0.6550824642181396, "alpha_loss": -0.0008807990234345198, "alpha_value": 0.005410898811422422, "duration": 1.0779728889465332, "step": 11244}
{"episode_reward": -1.3675718386978635, "episode": 295.0, "batch_reward": -0.006860651134047657, "critic_loss": 0.010939579689875245, "ae_transition_loss": -1.0301970839500427, "ae_encoder_loss": 0.06784859485924244, "actor_loss": 0.16884707659482956, "actor_target_entropy": -2.0, "actor_entropy": -0.8856767117977142, "alpha_loss": -0.00027218294417252764, "alpha_value": 0.0054109883668908764, "duration": 8.489639520645142, "step": 11286}
{"episode_reward": 6.458629599539355, "episode": 296.0, "duration": 0.2433922290802002, "step": 11287}
{"episode_reward": -0.5665557384490967, "episode": 297.0, "batch_reward": -0.0056285203124086065, "critic_loss": 0.01275753773127993, "ae_transition_loss": -1.0222253402074177, "ae_encoder_loss": 0.08044486244519551, "actor_loss": 0.17406008640925089, "actor_target_entropy": -2.0, "actor_entropy": -1.1853053172429402, "alpha_loss": -0.004000536631792784, "alpha_value": 0.005412031679163686, "duration": 5.9002463817596436, "step": 11317}
{"episode_reward": 7.441519079730951, "episode": 298.0, "duration": 0.22755050659179688, "step": 11318}
{"episode_reward": -0.4194633902614968, "episode": 299.0, "batch_reward": -0.009625301463529468, "critic_loss": 0.015026002191007137, "ae_transition_loss": -1.228144645690918, "ae_encoder_loss": 0.08360378816723824, "actor_loss": 0.13077229261398315, "actor_target_entropy": -2.0, "actor_entropy": -0.916114866733551, "alpha_loss": -0.004238080000504851, "alpha_value": 0.00541585967212934, "duration": 4.032186031341553, "step": 11337}
{"episode_reward": 0.9388590445061844, "episode": 300.0, "batch_reward": -0.007226913080861171, "critic_loss": 0.009772651052723328, "ae_transition_loss": -1.3291190067927043, "ae_encoder_loss": 0.09218838810920715, "actor_loss": 0.16326668361822763, "actor_target_entropy": -2.0, "actor_entropy": -1.1356274286905925, "alpha_loss": -0.007244771812111139, "alpha_value": 0.0054298076077988755, "duration": 11.564487934112549, "step": 11395}
{"episode_reward": 24.339708285107065, "episode": 301.0, "batch_reward": 0.0010758991120383143, "critic_loss": 0.009271939401514828, "ae_transition_loss": -1.4929068088531494, "ae_encoder_loss": 0.09363027848303318, "actor_loss": 0.1440514624118805, "actor_target_entropy": -2.0, "actor_entropy": -0.98111991584301, "alpha_loss": -0.003831518057268113, "alpha_value": 0.005458086263581596, "duration": 48.28299021720886, "step": 11436}
{"episode_reward": 10.756887875636531, "episode": 302.0, "batch_reward": 0.004920352715998888, "critic_loss": 0.02093939743936062, "ae_transition_loss": -1.603352665901184, "ae_encoder_loss": 0.08864986896514893, "actor_loss": 0.1373804032802582, "actor_target_entropy": -2.0, "actor_entropy": -1.0745447158813477, "alpha_loss": -0.006218776572495699, "alpha_value": 0.005485498762036142, "duration": 10.415552616119385, "step": 11486}
{"episode_reward": 13.874518172088493, "episode": 303.0, "batch_reward": 0.00416128554691871, "critic_loss": 0.0186524565021197, "ae_transition_loss": -1.6812483072280884, "ae_encoder_loss": 0.09383411953846614, "actor_loss": 0.16346591711044312, "actor_target_entropy": -2.0, "actor_entropy": -1.477131764094035, "alpha_loss": -0.008892814939220747, "alpha_value": 0.005512984964193839, "duration": 5.716287136077881, "step": 11515}
{"episode_reward": 8.766269377977542, "episode": 304.0, "batch_reward": -0.011406755074858665, "critic_loss": 0.01290597440674901, "ae_transition_loss": -1.5678134560585022, "ae_encoder_loss": 0.1086794063448906, "actor_loss": 0.10234449803829193, "actor_target_entropy": -2.0, "actor_entropy": -1.6850457191467285, "alpha_loss": -0.007246605586260557, "alpha_value": 0.005533936883232967, "duration": 3.877748489379883, "step": 11533}
{"episode_reward": 0.22540768988442356, "episode": 305.0, "batch_reward": 0.003310013096779585, "critic_loss": 0.017866892740130424, "ae_transition_loss": -1.6029167175292969, "ae_encoder_loss": 0.1089995726943016, "actor_loss": 0.09351816773414612, "actor_target_entropy": -2.0, "actor_entropy": -1.6713857650756836, "alpha_loss": -0.00805133581161499, "alpha_value": 0.005547217282822937, "duration": 2.2695791721343994, "step": 11543}
{"episode_reward": -1.1392886406211216, "episode": 306.0, "batch_reward": 0.0015588128784050543, "critic_loss": 0.019351159532864887, "ae_transition_loss": -1.5206920107205708, "ae_encoder_loss": 0.09877252330382665, "actor_loss": 0.12419264639417331, "actor_target_entropy": -2.0, "actor_entropy": -1.4199965397516887, "alpha_loss": -0.009345660141358772, "alpha_value": 0.005580312985026485, "duration": 11.756248235702515, "step": 11601}
{"episode_reward": 13.907455476447666, "episode": 307.0, "batch_reward": -0.0028822257881984115, "critic_loss": 0.011281595099717379, "ae_transition_loss": -1.359735369682312, "ae_encoder_loss": 0.10697977617383003, "actor_loss": 0.15278880298137665, "actor_target_entropy": -2.0, "actor_entropy": -1.0233123302459717, "alpha_loss": -0.009288700297474861, "alpha_value": 0.005622232826212878, "duration": 4.56110692024231, "step": 11624}
{"episode_reward": -1.6633301433205556, "episode": 308.0, "batch_reward": 0.00783994747325778, "critic_loss": 0.018358160741627216, "ae_transition_loss": -1.556007444858551, "ae_encoder_loss": 0.0942828617990017, "actor_loss": 0.14424783736467361, "actor_target_entropy": -2.0, "actor_entropy": -1.1147032380104065, "alpha_loss": -0.010316824074834585, "alpha_value": 0.0056451602356383185, "duration": 5.213697195053101, "step": 11650}
{"episode_reward": 5.058780216366006, "episode": 309.0, "batch_reward": 0.006176129914820194, "critic_loss": 0.011489578522741795, "ae_transition_loss": -1.5853796005249023, "ae_encoder_loss": 0.09097876399755478, "actor_loss": 0.11542782187461853, "actor_target_entropy": -2.0, "actor_entropy": -1.2007007598876953, "alpha_loss": -0.011367054656147957, "alpha_value": 0.005662926173220445, "duration": 0.6565773487091064, "step": 11651}
{"episode_reward": -0.6796831329511421, "episode": 310.0, "batch_reward": -0.004287328105419874, "critic_loss": 0.010435197502374649, "ae_transition_loss": -1.4575358033180237, "ae_encoder_loss": 0.10188056901097298, "actor_loss": 0.11878553777933121, "actor_target_entropy": -2.0, "actor_entropy": -1.2203153371810913, "alpha_loss": -0.009117061272263527, "alpha_value": 0.005681424458300368, "duration": 4.935178279876709, "step": 11677}
{"episode_reward": 4.53346406445333, "episode": 311.0, "batch_reward": 0.008128276626978601, "critic_loss": 0.018667679013950483, "ae_transition_loss": -1.494698132787432, "ae_encoder_loss": 0.0808636588709695, "actor_loss": 0.11318856264863696, "actor_target_entropy": -2.0, "actor_entropy": -1.1165368046079363, "alpha_loss": -0.005130976438522339, "alpha_value": 0.005733532200601624, "duration": 49.37757635116577, "step": 11741}
{"episode_reward": 21.449177958018623, "episode": 312.0, "batch_reward": 0.011688207229599356, "critic_loss": 0.02290769964456558, "ae_transition_loss": -1.8262300491333008, "ae_encoder_loss": 0.05080553740262985, "actor_loss": 0.10103992149233817, "actor_target_entropy": -2.0, "actor_entropy": -0.794717812538147, "alpha_loss": -0.011753647029399872, "alpha_value": 0.005794975864668758, "duration": 10.86627745628357, "step": 11794}
{"episode_reward": 11.758145770523067, "episode": 313.0, "batch_reward": 0.012996389530599117, "critic_loss": 0.018021080642938614, "ae_transition_loss": -1.8671098947525024, "ae_encoder_loss": 0.036668576300144196, "actor_loss": 0.155409574508667, "actor_target_entropy": -2.0, "actor_entropy": -0.7803624868392944, "alpha_loss": -0.013796942308545113, "alpha_value": 0.005829439029552056, "duration": 2.9275386333465576, "step": 11808}
{"episode_reward": -0.5538095419027551, "episode": 314.0, "duration": 0.22357678413391113, "step": 11809}
{"episode_reward": -0.15907488688212534, "episode": 315.0, "batch_reward": 0.014841351347664991, "critic_loss": 0.013967391413946947, "ae_transition_loss": -1.9500768184661865, "ae_encoder_loss": 0.043329873432715736, "actor_loss": 0.1150684580206871, "actor_target_entropy": -2.0, "actor_entropy": -1.1562260389328003, "alpha_loss": -0.010462848469614983, "alpha_value": 0.005855850552189297, "duration": 5.185184717178345, "step": 11834}
{"episode_reward": 4.46924322709164, "episode": 316.0, "duration": 0.2143690586090088, "step": 11835}
{"episode_reward": -1.8048999233681013, "episode": 317.0, "duration": 0.2322070598602295, "step": 11836}
{"episode_reward": 0.23267760922930447, "episode": 318.0, "batch_reward": 0.011077353071110943, "critic_loss": 0.017216662565867107, "ae_transition_loss": -2.0826658407847085, "ae_encoder_loss": 0.04915963610013326, "actor_loss": 0.10498179495334625, "actor_target_entropy": -2.0, "actor_entropy": -1.6141944726308186, "alpha_loss": -0.005991299481441577, "alpha_value": 0.005895174874200805, "duration": 6.479758024215698, "step": 11868}
{"episode_reward": 8.898528293205061, "episode": 319.0, "batch_reward": 0.015676981303840876, "critic_loss": 0.02605700120329857, "ae_transition_loss": -2.073781967163086, "ae_encoder_loss": 0.05883720889687538, "actor_loss": 0.08768854662775993, "actor_target_entropy": -2.0, "actor_entropy": -1.571402668952942, "alpha_loss": -0.006182987010106444, "alpha_value": 0.005925411277105653, "duration": 4.1195244789123535, "step": 11887}
{"episode_reward": 1.0965402675835454, "episode": 320.0, "batch_reward": -0.003625575336627662, "critic_loss": 0.018274526111781597, "ae_transition_loss": -2.1359702348709106, "ae_encoder_loss": 0.0575062520802021, "actor_loss": 0.1555854231119156, "actor_target_entropy": -2.0, "actor_entropy": -1.4650439023971558, "alpha_loss": -0.005992307094857097, "alpha_value": 0.005947864584124394, "duration": 4.311959743499756, "step": 11908}
{"episode_reward": 1.8465532003479366, "episode": 321.0, "batch_reward": 0.006086242385208607, "critic_loss": 0.019432850182056427, "ae_transition_loss": -2.1048951943715415, "ae_encoder_loss": 0.0704803466796875, "actor_loss": 0.19981585443019867, "actor_target_entropy": -2.0, "actor_entropy": -1.3260811567306519, "alpha_loss": -0.00799135925869147, "alpha_value": 0.005974922314640648, "duration": 38.23457479476929, "step": 11934}
{"episode_reward": 2.3896612595745883, "episode": 322.0, "duration": 0.21713042259216309, "step": 11935}
{"episode_reward": -0.4740989715180278, "episode": 323.0, "batch_reward": 0.027943881601095198, "critic_loss": 0.025718647986650467, "ae_transition_loss": -1.9862783193588256, "ae_encoder_loss": 0.07190012112259865, "actor_loss": 0.08598548918962479, "actor_target_entropy": -2.0, "actor_entropy": -1.4552084922790527, "alpha_loss": -0.006259151082485914, "alpha_value": 0.006017132086481458, "duration": 10.999808311462402, "step": 11990}
{"episode_reward": 14.420856016858076, "episode": 324.0, "batch_reward": -0.0021962962734202542, "critic_loss": 0.017601003870368004, "ae_transition_loss": -1.7498738368352253, "ae_encoder_loss": 0.09386449058850606, "actor_loss": 0.19104155401388803, "actor_target_entropy": -2.0, "actor_entropy": -0.9979862968126932, "alpha_loss": -0.01353427100305756, "alpha_value": 0.006057642899746825, "duration": 4.790050506591797, "step": 12012}
{"episode_reward": 1.5826196120632923, "episode": 325.0, "batch_reward": 0.015553080110943742, "critic_loss": 0.02340359693127019, "ae_transition_loss": -1.7559874057769775, "ae_encoder_loss": 0.08396256182874952, "actor_loss": 0.10852509204830442, "actor_target_entropy": -2.0, "actor_entropy": -0.9831297738211495, "alpha_loss": -0.010601898788341455, "alpha_value": 0.00612114234787113, "duration": 15.217528104782104, "step": 12087}
{"episode_reward": 23.991706800582318, "episode": 326.0, "batch_reward": 0.01203431747853756, "critic_loss": 0.013327762484550476, "ae_transition_loss": -1.7501121163368225, "ae_encoder_loss": 0.05707240477204323, "actor_loss": 0.07780227065086365, "actor_target_entropy": -2.0, "actor_entropy": -1.633358120918274, "alpha_loss": -0.01112636923789978, "alpha_value": 0.006180312954084409, "duration": 3.749354839324951, "step": 12104}
{"episode_reward": -0.9949981594911498, "episode": 327.0, "batch_reward": 0.007781316215793292, "critic_loss": 0.024163244913021725, "ae_transition_loss": -1.7536386251449585, "ae_encoder_loss": 0.06694261605540912, "actor_loss": 0.08086462939778964, "actor_target_entropy": -2.0, "actor_entropy": -1.5427120129267375, "alpha_loss": -0.011994322451452414, "alpha_value": 0.006213809628070328, "duration": 6.367001533508301, "step": 12134}
{"episode_reward": 7.409925483295103, "episode": 328.0, "batch_reward": 0.018146782647818327, "critic_loss": 0.030999441631138325, "ae_transition_loss": -1.7259430885314941, "ae_encoder_loss": 0.08262742310762405, "actor_loss": 0.1014285683631897, "actor_target_entropy": -2.0, "actor_entropy": -1.2585690021514893, "alpha_loss": -0.013982107397168875, "alpha_value": 0.006248792610022553, "duration": 4.286039113998413, "step": 12153}
{"episode_reward": 0.4529305190738521, "episode": 329.0, "batch_reward": -0.009372313041239977, "critic_loss": 0.015094217844307423, "ae_transition_loss": -1.7668444514274597, "ae_encoder_loss": 0.0820942223072052, "actor_loss": 0.152082160115242, "actor_target_entropy": -2.0, "actor_entropy": -0.8846161961555481, "alpha_loss": -0.014522505924105644, "alpha_value": 0.006278392803972528, "duration": 4.4163970947265625, "step": 12173}
{"episode_reward": 3.7341652574891446, "episode": 330.0, "batch_reward": 0.020938641702135403, "critic_loss": 0.022527751202384632, "ae_transition_loss": -1.8421022097269695, "ae_encoder_loss": 0.09915534158547719, "actor_loss": 0.08503033220767975, "actor_target_entropy": -2.0, "actor_entropy": -0.5868341326713562, "alpha_loss": -0.013749967950085798, "alpha_value": 0.0063173725169992576, "duration": 6.7120680809021, "step": 12206}
{"episode_reward": 4.85461261305472, "episode": 331.0, "batch_reward": -0.009202801156789064, "critic_loss": 0.014497420750558376, "ae_transition_loss": -1.7678829034169514, "ae_encoder_loss": 0.11721641570329666, "actor_loss": 0.11149449894825618, "actor_target_entropy": -2.0, "actor_entropy": -1.1650816599527996, "alpha_loss": -0.009270171324412027, "alpha_value": 0.006364908094875732, "duration": 59.96775484085083, "step": 12231}
{"episode_reward": 3.3881951003177355, "episode": 332.0, "duration": 0.9796924591064453, "step": 12236}
{"episode_reward": -1.5298707371442304, "episode": 333.0, "batch_reward": 0.00994376913877204, "critic_loss": 0.025346535723656416, "ae_transition_loss": -1.7779788970947266, "ae_encoder_loss": 0.10588848777115345, "actor_loss": 0.142256498336792, "actor_target_entropy": -2.0, "actor_entropy": -0.30858311243355274, "alpha_loss": -0.003983461298048496, "alpha_value": 0.006415793203225394, "duration": 7.962087154388428, "step": 12272}
{"episode_reward": -1.392046239736754, "episode": 334.0, "batch_reward": -0.001959461427759379, "critic_loss": 0.014108262956142426, "ae_transition_loss": -1.8936797976493835, "ae_encoder_loss": 0.08218418434262276, "actor_loss": 0.11117179319262505, "actor_target_entropy": -2.0, "actor_entropy": -0.7397601008415222, "alpha_loss": -0.009038134478032589, "alpha_value": 0.006452715991730539, "duration": 5.041774749755859, "step": 12296}
{"episode_reward": -1.1078164422365766, "episode": 335.0, "duration": 0.275604248046875, "step": 12297}
{"episode_reward": -0.47132906317710876, "episode": 336.0, "duration": 0.22778820991516113, "step": 12298}
{"episode_reward": -0.6597260799427593, "episode": 337.0, "batch_reward": 0.0074828388169407845, "critic_loss": 0.007955813780426979, "ae_transition_loss": -1.9252663850784302, "ae_encoder_loss": 0.08367570489645004, "actor_loss": 0.105660580098629, "actor_target_entropy": -2.0, "actor_entropy": -0.8661028146743774, "alpha_loss": -0.008976437151432037, "alpha_value": 0.006470368819272517, "duration": 2.5678422451019287, "step": 12310}
{"episode_reward": -3.4935505130845845, "episode": 338.0, "batch_reward": 0.02443189515421788, "critic_loss": 0.023394042005141575, "ae_transition_loss": -1.9602930148442586, "ae_encoder_loss": 0.08641633639732997, "actor_loss": 0.11778360108534495, "actor_target_entropy": -2.0, "actor_entropy": -0.8831393321355184, "alpha_loss": -0.008638832718133926, "alpha_value": 0.006493935639990327, "duration": 4.946509122848511, "step": 12332}
{"episode_reward": -0.800637960591607, "episode": 339.0, "batch_reward": 0.004442551406100392, "critic_loss": 0.010564961470663548, "ae_transition_loss": -2.0687179565429688, "ae_encoder_loss": 0.08260948583483696, "actor_loss": 0.11221936717629433, "actor_target_entropy": -2.0, "actor_entropy": -1.0187967717647552, "alpha_loss": -0.00801208964549005, "alpha_value": 0.006523218280895837, "duration": 4.609618663787842, "step": 12354}
{"episode_reward": 1.834120322014765, "episode": 340.0, "batch_reward": 0.06616942584514618, "critic_loss": 0.04196260869503021, "ae_transition_loss": -2.0083084106445312, "ae_encoder_loss": 0.09283191710710526, "actor_loss": 0.06684090197086334, "actor_target_entropy": -2.0, "actor_entropy": -0.9119257926940918, "alpha_loss": -0.00938886683434248, "alpha_value": 0.006540557501004905, "duration": 3.5274465084075928, "step": 12370}
{"episode_reward": 0.00023604071590493936, "episode": 341.0, "batch_reward": 0.014917836524546146, "critic_loss": 0.01586370263248682, "ae_transition_loss": -2.0368120670318604, "ae_encoder_loss": 0.09322402253746986, "actor_loss": 0.05340432934463024, "actor_target_entropy": -2.0, "actor_entropy": -0.8506282866001129, "alpha_loss": -0.010177718475461006, "alpha_value": 0.00655798158126531, "duration": 45.37194752693176, "step": 12387}
{"episode_reward": -1.549634484095388, "episode": 342.0, "batch_reward": 0.003816140815615654, "critic_loss": 0.01977505348622799, "ae_transition_loss": -2.0513179302215576, "ae_encoder_loss": 0.08886304497718811, "actor_loss": 0.06591874361038208, "actor_target_entropy": -2.0, "actor_entropy": -1.0027402639389038, "alpha_loss": -0.014630273915827274, "alpha_value": 0.006575766254445154, "duration": 2.767587184906006, "step": 12399}
{"episode_reward": -2.2824807381638665, "episode": 343.0, "batch_reward": 0.028743353051443894, "critic_loss": 0.026530902832746506, "ae_transition_loss": -1.9781992832819622, "ae_encoder_loss": 0.11390697707732518, "actor_loss": 0.10590196897586186, "actor_target_entropy": -2.0, "actor_entropy": -1.2029435634613037, "alpha_loss": -0.011761390914519628, "alpha_value": 0.006601526263440346, "duration": 5.15756630897522, "step": 12423}
{"episode_reward": 1.7563743928057964, "episode": 344.0, "batch_reward": 0.02711282018572092, "critic_loss": 0.027252004947513342, "ae_transition_loss": -2.0184797942638397, "ae_encoder_loss": 0.11202477291226387, "actor_loss": 0.051554618403315544, "actor_target_entropy": -2.0, "actor_entropy": -1.1833122670650482, "alpha_loss": -0.012556940782815218, "alpha_value": 0.006648485884595439, "duration": 9.990275144577026, "step": 12470}
{"episode_reward": 14.968359844070612, "episode": 345.0, "batch_reward": 0.015490584385891756, "critic_loss": 0.018541056662797928, "ae_transition_loss": -1.9204318523406982, "ae_encoder_loss": 0.09461286912361781, "actor_loss": 0.09374478707710902, "actor_target_entropy": -2.0, "actor_entropy": -0.7854953010876974, "alpha_loss": -0.010698646306991577, "alpha_value": 0.0066983951078702685, "duration": 5.211443662643433, "step": 12493}
{"episode_reward": 0.5510013370335486, "episode": 346.0, "batch_reward": 0.053235046565532684, "critic_loss": 0.021335292607545853, "ae_transition_loss": -1.9640284776687622, "ae_encoder_loss": 0.10072725266218185, "actor_loss": 0.11069940775632858, "actor_target_entropy": -2.0, "actor_entropy": -0.5240043997764587, "alpha_loss": -0.006604017689824104, "alpha_value": 0.006727339348930533, "duration": 2.6317219734191895, "step": 12506}
{"episode_reward": -0.3177173648730087, "episode": 347.0, "duration": 0.3678553104400635, "step": 12507}
{"episode_reward": -0.05387252276619564, "episode": 348.0, "batch_reward": 0.005219877697527409, "critic_loss": 0.011669738994290432, "ae_transition_loss": -1.9478041330973308, "ae_encoder_loss": 0.11262983083724976, "actor_loss": 0.15167573591073355, "actor_target_entropy": -2.0, "actor_entropy": -0.5828242401281992, "alpha_loss": -0.0033402263652533293, "alpha_value": 0.006753335335821357, "duration": 5.8148581981658936, "step": 12534}
{"episode_reward": 0.05857108744160061, "episode": 349.0, "batch_reward": 0.01373395195696503, "critic_loss": 0.014829336355129877, "ae_transition_loss": -1.993359128634135, "ae_encoder_loss": 0.09614366292953491, "actor_loss": 0.11258259539802869, "actor_target_entropy": -2.0, "actor_entropy": -0.802984207868576, "alpha_loss": -0.004619080534515281, "alpha_value": 0.006802296862889703, "duration": 13.166634798049927, "step": 12598}
{"episode_reward": 10.828516444678547, "episode": 350.0, "batch_reward": 0.025674117729067802, "critic_loss": 0.01588176190853119, "ae_transition_loss": -2.034024238586426, "ae_encoder_loss": 0.09706785902380943, "actor_loss": 0.0767693743109703, "actor_target_entropy": -2.0, "actor_entropy": -1.3486990928649902, "alpha_loss": -0.011436858214437962, "alpha_value": 0.006839578847365892, "duration": 3.929246664047241, "step": 12616}
{"episode_reward": 0.547285480612373, "episode": 351.0, "batch_reward": 0.020739988918649033, "critic_loss": 0.021768451144453138, "ae_transition_loss": -1.9053764194250107, "ae_encoder_loss": 0.10953079303726554, "actor_loss": 0.12018038658425212, "actor_target_entropy": -2.0, "actor_entropy": -1.4221874475479126, "alpha_loss": -0.00997493889008183, "alpha_value": 0.0069523372726305694, "duration": 90.81623792648315, "step": 12780}
{"episode_reward": 57.08367326964857, "episode": 352.0, "batch_reward": 0.023528359131887555, "critic_loss": 0.019366420106962323, "ae_transition_loss": -1.9458160102367401, "ae_encoder_loss": 0.11174985021352768, "actor_loss": 0.09755264781415462, "actor_target_entropy": -2.0, "actor_entropy": -1.041416347026825, "alpha_loss": -0.01121406489983201, "alpha_value": 0.007074339207588123, "duration": 7.020583391189575, "step": 12814}
{"episode_reward": 7.467601118768702, "episode": 353.0, "batch_reward": 0.024589485256001353, "critic_loss": 0.016782630002126098, "ae_transition_loss": -1.7467402517795563, "ae_encoder_loss": 0.13323060795664787, "actor_loss": 0.08973599411547184, "actor_target_entropy": -2.0, "actor_entropy": -0.7046746164560318, "alpha_loss": -0.011113509302958846, "alpha_value": 0.007148775647500574, "duration": 16.01951575279236, "step": 12891}
{"episode_reward": 25.131216016961034, "episode": 354.0, "batch_reward": 0.0454397052526474, "critic_loss": 0.02891724556684494, "ae_transition_loss": -1.8107531070709229, "ae_encoder_loss": 0.14482632279396057, "actor_loss": 0.04252888634800911, "actor_target_entropy": -2.0, "actor_entropy": 0.03069499135017395, "alpha_loss": -0.003538531018421054, "alpha_value": 0.007208427583201128, "duration": 3.423427104949951, "step": 12909}
{"episode_reward": -2.310258815525615, "episode": 355.0, "batch_reward": 0.03232550993561745, "critic_loss": 0.02682036254554987, "ae_transition_loss": -1.8689936995506287, "ae_encoder_loss": 0.12700291350483894, "actor_loss": 0.08800047263503075, "actor_target_entropy": -2.0, "actor_entropy": -0.42793240398168564, "alpha_loss": -0.008479309268295765, "alpha_value": 0.007226920614755302, "duration": 3.1435134410858154, "step": 12922}
{"episode_reward": -1.9315986553419213, "episode": 356.0, "batch_reward": 0.05261624604463577, "critic_loss": 0.021627359092235565, "ae_transition_loss": -1.8654165267944336, "ae_encoder_loss": 0.133760005235672, "actor_loss": 0.11894860863685608, "actor_target_entropy": -2.0, "actor_entropy": -1.0021164417266846, "alpha_loss": -0.012281514704227448, "alpha_value": 0.007245192650730467, "duration": 3.663945198059082, "step": 12940}
{"episode_reward": -2.507387377470056, "episode": 357.0, "batch_reward": 0.013208363321609795, "critic_loss": 0.013993261381983757, "ae_transition_loss": -1.8233656287193298, "ae_encoder_loss": 0.12340348958969116, "actor_loss": 0.14248234033584595, "actor_target_entropy": -2.0, "actor_entropy": -1.2430719137191772, "alpha_loss": -0.012009033933281898, "alpha_value": 0.007264135134360085, "duration": 3.8119025230407715, "step": 12958}
{"episode_reward": 1.9492591408024267, "episode": 358.0, "batch_reward": 0.019713904708623886, "critic_loss": 0.024448572658002377, "ae_transition_loss": -1.7950050234794617, "ae_encoder_loss": 0.13518298789858818, "actor_loss": 0.1400892287492752, "actor_target_entropy": -2.0, "actor_entropy": -1.0959567427635193, "alpha_loss": -0.00860884739086032, "alpha_value": 0.007290242232178215, "duration": 4.25982403755188, "step": 12978}
{"episode_reward": -2.478458149613454, "episode": 359.0, "duration": 0.24470114707946777, "step": 12979}
{"episode_reward": -0.19558031857013702, "episode": 360.0, "batch_reward": 0.037703320384025574, "critic_loss": 0.024816622957587242, "ae_transition_loss": -1.8469777901967366, "ae_encoder_loss": 0.1280618409315745, "actor_loss": 0.08695715665817261, "actor_target_entropy": -2.0, "actor_entropy": -0.6636955340703329, "alpha_loss": -0.0046953366448481875, "alpha_value": 0.0073214233395951815, "duration": 5.559294700622559, "step": 13005}
{"episode_reward": 1.112145833571193, "episode": 361.0, "batch_reward": 0.03172320816665888, "critic_loss": 0.027241387590765952, "ae_transition_loss": -1.8289149761199952, "ae_encoder_loss": 0.13951771408319474, "actor_loss": 0.07305115312337876, "actor_target_entropy": -2.0, "actor_entropy": -0.7297241687774658, "alpha_loss": -0.00847237855195999, "alpha_value": 0.00736563082173365, "duration": 103.41131734848022, "step": 13058}
{"episode_reward": 15.641332121752358, "episode": 362.0, "batch_reward": 0.03656846651045436, "critic_loss": 0.02807342532006177, "ae_transition_loss": -1.815094980326566, "ae_encoder_loss": 0.12714599140665747, "actor_loss": 0.1008666804568334, "actor_target_entropy": -2.0, "actor_entropy": -0.6431886770508506, "alpha_loss": -0.008912690237841824, "alpha_value": 0.0074592559875437114, "duration": 22.857360124588013, "step": 13167}
{"episode_reward": 47.13511367905562, "episode": 363.0, "batch_reward": 0.017580073419958354, "critic_loss": 0.02947995364665985, "ae_transition_loss": -1.7777592182159423, "ae_encoder_loss": 0.1239549234509468, "actor_loss": 0.1336217552423477, "actor_target_entropy": -2.0, "actor_entropy": -0.3939401715993881, "alpha_loss": 0.00030164942145347593, "alpha_value": 0.00754976779547247, "duration": 10.202100276947021, "step": 13216}
{"episode_reward": 22.997060877193046, "episode": 364.0, "batch_reward": 0.04024613602086902, "critic_loss": 0.031755874399095774, "ae_transition_loss": -1.5765119791030884, "ae_encoder_loss": 0.09986010193824768, "actor_loss": 0.06360575277358294, "actor_target_entropy": -2.0, "actor_entropy": -0.278605330735445, "alpha_loss": 0.001915323213324882, "alpha_value": 0.007579673884990442, "duration": 7.751864433288574, "step": 13251}
{"episode_reward": 7.919607828288204, "episode": 365.0, "batch_reward": 0.03648252114653587, "critic_loss": 0.0242674021050334, "ae_transition_loss": -1.3677203893661498, "ae_encoder_loss": 0.12642169743776321, "actor_loss": 0.07816357314586639, "actor_target_entropy": -2.0, "actor_entropy": -0.2625317484140396, "alpha_loss": -0.00466458008158952, "alpha_value": 0.007595502616098146, "duration": 11.759865283966064, "step": 13308}
{"episode_reward": 17.608576350980066, "episode": 366.0, "batch_reward": 0.03742964565753937, "critic_loss": 0.03352733515202999, "ae_transition_loss": -1.0121282935142517, "ae_encoder_loss": 0.1534803956747055, "actor_loss": 0.057217804715037346, "actor_target_entropy": -2.0, "actor_entropy": -0.39609062671661377, "alpha_loss": -0.014985974878072739, "alpha_value": 0.007610563970190812, "duration": 4.179999589920044, "step": 13327}
{"episode_reward": 2.0717481663835287, "episode": 367.0, "duration": 0.22742009162902832, "step": 13328}
{"episode_reward": -0.7997510433197021, "episode": 368.0, "batch_reward": 0.022687891498208046, "critic_loss": 0.07257871329784393, "ae_transition_loss": -0.3087303638458252, "ae_encoder_loss": 0.1586577519774437, "actor_loss": 0.2459498643875122, "actor_target_entropy": -2.0, "actor_entropy": 0.02257503941655159, "alpha_loss": -0.015719471499323845, "alpha_value": 0.007625562468740918, "duration": 4.4919915199279785, "step": 13348}
{"episode_reward": -2.294765726023747, "episode": 369.0, "batch_reward": 0.042247939854860306, "critic_loss": 0.08375081643462182, "ae_transition_loss": -1.0877520203590394, "ae_encoder_loss": 0.10825841575860977, "actor_loss": 0.05216013640165329, "actor_target_entropy": -2.0, "actor_entropy": -0.452526381611824, "alpha_loss": -0.01836398206651211, "alpha_value": 0.007664520032314245, "duration": 10.087868452072144, "step": 13398}
{"episode_reward": 6.623756258952835, "episode": 370.0, "batch_reward": 0.04532577656209469, "critic_loss": 0.0441165417432785, "ae_transition_loss": -0.9691727757453918, "ae_encoder_loss": 0.06481785327196121, "actor_loss": 0.11379138380289078, "actor_target_entropy": -2.0, "actor_entropy": 0.10470525547862053, "alpha_loss": -0.017776240594685078, "alpha_value": 0.007715095082720979, "duration": 3.375802993774414, "step": 13413}
{"episode_reward": -2.639865904410846, "episode": 371.0, "batch_reward": 0.012269631959497929, "critic_loss": 0.14779123663902283, "ae_transition_loss": -0.975123405456543, "ae_encoder_loss": 0.0498244222253561, "actor_loss": 0.2813262343406677, "actor_target_entropy": -2.0, "actor_entropy": 0.13657332211732864, "alpha_loss": -0.009207203285768628, "alpha_value": 0.007749012360975969, "duration": 25.30386447906494, "step": 13437}
{"episode_reward": -14.28294362525406, "episode": 372.0, "duration": 0.23523545265197754, "step": 13438}
{"episode_reward": -0.01696489949494693, "episode": 373.0, "batch_reward": 0.017912391883631546, "critic_loss": 0.27858476464947063, "ae_transition_loss": -1.0125514268875122, "ae_encoder_loss": 0.056311129281918205, "actor_loss": 0.5451168914635977, "actor_target_entropy": -2.0, "actor_entropy": 3.191829522450765, "alpha_loss": -0.020519856130704284, "alpha_value": 0.00778886828665247, "duration": 5.213823556900024, "step": 13462}
{"episode_reward": -20.245045478142195, "episode": 374.0, "batch_reward": 0.026559317399832336, "critic_loss": 0.18902131982825018, "ae_transition_loss": -1.0927883332425898, "ae_encoder_loss": 0.06561598351055925, "actor_loss": 0.7922693003307689, "actor_target_entropy": -2.0, "actor_entropy": 0.24852993271567606, "alpha_loss": -0.07923213180831888, "alpha_value": 0.007986196567292242, "duration": 22.309247493743896, "step": 13572}
{"episode_reward": -105.7556257926017, "episode": 375.0, "batch_reward": 0.0007848183934887251, "critic_loss": 0.12549578150113425, "ae_transition_loss": -1.304745892683665, "ae_encoder_loss": 0.0747376624494791, "actor_loss": 0.6457852125167847, "actor_target_entropy": -2.0, "actor_entropy": 1.0968332886695862, "alpha_loss": -0.007315428073828419, "alpha_value": 0.00829066678620977, "duration": 13.44897174835205, "step": 13639}
{"episode_reward": -52.443291931713176, "episode": 376.0, "batch_reward": 0.038394223898649216, "critic_loss": 0.14057394862174988, "ae_transition_loss": -1.3026740550994873, "ae_encoder_loss": 0.07131042331457138, "actor_loss": 0.4126334488391876, "actor_target_entropy": -2.0, "actor_entropy": 1.2648980617523193, "alpha_loss": 0.0021429527550935745, "alpha_value": 0.008379608876864859, "duration": 2.3314216136932373, "step": 13650}
{"episode_reward": -4.422465198807362, "episode": 377.0, "batch_reward": 0.010223712772130966, "critic_loss": 0.18373280266920725, "ae_transition_loss": -0.908203105131785, "ae_encoder_loss": 0.10101133088270824, "actor_loss": 0.1104874312877655, "actor_target_entropy": -2.0, "actor_entropy": 1.303964614868164, "alpha_loss": 0.0007306115488366535, "alpha_value": 0.008416404706329511, "duration": 5.1959474086761475, "step": 13675}
{"episode_reward": -3.9714928023022105, "episode": 378.0, "duration": 0.23991894721984863, "step": 13676}
{"episode_reward": -0.6420759526454053, "episode": 379.0, "batch_reward": 0.03425156511366367, "critic_loss": 0.0916569357117017, "ae_transition_loss": -1.2751764853795369, "ae_encoder_loss": 0.09530545274416606, "actor_loss": 0.04806508310139179, "actor_target_entropy": -2.0, "actor_entropy": -0.43503399689992267, "alpha_loss": 0.0004653862367073695, "alpha_value": 0.008460069283342182, "duration": 5.793991804122925, "step": 13703}
{"episode_reward": -3.9173212528674046, "episode": 380.0, "batch_reward": -0.0032070865854620934, "critic_loss": 0.10873457789421082, "ae_transition_loss": -1.2310656309127808, "ae_encoder_loss": 0.03709197137504816, "actor_loss": 0.259087473154068, "actor_target_entropy": -2.0, "actor_entropy": 1.482192575931549, "alpha_loss": 0.010503856465220451, "alpha_value": 0.008487307715462192, "duration": 4.457671403884888, "step": 13724}
{"episode_reward": -3.055410145149831, "episode": 381.0, "batch_reward": 0.019024235506852467, "critic_loss": 0.15151551365852356, "ae_transition_loss": -1.2489936749140422, "ae_encoder_loss": 0.06672586997350057, "actor_loss": 0.10225658242901166, "actor_target_entropy": -2.0, "actor_entropy": 0.11491252978642781, "alpha_loss": 0.0011469008556256692, "alpha_value": 0.008504361664222118, "duration": 39.967528104782104, "step": 13755}
{"episode_reward": -1.06529875388407, "episode": 382.0, "batch_reward": 0.029291813261806965, "critic_loss": 0.10677205957472324, "ae_transition_loss": -1.3748953938484192, "ae_encoder_loss": 0.04012667387723923, "actor_loss": 0.08000178064685315, "actor_target_entropy": -2.0, "actor_entropy": -0.29306576400995255, "alpha_loss": -0.006023370660841465, "alpha_value": 0.008517291627899399, "duration": 4.00722861289978, "step": 13774}
{"episode_reward": 0.8199087508694536, "episode": 383.0, "batch_reward": 0.0059325011063586265, "critic_loss": 0.17924072242834987, "ae_transition_loss": -1.5215912776834823, "ae_encoder_loss": 0.044060673948158234, "actor_loss": 0.5262079808641883, "actor_target_entropy": -2.0, "actor_entropy": 0.17651269628721125, "alpha_loss": -0.0014985698850496726, "alpha_value": 0.00855417876206617, "duration": 35.774165391922, "step": 13948}
{"episode_reward": -74.66122381224436, "episode": 384.0, "batch_reward": 0.003946236101910472, "critic_loss": 0.0858775619417429, "ae_transition_loss": -1.4175284802913666, "ae_encoder_loss": 0.058572073467075825, "actor_loss": 0.1747757587581873, "actor_target_entropy": -2.0, "actor_entropy": 0.20679818838834763, "alpha_loss": 0.0030699141789227724, "alpha_value": 0.008575574128929534, "duration": 7.28411078453064, "step": 13983}
{"episode_reward": 7.063182461148138, "episode": 385.0, "batch_reward": 0.02225824072957039, "critic_loss": 0.08255103975534439, "ae_transition_loss": -1.448374629020691, "ae_encoder_loss": 0.052948202937841415, "actor_loss": 0.31919723749160767, "actor_target_entropy": -2.0, "actor_entropy": 0.8969775438308716, "alpha_loss": 0.007588796783238649, "alpha_value": 0.008577305959050556, "duration": 2.7138092517852783, "step": 13996}
{"episode_reward": -1.777752999994711, "episode": 386.0, "batch_reward": 0.01987184975296259, "critic_loss": 0.06613084748387336, "ae_transition_loss": -1.5805914640426635, "ae_encoder_loss": 0.05651337131857872, "actor_loss": 0.19338313043117522, "actor_target_entropy": -2.0, "actor_entropy": -0.2517473638057709, "alpha_loss": -0.005003810953348875, "alpha_value": 0.008576215143760866, "duration": 9.342456340789795, "step": 14041}
{"episode_reward": 4.150487940713537, "episode": 387.0, "batch_reward": 0.015734031796455383, "critic_loss": 0.04184877499938011, "ae_transition_loss": -1.6550439596176147, "ae_encoder_loss": 0.029324783012270927, "actor_loss": 0.07802416384220123, "actor_target_entropy": -2.0, "actor_entropy": -0.861052930355072, "alpha_loss": -0.016747549176216125, "alpha_value": 0.008577884886101466, "duration": 3.112765073776245, "step": 14056}
{"episode_reward": -2.47167220251345, "episode": 388.0, "batch_reward": 0.009130085508028666, "critic_loss": 0.056729755053917565, "ae_transition_loss": -1.787771741549174, "ae_encoder_loss": 0.062098621080319084, "actor_loss": 0.10695949196815491, "actor_target_entropy": -2.0, "actor_entropy": -1.6646562019983928, "alpha_loss": -0.01766902891298135, "alpha_value": 0.008583903570122882, "duration": 6.5121684074401855, "step": 14087}
{"episode_reward": 1.5354139147606598, "episode": 389.0, "duration": 0.22718238830566406, "step": 14088}
{"episode_reward": -0.33585745096206665, "episode": 390.0, "batch_reward": 0.01528364202628533, "critic_loss": 0.04503463332851728, "ae_transition_loss": -1.9668186902999878, "ae_encoder_loss": 0.04143626118699709, "actor_loss": 0.2031947374343872, "actor_target_entropy": -2.0, "actor_entropy": -0.7479328711827596, "alpha_loss": -0.022354160745938618, "alpha_value": 0.00859968663208497, "duration": 5.8883891105651855, "step": 14116}
{"episode_reward": 7.548353009045875, "episode": 391.0, "batch_reward": 0.016131493262946606, "critic_loss": 0.04189988225698471, "ae_transition_loss": -2.1816251277923584, "ae_encoder_loss": 0.02505240651468436, "actor_loss": 0.06905096520980199, "actor_target_entropy": -2.0, "actor_entropy": -1.0044352809588115, "alpha_loss": -0.01904589372376601, "alpha_value": 0.00862400239654384, "duration": 43.652448415756226, "step": 14143}
{"episode_reward": -0.33612836820659137, "episode": 392.0, "batch_reward": 0.01057306157114605, "critic_loss": 0.032442708422119416, "ae_transition_loss": -2.6014057199160256, "ae_encoder_loss": 0.02704906164823721, "actor_loss": 0.15006979182362556, "actor_target_entropy": -2.0, "actor_entropy": -1.2128506675362587, "alpha_loss": -0.018910916444535058, "alpha_value": 0.008780520530304594, "duration": 48.72748589515686, "step": 14383}
{"episode_reward": -20.17935546683502, "episode": 393.0, "batch_reward": -0.002152408805808851, "critic_loss": 0.03281340029622827, "ae_transition_loss": -2.6354900428227017, "ae_encoder_loss": 0.026194421707519462, "actor_loss": 0.19709828070231847, "actor_target_entropy": -2.0, "actor_entropy": -0.8650528831141335, "alpha_loss": -0.0076141217390873605, "alpha_value": 0.008976116466718245, "duration": 14.56906270980835, "step": 14454}
{"episode_reward": 8.103959596457281, "episode": 394.0, "batch_reward": -0.0013639846195777257, "critic_loss": 0.02375838595132033, "ae_transition_loss": -2.6489601135253906, "ae_encoder_loss": 0.02039001478503148, "actor_loss": 0.25331844886144, "actor_target_entropy": -2.0, "actor_entropy": -0.5609591007232666, "alpha_loss": -0.005469311028718948, "alpha_value": 0.009024345125490685, "duration": 6.5050060749053955, "step": 14485}
{"episode_reward": 8.352046963770919, "episode": 395.0, "batch_reward": 0.03353022895753384, "critic_loss": 0.03159160315990448, "ae_transition_loss": -2.6911494731903076, "ae_encoder_loss": 0.014407781511545181, "actor_loss": 0.15046179592609404, "actor_target_entropy": -2.0, "actor_entropy": -1.2564022064208984, "alpha_loss": -0.011204073205590248, "alpha_value": 0.00905419639262074, "duration": 10.896722078323364, "step": 14539}
{"episode_reward": 17.128365992037857, "episode": 396.0, "batch_reward": 0.050759727135300636, "critic_loss": 0.03605028800666332, "ae_transition_loss": -2.7133058309555054, "ae_encoder_loss": 0.020751203875988722, "actor_loss": 0.13424032181501389, "actor_target_entropy": -2.0, "actor_entropy": -0.5956422388553619, "alpha_loss": -0.019129044841974974, "alpha_value": 0.00908069332257307, "duration": 4.091811656951904, "step": 14558}
{"episode_reward": -0.8083969806176781, "episode": 397.0, "batch_reward": 0.016880672425031662, "critic_loss": 0.04137264937162399, "ae_transition_loss": -2.7318532466888428, "ae_encoder_loss": 0.04204916022717953, "actor_loss": 0.2010628953576088, "actor_target_entropy": -2.0, "actor_entropy": -1.1624909043312073, "alpha_loss": -0.022753598168492317, "alpha_value": 0.00909872802393233, "duration": 4.767708778381348, "step": 14580}
{"episode_reward": 1.639478045009343, "episode": 398.0, "batch_reward": 0.019991070963442326, "critic_loss": 0.03502555564045906, "ae_transition_loss": -2.8055436611175537, "ae_encoder_loss": 0.038872161880135536, "actor_loss": 0.15667782723903656, "actor_target_entropy": -2.0, "actor_entropy": -1.5106208324432373, "alpha_loss": -0.017363018356263638, "alpha_value": 0.009119504643913003, "duration": 3.113161563873291, "step": 14593}
{"episode_reward": -0.4841734421585193, "episode": 399.0, "batch_reward": 0.03068369277752936, "critic_loss": 0.031173442024737597, "ae_transition_loss": -2.880276918411255, "ae_encoder_loss": 0.03408596571534872, "actor_loss": 0.11490614339709282, "actor_target_entropy": -2.0, "actor_entropy": -0.9075548350811005, "alpha_loss": -0.015252120094373822, "alpha_value": 0.009151898674212356, "duration": 8.96657395362854, "step": 14636}
{"episode_reward": 15.874394609118404, "episode": 400.0, "batch_reward": 0.008884973668803772, "critic_loss": 0.029164426649610203, "ae_transition_loss": -2.7305100758870444, "ae_encoder_loss": 0.03363732031236092, "actor_loss": 0.19134452193975449, "actor_target_entropy": -2.0, "actor_entropy": -1.007331778605779, "alpha_loss": -0.013135128809760014, "alpha_value": 0.00920722855481905, "duration": 13.075783967971802, "step": 14698}
{"episode_reward": 40.63052038626721, "episode": 401.0, "batch_reward": 0.023553213725487392, "critic_loss": 0.03174656220815248, "ae_transition_loss": -2.650583121511671, "ae_encoder_loss": 0.03537706673766176, "actor_loss": 0.1679110825061798, "actor_target_entropy": -2.0, "actor_entropy": -0.8389648613002565, "alpha_loss": -0.012527089514252212, "alpha_value": 0.00932794667037703, "duration": 147.60134029388428, "step": 14872}
{"episode_reward": 48.2479773663823, "episode": 402.0, "batch_reward": 0.019998957752250135, "critic_loss": 0.0473763276822865, "ae_transition_loss": -2.6279460191726685, "ae_encoder_loss": 0.03980335360392928, "actor_loss": 0.1842337679117918, "actor_target_entropy": -2.0, "actor_entropy": -1.1202974319458008, "alpha_loss": -0.012643638765439391, "alpha_value": 0.009435883237947085, "duration": 8.35053014755249, "step": 14913}
{"episode_reward": 5.126541353619217, "episode": 403.0, "batch_reward": 0.019128320273011923, "critic_loss": 0.03193997824564576, "ae_transition_loss": -2.762501537799835, "ae_encoder_loss": 0.04091448150575161, "actor_loss": 0.2063460759818554, "actor_target_entropy": -2.0, "actor_entropy": -1.1397608518600464, "alpha_loss": -0.015081861987709999, "alpha_value": 0.009474449381304057, "duration": 8.14049243927002, "step": 14953}
{"episode_reward": 14.907559688084897, "episode": 404.0, "batch_reward": -0.00549274729564786, "critic_loss": 0.02538614347577095, "ae_transition_loss": -2.859701156616211, "ae_encoder_loss": 0.04510544426739216, "actor_loss": 0.19135832041502, "actor_target_entropy": -2.0, "actor_entropy": -1.0406080186367035, "alpha_loss": -0.010468063177540898, "alpha_value": 0.009504743799319221, "duration": 4.134196519851685, "step": 14972}
{"episode_reward": -2.0435565242318114, "episode": 405.0, "batch_reward": 0.03000457709034284, "critic_loss": 0.04667014628648758, "ae_transition_loss": -2.816298723220825, "ae_encoder_loss": 0.07169463237126668, "actor_loss": 0.12979081273078918, "actor_target_entropy": -2.0, "actor_entropy": -0.4454529086748759, "alpha_loss": -0.0019046577702586849, "alpha_value": 0.00952872002783653, "duration": 7.40492844581604, "step": 15009}
{"episode_reward": 2.6251232625526817, "episode": 406.0, "batch_reward": 0.009491569362580776, "critic_loss": 0.03893169201910496, "ae_transition_loss": -2.956291675567627, "ae_encoder_loss": 0.06267082318663597, "actor_loss": 0.11843112111091614, "actor_target_entropy": -2.0, "actor_entropy": -0.7100936472415924, "alpha_loss": -0.004265921888872981, "alpha_value": 0.009548413871702587, "duration": 3.5790703296661377, "step": 15027}
{"episode_reward": -1.0042663579774131, "episode": 407.0, "batch_reward": 0.03367221634835005, "critic_loss": 0.029088012874126434, "ae_transition_loss": -2.8712215423583984, "ae_encoder_loss": 0.03348604030907154, "actor_loss": 0.12128297612071037, "actor_target_entropy": -2.0, "actor_entropy": -1.0095185041427612, "alpha_loss": -0.012598683591932058, "alpha_value": 0.00956217391296759, "duration": 3.5096421241760254, "step": 15044}
{"episode_reward": 1.091265634771422, "episode": 408.0, "duration": 0.2020876407623291, "step": 15045}
{"episode_reward": -0.4609358502366339, "episode": 409.0, "duration": 0.23952555656433105, "step": 15046}
{"episode_reward": -0.48995991236078984, "episode": 410.0, "batch_reward": 0.02599614965064185, "critic_loss": 0.03565179742872715, "ae_transition_loss": -2.7155522959572926, "ae_encoder_loss": 0.054421570152044296, "actor_loss": 0.16874818610293524, "actor_target_entropy": -2.0, "actor_entropy": -1.1500921930585588, "alpha_loss": -0.01573394930788449, "alpha_value": 0.009598607975445882, "duration": 14.360013723373413, "step": 15118}
{"episode_reward": 32.89470207377584, "episode": 411.0, "batch_reward": 0.0066024623811244965, "critic_loss": 0.07037054747343063, "ae_transition_loss": -2.640057325363159, "ae_encoder_loss": 0.09722549468278885, "actor_loss": 0.09827450662851334, "actor_target_entropy": -2.0, "actor_entropy": -1.368912935256958, "alpha_loss": -0.019724087789654732, "alpha_value": 0.009635852707881155, "duration": 107.98823285102844, "step": 15124}
{"episode_reward": -2.327830101476832, "episode": 412.0, "batch_reward": 0.03448278084397316, "critic_loss": 0.03812283184379339, "ae_transition_loss": -2.704421877861023, "ae_encoder_loss": 0.04441635776311159, "actor_loss": 0.18223046511411667, "actor_target_entropy": -2.0, "actor_entropy": -1.0371429026126862, "alpha_loss": -0.018733569886535406, "alpha_value": 0.009662806378637848, "duration": 9.423228979110718, "step": 15170}
{"episode_reward": 18.82423837512715, "episode": 413.0, "batch_reward": 0.04847310483455658, "critic_loss": 0.03826969861984253, "ae_transition_loss": -2.7653331756591797, "ae_encoder_loss": 0.030046405270695686, "actor_loss": 0.18210318684577942, "actor_target_entropy": -2.0, "actor_entropy": -0.7958576083183289, "alpha_loss": -0.01473745983093977, "alpha_value": 0.00969163303460348, "duration": 0.5551435947418213, "step": 15171}
{"episode_reward": 0.3098867002100318, "episode": 414.0, "batch_reward": 0.07248957455158234, "critic_loss": 0.0612340047955513, "ae_transition_loss": -2.7402915954589844, "ae_encoder_loss": 0.038038577884435654, "actor_loss": 0.14024627208709717, "actor_target_entropy": -2.0, "actor_entropy": -0.6561907529830933, "alpha_loss": -0.011577211320400238, "alpha_value": 0.00970338030323633, "duration": 3.2446041107177734, "step": 15187}
{"episode_reward": -2.0032339134014947, "episode": 415.0, "batch_reward": 0.02622001338750124, "critic_loss": 0.029443304054439068, "ae_transition_loss": -2.787850081920624, "ae_encoder_loss": 0.043124784249812365, "actor_loss": 0.11902789026498795, "actor_target_entropy": -2.0, "actor_entropy": -0.7095546424388885, "alpha_loss": -0.00966911087743938, "alpha_value": 0.009731389982820958, "duration": 7.46759557723999, "step": 15221}
{"episode_reward": 8.574833516507615, "episode": 416.0, "batch_reward": 0.04985895846039057, "critic_loss": 0.03778991103172302, "ae_transition_loss": -2.8658393224080405, "ae_encoder_loss": 0.04402093527217706, "actor_loss": 0.14467911422252655, "actor_target_entropy": -2.0, "actor_entropy": -0.864500880241394, "alpha_loss": -0.011590595357120037, "alpha_value": 0.009767556543204752, "duration": 8.011990547180176, "step": 15260}
{"episode_reward": 0.5147072513859356, "episode": 417.0, "batch_reward": 0.026977693720255047, "critic_loss": 0.033761085011065006, "ae_transition_loss": -2.9091113805770874, "ae_encoder_loss": 0.03978293668478727, "actor_loss": 0.20393632352352142, "actor_target_entropy": -2.0, "actor_entropy": -1.1754685193300247, "alpha_loss": -0.014838775154203176, "alpha_value": 0.009802795928363188, "duration": 6.8904032707214355, "step": 15292}
{"episode_reward": -1.8517767951849948, "episode": 418.0, "batch_reward": 0.02039270903915167, "critic_loss": 0.029419435560703276, "ae_transition_loss": -2.907127618789673, "ae_encoder_loss": 0.046971707791090014, "actor_loss": 0.13316648155450822, "actor_target_entropy": -2.0, "actor_entropy": -0.9671389102935791, "alpha_loss": -0.013395805656909943, "alpha_value": 0.009849809266257475, "duration": 10.349028825759888, "step": 15342}
{"episode_reward": 5.4286889026694425, "episode": 419.0, "batch_reward": 0.06262344866991043, "critic_loss": 0.026963621377944946, "ae_transition_loss": -2.9262932538986206, "ae_encoder_loss": 0.032154087908566, "actor_loss": 0.11757832020521164, "actor_target_entropy": -2.0, "actor_entropy": -0.2936186045408249, "alpha_loss": -0.009706468321383, "alpha_value": 0.009886599239589627, "duration": 4.5233964920043945, "step": 15362}
{"episode_reward": -1.249975155069189, "episode": 420.0, "batch_reward": 0.037146227434277534, "critic_loss": 0.04285387322306633, "ae_transition_loss": -2.828403353691101, "ae_encoder_loss": 0.059469759464263916, "actor_loss": 0.0786733590066433, "actor_target_entropy": -2.0, "actor_entropy": -0.7033730447292328, "alpha_loss": -0.01064347242936492, "alpha_value": 0.009916215448923071, "duration": 8.56623125076294, "step": 15402}
{"episode_reward": 5.0523198431475596, "episode": 421.0, "batch_reward": 0.10297579318284988, "critic_loss": 0.038049858063459396, "ae_transition_loss": -2.8132355213165283, "ae_encoder_loss": 0.043836887925863266, "actor_loss": 0.05327219516038895, "actor_target_entropy": -2.0, "actor_entropy": -0.8993198871612549, "alpha_loss": -0.010327906347811222, "alpha_value": 0.009940247236715397, "duration": 74.4296338558197, "step": 15416}
{"episode_reward": -2.6591972109385233, "episode": 422.0, "batch_reward": 0.03633306547999382, "critic_loss": 0.025127681903541088, "ae_transition_loss": -2.873102068901062, "ae_encoder_loss": 0.04840262047946453, "actor_loss": 0.11624781414866447, "actor_target_entropy": -2.0, "actor_entropy": -0.7243333756923676, "alpha_loss": -0.0013572773896157742, "alpha_value": 0.009953925851551755, "duration": 4.720066785812378, "step": 15439}
{"episode_reward": -0.4397877104309384, "episode": 423.0, "duration": 0.19019651412963867, "step": 15440}
{"episode_reward": -0.14099050698843507, "episode": 424.0, "batch_reward": 0.03298081457614899, "critic_loss": 0.026967528276145458, "ae_transition_loss": -2.8956642150878906, "ae_encoder_loss": 0.045497067272663116, "actor_loss": 0.109987273812294, "actor_target_entropy": -2.0, "actor_entropy": -0.9134409427642822, "alpha_loss": -0.008803925476968288, "alpha_value": 0.009969877541584751, "duration": 3.429248094558716, "step": 15456}
{"episode_reward": -0.9496123729837053, "episode": 425.0, "batch_reward": 0.02779308147728443, "critic_loss": 0.022686602547764778, "ae_transition_loss": -2.9098293781280518, "ae_encoder_loss": 0.04104739800095558, "actor_loss": 0.11134780198335648, "actor_target_entropy": -2.0, "actor_entropy": -0.972528338432312, "alpha_loss": -0.011931764893233776, "alpha_value": 0.00998529580378512, "duration": 4.7077343463897705, "step": 15480}
{"episode_reward": 0.6516003330769199, "episode": 426.0, "batch_reward": 0.021900713443756104, "critic_loss": 0.038015447556972504, "ae_transition_loss": -2.921902656555176, "ae_encoder_loss": 0.08418166637420654, "actor_loss": 0.09411535412073135, "actor_target_entropy": -2.0, "actor_entropy": -0.9324342012405396, "alpha_loss": -0.010657967999577522, "alpha_value": 0.00999724547861502, "duration": 0.5246360301971436, "step": 15481}
{"episode_reward": -0.14332680558379238, "episode": 427.0, "batch_reward": 0.06314083188772202, "critic_loss": 0.029753301292657852, "ae_transition_loss": -2.9422401189804077, "ae_encoder_loss": 0.04087847284972668, "actor_loss": 0.1320677250623703, "actor_target_entropy": -2.0, "actor_entropy": -0.7585183680057526, "alpha_loss": -0.007930034771561623, "alpha_value": 0.010009289709692185, "duration": 5.6590354442596436, "step": 15509}
{"episode_reward": 3.062217024932779, "episode": 428.0, "batch_reward": 0.02939929770813747, "critic_loss": 0.02628659727898511, "ae_transition_loss": -3.0067866065285425, "ae_encoder_loss": 0.05053127235309644, "actor_loss": 0.12910895997827704, "actor_target_entropy": -2.0, "actor_entropy": -0.7595633078705181, "alpha_loss": -0.005565447013147853, "alpha_value": 0.01005602982087248, "duration": 22.291937828063965, "step": 15617}
{"episode_reward": 42.59118364300716, "episode": 429.0, "batch_reward": 0.02702905268718799, "critic_loss": 0.029544271528720856, "ae_transition_loss": -3.0097426573435464, "ae_encoder_loss": 0.054167658711473145, "actor_loss": 0.1378522589802742, "actor_target_entropy": -2.0, "actor_entropy": -0.8370049595832825, "alpha_loss": -0.005352392482260863, "alpha_value": 0.010098410680738393, "duration": 5.743625640869141, "step": 15645}
{"episode_reward": 6.201966476896341, "episode": 430.0, "batch_reward": 0.0560446185991168, "critic_loss": 0.04298956133425236, "ae_transition_loss": -2.935079336166382, "ae_encoder_loss": 0.06465616170316935, "actor_loss": 0.0910746093140915, "actor_target_entropy": -2.0, "actor_entropy": -0.4526972994208336, "alpha_loss": -0.0051670518587343395, "alpha_value": 0.010115792912983437, "duration": 8.69440770149231, "step": 15687}
{"episode_reward": 2.5650117733917432, "episode": 431.0, "batch_reward": 0.0003187563270330429, "critic_loss": 0.05635574832558632, "ae_transition_loss": -2.7081475257873535, "ae_encoder_loss": 0.09826721996068954, "actor_loss": 0.01370425894856453, "actor_target_entropy": -2.0, "actor_entropy": -0.4952518045902252, "alpha_loss": -0.003636140376329422, "alpha_value": 0.010128066217512685, "duration": 121.13737654685974, "step": 15698}
{"episode_reward": 0.42874846581974346, "episode": 432.0, "batch_reward": 0.0162168409054478, "critic_loss": 0.04277429978052775, "ae_transition_loss": -2.7983781496683755, "ae_encoder_loss": 0.07057611768444379, "actor_loss": 0.10933771977821986, "actor_target_entropy": -2.0, "actor_entropy": -0.8267174561818441, "alpha_loss": -0.010861633655925592, "alpha_value": 0.010137779679808558, "duration": 5.24514102935791, "step": 15721}
{"episode_reward": 5.70065027778507, "episode": 433.0, "duration": 0.2176189422607422, "step": 15722}
{"episode_reward": -0.2852318584918976, "episode": 434.0, "batch_reward": 0.031075914856046438, "critic_loss": 0.040276989340782166, "ae_transition_loss": -2.879670262336731, "ae_encoder_loss": 0.10353567078709602, "actor_loss": 0.13344430923461914, "actor_target_entropy": -2.0, "actor_entropy": -0.3924846798181534, "alpha_loss": -0.012910628691315651, "alpha_value": 0.010151957115147048, "duration": 5.012614727020264, "step": 15745}
{"episode_reward": 2.335539988940555, "episode": 435.0, "batch_reward": 0.04226720333099365, "critic_loss": 0.03185016196221113, "ae_transition_loss": -2.812302589416504, "ae_encoder_loss": 0.03574656415730715, "actor_loss": 0.15208227932453156, "actor_target_entropy": -2.0, "actor_entropy": -0.3926370143890381, "alpha_loss": -0.007267884444445372, "alpha_value": 0.01016504791682659, "duration": 4.395636796951294, "step": 15766}
{"episode_reward": 4.06685298853082, "episode": 436.0, "batch_reward": 0.022406633011996746, "critic_loss": 0.022145730443298817, "ae_transition_loss": -2.735569477081299, "ae_encoder_loss": 0.05754035711288452, "actor_loss": 0.07372715696692467, "actor_target_entropy": -2.0, "actor_entropy": -0.9322332143783569, "alpha_loss": -0.010631402023136616, "alpha_value": 0.010178393112746768, "duration": 3.754866361618042, "step": 15783}
{"episode_reward": 0.5442768482022322, "episode": 437.0, "duration": 0.22079801559448242, "step": 15784}
{"episode_reward": -0.8448332798111617, "episode": 438.0, "batch_reward": 0.03868030495941639, "critic_loss": 0.03829525038599968, "ae_transition_loss": -2.896614694595337, "ae_encoder_loss": 0.05151939354836941, "actor_loss": 0.11653501465916634, "actor_target_entropy": -2.0, "actor_entropy": -0.9376837253570557, "alpha_loss": -0.013126100692898036, "alpha_value": 0.010204720815677045, "duration": 10.284546136856079, "step": 15834}
{"episode_reward": 10.356593035828546, "episode": 439.0, "batch_reward": 0.015569995157420635, "critic_loss": 0.02787388488650322, "ae_transition_loss": -2.9470574458440146, "ae_encoder_loss": 0.054655282447735466, "actor_loss": 0.16047367453575134, "actor_target_entropy": -2.0, "actor_entropy": -0.6041965186595917, "alpha_loss": -0.005724821782981356, "alpha_value": 0.010248884595615949, "duration": 12.3263840675354, "step": 15892}
{"episode_reward": 9.84302795167559, "episode": 440.0, "batch_reward": 0.010363467037677765, "critic_loss": 0.030115066096186638, "ae_transition_loss": -2.894892454147339, "ae_encoder_loss": 0.09183911979198456, "actor_loss": 0.06397512555122375, "actor_target_entropy": -2.0, "actor_entropy": -0.5310375094413757, "alpha_loss": -0.00825958140194416, "alpha_value": 0.010273552247790672, "duration": 3.156423807144165, "step": 15908}
{"episode_reward": 3.2288054269813586, "episode": 441.0, "batch_reward": 0.04656711171070735, "critic_loss": 0.03589453920722008, "ae_transition_loss": -2.996208079655965, "ae_encoder_loss": 0.05658910758793354, "actor_loss": 0.07625885388503471, "actor_target_entropy": -2.0, "actor_entropy": -0.8727379639943441, "alpha_loss": -0.010101763081426423, "alpha_value": 0.010336535733383724, "duration": 111.29013967514038, "step": 16056}
{"episode_reward": 106.08142812427693, "episode": 442.0, "batch_reward": 0.04929437953978777, "critic_loss": 0.040144906068841614, "ae_transition_loss": -3.0415350596110025, "ae_encoder_loss": 0.06529040758808453, "actor_loss": 0.1290527656674385, "actor_target_entropy": -2.0, "actor_entropy": -0.8198380072911581, "alpha_loss": -0.012368511408567429, "alpha_value": 0.01040870879710082, "duration": 6.417475461959839, "step": 16087}
{"episode_reward": 0.3010647843236509, "episode": 443.0, "batch_reward": 0.05459207917253176, "critic_loss": 0.037622554848591484, "ae_transition_loss": -2.9016454219818115, "ae_encoder_loss": 0.04983210191130638, "actor_loss": 0.10855528712272644, "actor_target_entropy": -2.0, "actor_entropy": -0.7789064248402914, "alpha_loss": -0.008543825009837747, "alpha_value": 0.010434048854330955, "duration": 6.899785757064819, "step": 16120}
{"episode_reward": 0.63530036275709, "episode": 444.0, "batch_reward": 0.051329882070422175, "critic_loss": 0.03262723460793495, "ae_transition_loss": -3.039237213134766, "ae_encoder_loss": 0.09291532784700393, "actor_loss": 0.0903215080499649, "actor_target_entropy": -2.0, "actor_entropy": -0.902662205696106, "alpha_loss": -0.014325470477342606, "alpha_value": 0.010469095903460955, "duration": 10.156017541885376, "step": 16169}
{"episode_reward": 9.867285419650294, "episode": 445.0, "batch_reward": 0.05003964528441429, "critic_loss": 0.04609745927155018, "ae_transition_loss": -3.1246988773345947, "ae_encoder_loss": 0.04341519996523857, "actor_loss": 0.04601578414440155, "actor_target_entropy": -2.0, "actor_entropy": -0.3201499208807945, "alpha_loss": -0.006809683283790946, "alpha_value": 0.01050270951432209, "duration": 2.949517011642456, "step": 16181}
{"episode_reward": -1.993916588913697, "episode": 446.0, "batch_reward": 0.0832005242506663, "critic_loss": 0.055250465869903564, "ae_transition_loss": -3.0971856911977134, "ae_encoder_loss": 0.0716960256298383, "actor_loss": 0.10044807940721512, "actor_target_entropy": -2.0, "actor_entropy": -0.5816181277235349, "alpha_loss": -0.005595543305389583, "alpha_value": 0.010525037818558706, "duration": 6.775150775909424, "step": 16214}
{"episode_reward": 5.417701379390035, "episode": 447.0, "batch_reward": 0.017741192132234573, "critic_loss": 0.028733041137456894, "ae_transition_loss": -3.009542226791382, "ae_encoder_loss": 0.08022063970565796, "actor_loss": 0.08751528710126877, "actor_target_entropy": -2.0, "actor_entropy": -1.097237229347229, "alpha_loss": -0.008245307952165604, "alpha_value": 0.010541360876807057, "duration": 3.2385010719299316, "step": 16230}
{"episode_reward": -0.5306387370359202, "episode": 448.0, "batch_reward": 0.03845779225230217, "critic_loss": 0.044323816895484924, "ae_transition_loss": -3.009533643722534, "ae_encoder_loss": 0.044937796890735626, "actor_loss": 0.10897871106863022, "actor_target_entropy": -2.0, "actor_entropy": -0.9504244327545166, "alpha_loss": -0.004230366088449955, "alpha_value": 0.01054904953857127, "duration": 0.5198080539703369, "step": 16231}
{"episode_reward": -0.42387675131510405, "episode": 449.0, "batch_reward": 0.05792330019176006, "critic_loss": 0.04238131456077099, "ae_transition_loss": -3.0424054861068726, "ae_encoder_loss": 0.10353197157382965, "actor_loss": -0.011562799103558064, "actor_target_entropy": -2.0, "actor_entropy": -0.6545864939689636, "alpha_loss": -0.01017933152616024, "alpha_value": 0.010559993476072595, "duration": 5.396013259887695, "step": 16258}
{"episode_reward": 4.34518372725101, "episode": 450.0, "batch_reward": 0.04539744804302851, "critic_loss": 0.03520737091700236, "ae_transition_loss": -2.937261978785197, "ae_encoder_loss": 0.05801530430714289, "actor_loss": 0.011471086492141088, "actor_target_entropy": -2.0, "actor_entropy": -0.6315499345461527, "alpha_loss": -0.011573100772996744, "alpha_value": 0.010578963308259012, "duration": 5.029491662979126, "step": 16281}
{"episode_reward": 2.4707334974033026, "episode": 451.0, "batch_reward": 0.025728643871843815, "critic_loss": 0.026939054019749165, "ae_transition_loss": -2.9226927757263184, "ae_encoder_loss": 0.06767204403877258, "actor_loss": 0.0675499327480793, "actor_target_entropy": -2.0, "actor_entropy": -0.6621270179748535, "alpha_loss": -0.01267207833006978, "alpha_value": 0.010599353623271622, "duration": 62.822242736816406, "step": 16310}
{"episode_reward": 6.675591194409079, "episode": 452.0, "batch_reward": 0.02585672400891781, "critic_loss": 0.029545858502388, "ae_transition_loss": -2.9559913873672485, "ae_encoder_loss": 0.05332820303738117, "actor_loss": 0.12569041550159454, "actor_target_entropy": -2.0, "actor_entropy": -0.3876820355653763, "alpha_loss": -0.0036640490870922804, "alpha_value": 0.010616653892657934, "duration": 3.1364786624908447, "step": 16324}
{"episode_reward": -1.2162975073049318, "episode": 453.0, "batch_reward": 0.0612186590830485, "critic_loss": 0.03697852479914824, "ae_transition_loss": -2.780042886734009, "ae_encoder_loss": 0.05309603735804558, "actor_loss": 0.09754056110978127, "actor_target_entropy": -2.0, "actor_entropy": -0.6075196464856466, "alpha_loss": -0.003435158170759678, "alpha_value": 0.010635605718646505, "duration": 6.177756309509277, "step": 16353}
{"episode_reward": 3.18921960024449, "episode": 454.0, "batch_reward": 0.07652422785758972, "critic_loss": 0.0327625572681427, "ae_transition_loss": -2.862846851348877, "ae_encoder_loss": 0.05588359758257866, "actor_loss": 0.021784618496894836, "actor_target_entropy": -2.0, "actor_entropy": -0.8446120023727417, "alpha_loss": -0.004665448796004057, "alpha_value": 0.010649059044492516, "duration": 3.2377099990844727, "step": 16369}
{"episode_reward": -1.0129339598544718, "episode": 455.0, "batch_reward": 0.03808976896107197, "critic_loss": 0.048974365927278996, "ae_transition_loss": -2.8580512404441833, "ae_encoder_loss": 0.08945312723517418, "actor_loss": 0.06805040733888745, "actor_target_entropy": -2.0, "actor_entropy": -1.3374552130699158, "alpha_loss": -0.01403282256796956, "alpha_value": 0.010665438480896424, "duration": 6.925920248031616, "step": 16401}
{"episode_reward": 10.171739775914043, "episode": 456.0, "batch_reward": 0.04653721683037778, "critic_loss": 0.0411994275636971, "ae_transition_loss": -2.761851837237676, "ae_encoder_loss": 0.07281304026643436, "actor_loss": 0.09154258936177939, "actor_target_entropy": -2.0, "actor_entropy": -0.9456845714400212, "alpha_loss": -0.010912171594100073, "alpha_value": 0.010783152350995704, "duration": 50.81275939941406, "step": 16650}
{"episode_reward": 139.33103639527815, "episode": 457.0, "batch_reward": 0.07478643581271172, "critic_loss": 0.07168857753276825, "ae_transition_loss": -2.3987855911254883, "ae_encoder_loss": 0.13909151405096054, "actor_loss": 0.036819739267230034, "actor_target_entropy": -2.0, "actor_entropy": -0.11985581368207932, "alpha_loss": 0.0021788006415590644, "alpha_value": 0.010905582246312516, "duration": 3.5479280948638916, "step": 16667}
{"episode_reward": 0.7727464456531645, "episode": 458.0, "batch_reward": 0.07065655663609505, "critic_loss": 0.05893614888191223, "ae_transition_loss": -2.4543814659118652, "ae_encoder_loss": 0.08361708497007687, "actor_loss": -0.05310080386698246, "actor_target_entropy": -2.0, "actor_entropy": -0.45955952008565265, "alpha_loss": -0.003217009148405244, "alpha_value": 0.010924847065687521, "duration": 6.579597234725952, "step": 16700}
{"episode_reward": 3.7105173252593415, "episode": 459.0, "batch_reward": 0.05865144357085228, "critic_loss": 0.05333429574966431, "ae_transition_loss": -2.447341203689575, "ae_encoder_loss": 0.09942927956581116, "actor_loss": 0.024947743862867355, "actor_target_entropy": -2.0, "actor_entropy": -0.7020633220672607, "alpha_loss": -0.009024874307215214, "alpha_value": 0.010938092850677426, "duration": 0.579186201095581, "step": 16701}
{"episode_reward": -0.3899294188837407, "episode": 460.0, "batch_reward": 0.06269164755940437, "critic_loss": 0.0509004145860672, "ae_transition_loss": -2.412797212600708, "ae_encoder_loss": 0.0829878319054842, "actor_loss": 0.11113590374588966, "actor_target_entropy": -2.0, "actor_entropy": -0.8219239711761475, "alpha_loss": -0.009693615604192019, "alpha_value": 0.01094844987142447, "duration": 4.59343147277832, "step": 16724}
{"episode_reward": -0.7103852145140517, "episode": 461.0, "batch_reward": 0.038635723292827606, "critic_loss": 0.07149228826165199, "ae_transition_loss": -2.4365743001302085, "ae_encoder_loss": 0.07176939646402995, "actor_loss": 0.18140241503715515, "actor_target_entropy": -2.0, "actor_entropy": -0.822746197382609, "alpha_loss": -0.005079775582998991, "alpha_value": 0.0109660194842414, "duration": 35.99091386795044, "step": 16760}
{"episode_reward": -1.573924911576815, "episode": 462.0, "batch_reward": 0.08765852451324463, "critic_loss": 0.06572100147604942, "ae_transition_loss": -2.2358415126800537, "ae_encoder_loss": 0.07243344560265541, "actor_loss": 0.11577552929520607, "actor_target_entropy": -2.0, "actor_entropy": -1.3466166257858276, "alpha_loss": -0.010184062179178, "alpha_value": 0.010982616342231, "duration": 2.906801700592041, "step": 16773}
{"episode_reward": -1.1012603137356394, "episode": 463.0, "duration": 0.1839122772216797, "step": 16774}
{"episode_reward": -0.404694139957428, "episode": 464.0, "batch_reward": 0.049741387367248535, "critic_loss": 0.03578377328813076, "ae_transition_loss": -2.3454372882843018, "ae_encoder_loss": 0.06440878845751286, "actor_loss": 0.018913368694484234, "actor_target_entropy": -2.0, "actor_entropy": -1.0317376255989075, "alpha_loss": -0.006355170626193285, "alpha_value": 0.010996242667095119, "duration": 4.8486411571502686, "step": 16798}
{"episode_reward": 2.150244556766724, "episode": 465.0, "duration": 0.24830865859985352, "step": 16799}
{"episode_reward": -0.6894018311622923, "episode": 466.0, "batch_reward": 0.08523680549114943, "critic_loss": 0.05983061157166958, "ae_transition_loss": -2.341786026954651, "ae_encoder_loss": 0.07014892622828484, "actor_loss": -0.069000787101686, "actor_target_entropy": -2.0, "actor_entropy": -0.24125614948570728, "alpha_loss": -0.014062508475035429, "alpha_value": 0.011017745894456098, "duration": 7.255311489105225, "step": 16833}
{"episode_reward": 7.718684805567047, "episode": 467.0, "duration": 0.18308115005493164, "step": 16834}
{"episode_reward": -0.5214638113975525, "episode": 468.0, "batch_reward": 0.07478215917944908, "critic_loss": 0.05920467525720596, "ae_transition_loss": -2.3061559200286865, "ae_encoder_loss": 0.094214528799057, "actor_loss": 0.059513666201382875, "actor_target_entropy": -2.0, "actor_entropy": -0.09089590236544609, "alpha_loss": -0.016620333306491375, "alpha_value": 0.011043531696958011, "duration": 5.1085124015808105, "step": 16859}
{"episode_reward": 5.020775544322331, "episode": 469.0, "batch_reward": 0.07570197226272689, "critic_loss": 0.04858231130573484, "ae_transition_loss": -2.4551581541697183, "ae_encoder_loss": 0.08171380600995487, "actor_loss": 0.034173530681679644, "actor_target_entropy": -2.0, "actor_entropy": -0.4346761504809062, "alpha_loss": -0.004528669595149242, "alpha_value": 0.011092621823529542, "duration": 18.356083154678345, "step": 16948}
{"episode_reward": 58.256472708268, "episode": 470.0, "batch_reward": 0.05291395215317607, "critic_loss": 0.039254228584468365, "ae_transition_loss": -2.6369487643241882, "ae_encoder_loss": 0.08236147277057171, "actor_loss": 0.012637170031666756, "actor_target_entropy": -2.0, "actor_entropy": -0.6592659950256348, "alpha_loss": -0.014139151200652122, "alpha_value": 0.011138591302358556, "duration": 8.199686527252197, "step": 16988}
{"episode_reward": 7.481931841007755, "episode": 471.0, "batch_reward": 0.07085982922996793, "critic_loss": 0.05014833541853087, "ae_transition_loss": -2.696065732410976, "ae_encoder_loss": 0.10288768687418529, "actor_loss": 0.037688402725117545, "actor_target_entropy": -2.0, "actor_entropy": -0.2809914840119226, "alpha_loss": -0.004420152266642877, "alpha_value": 0.01118438368454249, "duration": 87.31437420845032, "step": 17055}
{"episode_reward": 23.66947283486343, "episode": 472.0, "batch_reward": 0.0742582157254219, "critic_loss": 0.0723789893090725, "ae_transition_loss": -2.7869274616241455, "ae_encoder_loss": 0.07271517068147659, "actor_loss": -0.03314655739814043, "actor_target_entropy": -2.0, "actor_entropy": -0.1753636673092842, "alpha_loss": -0.003319934825412929, "alpha_value": 0.011215548246054346, "duration": 3.827285051345825, "step": 17072}
{"episode_reward": 1.5434957369710793, "episode": 473.0, "batch_reward": 0.07153044641017914, "critic_loss": 0.04418061673641205, "ae_transition_loss": -2.798119068145752, "ae_encoder_loss": 0.04338183254003525, "actor_loss": 0.09824621677398682, "actor_target_entropy": -2.0, "actor_entropy": -0.34606754779815674, "alpha_loss": -0.007923154160380363, "alpha_value": 0.011223955103449316, "duration": 3.125882148742676, "step": 17087}
{"episode_reward": -0.8772194146861384, "episode": 474.0, "batch_reward": 0.05560695628325144, "critic_loss": 0.04191772639751434, "ae_transition_loss": -2.695906321207682, "ae_encoder_loss": 0.07794259861111641, "actor_loss": 0.11943534016609192, "actor_target_entropy": -2.0, "actor_entropy": -0.5780818661053976, "alpha_loss": -0.006319438107311726, "alpha_value": 0.011235257651267353, "duration": 6.151390790939331, "step": 17115}
{"episode_reward": 2.5645752098022374, "episode": 475.0, "batch_reward": 0.054472832216156855, "critic_loss": 0.03904089755896065, "ae_transition_loss": -2.8387780586878457, "ae_encoder_loss": 0.09943636113570796, "actor_loss": 0.019612622680142522, "actor_target_entropy": -2.0, "actor_entropy": -0.6250831186771393, "alpha_loss": -0.00875868798337049, "alpha_value": 0.011301027573884577, "duration": 39.00373983383179, "step": 17300}
{"episode_reward": 34.40636867717755, "episode": 476.0, "batch_reward": 0.047939041474213205, "critic_loss": 0.041133102029561996, "ae_transition_loss": -2.9374287923177085, "ae_encoder_loss": 0.10268986846009891, "actor_loss": 0.013660552445799112, "actor_target_entropy": -2.0, "actor_entropy": -1.3325099150339763, "alpha_loss": -0.013260674042006334, "alpha_value": 0.01138345580695946, "duration": 5.176378011703491, "step": 17325}
{"episode_reward": 2.495156441306552, "episode": 477.0, "batch_reward": 0.07915464043617249, "critic_loss": 0.045306168496608734, "ae_transition_loss": -2.9060410261154175, "ae_encoder_loss": 0.07376144267618656, "actor_loss": 0.04682953283190727, "actor_target_entropy": -2.0, "actor_entropy": -1.2212122678756714, "alpha_loss": -0.01479152962565422, "alpha_value": 0.011406049136610218, "duration": 3.634838104248047, "step": 17341}
{"episode_reward": -0.01448659479923431, "episode": 478.0, "batch_reward": 0.09346183761954308, "critic_loss": 0.028827148489654064, "ae_transition_loss": -2.913275957107544, "ae_encoder_loss": 0.1026906929910183, "actor_loss": 0.010614749044179916, "actor_target_entropy": -2.0, "actor_entropy": -1.035733014345169, "alpha_loss": -0.016745968721807003, "alpha_value": 0.011426349588687351, "duration": 4.939842700958252, "step": 17365}
{"episode_reward": 1.557765629690231, "episode": 479.0, "batch_reward": 0.055689604580402376, "critic_loss": 0.047181344032287596, "ae_transition_loss": -2.7695988178253175, "ae_encoder_loss": 0.08807077556848526, "actor_loss": 0.04530728068202734, "actor_target_entropy": -2.0, "actor_entropy": -0.7211795330047608, "alpha_loss": -0.012393949553370476, "alpha_value": 0.011466609409180673, "duration": 10.148132801055908, "step": 17415}
{"episode_reward": 29.640188743640337, "episode": 480.0, "batch_reward": 0.06722453609108925, "critic_loss": 0.05261856530393873, "ae_transition_loss": -2.7587245873042514, "ae_encoder_loss": 0.0913421990615981, "actor_loss": -0.019181045570543835, "actor_target_entropy": -2.0, "actor_entropy": -0.5035072650228228, "alpha_loss": -0.0067245664873293465, "alpha_value": 0.011532516927018415, "duration": 13.959272861480713, "step": 17484}
{"episode_reward": 15.167571550504453, "episode": 481.0, "batch_reward": 0.06238862872123718, "critic_loss": 0.04171501100063324, "ae_transition_loss": -2.6713523864746094, "ae_encoder_loss": 0.06849293410778046, "actor_loss": -0.05434544384479523, "actor_target_entropy": -2.0, "actor_entropy": -0.5948567390441895, "alpha_loss": -0.009586678817868233, "alpha_value": 0.011569988547431097, "duration": 76.11223006248474, "step": 17497}
{"episode_reward": -0.1059428693416076, "episode": 482.0, "batch_reward": 0.07793734967708588, "critic_loss": 0.046305811032652855, "ae_transition_loss": -2.6862844228744507, "ae_encoder_loss": 0.09376894682645798, "actor_loss": 0.043603433296084404, "actor_target_entropy": -2.0, "actor_entropy": -0.652129739522934, "alpha_loss": -0.012047311756759882, "alpha_value": 0.011583402935368267, "duration": 3.3104329109191895, "step": 17512}
{"episode_reward": 1.4718255204282435, "episode": 483.0, "batch_reward": 0.052818071097135544, "critic_loss": 0.04838692024350166, "ae_transition_loss": -2.805458641052246, "ae_encoder_loss": 0.10785688310861588, "actor_loss": -0.004138665646314621, "actor_target_entropy": -2.0, "actor_entropy": -0.6829110145568847, "alpha_loss": -0.014271282032132149, "alpha_value": 0.01161767387087457, "duration": 10.351606845855713, "step": 17564}
{"episode_reward": 11.547539703460794, "episode": 484.0, "duration": 0.2293381690979004, "step": 17565}
{"episode_reward": -0.25308870978241116, "episode": 485.0, "duration": 0.23044657707214355, "step": 17566}
{"episode_reward": -0.7739182357254815, "episode": 486.0, "batch_reward": 0.13543733954429626, "critic_loss": 0.05804029852151871, "ae_transition_loss": -2.960179328918457, "ae_encoder_loss": 0.1277616024017334, "actor_loss": -0.03190149366855621, "actor_target_entropy": -2.0, "actor_entropy": -0.5971527099609375, "alpha_loss": -0.010245856828987598, "alpha_value": 0.011650170482742327, "duration": 1.51637601852417, "step": 17572}
{"episode_reward": -0.39404818204473513, "episode": 487.0, "batch_reward": 0.04741327961285909, "critic_loss": 0.026345811784267426, "ae_transition_loss": -2.9470859368642173, "ae_encoder_loss": 0.06994709620873134, "actor_loss": 0.04011097550392151, "actor_target_entropy": -2.0, "actor_entropy": -0.5429949561754862, "alpha_loss": -0.008653574002285799, "alpha_value": 0.011671739298504675, "duration": 6.431371450424194, "step": 17604}
{"episode_reward": 7.654690480701259, "episode": 488.0, "duration": 0.21309137344360352, "step": 17605}
{"episode_reward": -1.1169663305664241, "episode": 489.0, "batch_reward": 0.06335086561739445, "critic_loss": 0.044641830027103424, "ae_transition_loss": -2.9630680084228516, "ae_encoder_loss": 0.0897427387535572, "actor_loss": 0.028287041932344437, "actor_target_entropy": -2.0, "actor_entropy": -0.5345639884471893, "alpha_loss": -0.007366095203906298, "alpha_value": 0.01169751535316992, "duration": 4.949012994766235, "step": 17630}
{"episode_reward": 0.15066742035972053, "episode": 490.0, "batch_reward": 0.06929756080110867, "critic_loss": 0.05084326987465223, "ae_transition_loss": -2.804321527481079, "ae_encoder_loss": 0.0953180268406868, "actor_loss": -0.059185647716124855, "actor_target_entropy": -2.0, "actor_entropy": -0.5608277519543966, "alpha_loss": -0.007424009342988332, "alpha_value": 0.011721872408075781, "duration": 4.760041236877441, "step": 17652}
{"episode_reward": 4.478115097207764, "episode": 491.0, "duration": 49.7179536819458, "step": 17653}
{"episode_reward": -0.705270893482547, "episode": 492.0, "batch_reward": 0.054364513605833054, "critic_loss": 0.04340599849820137, "ae_transition_loss": -2.9114067554473877, "ae_encoder_loss": 0.10412381589412689, "actor_loss": -0.0033363550901412964, "actor_target_entropy": -2.0, "actor_entropy": -0.5463503003120422, "alpha_loss": -0.008640995249152184, "alpha_value": 0.011740529268964135, "duration": 2.4429216384887695, "step": 17663}
{"episode_reward": -2.922181216472764, "episode": 493.0, "duration": 0.18311452865600586, "step": 17664}
{"episode_reward": -0.09509378268261195, "episode": 494.0, "batch_reward": 0.057474344968795776, "critic_loss": 0.033432962372899055, "ae_transition_loss": -2.6958340406417847, "ae_encoder_loss": 0.07376895099878311, "actor_loss": -0.029717391822487116, "actor_target_entropy": -2.0, "actor_entropy": -0.5136449038982391, "alpha_loss": -0.003708201926201582, "alpha_value": 0.011753922897283022, "duration": 4.253533840179443, "step": 17684}
{"episode_reward": 0.26433191573566667, "episode": 495.0, "batch_reward": 0.08095550164580345, "critic_loss": 0.023420173674821854, "ae_transition_loss": -2.781575560569763, "ae_encoder_loss": 0.058910785242915154, "actor_loss": 0.007780827581882477, "actor_target_entropy": -2.0, "actor_entropy": -0.5357465445995331, "alpha_loss": -0.007166209630668163, "alpha_value": 0.011770212731297521, "duration": 4.747910976409912, "step": 17706}
{"episode_reward": 1.3603501327125074, "episode": 496.0, "duration": 0.2317366600036621, "step": 17707}
{"episode_reward": -0.777712881565094, "episode": 497.0, "duration": 0.22795414924621582, "step": 17708}
{"episode_reward": -1.4010474596002025, "episode": 498.0, "batch_reward": 0.05011090263724327, "critic_loss": 0.037274543195962906, "ae_transition_loss": -2.8553942839304605, "ae_encoder_loss": 0.1152720997730891, "actor_loss": -0.00673417995373408, "actor_target_entropy": -2.0, "actor_entropy": -0.6115514238675436, "alpha_loss": -0.009543715044856071, "alpha_value": 0.011790051078339503, "duration": 5.839788436889648, "step": 17735}
{"episode_reward": 2.337013910174039, "episode": 499.0, "batch_reward": 0.07143181934952736, "critic_loss": 0.04093796946108341, "ae_transition_loss": -2.792377531528473, "ae_encoder_loss": 0.11566995270550251, "actor_loss": 0.004294967046007514, "actor_target_entropy": -2.0, "actor_entropy": -0.6289542317390442, "alpha_loss": -0.006500004150439054, "alpha_value": 0.01181914291830668, "duration": 8.515928506851196, "step": 17776}
{"episode_reward": -1.4689926962595607, "episode": 500.0, "batch_reward": 0.051994726061820984, "critic_loss": 0.037308208644390106, "ae_transition_loss": -2.8600921630859375, "ae_encoder_loss": 0.08979352563619614, "actor_loss": 0.041752807796001434, "actor_target_entropy": -2.0, "actor_entropy": -0.46688079833984375, "alpha_loss": -0.00460842764005065, "alpha_value": 0.011839069866754504, "duration": 2.83962345123291, "step": 17789}
{"episode_reward": 0.2981049622966319, "episode": 501.0, "batch_reward": 0.09171670178572337, "critic_loss": 0.045862359926104546, "ae_transition_loss": -2.8314170837402344, "ae_encoder_loss": 0.12524045258760452, "actor_loss": -0.03638234734535217, "actor_target_entropy": -2.0, "actor_entropy": -0.4798627197742462, "alpha_loss": -0.004146212789540489, "alpha_value": 0.011852905155166895, "duration": 105.45110392570496, "step": 17812}
{"episode_reward": -1.1523744856166453, "episode": 502.0, "batch_reward": 0.07320931553840637, "critic_loss": 0.08611714094877243, "ae_transition_loss": -2.8485865592956543, "ae_encoder_loss": 0.1409539133310318, "actor_loss": -0.025859372690320015, "actor_target_entropy": -2.0, "actor_entropy": -0.5520583391189575, "alpha_loss": -0.01045798696577549, "alpha_value": 0.011865920443330187, "duration": 3.268620491027832, "step": 17829}
{"episode_reward": -2.124966338432161, "episode": 503.0, "duration": 0.22372221946716309, "step": 17830}
{"episode_reward": -0.6188120399308403, "episode": 504.0, "batch_reward": 0.060735151171684265, "critic_loss": 0.03642766643315554, "ae_transition_loss": -2.8110427856445312, "ae_encoder_loss": 0.07679712027311325, "actor_loss": 0.051412006840109825, "actor_target_entropy": -2.0, "actor_entropy": -0.5797839760780334, "alpha_loss": -0.008193557383492589, "alpha_value": 0.011876363926671435, "duration": 3.9159345626831055, "step": 17849}
{"episode_reward": 0.08752591127848072, "episode": 505.0, "batch_reward": 0.07779956236481667, "critic_loss": 0.062482329085469246, "ae_transition_loss": -2.8671863079071045, "ae_encoder_loss": 0.07441310584545135, "actor_loss": 0.042469905223697424, "actor_target_entropy": -2.0, "actor_entropy": -0.5849455296993256, "alpha_loss": -0.00926288403570652, "alpha_value": 0.011890784697210187, "duration": 3.147737503051758, "step": 17862}
{"episode_reward": -2.051228620461629, "episode": 506.0, "batch_reward": 0.11789009720087051, "critic_loss": 0.06245169167717298, "ae_transition_loss": -2.714381456375122, "ae_encoder_loss": 0.10838827739159267, "actor_loss": -0.09977600397542119, "actor_target_entropy": -2.0, "actor_entropy": -0.5328916509946188, "alpha_loss": -0.008162287529557943, "alpha_value": 0.011909762043311638, "duration": 7.403759241104126, "step": 17898}
{"episode_reward": 13.38641567064893, "episode": 507.0, "duration": 0.22428345680236816, "step": 17899}
{"episode_reward": -0.5452718325384823, "episode": 508.0, "batch_reward": 0.07829801961779595, "critic_loss": 0.06274316981434822, "ae_transition_loss": -2.6017842292785645, "ae_encoder_loss": 0.10196305960416793, "actor_loss": -0.048848305642604825, "actor_target_entropy": -2.0, "actor_entropy": -0.455465167760849, "alpha_loss": -0.00425999597646296, "alpha_value": 0.011938695685336174, "duration": 10.027475833892822, "step": 17947}
{"episode_reward": 13.724848543635066, "episode": 509.0, "batch_reward": 0.09454544261097908, "critic_loss": 0.05594038823619485, "ae_transition_loss": -2.4973065853118896, "ae_encoder_loss": 0.09738196711987257, "actor_loss": -0.017038062680512667, "actor_target_entropy": -2.0, "actor_entropy": -0.4958551600575447, "alpha_loss": -0.010447940323501825, "alpha_value": 0.01196879407209642, "duration": 7.303609132766724, "step": 17981}
{"episode_reward": 2.644318287046617, "episode": 510.0, "batch_reward": 0.04249917296692729, "critic_loss": 0.03882313892245293, "ae_transition_loss": -2.4689345359802246, "ae_encoder_loss": 0.07653330080211163, "actor_loss": -0.028538807295262814, "actor_target_entropy": -2.0, "actor_entropy": -0.5507151186466217, "alpha_loss": -0.01015384029597044, "alpha_value": 0.012000215933566712, "duration": 9.279801607131958, "step": 18027}
{"episode_reward": 1.8085780628594417, "episode": 511.0, "batch_reward": 0.08122561825439334, "critic_loss": 0.04947542538866401, "ae_transition_loss": -2.567904055118561, "ae_encoder_loss": 0.11022561322897673, "actor_loss": -0.03274908958701417, "actor_target_entropy": -2.0, "actor_entropy": -0.6854480355978012, "alpha_loss": -0.009928922983817756, "alpha_value": 0.01205510112578435, "duration": 66.17639994621277, "step": 18101}
{"episode_reward": 6.519738451191417, "episode": 512.0, "batch_reward": 0.07775826255480449, "critic_loss": 0.04646560891220967, "ae_transition_loss": -2.655637582143148, "ae_encoder_loss": 0.12006880342960358, "actor_loss": -0.006120213307440281, "actor_target_entropy": -2.0, "actor_entropy": -0.5622949401537577, "alpha_loss": -0.005304231968087454, "alpha_value": 0.01211984644405766, "duration": 12.400919914245605, "step": 18162}
{"episode_reward": 13.127606940729812, "episode": 513.0, "batch_reward": 0.10269419103860855, "critic_loss": 0.0769110843539238, "ae_transition_loss": -2.635493516921997, "ae_encoder_loss": 0.12681293487548828, "actor_loss": -0.10044413059949875, "actor_target_entropy": -2.0, "actor_entropy": -0.38208073377609253, "alpha_loss": -0.005941081792116165, "alpha_value": 0.01214801343453604, "duration": 3.309919595718384, "step": 18179}
{"episode_reward": 0.9280602819772368, "episode": 514.0, "batch_reward": 0.07386902081114906, "critic_loss": 0.05132225049393518, "ae_transition_loss": -2.670036792755127, "ae_encoder_loss": 0.11429783595459801, "actor_loss": -0.053989660793117115, "actor_target_entropy": -2.0, "actor_entropy": -0.5179796772343772, "alpha_loss": -0.0038397939975506495, "alpha_value": 0.012172862226780925, "duration": 13.034571409225464, "step": 18243}
{"episode_reward": 8.75683011883376, "episode": 515.0, "batch_reward": 0.07647181240220864, "critic_loss": 0.039280167470375695, "ae_transition_loss": -2.7937488158543906, "ae_encoder_loss": 0.11848947405815125, "actor_loss": -0.07038283844788869, "actor_target_entropy": -2.0, "actor_entropy": -0.36249934136867523, "alpha_loss": -0.014022444530079762, "alpha_value": 0.01221252074914684, "duration": 13.738290071487427, "step": 18310}
{"episode_reward": -6.082577201035395, "episode": 516.0, "batch_reward": 0.08226406574249268, "critic_loss": 0.046513610829909645, "ae_transition_loss": -2.86515204111735, "ae_encoder_loss": 0.11254592736562093, "actor_loss": -0.05575496579209963, "actor_target_entropy": -2.0, "actor_entropy": -0.6360616087913513, "alpha_loss": -0.016470432902375858, "alpha_value": 0.012254158872979247, "duration": 5.375372648239136, "step": 18336}
{"episode_reward": 1.9843994536849578, "episode": 517.0, "batch_reward": 0.03049364872276783, "critic_loss": 0.03072137013077736, "ae_transition_loss": -2.8942363262176514, "ae_encoder_loss": 0.13184624910354614, "actor_loss": -0.10165335237979889, "actor_target_entropy": -2.0, "actor_entropy": -0.9411274194717407, "alpha_loss": -0.013300489634275436, "alpha_value": 0.012277451754651576, "duration": 2.01511812210083, "step": 18345}
{"episode_reward": -0.5699095470567904, "episode": 518.0, "batch_reward": 0.06947949528694153, "critic_loss": 0.07841160148382187, "ae_transition_loss": -2.7838873863220215, "ae_encoder_loss": 0.13355710357427597, "actor_loss": -0.05342552065849304, "actor_target_entropy": -2.0, "actor_entropy": -1.1321993470191956, "alpha_loss": -0.011240084655582905, "alpha_value": 0.012295647543843326, "duration": 3.6943607330322266, "step": 18361}
{"episode_reward": -0.13569119527954399, "episode": 519.0, "duration": 0.18825340270996094, "step": 18362}
{"episode_reward": -0.05138348941970727, "episode": 520.0, "batch_reward": 0.11134314288695653, "critic_loss": 0.04858707388242086, "ae_transition_loss": -2.7706472873687744, "ae_encoder_loss": 0.14084095507860184, "actor_loss": -0.09589975327253342, "actor_target_entropy": -2.0, "actor_entropy": -1.216410517692566, "alpha_loss": -0.014702990651130676, "alpha_value": 0.012326302088061876, "duration": 6.161674976348877, "step": 18391}
{"episode_reward": 7.411164418410501, "episode": 521.0, "batch_reward": 0.08367233350872993, "critic_loss": 0.04167663399130106, "ae_transition_loss": -2.752883195877075, "ae_encoder_loss": 0.10121443495154381, "actor_loss": -0.0905698835849762, "actor_target_entropy": -2.0, "actor_entropy": -1.07004052400589, "alpha_loss": -0.01792721636593342, "alpha_value": 0.012358693988570934, "duration": 71.08644843101501, "step": 18413}
{"episode_reward": 0.5202178234289515, "episode": 522.0, "batch_reward": 0.05827788636088371, "critic_loss": 0.050577620044350624, "ae_transition_loss": -2.7450089852015176, "ae_encoder_loss": 0.10627625634272893, "actor_loss": -0.030432166221241157, "actor_target_entropy": -2.0, "actor_entropy": -0.8007336755593618, "alpha_loss": -0.01205993831778566, "alpha_value": 0.01241554804939271, "duration": 12.532482624053955, "step": 18475}
{"episode_reward": 12.359856640790477, "episode": 523.0, "batch_reward": 0.07980486440161864, "critic_loss": 0.039431991055607796, "ae_transition_loss": -2.77268393834432, "ae_encoder_loss": 0.09791060661276181, "actor_loss": -0.11935139199097951, "actor_target_entropy": -2.0, "actor_entropy": -0.7583518524964651, "alpha_loss": -0.012320052832365036, "alpha_value": 0.0124956364685816, "duration": 11.40619421005249, "step": 18531}
{"episode_reward": 21.345960599912733, "episode": 524.0, "batch_reward": 0.07369692499438922, "critic_loss": 0.04823629558086395, "ae_transition_loss": -2.8091603914896646, "ae_encoder_loss": 0.13470709323883057, "actor_loss": -0.017917795727650326, "actor_target_entropy": -2.0, "actor_entropy": -0.9008629322052002, "alpha_loss": -0.014792257609466711, "alpha_value": 0.012554499556014134, "duration": 6.597384929656982, "step": 18565}
{"episode_reward": 3.737688627661306, "episode": 525.0, "batch_reward": 0.050927864387631416, "critic_loss": 0.040590450167655945, "ae_transition_loss": -2.7110811471939087, "ae_encoder_loss": 0.1084618791937828, "actor_loss": -0.06572890793904662, "actor_target_entropy": -2.0, "actor_entropy": -0.7552850544452667, "alpha_loss": -0.009752622805535793, "alpha_value": 0.012589340810504945, "duration": 4.73960280418396, "step": 18589}
{"episode_reward": 1.86846370564398, "episode": 526.0, "duration": 0.2436046600341797, "step": 18590}
{"episode_reward": -0.3294449614578917, "episode": 527.0, "batch_reward": 0.05964970402419567, "critic_loss": 0.027420436963438988, "ae_transition_loss": -2.750867486000061, "ae_encoder_loss": 0.1270652450621128, "actor_loss": -0.06582286953926086, "actor_target_entropy": -2.0, "actor_entropy": -0.6725834012031555, "alpha_loss": -0.012638982385396957, "alpha_value": 0.012616042567257606, "duration": 3.1031949520111084, "step": 18605}
{"episode_reward": -2.1817833280655416, "episode": 528.0, "batch_reward": 0.061865177005529404, "critic_loss": 0.05414969753473997, "ae_transition_loss": -2.7260221242904663, "ae_encoder_loss": 0.11841035634279251, "actor_loss": -0.050045766634866595, "actor_target_entropy": -2.0, "actor_entropy": -0.624580591917038, "alpha_loss": -0.012931071920320392, "alpha_value": 0.012656067050395714, "duration": 8.80079436302185, "step": 18648}
{"episode_reward": 12.65574769019917, "episode": 529.0, "batch_reward": 0.07524579266707103, "critic_loss": 0.039321246246496834, "ae_transition_loss": -2.781775633494059, "ae_encoder_loss": 0.08198220406969388, "actor_loss": -0.08030816912651062, "actor_target_entropy": -2.0, "actor_entropy": -0.6829120914141337, "alpha_loss": -0.01273849792778492, "alpha_value": 0.012703375256554622, "duration": 5.019680500030518, "step": 18672}
{"episode_reward": 1.7211829500671338, "episode": 530.0, "duration": 0.22466826438903809, "step": 18673}
{"episode_reward": -0.26267947625960875, "episode": 531.0, "batch_reward": 0.14586126804351807, "critic_loss": 0.062053728848695755, "ae_transition_loss": -2.782125234603882, "ae_encoder_loss": 0.1407286524772644, "actor_loss": -0.1408875584602356, "actor_target_entropy": -2.0, "actor_entropy": -0.7258303165435791, "alpha_loss": -0.010343197733163834, "alpha_value": 0.012730613599373174, "duration": 64.51481318473816, "step": 18690}
{"episode_reward": -0.7837688663607668, "episode": 532.0, "batch_reward": 0.06978153809905052, "critic_loss": 0.05761551670730114, "ae_transition_loss": -2.7166751623153687, "ae_encoder_loss": 0.0987543873488903, "actor_loss": -0.07507330738008022, "actor_target_entropy": -2.0, "actor_entropy": -0.7616938948631287, "alpha_loss": -0.012989380396902561, "alpha_value": 0.012750659000031278, "duration": 2.8793835639953613, "step": 18701}
{"episode_reward": -2.3275361681428803, "episode": 533.0, "batch_reward": 0.08916325867176056, "critic_loss": 0.07867933809757233, "ae_transition_loss": -2.7322442531585693, "ae_encoder_loss": 0.13903522491455078, "actor_loss": -0.16581548750400543, "actor_target_entropy": -2.0, "actor_entropy": -0.8771369457244873, "alpha_loss": -0.013996221125125885, "alpha_value": 0.01277083569294513, "duration": 3.388270616531372, "step": 18718}
{"episode_reward": 1.7972615808640877, "episode": 534.0, "duration": 0.2315378189086914, "step": 18719}
{"episode_reward": -0.4688489287385869, "episode": 535.0, "batch_reward": 0.05650804191827774, "critic_loss": 0.04242315702140331, "ae_transition_loss": -2.5839552879333496, "ae_encoder_loss": 0.11143132671713829, "actor_loss": -0.009414737112820148, "actor_target_entropy": -2.0, "actor_entropy": -0.9558808207511902, "alpha_loss": -0.012948139570653439, "alpha_value": 0.012791332942533281, "duration": 3.3560705184936523, "step": 18733}
{"episode_reward": -3.6792402686286287, "episode": 536.0, "batch_reward": 0.047549826403458915, "critic_loss": 0.06110945592323939, "ae_transition_loss": -2.528242746988932, "ae_encoder_loss": 0.12479234983523686, "actor_loss": -0.025296335419019062, "actor_target_entropy": -2.0, "actor_entropy": -1.0145168701807659, "alpha_loss": -0.006720233087738355, "alpha_value": 0.012824613010215766, "duration": 6.340585470199585, "step": 18762}
{"episode_reward": 3.097209072388381, "episode": 537.0, "batch_reward": 0.05439850160231193, "critic_loss": 0.03945155752201875, "ae_transition_loss": -2.5965097745259604, "ae_encoder_loss": 0.09567902113000552, "actor_loss": -0.11418739892542362, "actor_target_entropy": -2.0, "actor_entropy": -0.6530373692512512, "alpha_loss": -0.014560764655470848, "alpha_value": 0.012879961352571868, "duration": 13.295032978057861, "step": 18824}
{"episode_reward": 16.90734635560348, "episode": 538.0, "batch_reward": 0.0801103226840496, "critic_loss": 0.031763368751853704, "ae_transition_loss": -2.5872327089309692, "ae_encoder_loss": 0.07867458835244179, "actor_loss": -0.006991158705204725, "actor_target_entropy": -2.0, "actor_entropy": -0.6854096502065659, "alpha_loss": -0.010988606605678797, "alpha_value": 0.012947730760400816, "duration": 8.505521297454834, "step": 18864}
{"episode_reward": 1.323506034473425, "episode": 539.0, "batch_reward": 0.06374878087081015, "critic_loss": 0.0355176804587245, "ae_transition_loss": -2.701383352279663, "ae_encoder_loss": 0.09486214816570282, "actor_loss": -0.06248835287988186, "actor_target_entropy": -2.0, "actor_entropy": -0.5042869746685028, "alpha_loss": -0.0038613956421613693, "alpha_value": 0.012999628435264804, "duration": 8.215983867645264, "step": 18902}
{"episode_reward": 7.125377425181239, "episode": 540.0, "batch_reward": 0.08211116741100948, "critic_loss": 0.04912696468333403, "ae_transition_loss": -2.7471977869669595, "ae_encoder_loss": 0.1152844453851382, "actor_loss": -0.08647499481836955, "actor_target_entropy": -2.0, "actor_entropy": -0.44930975635846454, "alpha_loss": -0.006029921195780237, "alpha_value": 0.013036729459032101, "duration": 7.690039157867432, "step": 18939}
{"episode_reward": 4.252403487095031, "episode": 541.0, "batch_reward": 0.06133389100432396, "critic_loss": 0.026103904470801353, "ae_transition_loss": -2.8599212964375815, "ae_encoder_loss": 0.1197781835993131, "actor_loss": -0.1323027859131495, "actor_target_entropy": -2.0, "actor_entropy": -0.7394760648409525, "alpha_loss": -0.01275093232591947, "alpha_value": 0.013065627903746949, "duration": 73.8679211139679, "step": 18969}
{"episode_reward": 2.050706836238408, "episode": 542.0, "batch_reward": 0.07417678833007812, "critic_loss": 0.03612688556313515, "ae_transition_loss": -2.735272526741028, "ae_encoder_loss": 0.14062310010194778, "actor_loss": -0.12354597076773643, "actor_target_entropy": -2.0, "actor_entropy": -0.6314063668251038, "alpha_loss": -0.010792698711156845, "alpha_value": 0.013091536900857037, "duration": 4.131932497024536, "step": 18989}
{"episode_reward": 2.476628260540593, "episode": 543.0, "batch_reward": 0.055457308888435364, "critic_loss": 0.04298468306660652, "ae_transition_loss": -2.848301649093628, "ae_encoder_loss": 0.1281181126832962, "actor_loss": -0.05142789613455534, "actor_target_entropy": -2.0, "actor_entropy": -0.48290395736694336, "alpha_loss": -0.009490382391959429, "alpha_value": 0.01311855906062083, "duration": 5.15084981918335, "step": 19014}
{"episode_reward": 0.2689830395986561, "episode": 544.0, "batch_reward": 0.07628659904003143, "critic_loss": 0.043777234852313995, "ae_transition_loss": -2.638239622116089, "ae_encoder_loss": 0.13203835487365723, "actor_loss": -0.061608465388417244, "actor_target_entropy": -2.0, "actor_entropy": -0.3931678235530853, "alpha_loss": -0.006315917707979679, "alpha_value": 0.013145354876456575, "duration": 4.60074520111084, "step": 19036}
{"episode_reward": 2.3449566276058085, "episode": 545.0, "batch_reward": 0.07445475955804189, "critic_loss": 0.042342824240525566, "ae_transition_loss": -2.6589110692342124, "ae_encoder_loss": 0.11772328118483226, "actor_loss": -0.11149343227346738, "actor_target_entropy": -2.0, "actor_entropy": -0.5156346162160238, "alpha_loss": -0.006645985180512071, "alpha_value": 0.013170462328575723, "duration": 5.731316328048706, "step": 19063}
{"episode_reward": 4.79719882384881, "episode": 546.0, "batch_reward": 0.06144752725958824, "critic_loss": 0.04156354442238808, "ae_transition_loss": -2.755137801170349, "ae_encoder_loss": 0.0970751978456974, "actor_loss": -0.10326391458511353, "actor_target_entropy": -2.0, "actor_entropy": -0.6687951683998108, "alpha_loss": -0.008653923403471708, "alpha_value": 0.013194095807446711, "duration": 5.339999437332153, "step": 19090}
{"episode_reward": 1.5495007193327404, "episode": 547.0, "batch_reward": 0.06920194625854492, "critic_loss": 0.05345923267304897, "ae_transition_loss": -2.585650682449341, "ae_encoder_loss": 0.12418490089476109, "actor_loss": -0.0679650167003274, "actor_target_entropy": -2.0, "actor_entropy": -0.6230479329824448, "alpha_loss": -0.009580296580679715, "alpha_value": 0.01322233688890138, "duration": 6.915661334991455, "step": 19123}
{"episode_reward": 3.6867371266069893, "episode": 548.0, "batch_reward": 0.05956710750857989, "critic_loss": 0.04231959953904152, "ae_transition_loss": -2.648228645324707, "ae_encoder_loss": 0.11255218336979549, "actor_loss": -0.05188649892807007, "actor_target_entropy": -2.0, "actor_entropy": -0.5631926854451498, "alpha_loss": -0.006556421828766664, "alpha_value": 0.01325650538802669, "duration": 6.091946840286255, "step": 19152}
{"episode_reward": 11.675546154758864, "episode": 549.0, "duration": 0.2235102653503418, "step": 19153}
{"episode_reward": -0.5680727185760397, "episode": 550.0, "batch_reward": 0.08380195250113805, "critic_loss": 0.054330324133237205, "ae_transition_loss": -2.6343812147776284, "ae_encoder_loss": 0.14013826102018356, "actor_loss": -0.11378978192806244, "actor_target_entropy": -2.0, "actor_entropy": -0.5877505739529928, "alpha_loss": -0.012083634113272032, "alpha_value": 0.013284952974380532, "duration": 6.118413925170898, "step": 19181}
{"episode_reward": 1.433640686764532, "episode": 551.0, "batch_reward": 0.06155910715460777, "critic_loss": 0.03781488910317421, "ae_transition_loss": -2.7018041610717773, "ae_encoder_loss": 0.10520521551370621, "actor_loss": -0.020196471363306046, "actor_target_entropy": -2.0, "actor_entropy": -0.510239839553833, "alpha_loss": -0.008563797920942307, "alpha_value": 0.01330524675732929, "duration": 47.4019889831543, "step": 19192}
{"episode_reward": -2.5576391765520783, "episode": 552.0, "batch_reward": 0.08276097476482391, "critic_loss": 0.04645133577287197, "ae_transition_loss": -2.71369469165802, "ae_encoder_loss": 0.10552186518907547, "actor_loss": -0.08266935031861067, "actor_target_entropy": -2.0, "actor_entropy": -0.5749194025993347, "alpha_loss": -0.0066239540465176105, "alpha_value": 0.013320569792126816, "duration": 4.527440071105957, "step": 19215}
{"episode_reward": 4.2277099302021295, "episode": 553.0, "batch_reward": 0.0739197514951229, "critic_loss": 0.05259000889956951, "ae_transition_loss": -2.6115944480895994, "ae_encoder_loss": 0.13904894053936004, "actor_loss": -0.10047686830163002, "actor_target_entropy": -2.0, "actor_entropy": -0.7300120031833649, "alpha_loss": -0.009217669880017638, "alpha_value": 0.013445306937389148, "duration": 50.66782069206238, "step": 19464}
{"episode_reward": 60.95948341761357, "episode": 554.0, "batch_reward": 0.07216066122055054, "critic_loss": 0.059062412629524864, "ae_transition_loss": -2.3619592984517417, "ae_encoder_loss": 0.13824557016293207, "actor_loss": -0.0942669187982877, "actor_target_entropy": -2.0, "actor_entropy": -0.785715917746226, "alpha_loss": -0.0067594464247425394, "alpha_value": 0.013588283584008409, "duration": 5.859152317047119, "step": 19491}
{"episode_reward": 4.086678326525375, "episode": 555.0, "duration": 1.4600353240966797, "step": 19499}
{"episode_reward": -1.2812564389852026, "episode": 556.0, "duration": 0.25208330154418945, "step": 19500}
{"episode_reward": -0.1616226028619716, "episode": 557.0, "batch_reward": 0.09981383649366242, "critic_loss": 0.048316663929394314, "ae_transition_loss": -2.4226547990526472, "ae_encoder_loss": 0.1346598363348416, "actor_loss": -0.1406662448176316, "actor_target_entropy": -2.0, "actor_entropy": -0.5954692959785461, "alpha_loss": -0.004337524828900184, "alpha_value": 0.013641245800344174, "duration": 12.77639389038086, "step": 19562}
{"episode_reward": 21.31999870869305, "episode": 558.0, "batch_reward": 0.08191732466220855, "critic_loss": 0.04863031283020973, "ae_transition_loss": -2.4335983276367186, "ae_encoder_loss": 0.14950515627861022, "actor_loss": -0.08344364389777184, "actor_target_entropy": -2.0, "actor_entropy": -0.6425756454467774, "alpha_loss": -0.008287962432950735, "alpha_value": 0.013692303352030472, "duration": 10.174230575561523, "step": 19612}
{"episode_reward": 15.187970093010508, "episode": 559.0, "batch_reward": 0.07872942338387172, "critic_loss": 0.04592954615751902, "ae_transition_loss": -2.480999708175659, "ae_encoder_loss": 0.12485221276680629, "actor_loss": -0.15120733777681986, "actor_target_entropy": -2.0, "actor_entropy": -0.8724251588185629, "alpha_loss": -0.01415278265873591, "alpha_value": 0.013726582696847298, "duration": 6.120558738708496, "step": 19641}
{"episode_reward": 5.0276783999092896, "episode": 560.0, "batch_reward": 0.08445550923546155, "critic_loss": 0.04960432487229506, "ae_transition_loss": -2.3744160175323485, "ae_encoder_loss": 0.14583148807287216, "actor_loss": -0.11945064713557561, "actor_target_entropy": -2.0, "actor_entropy": -0.4872784157594045, "alpha_loss": -0.0075451861213271815, "alpha_value": 0.013819158550146255, "duration": 31.990487575531006, "step": 19794}
{"episode_reward": 65.61300962140167, "episode": 561.0, "batch_reward": 0.07403768599033356, "critic_loss": 0.046611180528998375, "ae_transition_loss": -2.450090169906616, "ae_encoder_loss": 0.11326926946640015, "actor_loss": -0.09842269495129585, "actor_target_entropy": -2.0, "actor_entropy": -0.6774863302707672, "alpha_loss": -0.012580058071762323, "alpha_value": 0.013903815730456098, "duration": 45.857112884521484, "step": 19819}
{"episode_reward": 3.608752212676199, "episode": 562.0, "batch_reward": 0.06607627868652344, "critic_loss": 0.06912345066666603, "ae_transition_loss": -2.5132362842559814, "ae_encoder_loss": 0.14258457720279694, "actor_loss": -0.06305817514657974, "actor_target_entropy": -2.0, "actor_entropy": -0.858639657497406, "alpha_loss": -0.015397094655781984, "alpha_value": 0.013924542929520153, "duration": 3.3126771450042725, "step": 19834}
{"episode_reward": -1.471187455696115, "episode": 563.0, "duration": 0.23375654220581055, "step": 19835}
{"episode_reward": -0.580202478604672, "episode": 564.0, "batch_reward": 0.097958043217659, "critic_loss": 0.051410420487324394, "ae_transition_loss": -2.2961705525716147, "ae_encoder_loss": 0.1728051652510961, "actor_loss": -0.16679703195889792, "actor_target_entropy": -2.0, "actor_entropy": -0.7399409612019857, "alpha_loss": -0.0064230320664743585, "alpha_value": 0.013953290720108211, "duration": 6.261017084121704, "step": 19865}
{"episode_reward": 4.038922556636607, "episode": 565.0, "batch_reward": 0.09249933436512947, "critic_loss": 0.06722946092486382, "ae_transition_loss": -2.2827707529067993, "ae_encoder_loss": 0.19033197313547134, "actor_loss": -0.18872203677892685, "actor_target_entropy": -2.0, "actor_entropy": -0.40269675850868225, "alpha_loss": -0.008777182782068849, "alpha_value": 0.013980691102218976, "duration": 4.82390570640564, "step": 19888}
{"episode_reward": 5.4687672188496075, "episode": 566.0, "batch_reward": 0.09014026261866093, "critic_loss": 0.04932732072969278, "ae_transition_loss": -2.3370798428853354, "ae_encoder_loss": 0.16104207187891006, "actor_loss": -0.11383016236747305, "actor_target_entropy": -2.0, "actor_entropy": -0.25194109603762627, "alpha_loss": -0.0019510752366234858, "alpha_value": 0.014018979558821032, "duration": 11.462826490402222, "step": 19944}
{"episode_reward": 23.765193218137274, "episode": 567.0, "batch_reward": 0.09812228381633759, "critic_loss": 0.06887739213804404, "ae_transition_loss": -2.03022567431132, "ae_encoder_loss": 0.16765631486972174, "actor_loss": -0.18640534083048502, "actor_target_entropy": -2.0, "actor_entropy": -0.6798205574353536, "alpha_loss": -0.015961844163636368, "alpha_value": 0.014066700385360231, "duration": 16.208066701889038, "step": 20005}
{"episode_reward": 20.580515669102297, "episode": 568.0, "batch_reward": 0.08532275818288326, "critic_loss": 0.06735128909349442, "ae_transition_loss": -2.116106331348419, "ae_encoder_loss": 0.1553701050579548, "actor_loss": -0.15211942605674267, "actor_target_entropy": -2.0, "actor_entropy": -0.6739857643842697, "alpha_loss": -0.0053676406387239695, "alpha_value": 0.014124245829373288, "duration": 8.792427062988281, "step": 20049}
{"episode_reward": 7.378731464596516, "episode": 569.0, "batch_reward": 0.0631767250597477, "critic_loss": 0.13263673707842827, "ae_transition_loss": -2.056472957134247, "ae_encoder_loss": 0.12666546553373337, "actor_loss": -0.10059502860531211, "actor_target_entropy": -2.0, "actor_entropy": -0.5253337472677231, "alpha_loss": -0.005803705076687038, "alpha_value": 0.014167431986645393, "duration": 6.946928977966309, "step": 20082}
{"episode_reward": 7.385848574319093, "episode": 570.0, "duration": 0.19793391227722168, "step": 20083}
{"episode_reward": -0.4909606895167305, "episode": 571.0, "batch_reward": 0.1037136862675349, "critic_loss": 0.10197056209047635, "ae_transition_loss": -2.179778973261515, "ae_encoder_loss": 0.1440553516149521, "actor_loss": -0.06717874109745026, "actor_target_entropy": -2.0, "actor_entropy": -0.4980308711528778, "alpha_loss": -0.009598602075129747, "alpha_value": 0.014200783698193076, "duration": 62.04702830314636, "step": 20112}
{"episode_reward": 2.3357631425430974, "episode": 572.0, "duration": 0.18394136428833008, "step": 20113}
{"episode_reward": -0.5617136718089284, "episode": 573.0, "batch_reward": 0.12163592875003815, "critic_loss": 0.08866479992866516, "ae_transition_loss": -2.2309675216674805, "ae_encoder_loss": 0.11493975669145584, "actor_loss": -0.15352223813533783, "actor_target_entropy": -2.0, "actor_entropy": -0.47716280817985535, "alpha_loss": -0.011702473275363445, "alpha_value": 0.014220755265544978, "duration": 2.322652578353882, "step": 20124}
{"episode_reward": -1.7371557170726326, "episode": 574.0, "batch_reward": 0.07593853212893009, "critic_loss": 0.05666727852076292, "ae_transition_loss": -2.096874952316284, "ae_encoder_loss": 0.14645236730575562, "actor_loss": -0.18805815279483795, "actor_target_entropy": -2.0, "actor_entropy": -0.5529942959547043, "alpha_loss": -0.009231287753209472, "alpha_value": 0.014247646851196307, "duration": 7.972623825073242, "step": 20161}
{"episode_reward": 6.344480902342723, "episode": 575.0, "duration": 0.1815786361694336, "step": 20162}
{"episode_reward": -0.3938493689625756, "episode": 576.0, "batch_reward": 0.0860265778998534, "critic_loss": 0.05813639424741268, "ae_transition_loss": -2.0048665603001914, "ae_encoder_loss": 0.1259307103852431, "actor_loss": -0.1068397209358712, "actor_target_entropy": -2.0, "actor_entropy": -0.6934134165445963, "alpha_loss": -0.008252885891124606, "alpha_value": 0.014304170675983838, "duration": 12.183586120605469, "step": 20224}
{"episode_reward": 15.214382146908363, "episode": 577.0, "batch_reward": 0.08253384679555893, "critic_loss": 0.04955468662083149, "ae_transition_loss": -2.0849582672119142, "ae_encoder_loss": 0.1520241990685463, "actor_loss": -0.15190339609980583, "actor_target_entropy": -2.0, "actor_entropy": -0.5812038004398346, "alpha_loss": -0.006549537018872798, "alpha_value": 0.014383901988659787, "duration": 21.1297926902771, "step": 20329}
{"episode_reward": 57.25416838566777, "episode": 578.0, "batch_reward": 0.09727250412106514, "critic_loss": 0.05406682938337326, "ae_transition_loss": -2.193501830101013, "ae_encoder_loss": 0.15056100860238075, "actor_loss": -0.18850895389914513, "actor_target_entropy": -2.0, "actor_entropy": -0.5389872044324875, "alpha_loss": -0.011281810235232115, "alpha_value": 0.014447656995516265, "duration": 6.757492542266846, "step": 20361}
{"episode_reward": 4.723009791005628, "episode": 579.0, "batch_reward": 0.08208275054182325, "critic_loss": 0.06086943777544158, "ae_transition_loss": -2.2451110226767406, "ae_encoder_loss": 0.1678710196699415, "actor_loss": -0.19141736839498794, "actor_target_entropy": -2.0, "actor_entropy": -0.6774292673383441, "alpha_loss": -0.014003781734832696, "alpha_value": 0.014512998936696109, "duration": 14.537587404251099, "step": 20434}
{"episode_reward": 45.042096223253935, "episode": 580.0, "batch_reward": 0.09594224095344543, "critic_loss": 0.07433123365044594, "ae_transition_loss": -2.327452278137207, "ae_encoder_loss": 0.15621917098760604, "actor_loss": -0.14702219925820828, "actor_target_entropy": -2.0, "actor_entropy": -0.6791992902755737, "alpha_loss": -0.010951036028563977, "alpha_value": 0.0145968352230086, "duration": 10.448366641998291, "step": 20484}
{"episode_reward": 7.361425647314634, "episode": 581.0, "batch_reward": 0.10918812081217766, "critic_loss": 0.05444570630788803, "ae_transition_loss": -2.2969086170196533, "ae_encoder_loss": 0.1533193141222, "actor_loss": -0.20257296413183212, "actor_target_entropy": -2.0, "actor_entropy": -0.4109608680009842, "alpha_loss": -0.005441938992589712, "alpha_value": 0.014646157981812676, "duration": 46.85605502128601, "step": 20510}
{"episode_reward": -1.0306647462008598, "episode": 582.0, "batch_reward": 0.08512271195650101, "critic_loss": 0.20691092312335968, "ae_transition_loss": -2.3434466123580933, "ae_encoder_loss": 0.21884635090827942, "actor_loss": -0.22991323471069336, "actor_target_entropy": -2.0, "actor_entropy": -0.36846622824668884, "alpha_loss": -0.0032179439440369606, "alpha_value": 0.014671453717477127, "duration": 3.7755420207977295, "step": 20528}
{"episode_reward": 0.9045985631693818, "episode": 583.0, "batch_reward": 0.112027108669281, "critic_loss": 0.03301073610782623, "ae_transition_loss": -2.2819488048553467, "ae_encoder_loss": 0.1582653522491455, "actor_loss": -0.1342184692621231, "actor_target_entropy": -2.0, "actor_entropy": -0.3932550251483917, "alpha_loss": -0.007090566214174032, "alpha_value": 0.014688429521357215, "duration": 2.147747278213501, "step": 20538}
{"episode_reward": -0.8597240350198738, "episode": 584.0, "batch_reward": 0.11058450490236282, "critic_loss": 0.04822354018688202, "ae_transition_loss": -2.187456965446472, "ae_encoder_loss": 0.14363989233970642, "actor_loss": -0.1520778313279152, "actor_target_entropy": -2.0, "actor_entropy": -0.44990454614162445, "alpha_loss": -0.010992368683218956, "alpha_value": 0.014704982147917333, "duration": 3.681730031967163, "step": 20556}
{"episode_reward": 3.1137886584037973, "episode": 585.0, "batch_reward": 0.1065588283042113, "critic_loss": 0.053437688698371254, "ae_transition_loss": -2.297410011291504, "ae_encoder_loss": 0.16681448370218277, "actor_loss": -0.20020541300376257, "actor_target_entropy": -2.0, "actor_entropy": -0.5904296487569809, "alpha_loss": -0.011065966915339231, "alpha_value": 0.014752623477999044, "duration": 12.05021858215332, "step": 20614}
{"episode_reward": 21.838624636765285, "episode": 586.0, "batch_reward": 0.08089068233966827, "critic_loss": 0.0511581227183342, "ae_transition_loss": -2.163860487937927, "ae_encoder_loss": 0.1498276859521866, "actor_loss": -0.2158189207315445, "actor_target_entropy": -2.0, "actor_entropy": -0.4817087471485138, "alpha_loss": -0.010123534314334392, "alpha_value": 0.014821699090189872, "duration": 9.883697986602783, "step": 20664}
{"episode_reward": 5.514613575584899, "episode": 587.0, "batch_reward": 0.11618999391794205, "critic_loss": 0.06357130656639735, "ae_transition_loss": -2.306824525197347, "ae_encoder_loss": 0.17235718667507172, "actor_loss": -0.2540913422902425, "actor_target_entropy": -2.0, "actor_entropy": -0.4830627938111623, "alpha_loss": -0.014398448169231415, "alpha_value": 0.014873526123649962, "duration": 5.966338634490967, "step": 20692}
{"episode_reward": 2.9395384109165668, "episode": 588.0, "batch_reward": 0.11852182447910309, "critic_loss": 0.047845080494880676, "ae_transition_loss": -2.306945323944092, "ae_encoder_loss": 0.18338161706924438, "actor_loss": -0.34363219141960144, "actor_target_entropy": -2.0, "actor_entropy": -0.6028362512588501, "alpha_loss": -0.01704661175608635, "alpha_value": 0.014901930182561529, "duration": 3.0570759773254395, "step": 20707}
{"episode_reward": -0.8267514631436503, "episode": 589.0, "batch_reward": 0.0947997123003006, "critic_loss": 0.045108062939511404, "ae_transition_loss": -2.3266458246443005, "ae_encoder_loss": 0.1688860629995664, "actor_loss": -0.1558654262787766, "actor_target_entropy": -2.0, "actor_entropy": -0.5673698948489295, "alpha_loss": -0.0035286216686169305, "alpha_value": 0.014971025074181486, "duration": 18.443643808364868, "step": 20796}
{"episode_reward": 38.71811983741843, "episode": 590.0, "batch_reward": 0.09431618452072144, "critic_loss": 0.05537245236337185, "ae_transition_loss": -2.3698419332504272, "ae_encoder_loss": 0.13288801908493042, "actor_loss": -0.25397635996341705, "actor_target_entropy": -2.0, "actor_entropy": -0.474791944026947, "alpha_loss": -0.014664629008620977, "alpha_value": 0.015026809626156594, "duration": 4.500050067901611, "step": 20818}
{"episode_reward": 2.2682413533904713, "episode": 591.0, "duration": 78.55494546890259, "step": 20819}
{"episode_reward": -0.06280327637279641, "episode": 592.0, "batch_reward": 0.09377062107835497, "critic_loss": 0.06050838157534599, "ae_transition_loss": -2.3337951387677873, "ae_encoder_loss": 0.14851117027657373, "actor_loss": -0.1797466320650918, "actor_target_entropy": -2.0, "actor_entropy": -0.546548238822392, "alpha_loss": -0.0075603194002594265, "alpha_value": 0.015076564248667197, "duration": 14.060668230056763, "step": 20887}
{"episode_reward": 12.12216112191646, "episode": 593.0, "batch_reward": 0.0405341275036335, "critic_loss": 0.04701024666428566, "ae_transition_loss": -2.2443103790283203, "ae_encoder_loss": 0.14467892050743103, "actor_loss": -0.1568772867321968, "actor_target_entropy": -2.0, "actor_entropy": -0.2998155802488327, "alpha_loss": 0.00032825072412379086, "alpha_value": 0.015123303567183078, "duration": 4.379640579223633, "step": 20908}
{"episode_reward": -2.0811342242648663, "episode": 594.0, "batch_reward": 0.09993262110011918, "critic_loss": 0.05533096620014736, "ae_transition_loss": -2.2853031158447266, "ae_encoder_loss": 0.18945662251540593, "actor_loss": -0.1827882251569203, "actor_target_entropy": -2.0, "actor_entropy": -0.4464968613215855, "alpha_loss": -0.010313307234485234, "alpha_value": 0.015161344480313243, "duration": 13.328824281692505, "step": 20974}
{"episode_reward": 8.195090911956065, "episode": 595.0, "batch_reward": 0.11632130146026612, "critic_loss": 0.09779721722006798, "ae_transition_loss": -2.194249153137207, "ae_encoder_loss": 0.17391936480998993, "actor_loss": -0.2511083632707596, "actor_target_entropy": -2.0, "actor_entropy": -0.31693350672721865, "alpha_loss": -0.0006801015581004322, "alpha_value": 0.015220247730143957, "duration": 10.276721477508545, "step": 21023}
{"episode_reward": 26.20897506968892, "episode": 596.0, "batch_reward": 0.08353901840746403, "critic_loss": 0.06842176429927349, "ae_transition_loss": -2.219925105571747, "ae_encoder_loss": 0.15951013192534447, "actor_loss": -0.2500523738563061, "actor_target_entropy": -2.0, "actor_entropy": -0.35727962851524353, "alpha_loss": -0.0066015408374369144, "alpha_value": 0.015253329968500727, "duration": 9.566139221191406, "step": 21069}
{"episode_reward": 6.392259990790068, "episode": 597.0, "batch_reward": 0.09468136931007559, "critic_loss": 0.07257644899866798, "ae_transition_loss": -2.1515015688809482, "ae_encoder_loss": 0.16028049723668533, "actor_loss": -0.18055538088083267, "actor_target_entropy": -2.0, "actor_entropy": -0.30688324909318576, "alpha_loss": -0.0021416879184967415, "alpha_value": 0.01530189043204385, "duration": 23.219404697418213, "step": 21180}
{"episode_reward": -6.348221578469951, "episode": 598.0, "batch_reward": 0.058735742854575314, "critic_loss": 0.08582354585329692, "ae_transition_loss": -2.1711307366689048, "ae_encoder_loss": 0.18231656650702158, "actor_loss": -0.23855284849802652, "actor_target_entropy": -2.0, "actor_entropy": -0.32997676730155945, "alpha_loss": -0.0014001621554295223, "alpha_value": 0.015336130925135574, "duration": 6.131988048553467, "step": 21209}
{"episode_reward": 4.063190308879218, "episode": 599.0, "batch_reward": 0.08428364805877209, "critic_loss": 0.05428292788565159, "ae_transition_loss": -1.762231469154358, "ae_encoder_loss": 0.16275287916262945, "actor_loss": -0.1811113196114699, "actor_target_entropy": -2.0, "actor_entropy": -0.6655368556578954, "alpha_loss": -0.012999469259132942, "alpha_value": 0.015357152544312547, "duration": 11.521206140518188, "step": 21262}
{"episode_reward": 3.50913958463913, "episode": 600.0, "batch_reward": 0.07378553971648216, "critic_loss": 0.055558658515413605, "ae_transition_loss": -1.8697853485743205, "ae_encoder_loss": 0.14869793752829233, "actor_loss": -0.08537458131710689, "actor_target_entropy": -2.0, "actor_entropy": -0.6602304577827454, "alpha_loss": -0.00771744300921758, "alpha_value": 0.015397399270053236, "duration": 6.954193592071533, "step": 21294}
{"episode_reward": 2.9055774974169744, "episode": 601.0, "batch_reward": 0.10113074444234371, "critic_loss": 0.07832873426377773, "ae_transition_loss": -1.742523431777954, "ae_encoder_loss": 0.16603468172252178, "actor_loss": -0.2980174943804741, "actor_target_entropy": -2.0, "actor_entropy": -0.38957659900188446, "alpha_loss": -0.004791579180164263, "alpha_value": 0.015434168136057046, "duration": 50.5042724609375, "step": 21334}
{"episode_reward": 1.2028145578014637, "episode": 602.0, "batch_reward": 0.0785048808902502, "critic_loss": 0.03987119905650616, "ae_transition_loss": -1.659889817237854, "ae_encoder_loss": 0.1320062018930912, "actor_loss": -0.19858187437057495, "actor_target_entropy": -2.0, "actor_entropy": -0.3046621233224869, "alpha_loss": -0.005143359070643783, "alpha_value": 0.01546246263947779, "duration": 3.8630805015563965, "step": 21352}
{"episode_reward": -1.240842244233567, "episode": 603.0, "batch_reward": 0.027017524155477684, "critic_loss": 0.06827849770585696, "ae_transition_loss": -1.618465820948283, "ae_encoder_loss": 0.17221584419409433, "actor_loss": -0.13009323179721832, "actor_target_entropy": -2.0, "actor_entropy": -0.2625986784696579, "alpha_loss": -0.0034970272584663085, "alpha_value": 0.01548440594507293, "duration": 6.7161407470703125, "step": 21386}
{"episode_reward": 12.514243566142126, "episode": 604.0, "duration": 0.23983430862426758, "step": 21387}
{"episode_reward": -1.0334732968626845, "episode": 605.0, "duration": 0.22359633445739746, "step": 21388}
{"episode_reward": -0.4427150366444562, "episode": 606.0, "batch_reward": 0.10529642403125763, "critic_loss": 0.11654750555753708, "ae_transition_loss": -1.6811336994171142, "ae_encoder_loss": 0.14525554180145264, "actor_loss": -0.22576041370630265, "actor_target_entropy": -2.0, "actor_entropy": 0.05463702529668808, "alpha_loss": 0.004963522823527455, "alpha_value": 0.015510771390672588, "duration": 8.997614860534668, "step": 21433}
{"episode_reward": 4.071421413026878, "episode": 607.0, "batch_reward": 0.06139744445681572, "critic_loss": 0.05143849551677704, "ae_transition_loss": -1.5576304197311401, "ae_encoder_loss": 0.18482470512390137, "actor_loss": -0.24436405301094055, "actor_target_entropy": -2.0, "actor_entropy": -0.11654369533061981, "alpha_loss": -0.002412971341982484, "alpha_value": 0.015520438140857452, "duration": 3.0899860858917236, "step": 21448}
{"episode_reward": 1.311545387441415, "episode": 608.0, "duration": 0.22797870635986328, "step": 21449}
{"episode_reward": -0.7772733384301341, "episode": 609.0, "batch_reward": 0.1289147473871708, "critic_loss": 0.05605698749423027, "ae_transition_loss": -1.6802645921707153, "ae_encoder_loss": 0.15457846969366074, "actor_loss": -0.23754402995109558, "actor_target_entropy": -2.0, "actor_entropy": -0.2808094322681427, "alpha_loss": -0.009060234762728214, "alpha_value": 0.015523584435607925, "duration": 2.9103448390960693, "step": 21461}
{"episode_reward": 0.9720273834932711, "episode": 610.0, "batch_reward": 0.1273251175880432, "critic_loss": 0.07628544792532921, "ae_transition_loss": -1.6145418286323547, "ae_encoder_loss": 0.21964482218027115, "actor_loss": -0.24845591187477112, "actor_target_entropy": -2.0, "actor_entropy": -0.34978003799915314, "alpha_loss": -0.007387796067632735, "alpha_value": 0.015531182048009008, "duration": 4.957277774810791, "step": 21488}
{"episode_reward": 3.794474753329099, "episode": 611.0, "batch_reward": 0.11897717912991841, "critic_loss": 0.06893842418988545, "ae_transition_loss": -1.741848349571228, "ae_encoder_loss": 0.1921130120754242, "actor_loss": -0.23787830770015717, "actor_target_entropy": -2.0, "actor_entropy": -0.5632810393969218, "alpha_loss": -0.01205569381515185, "alpha_value": 0.01554502966718279, "duration": 92.18995547294617, "step": 21514}
{"episode_reward": 3.0097317596211832, "episode": 612.0, "batch_reward": 0.13577977381646633, "critic_loss": 0.08778448216617107, "ae_transition_loss": -1.701314777135849, "ae_encoder_loss": 0.2367253713309765, "actor_loss": -0.3634597882628441, "actor_target_entropy": -2.0, "actor_entropy": -0.576063483953476, "alpha_loss": -0.009335149079561234, "alpha_value": 0.015573410201016297, "duration": 8.124215602874756, "step": 21552}
{"episode_reward": 14.614546726517379, "episode": 613.0, "batch_reward": 0.09900924656540155, "critic_loss": 0.07162364106625319, "ae_transition_loss": -1.854414463043213, "ae_encoder_loss": 0.17380180209875107, "actor_loss": -0.2456902712583542, "actor_target_entropy": -2.0, "actor_entropy": -0.18617362653215727, "alpha_loss": -0.0010301222403844197, "alpha_value": 0.01562038455504057, "duration": 13.281070470809937, "step": 21618}
{"episode_reward": 23.051381228383068, "episode": 614.0, "batch_reward": 0.10224522401889165, "critic_loss": 0.05158341179291407, "ae_transition_loss": -1.9440216620763142, "ae_encoder_loss": 0.18272359669208527, "actor_loss": -0.3108367919921875, "actor_target_entropy": -2.0, "actor_entropy": 0.05521491418282191, "alpha_loss": 4.315810898939768e-05, "alpha_value": 0.015650404508801494, "duration": 6.331876754760742, "step": 21649}
{"episode_reward": 2.984090314495364, "episode": 615.0, "batch_reward": 0.1013955906033516, "critic_loss": 0.08728248551487923, "ae_transition_loss": -1.9385273456573486, "ae_encoder_loss": 0.198402339220047, "actor_loss": -0.23641877472400666, "actor_target_entropy": -2.0, "actor_entropy": -0.2823478639125824, "alpha_loss": -0.0025626856833696364, "alpha_value": 0.015665647210970794, "duration": 9.45988130569458, "step": 21695}
{"episode_reward": 8.013408791544428, "episode": 616.0, "batch_reward": 0.09410407692193985, "critic_loss": 0.07094433456659317, "ae_transition_loss": -2.0840019464492796, "ae_encoder_loss": 0.19964593946933745, "actor_loss": -0.2431985080242157, "actor_target_entropy": -2.0, "actor_entropy": -0.48371230959892275, "alpha_loss": -0.009008730575442315, "alpha_value": 0.01568617372445747, "duration": 10.251963376998901, "step": 21746}
{"episode_reward": 2.597626004914432, "episode": 617.0, "batch_reward": 0.09856591373682022, "critic_loss": 0.07907588283220927, "ae_transition_loss": -2.0977959632873535, "ae_encoder_loss": 0.16936881840229034, "actor_loss": -0.2246787150700887, "actor_target_entropy": -2.0, "actor_entropy": -0.3969113528728485, "alpha_loss": -0.012088378891348839, "alpha_value": 0.01571312018002845, "duration": 5.774144411087036, "step": 21774}
{"episode_reward": 3.470607179632535, "episode": 618.0, "batch_reward": 0.11508137732744217, "critic_loss": 0.0853498063981533, "ae_transition_loss": -2.052111601829529, "ae_encoder_loss": 0.18705279231071473, "actor_loss": -0.3457635879516602, "actor_target_entropy": -2.0, "actor_entropy": -0.3600963711738586, "alpha_loss": -0.009330028295516967, "alpha_value": 0.015754263834874254, "duration": 9.925068616867065, "step": 21821}
{"episode_reward": 6.868384692852033, "episode": 619.0, "batch_reward": 0.10561660304665565, "critic_loss": 0.09216879680752754, "ae_transition_loss": -1.961298555135727, "ae_encoder_loss": 0.1447228044271469, "actor_loss": -0.2314296681433916, "actor_target_entropy": -2.0, "actor_entropy": -0.42806990444660187, "alpha_loss": -0.003316605398140382, "alpha_value": 0.01580291120165169, "duration": 9.936039447784424, "step": 21870}
{"episode_reward": 7.476468601292091, "episode": 620.0, "batch_reward": 0.08245421759784222, "critic_loss": 0.09385883621871471, "ae_transition_loss": -1.951573371887207, "ae_encoder_loss": 0.15332527086138725, "actor_loss": -0.24731935933232307, "actor_target_entropy": -2.0, "actor_entropy": -0.38607504963874817, "alpha_loss": -0.002448271436151117, "alpha_value": 0.015839175738377276, "duration": 7.243206024169922, "step": 21904}
{"episode_reward": 5.07436506648879, "episode": 621.0, "batch_reward": 0.10820616781711578, "critic_loss": 0.03374174237251282, "ae_transition_loss": -1.7376341819763184, "ae_encoder_loss": 0.22660483419895172, "actor_loss": -0.3035699725151062, "actor_target_entropy": -2.0, "actor_entropy": -0.4056350588798523, "alpha_loss": -0.00483852531760931, "alpha_value": 0.015858748230198446, "duration": 54.35223984718323, "step": 21917}
{"episode_reward": 0.6603190267883757, "episode": 622.0, "batch_reward": 0.1158611352245013, "critic_loss": 0.13783431549866995, "ae_transition_loss": -1.5917336543401082, "ae_encoder_loss": 0.2081418385108312, "actor_loss": -0.2948291500409444, "actor_target_entropy": -2.0, "actor_entropy": -0.4624904791514079, "alpha_loss": -0.00522780012882625, "alpha_value": 0.015872276611375507, "duration": 5.391829967498779, "step": 21943}
{"episode_reward": 5.676264873311645, "episode": 623.0, "duration": 0.1879878044128418, "step": 21944}
{"episode_reward": -0.4079389194644493, "episode": 624.0, "batch_reward": 0.04440467990934849, "critic_loss": 0.07761017605662346, "ae_transition_loss": -1.5673816800117493, "ae_encoder_loss": 0.23558413982391357, "actor_loss": -0.13723112642765045, "actor_target_entropy": -2.0, "actor_entropy": -0.2471277341246605, "alpha_loss": 6.965524516999722e-05, "alpha_value": 0.015889536998907182, "duration": 4.687408924102783, "step": 21966}
{"episode_reward": 0.3299740423856072, "episode": 625.0, "batch_reward": 0.10439470708370209, "critic_loss": 0.11256155744194984, "ae_transition_loss": -1.5817058086395264, "ae_encoder_loss": 0.18469520211219786, "actor_loss": -0.31169084906578065, "actor_target_entropy": -2.0, "actor_entropy": -0.09191190898418426, "alpha_loss": 0.0011160832364112139, "alpha_value": 0.01590870756999511, "duration": 10.603877782821655, "step": 22015}
{"episode_reward": 4.588245071268074, "episode": 626.0, "batch_reward": 0.1086504856745402, "critic_loss": 0.04465869814157486, "ae_transition_loss": -1.5556445121765137, "ae_encoder_loss": 0.19690079987049103, "actor_loss": -0.32828067739804584, "actor_target_entropy": -2.0, "actor_entropy": -0.46731682618459064, "alpha_loss": -0.008789229517181715, "alpha_value": 0.01592368638881923, "duration": 5.642659902572632, "step": 22041}
{"episode_reward": -0.008442526275322715, "episode": 627.0, "duration": 0.1863536834716797, "step": 22042}
{"episode_reward": -0.45492233665925486, "episode": 628.0, "batch_reward": 0.11524611711502075, "critic_loss": 0.0787125714123249, "ae_transition_loss": -1.6200751662254333, "ae_encoder_loss": 0.2383626252412796, "actor_loss": -0.39164242148399353, "actor_target_entropy": -2.0, "actor_entropy": -0.37484847009181976, "alpha_loss": -0.012665299233049154, "alpha_value": 0.015936790042573593, "duration": 5.562378406524658, "step": 22070}
{"episode_reward": 7.571599062758173, "episode": 629.0, "batch_reward": 0.06074734404683113, "critic_loss": 0.06325136373440425, "ae_transition_loss": -1.627703587214152, "ae_encoder_loss": 0.15674009919166565, "actor_loss": -0.1697628249724706, "actor_target_entropy": -2.0, "actor_entropy": -0.30989651878674823, "alpha_loss": -0.006053208839148283, "alpha_value": 0.01595647048244134, "duration": 4.94459342956543, "step": 22091}
{"episode_reward": 1.9636283789498112, "episode": 630.0, "batch_reward": 0.1414945051074028, "critic_loss": 0.09691663458943367, "ae_transition_loss": -1.6110384464263916, "ae_encoder_loss": 0.15813427418470383, "actor_loss": -0.3416052609682083, "actor_target_entropy": -2.0, "actor_entropy": -0.27846721559762955, "alpha_loss": -0.0063316053710877895, "alpha_value": 0.015977024773328213, "duration": 5.6712658405303955, "step": 22120}
{"episode_reward": 1.246981551632047, "episode": 631.0, "batch_reward": 0.1233436365922292, "critic_loss": 0.06693248823285103, "ae_transition_loss": -1.5541543165842693, "ae_encoder_loss": 0.15680360794067383, "actor_loss": -0.37813544273376465, "actor_target_entropy": -2.0, "actor_entropy": -0.1991736888885498, "alpha_loss": 0.0005138869164511561, "alpha_value": 0.015996864066146938, "duration": 34.78739404678345, "step": 22148}
{"episode_reward": 1.722387377094119, "episode": 632.0, "batch_reward": 0.08910173018063818, "critic_loss": 0.08663384456719671, "ae_transition_loss": -1.6247811828340804, "ae_encoder_loss": 0.1829820317881448, "actor_loss": -0.29837546816893984, "actor_target_entropy": -2.0, "actor_entropy": -0.2528973583664213, "alpha_loss": -0.003972115327737161, "alpha_value": 0.016024403386408714, "duration": 13.81033730506897, "step": 22215}
{"episode_reward": 17.50538067689671, "episode": 633.0, "batch_reward": 0.12041039268175761, "critic_loss": 0.061347052454948425, "ae_transition_loss": -1.6912333567937214, "ae_encoder_loss": 0.18148134648799896, "actor_loss": -0.3124406188726425, "actor_target_entropy": -2.0, "actor_entropy": -0.49736587206522626, "alpha_loss": -0.0028671095691000423, "alpha_value": 0.016052237915151982, "duration": 6.441247940063477, "step": 22246}
{"episode_reward": 4.670358806741491, "episode": 634.0, "batch_reward": 0.0918180172642072, "critic_loss": 0.07062379519144694, "ae_transition_loss": -1.6427230437596638, "ae_encoder_loss": 0.1966483195622762, "actor_loss": -0.2825305759906769, "actor_target_entropy": -2.0, "actor_entropy": -0.24139376481374106, "alpha_loss": -0.001706410141196102, "alpha_value": 0.01606860110680922, "duration": 6.7559661865234375, "step": 22279}
{"episode_reward": 7.066739056509401, "episode": 635.0, "batch_reward": 0.11086295545101166, "critic_loss": 0.07785102725028992, "ae_transition_loss": -1.62702476978302, "ae_encoder_loss": 0.20719216763973236, "actor_loss": -0.368313729763031, "actor_target_entropy": -2.0, "actor_entropy": -0.18686698377132416, "alpha_loss": -0.002789512276649475, "alpha_value": 0.01607829116932706, "duration": 1.5437016487121582, "step": 22286}
{"episode_reward": -2.245867541012479, "episode": 636.0, "batch_reward": 0.09051255105684201, "critic_loss": 0.08893425762653351, "ae_transition_loss": -1.7713429530461628, "ae_encoder_loss": 0.16152292076084349, "actor_loss": -0.29743921260039013, "actor_target_entropy": -2.0, "actor_entropy": -0.3492094965444671, "alpha_loss": -0.002259218463829408, "alpha_value": 0.016099111143487593, "duration": 18.339872121810913, "step": 22378}
{"episode_reward": 47.312828538838126, "episode": 637.0, "batch_reward": 0.129740372300148, "critic_loss": 0.07770770664016406, "ae_transition_loss": -1.7388314803441365, "ae_encoder_loss": 0.21671544015407562, "actor_loss": -0.36219628651936847, "actor_target_entropy": -2.0, "actor_entropy": -0.10193180044492085, "alpha_loss": -0.00743449308599035, "alpha_value": 0.016125223514352045, "duration": 6.09967303276062, "step": 22407}
{"episode_reward": -0.8403072146111904, "episode": 638.0, "duration": 0.2197732925415039, "step": 22408}
{"episode_reward": -0.04013305994389449, "episode": 639.0, "batch_reward": 0.08990317657589912, "critic_loss": 0.1222143031656742, "ae_transition_loss": -1.697967290878296, "ae_encoder_loss": 0.18680726885795593, "actor_loss": -0.33222333788871766, "actor_target_entropy": -2.0, "actor_entropy": -0.5834292054176331, "alpha_loss": -0.00956890182569623, "alpha_value": 0.016152861342275886, "duration": 10.26382565498352, "step": 22459}
{"episode_reward": 22.295406821013664, "episode": 640.0, "batch_reward": 0.13353178277611732, "critic_loss": 0.10924543347209692, "ae_transition_loss": -1.6402063071727753, "ae_encoder_loss": 0.22310301661491394, "actor_loss": -0.3940858766436577, "actor_target_entropy": -2.0, "actor_entropy": 0.14067267253994942, "alpha_loss": 0.0012846163153881207, "alpha_value": 0.016189812770782876, "duration": 7.528174877166748, "step": 22496}
{"episode_reward": 0.6934941681710698, "episode": 641.0, "batch_reward": 0.11075649596750736, "critic_loss": 0.08386473916471004, "ae_transition_loss": -1.6773049235343933, "ae_encoder_loss": 0.21699155867099762, "actor_loss": -0.36262137070298195, "actor_target_entropy": -2.0, "actor_entropy": -0.2048656903207302, "alpha_loss": -0.0007651905762031674, "alpha_value": 0.01621144545797957, "duration": 57.113863706588745, "step": 22534}
{"episode_reward": 0.3757196933555359, "episode": 642.0, "batch_reward": 0.12000894919037819, "critic_loss": 0.08604892902076244, "ae_transition_loss": -1.6313934326171875, "ae_encoder_loss": 0.1933509260416031, "actor_loss": -0.3735659420490265, "actor_target_entropy": -2.0, "actor_entropy": -0.2578282654285431, "alpha_loss": -0.003976085456088185, "alpha_value": 0.016223683675013582, "duration": 5.453524112701416, "step": 22560}
{"episode_reward": 4.068643047353585, "episode": 643.0, "batch_reward": 0.09692101553082466, "critic_loss": 0.058400413021445274, "ae_transition_loss": -1.7800711691379547, "ae_encoder_loss": 0.17070171982049942, "actor_loss": -0.28432735800743103, "actor_target_entropy": -2.0, "actor_entropy": -0.23116414994001389, "alpha_loss": -0.0027354275807738304, "alpha_value": 0.01623744146597848, "duration": 7.1377575397491455, "step": 22594}
{"episode_reward": 3.9093209949405296, "episode": 644.0, "batch_reward": 0.1112559586763382, "critic_loss": 0.07349480049950737, "ae_transition_loss": -1.6299161911010742, "ae_encoder_loss": 0.20304100215435028, "actor_loss": -0.38359205637659344, "actor_target_entropy": -2.0, "actor_entropy": -0.10154913259404046, "alpha_loss": 0.0018855440846112157, "alpha_value": 0.016256179796912552, "duration": 14.397298336029053, "step": 22663}
{"episode_reward": 13.603239535194588, "episode": 645.0, "batch_reward": 0.08545668609440327, "critic_loss": 0.07242336962372065, "ae_transition_loss": -1.6842274963855743, "ae_encoder_loss": 0.2188522070646286, "actor_loss": -0.3086015060544014, "actor_target_entropy": -2.0, "actor_entropy": -0.1292478758841753, "alpha_loss": -0.0008282539201900363, "alpha_value": 0.016261882946192463, "duration": 9.244274139404297, "step": 22706}
{"episode_reward": 2.5145085350015046, "episode": 646.0, "batch_reward": 0.1011674995534122, "critic_loss": 0.07573080249130726, "ae_transition_loss": -1.674780935049057, "ae_encoder_loss": 0.22267741337418556, "actor_loss": -0.3923453167080879, "actor_target_entropy": -2.0, "actor_entropy": -0.1929616443812847, "alpha_loss": -0.0027938614366576076, "alpha_value": 0.016265297969091895, "duration": 7.557845592498779, "step": 22742}
{"episode_reward": 16.093447635597638, "episode": 647.0, "batch_reward": 0.12234644778072834, "critic_loss": 0.0796809010207653, "ae_transition_loss": -1.727682739496231, "ae_encoder_loss": 0.17589037492871284, "actor_loss": -0.377863347530365, "actor_target_entropy": -2.0, "actor_entropy": -0.2588576301932335, "alpha_loss": -0.0038852448342368007, "alpha_value": 0.016273888776073553, "duration": 9.453781604766846, "step": 22788}
{"episode_reward": 14.077850686000106, "episode": 648.0, "batch_reward": 0.11535921692848206, "critic_loss": 0.08913886547088623, "ae_transition_loss": -1.7648698091506958, "ae_encoder_loss": 0.17743495106697083, "actor_loss": -0.3240915536880493, "actor_target_entropy": -2.0, "actor_entropy": -0.28436192870140076, "alpha_loss": -0.0031664392445236444, "alpha_value": 0.016281450840706282, "duration": 1.6196424961090088, "step": 22795}
{"episode_reward": -1.133889092765759, "episode": 649.0, "duration": 0.21961617469787598, "step": 22796}
{"episode_reward": -0.5660439937887686, "episode": 650.0, "batch_reward": 0.08860885041455428, "critic_loss": 0.07787327530483405, "ae_transition_loss": -1.3396643002827961, "ae_encoder_loss": 0.20419901112715402, "actor_loss": -0.3272355298201243, "actor_target_entropy": -2.0, "actor_entropy": -0.155313724031051, "alpha_loss": 0.0009536753835467001, "alpha_value": 0.016293912429078874, "duration": 11.696699380874634, "step": 22852}
{"episode_reward": 3.2674783547028428, "episode": 651.0, "batch_reward": 0.067890215665102, "critic_loss": 0.09353523701429367, "ae_transition_loss": -1.3379366993904114, "ae_encoder_loss": 0.19643725454807281, "actor_loss": -0.4151735305786133, "actor_target_entropy": -2.0, "actor_entropy": -0.030247706919908524, "alpha_loss": 0.0016555821639485657, "alpha_value": 0.016301648933105588, "duration": 70.62556052207947, "step": 22874}
{"episode_reward": 0.5687635513599166, "episode": 652.0, "batch_reward": 0.11093921586871147, "critic_loss": 0.16152899339795113, "ae_transition_loss": -1.327377438545227, "ae_encoder_loss": 0.1989883854985237, "actor_loss": -0.4436187297105789, "actor_target_entropy": -2.0, "actor_entropy": -0.080216433852911, "alpha_loss": -0.005106900702230632, "alpha_value": 0.016301579962893883, "duration": 4.773390531539917, "step": 22897}
{"episode_reward": -1.0129469367860868, "episode": 653.0, "duration": 0.22388076782226562, "step": 22898}
{"episode_reward": -0.5520102334118503, "episode": 654.0, "batch_reward": 0.17302711308002472, "critic_loss": 0.08962924778461456, "ae_transition_loss": -1.397467017173767, "ae_encoder_loss": 0.18675269186496735, "actor_loss": -0.41437339782714844, "actor_target_entropy": -2.0, "actor_entropy": -0.07142077386379242, "alpha_loss": -0.007098358124494553, "alpha_value": 0.01630313475927965, "duration": 2.3240368366241455, "step": 22908}
{"episode_reward": -2.092088845677155, "episode": 655.0, "batch_reward": 0.08878375589847565, "critic_loss": 0.055716559290885925, "ae_transition_loss": -1.3889983892440796, "ae_encoder_loss": 0.18048647791147232, "actor_loss": -0.22377683222293854, "actor_target_entropy": -2.0, "actor_entropy": -0.1392911821603775, "alpha_loss": -0.009938398841768503, "alpha_value": 0.01630759637785162, "duration": 4.107534170150757, "step": 22928}
{"episode_reward": 0.053270681674242926, "episode": 656.0, "batch_reward": 0.1393770823876063, "critic_loss": 0.08041146645943324, "ae_transition_loss": -1.4893709023793538, "ae_encoder_loss": 0.17430380980173746, "actor_loss": -0.4206186930338542, "actor_target_entropy": -2.0, "actor_entropy": -0.2671727736790975, "alpha_loss": -0.008998655093212923, "alpha_value": 0.016320451498854974, "duration": 6.055723667144775, "step": 22955}
{"episode_reward": 4.9059545523245465, "episode": 657.0, "batch_reward": 0.1358610801398754, "critic_loss": 0.11426788568496704, "ae_transition_loss": -1.5519724488258362, "ae_encoder_loss": 0.18861331790685654, "actor_loss": -0.4978688508272171, "actor_target_entropy": -2.0, "actor_entropy": -0.3239010274410248, "alpha_loss": -0.0005489426548592746, "alpha_value": 0.016337233715012594, "duration": 3.715420722961426, "step": 22971}
{"episode_reward": -2.3853216626106635, "episode": 658.0, "batch_reward": 0.10940849632024766, "critic_loss": 0.12320474460721016, "ae_transition_loss": -1.5828985691070556, "ae_encoder_loss": 0.19958365261554717, "actor_loss": -0.3147583454847336, "actor_target_entropy": -2.0, "actor_entropy": -0.2020649403333664, "alpha_loss": 0.0035932108759880064, "alpha_value": 0.016356704330915173, "duration": 10.834214448928833, "step": 23025}
{"episode_reward": 23.24032138792562, "episode": 659.0, "batch_reward": 0.11752747185528278, "critic_loss": 0.053600143641233444, "ae_transition_loss": -1.5666356682777405, "ae_encoder_loss": 0.19226043298840523, "actor_loss": -0.42682453244924545, "actor_target_entropy": -2.0, "actor_entropy": -0.13888213224709034, "alpha_loss": 0.004436915856786072, "alpha_value": 0.016364740619077126, "duration": 8.190596342086792, "step": 23065}
{"episode_reward": 4.268938306281798, "episode": 660.0, "batch_reward": 0.1174252803126971, "critic_loss": 0.14827638864517212, "ae_transition_loss": -1.4671338399251301, "ae_encoder_loss": 0.2320334812005361, "actor_loss": -0.38519249359766644, "actor_target_entropy": -2.0, "actor_entropy": -0.18442152440547943, "alpha_loss": -0.003273688295545677, "alpha_value": 0.01636057782792649, "duration": 6.127231121063232, "step": 23095}
{"episode_reward": 2.6929448381115133, "episode": 661.0, "batch_reward": 0.1145059484988451, "critic_loss": 0.09134144708514214, "ae_transition_loss": -1.4098281562328339, "ae_encoder_loss": 0.20681492611765862, "actor_loss": -0.33569494634866714, "actor_target_entropy": -2.0, "actor_entropy": 0.04364452511072159, "alpha_loss": 0.0054522305727005005, "alpha_value": 0.016358875716663203, "duration": 75.47989082336426, "step": 23131}
{"episode_reward": 4.293670645934131, "episode": 662.0, "batch_reward": 0.09782521178325017, "critic_loss": 0.08837760239839554, "ae_transition_loss": -1.3032790025075276, "ae_encoder_loss": 0.19605142871538797, "actor_loss": -0.3743083079655965, "actor_target_entropy": -2.0, "actor_entropy": -0.04573748012383779, "alpha_loss": 0.00034110182120154303, "alpha_value": 0.0163510786885143, "duration": 7.907734394073486, "step": 23170}
{"episode_reward": 5.6138369581317935, "episode": 663.0, "batch_reward": 0.10961244404315948, "critic_loss": 0.15946190506219865, "ae_transition_loss": -1.446834135055542, "ae_encoder_loss": 0.21860722005367278, "actor_loss": -0.41713481247425077, "actor_target_entropy": -2.0, "actor_entropy": -0.42100642919540404, "alpha_loss": -0.009344261512160302, "alpha_value": 0.016347331503428295, "duration": 9.379901885986328, "step": 23215}
{"episode_reward": 22.750850552625877, "episode": 664.0, "batch_reward": 0.12310726046562195, "critic_loss": 0.08158830106258393, "ae_transition_loss": -1.4568332195281983, "ae_encoder_loss": 0.2218230426311493, "actor_loss": -0.44231120944023133, "actor_target_entropy": -2.0, "actor_entropy": -0.3731376647949219, "alpha_loss": -0.006730446638539433, "alpha_value": 0.016370083949819217, "duration": 10.323068618774414, "step": 23264}
{"episode_reward": -0.3249787623141138, "episode": 665.0, "batch_reward": 0.11095348248879115, "critic_loss": 0.11248297865192096, "ae_transition_loss": -1.590845803419749, "ae_encoder_loss": 0.19738238056500754, "actor_loss": -0.3614915112654368, "actor_target_entropy": -2.0, "actor_entropy": -0.1653402087589105, "alpha_loss": -0.00018153593797857562, "alpha_value": 0.01640211624159288, "duration": 12.95607304573059, "step": 23327}
{"episode_reward": 16.05884032241968, "episode": 666.0, "batch_reward": 0.10476711640755336, "critic_loss": 0.13604470094045004, "ae_transition_loss": -1.6525745789210002, "ae_encoder_loss": 0.18475819627443948, "actor_loss": -0.3713417450586955, "actor_target_entropy": -2.0, "actor_entropy": -0.3049910366535187, "alpha_loss": -0.006026749964803457, "alpha_value": 0.01642161607947545, "duration": 5.513708591461182, "step": 23353}
{"episode_reward": 1.7361040244042374, "episode": 667.0, "batch_reward": 0.11139551177620888, "critic_loss": 0.1285804957151413, "ae_transition_loss": -1.8187726736068726, "ae_encoder_loss": 0.19448565691709518, "actor_loss": -0.338093101978302, "actor_target_entropy": -2.0, "actor_entropy": -0.27011920511722565, "alpha_loss": -0.007148819277063012, "alpha_value": 0.0164355213716482, "duration": 4.549474239349365, "step": 23375}
{"episode_reward": -1.8820691860080547, "episode": 668.0, "batch_reward": 0.10627153515815735, "critic_loss": 0.1057882010936737, "ae_transition_loss": -1.8628573417663574, "ae_encoder_loss": 0.22933915257453918, "actor_loss": -0.2950683832168579, "actor_target_entropy": -2.0, "actor_entropy": -0.22573897242546082, "alpha_loss": -0.0017566005699336529, "alpha_value": 0.016444849366019917, "duration": 1.6837718486785889, "step": 23382}
{"episode_reward": -1.2607680191681292, "episode": 669.0, "batch_reward": 0.11279602845509847, "critic_loss": 0.07746483261386554, "ae_transition_loss": -1.7043301661809285, "ae_encoder_loss": 0.17822696268558502, "actor_loss": -0.5033650000890096, "actor_target_entropy": -2.0, "actor_entropy": 0.04614475121100744, "alpha_loss": -7.80021461347739e-05, "alpha_value": 0.016457566749231194, "duration": 5.999973773956299, "step": 23411}
{"episode_reward": 1.4807469227902388, "episode": 670.0, "duration": 0.19151806831359863, "step": 23412}
{"episode_reward": -0.32938814826547236, "episode": 671.0, "batch_reward": 0.07343544065952301, "critic_loss": 0.08301930874586105, "ae_transition_loss": -1.7077484130859375, "ae_encoder_loss": 0.16886261105537415, "actor_loss": -0.40854454040527344, "actor_target_entropy": -2.0, "actor_entropy": 0.39591148495674133, "alpha_loss": 0.015716126188635826, "alpha_value": 0.016468034957605727, "duration": 38.82038378715515, "step": 23425}
{"episode_reward": 1.8138855373593707, "episode": 672.0, "batch_reward": 0.12052558362483978, "critic_loss": 0.0966469943523407, "ae_transition_loss": -1.3965044617652893, "ae_encoder_loss": 0.17516061663627625, "actor_loss": -0.3561163544654846, "actor_target_entropy": -2.0, "actor_entropy": 0.48404982686042786, "alpha_loss": 0.010308461729437113, "alpha_value": 0.016469394772098356, "duration": 4.223728656768799, "step": 23446}
{"episode_reward": -0.42178415087117, "episode": 673.0, "batch_reward": 0.10968855023384094, "critic_loss": 0.13850446790456772, "ae_transition_loss": -1.4359824657440186, "ae_encoder_loss": 0.17682068794965744, "actor_loss": -0.3570491671562195, "actor_target_entropy": -2.0, "actor_entropy": 0.3648151010274887, "alpha_loss": 0.004999211756512523, "alpha_value": 0.016465828784298142, "duration": 4.719899654388428, "step": 23470}
{"episode_reward": 0.11354056271682395, "episode": 674.0, "batch_reward": 0.11738359183073044, "critic_loss": 0.10830552875995636, "ae_transition_loss": -1.2825393676757812, "ae_encoder_loss": 0.194055438041687, "actor_loss": -0.28691697120666504, "actor_target_entropy": -2.0, "actor_entropy": 0.12560364603996277, "alpha_loss": 0.009589754976332188, "alpha_value": 0.016461259974095727, "duration": 1.153202772140503, "step": 23475}
{"episode_reward": -2.095386386914348, "episode": 675.0, "batch_reward": 0.08075772225856781, "critic_loss": 0.11985720694065094, "ae_transition_loss": -1.2281243801116943, "ae_encoder_loss": 0.17073188722133636, "actor_loss": -0.3777768711249034, "actor_target_entropy": -2.0, "actor_entropy": -0.11294285953044891, "alpha_loss": -7.648952305316925e-06, "alpha_value": 0.01645267564660145, "duration": 6.343816757202148, "step": 23507}
{"episode_reward": -2.0191111167402656, "episode": 676.0, "batch_reward": 0.13452114909887314, "critic_loss": 0.14526135474443436, "ae_transition_loss": -1.2577228546142578, "ae_encoder_loss": 0.2505075931549072, "actor_loss": -0.40461914241313934, "actor_target_entropy": -2.0, "actor_entropy": -0.36211296916007996, "alpha_loss": -0.005340466741472483, "alpha_value": 0.016444511440196086, "duration": 3.313009023666382, "step": 23522}
{"episode_reward": -0.36970828891332147, "episode": 677.0, "batch_reward": 0.09292251244187355, "critic_loss": 0.07870082929730415, "ae_transition_loss": -1.261594831943512, "ae_encoder_loss": 0.274482399225235, "actor_loss": -0.3409546986222267, "actor_target_entropy": -2.0, "actor_entropy": -0.4294753968715668, "alpha_loss": -0.007787640439346433, "alpha_value": 0.016443216515558905, "duration": 5.245132684707642, "step": 23548}
{"episode_reward": 1.4310428612883501, "episode": 678.0, "batch_reward": 0.09626491367816925, "critic_loss": 0.1748003363609314, "ae_transition_loss": -1.2760493755340576, "ae_encoder_loss": 0.21599692478775978, "actor_loss": -0.3486640155315399, "actor_target_entropy": -2.0, "actor_entropy": -0.38047368079423904, "alpha_loss": -0.002094804192893207, "alpha_value": 0.016449487890810924, "duration": 7.6522862911224365, "step": 23586}
{"episode_reward": 4.333527555986438, "episode": 679.0, "batch_reward": 0.0964917317032814, "critic_loss": 0.09867533296346664, "ae_transition_loss": -1.2898378372192383, "ae_encoder_loss": 0.2109685316681862, "actor_loss": -0.4960777461528778, "actor_target_entropy": -2.0, "actor_entropy": -0.15658946335315704, "alpha_loss": 0.005360126378946006, "alpha_value": 0.016456405641782603, "duration": 4.803280830383301, "step": 23610}
{"episode_reward": 4.094010794636713, "episode": 680.0, "batch_reward": 0.08744728937745094, "critic_loss": 0.062216248363256454, "ae_transition_loss": -1.3740471005439758, "ae_encoder_loss": 0.16165979951620102, "actor_loss": -0.33188968896865845, "actor_target_entropy": -2.0, "actor_entropy": -0.018658217042684555, "alpha_loss": 0.00752159021794796, "alpha_value": 0.01645658270801844, "duration": 3.391984701156616, "step": 23626}
{"episode_reward": -2.073633482736227, "episode": 681.0, "batch_reward": 0.09954372607171535, "critic_loss": 0.08146977424621582, "ae_transition_loss": -1.2940278947353363, "ae_encoder_loss": 0.1714000403881073, "actor_loss": -0.36601557582616806, "actor_target_entropy": -2.0, "actor_entropy": -0.10485752485692501, "alpha_loss": 0.0029031637241132557, "alpha_value": 0.016448853581830996, "duration": 63.51668930053711, "step": 23663}
{"episode_reward": 3.938208682140522, "episode": 682.0, "batch_reward": 0.1310513292749723, "critic_loss": 0.1002676822245121, "ae_transition_loss": -1.3886758883794148, "ae_encoder_loss": 0.2260890652736028, "actor_loss": -0.47923562427361804, "actor_target_entropy": -2.0, "actor_entropy": -0.083886057138443, "alpha_loss": 0.0017189267673529685, "alpha_value": 0.016433984517701405, "duration": 13.515040159225464, "step": 23730}
{"episode_reward": 25.779744718366075, "episode": 683.0, "batch_reward": 0.11313476368784904, "critic_loss": 0.09856408074498177, "ae_transition_loss": -1.2140308952331542, "ae_encoder_loss": 0.19686641573905944, "actor_loss": -0.4426992255449295, "actor_target_entropy": -2.0, "actor_entropy": -0.15901358872652055, "alpha_loss": -0.001561410347931087, "alpha_value": 0.016431702161843555, "duration": 50.40343737602234, "step": 23979}
{"episode_reward": -12.410865874768135, "episode": 684.0, "batch_reward": 0.11638669421275456, "critic_loss": 0.14339762243131796, "ae_transition_loss": -1.1800002853075664, "ae_encoder_loss": 0.21542825053135553, "actor_loss": -0.4266812453667323, "actor_target_entropy": -2.0, "actor_entropy": -0.16133383040626845, "alpha_loss": -0.0013191936498818297, "alpha_value": 0.016441777110245148, "duration": 11.331759691238403, "step": 24032}
{"episode_reward": 12.019336306158499, "episode": 685.0, "duration": 1.0600650310516357, "step": 24037}
{"episode_reward": -1.4787230106741849, "episode": 686.0, "batch_reward": 0.09464211974825178, "critic_loss": 0.10656618646212987, "ae_transition_loss": -1.2450900418417794, "ae_encoder_loss": 0.20946041813918523, "actor_loss": -0.3956590550286429, "actor_target_entropy": -2.0, "actor_entropy": -0.39538690873554777, "alpha_loss": -0.0010034081393054553, "alpha_value": 0.016458226497818116, "duration": 14.174960851669312, "step": 24104}
{"episode_reward": 12.807151294776078, "episode": 687.0, "batch_reward": 0.09594080001115798, "critic_loss": 0.10298914313316346, "ae_transition_loss": -1.1545741081237793, "ae_encoder_loss": 0.2291051924228668, "actor_loss": -0.48029341697692873, "actor_target_entropy": -2.0, "actor_entropy": -0.031042157113552092, "alpha_loss": 0.0005605312995612622, "alpha_value": 0.016467186359046378, "duration": 10.850425004959106, "step": 24156}
{"episode_reward": 14.82944138156635, "episode": 688.0, "batch_reward": 0.09656052570790052, "critic_loss": 0.10031405324116349, "ae_transition_loss": -1.1624707281589508, "ae_encoder_loss": 0.18281413242220879, "actor_loss": -0.4064387008547783, "actor_target_entropy": -2.0, "actor_entropy": 0.06736114714294672, "alpha_loss": 0.0027754535040003248, "alpha_value": 0.016468137852527598, "duration": 17.373862266540527, "step": 24239}
{"episode_reward": 31.553287989281163, "episode": 689.0, "batch_reward": 0.11666438728570938, "critic_loss": 0.14092817157506943, "ae_transition_loss": -1.1016178131103516, "ae_encoder_loss": 0.22686444222927094, "actor_loss": -0.44686323404312134, "actor_target_entropy": -2.0, "actor_entropy": 0.19615726172924042, "alpha_loss": 0.010267538018524647, "alpha_value": 0.01646135920863385, "duration": 3.659698247909546, "step": 24256}
{"episode_reward": -0.8272245121505233, "episode": 690.0, "duration": 0.22351861000061035, "step": 24257}
{"episode_reward": -0.38691879443196675, "episode": 691.0, "duration": 55.136085987091064, "step": 24258}
{"episode_reward": -0.41583372055473566, "episode": 692.0, "batch_reward": 0.1178518044097083, "critic_loss": 0.10459301407848086, "ae_transition_loss": -1.0119864770344325, "ae_encoder_loss": 0.25284517237118315, "actor_loss": -0.4750498788697379, "actor_target_entropy": -2.0, "actor_entropy": -0.05177548421280725, "alpha_loss": 0.002902850625105202, "alpha_value": 0.016436337968048834, "duration": 12.781813383102417, "step": 24321}
{"episode_reward": 16.07456297564833, "episode": 693.0, "batch_reward": 0.14131367206573486, "critic_loss": 0.12646302580833435, "ae_transition_loss": -1.0715392430623372, "ae_encoder_loss": 0.2155760775009791, "actor_loss": -0.559562067190806, "actor_target_entropy": -2.0, "actor_entropy": -0.2982468605041504, "alpha_loss": -0.009609580660859743, "alpha_value": 0.016413693236782014, "duration": 7.034059524536133, "step": 24357}
{"episode_reward": 1.9829203166161284, "episode": 694.0, "batch_reward": 0.08706828765571117, "critic_loss": 0.05484365485608578, "ae_transition_loss": -1.1353106796741486, "ae_encoder_loss": 0.23453841730952263, "actor_loss": -0.48823828250169754, "actor_target_entropy": -2.0, "actor_entropy": -0.346952423453331, "alpha_loss": -0.008603633032180369, "alpha_value": 0.01641953096982035, "duration": 7.499410390853882, "step": 24394}
{"episode_reward": -1.7131417404544187, "episode": 695.0, "batch_reward": 0.11969522386789322, "critic_loss": 0.06528082489967346, "ae_transition_loss": -1.1360214948654175, "ae_encoder_loss": 0.17333295941352844, "actor_loss": -0.5037028789520264, "actor_target_entropy": -2.0, "actor_entropy": -0.36294880509376526, "alpha_loss": -0.011121280491352081, "alpha_value": 0.016431333410989037, "duration": 2.948270320892334, "step": 24408}
{"episode_reward": -1.6056483111257651, "episode": 696.0, "batch_reward": 0.13199200853705406, "critic_loss": 0.10676862299442291, "ae_transition_loss": -1.185380220413208, "ae_encoder_loss": 0.2723357379436493, "actor_loss": -0.49420109391212463, "actor_target_entropy": -2.0, "actor_entropy": -0.32007329165935516, "alpha_loss": -0.009539621882140636, "alpha_value": 0.01644178576611683, "duration": 4.123520374298096, "step": 24428}
{"episode_reward": 1.8366780445037791, "episode": 697.0, "duration": 0.2275679111480713, "step": 24429}
{"episode_reward": 0.017571877448038176, "episode": 698.0, "batch_reward": 0.1263745129108429, "critic_loss": 0.12058744207024574, "ae_transition_loss": -0.9362395703792572, "ae_encoder_loss": 0.17947477847337723, "actor_loss": -0.472199946641922, "actor_target_entropy": -2.0, "actor_entropy": -0.18784108012914658, "alpha_loss": -0.0020214790129102767, "alpha_value": 0.01645799008288487, "duration": 4.1920928955078125, "step": 24450}
{"episode_reward": 0.6068539669750999, "episode": 699.0, "batch_reward": 0.10279457891980807, "critic_loss": 0.14517367320756117, "ae_transition_loss": -1.1948575178782146, "ae_encoder_loss": 0.21544243892033896, "actor_loss": -0.4821360111236572, "actor_target_entropy": -2.0, "actor_entropy": -0.10901021336515744, "alpha_loss": 0.0021825393584246435, "alpha_value": 0.016484962996023853, "duration": 11.004441261291504, "step": 24503}
{"episode_reward": 12.21777778882074, "episode": 700.0, "batch_reward": 0.10368554294109344, "critic_loss": 0.10214249789714813, "ae_transition_loss": -1.1101372241973877, "ae_encoder_loss": 0.1816001534461975, "actor_loss": -0.3639971613883972, "actor_target_entropy": -2.0, "actor_entropy": -0.03744807094335556, "alpha_loss": 0.005091309547424316, "alpha_value": 0.016498733186213584, "duration": 2.747095823287964, "step": 24516}
{"episode_reward": -0.39091985514458155, "episode": 701.0, "batch_reward": 0.11788286920636892, "critic_loss": 0.12214428745210171, "ae_transition_loss": -1.064163751900196, "ae_encoder_loss": 0.24253858998417854, "actor_loss": -0.5488950647413731, "actor_target_entropy": -2.0, "actor_entropy": -0.1257424307987094, "alpha_loss": 0.0039696590101812035, "alpha_value": 0.016495464387332286, "duration": 79.27183532714844, "step": 24592}
{"episode_reward": 34.85700173086444, "episode": 702.0, "batch_reward": 0.09438556618988514, "critic_loss": 0.14167273230850697, "ae_transition_loss": -1.1958305537700653, "ae_encoder_loss": 0.20573511347174644, "actor_loss": -0.4519968256354332, "actor_target_entropy": -2.0, "actor_entropy": -0.16845260933041573, "alpha_loss": 0.005704116192646325, "alpha_value": 0.01647692993408529, "duration": 8.812000274658203, "step": 24636}
{"episode_reward": 9.510807191412606, "episode": 703.0, "batch_reward": 0.1250390112400055, "critic_loss": 0.1637434922158718, "ae_transition_loss": -1.0531644076108932, "ae_encoder_loss": 0.21374399214982986, "actor_loss": -0.5807654708623886, "actor_target_entropy": -2.0, "actor_entropy": -0.1465739719569683, "alpha_loss": 0.0006546490039909258, "alpha_value": 0.016456360932050877, "duration": 7.519517660140991, "step": 24671}
{"episode_reward": 1.945855444362644, "episode": 704.0, "duration": 0.19056200981140137, "step": 24672}
{"episode_reward": -0.21827985547017284, "episode": 705.0, "batch_reward": 0.13008343428373337, "critic_loss": 0.1471698358654976, "ae_transition_loss": -0.9018115103244781, "ae_encoder_loss": 0.3463592529296875, "actor_loss": -0.44057559967041016, "actor_target_entropy": -2.0, "actor_entropy": -0.0663311816751957, "alpha_loss": 0.003423307090997696, "alpha_value": 0.016443379359906175, "duration": 4.933257818222046, "step": 24696}
{"episode_reward": 1.4115877906520198, "episode": 706.0, "batch_reward": 0.0951670240610838, "critic_loss": 0.18521306663751602, "ae_transition_loss": -1.1661877930164337, "ae_encoder_loss": 0.231544129550457, "actor_loss": -0.5654277205467224, "actor_target_entropy": -2.0, "actor_entropy": -0.13513240031898022, "alpha_loss": -0.007270244648680091, "alpha_value": 0.016435649188190703, "duration": 7.758788347244263, "step": 24731}
{"episode_reward": 0.04770039577151723, "episode": 707.0, "duration": 0.21255970001220703, "step": 24732}
{"episode_reward": -3.7316291821750736, "episode": 708.0, "duration": 0.20050740242004395, "step": 24733}
{"episode_reward": -0.3362463659218309, "episode": 709.0, "batch_reward": 0.10413518672188123, "critic_loss": 0.12802568823099136, "ae_transition_loss": -1.2911771138509114, "ae_encoder_loss": 0.2458478808403015, "actor_loss": -0.4643353621164958, "actor_target_entropy": -2.0, "actor_entropy": -0.2777407964070638, "alpha_loss": -0.010060061855862537, "alpha_value": 0.01643958668060019, "duration": 6.4550416469573975, "step": 24764}
{"episode_reward": 0.6988833882378886, "episode": 710.0, "batch_reward": 0.09312834839026134, "critic_loss": 0.09648080170154572, "ae_transition_loss": -1.3654299974441528, "ae_encoder_loss": 0.20172532399495444, "actor_loss": -0.49300341804822284, "actor_target_entropy": -2.0, "actor_entropy": -0.32252739866574603, "alpha_loss": -0.01194301899522543, "alpha_value": 0.016455896366429867, "duration": 6.535467147827148, "step": 24794}
{"episode_reward": 9.294471058424666, "episode": 711.0, "batch_reward": 0.08240296691656113, "critic_loss": 0.14315138012170792, "ae_transition_loss": -1.4376844763755798, "ae_encoder_loss": 0.2273842841386795, "actor_loss": -0.5033241510391235, "actor_target_entropy": -2.0, "actor_entropy": -0.11004868894815445, "alpha_loss": -0.0070108125219121575, "alpha_value": 0.016478112240304273, "duration": 61.9523446559906, "step": 24818}
{"episode_reward": 0.13575918550522031, "episode": 712.0, "batch_reward": 0.10218444839119911, "critic_loss": 0.07600806280970573, "ae_transition_loss": -1.540395200252533, "ae_encoder_loss": 0.1900816336274147, "actor_loss": -0.3639121651649475, "actor_target_entropy": -2.0, "actor_entropy": -0.0936550535261631, "alpha_loss": -0.0012422899017110467, "alpha_value": 0.016497412320770396, "duration": 4.235796213150024, "step": 24839}
{"episode_reward": 0.8381279103660971, "episode": 713.0, "batch_reward": 0.09694816172122955, "critic_loss": 0.1665937900543213, "ae_transition_loss": -1.4465960264205933, "ae_encoder_loss": 0.22125884890556335, "actor_loss": -0.4656432271003723, "actor_target_entropy": -2.0, "actor_entropy": -0.2882418632507324, "alpha_loss": -0.002373852301388979, "alpha_value": 0.01651017376094023, "duration": 2.187741756439209, "step": 24849}
{"episode_reward": 0.006509706169845142, "episode": 714.0, "batch_reward": 0.08567509800195694, "critic_loss": 0.14731040969491005, "ae_transition_loss": -1.4656938910484314, "ae_encoder_loss": 0.19899435341358185, "actor_loss": -0.5550835430622101, "actor_target_entropy": -2.0, "actor_entropy": -0.4514564573764801, "alpha_loss": -0.0022397778229787946, "alpha_value": 0.01652167210974533, "duration": 3.9825165271759033, "step": 24868}
{"episode_reward": 0.4596727982671107, "episode": 715.0, "batch_reward": 0.10943477302789688, "critic_loss": 0.10676532685756683, "ae_transition_loss": -1.1693597316741944, "ae_encoder_loss": 0.22279563546180725, "actor_loss": -0.5199463367462158, "actor_target_entropy": -2.0, "actor_entropy": -0.5170204818248749, "alpha_loss": -0.004287785757333041, "alpha_value": 0.016548304151194085, "duration": 10.405216455459595, "step": 24919}
{"episode_reward": 10.60330215891154, "episode": 716.0, "batch_reward": 0.12377555171648662, "critic_loss": 0.10817118113239606, "ae_transition_loss": -0.9546559850374857, "ae_encoder_loss": 0.24894007792075476, "actor_loss": -0.6286295255025228, "actor_target_entropy": -2.0, "actor_entropy": 0.08100195974111557, "alpha_loss": 0.0055434024446488666, "alpha_value": 0.016580778265394978, "duration": 12.227757453918457, "step": 24978}
{"episode_reward": 28.752183671369846, "episode": 717.0, "batch_reward": 0.061162468045949936, "critic_loss": 0.25271815061569214, "ae_transition_loss": -0.8890536427497864, "ae_encoder_loss": 0.28185272216796875, "actor_loss": -0.4333200454711914, "actor_target_entropy": -2.0, "actor_entropy": 0.3786851167678833, "alpha_loss": 0.01071914006024599, "alpha_value": 0.016585247495015377, "duration": 2.1516621112823486, "step": 24988}
{"episode_reward": -2.1511914741257274, "episode": 718.0, "batch_reward": 0.11694542194406192, "critic_loss": 0.17335217321912447, "ae_transition_loss": -0.9508937895298004, "ae_encoder_loss": 0.22348338117202124, "actor_loss": -0.4696555932362874, "actor_target_entropy": -2.0, "actor_entropy": 0.25837428743640584, "alpha_loss": 0.007304943030855308, "alpha_value": 0.016572664006663077, "duration": 11.579761028289795, "step": 25043}
{"episode_reward": 1.02837700902609, "episode": 719.0, "batch_reward": 0.12518062628805637, "critic_loss": 0.23562266305088997, "ae_transition_loss": -0.9975845962762833, "ae_encoder_loss": 0.2590649388730526, "actor_loss": -0.47920795530080795, "actor_target_entropy": -2.0, "actor_entropy": -0.03963049128651619, "alpha_loss": 0.0034856045385822654, "alpha_value": 0.01654214683777776, "duration": 8.675910949707031, "step": 25085}
{"episode_reward": 7.58064078500235, "episode": 720.0, "duration": 0.21963763236999512, "step": 25086}
{"episode_reward": 0.16534435247968993, "episode": 721.0, "batch_reward": 0.11698266367117564, "critic_loss": 0.13517781843741736, "ae_transition_loss": -1.0232776602109273, "ae_encoder_loss": 0.1516785348455111, "actor_loss": -0.4851046601931254, "actor_target_entropy": -2.0, "actor_entropy": -0.22148898740609488, "alpha_loss": -0.006808600543687741, "alpha_value": 0.016519365928002305, "duration": 115.10698962211609, "step": 25111}
{"episode_reward": 3.676209857900705, "episode": 722.0, "batch_reward": 0.11639641225337982, "critic_loss": 0.16440434753894806, "ae_transition_loss": -1.0452790260314941, "ae_encoder_loss": 0.16641634702682495, "actor_loss": -0.6349550187587738, "actor_target_entropy": -2.0, "actor_entropy": -0.18954195082187653, "alpha_loss": -0.012395948637276888, "alpha_value": 0.016513253965297424, "duration": 4.602253198623657, "step": 25133}
{"episode_reward": -0.8163426662844606, "episode": 723.0, "batch_reward": 0.07393139600753784, "critic_loss": 0.184869647026062, "ae_transition_loss": -1.1249744892120361, "ae_encoder_loss": 0.32288190722465515, "actor_loss": -0.4949037730693817, "actor_target_entropy": -2.0, "actor_entropy": -0.20700933039188385, "alpha_loss": -0.009132239036262035, "alpha_value": 0.016515881412678277, "duration": 2.0660054683685303, "step": 25142}
{"episode_reward": -2.7888546321236314, "episode": 724.0, "batch_reward": 0.11556083802133799, "critic_loss": 0.11200651153922081, "ae_transition_loss": -1.0106764808297157, "ae_encoder_loss": 0.2785698212683201, "actor_loss": -0.5500063896179199, "actor_target_entropy": -2.0, "actor_entropy": -0.24199645593762398, "alpha_loss": -0.009592673741281033, "alpha_value": 0.016546234210862452, "duration": 17.13408613204956, "step": 25224}
{"episode_reward": 26.443254725203587, "episode": 725.0, "batch_reward": 0.1131579065695405, "critic_loss": 0.18520724028348923, "ae_transition_loss": -0.9031365662813187, "ae_encoder_loss": 0.21077019348740578, "actor_loss": -0.5707427710294724, "actor_target_entropy": -2.0, "actor_entropy": 0.053542714565992355, "alpha_loss": 0.00037120508204679936, "alpha_value": 0.01660154894990773, "duration": 9.097864389419556, "step": 25268}
{"episode_reward": 5.9984999220820026, "episode": 726.0, "batch_reward": 0.13975121080875397, "critic_loss": 0.12344279140233994, "ae_transition_loss": -0.9662276208400726, "ae_encoder_loss": 0.17970560491085052, "actor_loss": -0.6454541087150574, "actor_target_entropy": -2.0, "actor_entropy": 0.23861533403396606, "alpha_loss": 0.00038246612530201674, "alpha_value": 0.016623164061577007, "duration": 4.2680344581604, "step": 25289}
{"episode_reward": -1.022658132622818, "episode": 727.0, "batch_reward": 0.12473126500844955, "critic_loss": 0.1377699002623558, "ae_transition_loss": -1.0088049471378326, "ae_encoder_loss": 0.15720902383327484, "actor_loss": -0.4768856465816498, "actor_target_entropy": -2.0, "actor_entropy": 0.3084065616130829, "alpha_loss": 0.004542584239970893, "alpha_value": 0.01663327479418622, "duration": 3.543739080429077, "step": 25305}
{"episode_reward": 0.6823716642557343, "episode": 728.0, "batch_reward": 0.1005467101931572, "critic_loss": 0.1610971949994564, "ae_transition_loss": -1.1138077974319458, "ae_encoder_loss": 0.21643615514039993, "actor_loss": -0.49199676513671875, "actor_target_entropy": -2.0, "actor_entropy": 0.3014552593231201, "alpha_loss": 0.004890432581305504, "alpha_value": 0.016639043396801133, "duration": 4.843596935272217, "step": 25328}
{"episode_reward": -1.9289601902528994, "episode": 729.0, "batch_reward": 0.0794740691781044, "critic_loss": 0.13587477058172226, "ae_transition_loss": -1.0448651313781738, "ae_encoder_loss": 0.2710847184062004, "actor_loss": -0.5165452361106873, "actor_target_entropy": -2.0, "actor_entropy": 0.25089704245328903, "alpha_loss": 0.008059427374973893, "alpha_value": 0.01664014712877074, "duration": 3.3469698429107666, "step": 25343}
{"episode_reward": -3.981893821689827, "episode": 730.0, "duration": 0.2437729835510254, "step": 25344}
{"episode_reward": -0.272645503282547, "episode": 731.0, "batch_reward": 0.09641778841614723, "critic_loss": 0.051973653957247734, "ae_transition_loss": -1.0263017416000366, "ae_encoder_loss": 0.2855323255062103, "actor_loss": -0.5671036243438721, "actor_target_entropy": -2.0, "actor_entropy": 0.291709303855896, "alpha_loss": 0.005670244689099491, "alpha_value": 0.016636117168667072, "duration": 36.88830280303955, "step": 25364}
{"episode_reward": -1.6831231049277986, "episode": 732.0, "batch_reward": 0.10071085020899773, "critic_loss": 0.23897794634103775, "ae_transition_loss": -0.8636803925037384, "ae_encoder_loss": 0.3271685093641281, "actor_loss": -0.5148385018110275, "actor_target_entropy": -2.0, "actor_entropy": 0.31970933079719543, "alpha_loss": 0.0071710809133946896, "alpha_value": 0.016628933068377483, "duration": 4.964271068572998, "step": 25388}
{"episode_reward": -1.9617046376059741, "episode": 733.0, "batch_reward": 0.12741005952869142, "critic_loss": 0.18804995715618134, "ae_transition_loss": -1.0112053496497018, "ae_encoder_loss": 0.2511589101382664, "actor_loss": -0.5502567929880959, "actor_target_entropy": -2.0, "actor_entropy": -0.05912154061453683, "alpha_loss": 0.005814549064130655, "alpha_value": 0.016601065787647893, "duration": 14.367533206939697, "step": 25457}
{"episode_reward": 10.004419116493597, "episode": 734.0, "batch_reward": 0.11006372173627217, "critic_loss": 0.08739482114712398, "ae_transition_loss": -1.0384336511294048, "ae_encoder_loss": 0.19386672476927438, "actor_loss": -0.6499140659968058, "actor_target_entropy": -2.0, "actor_entropy": 0.1626137395699819, "alpha_loss": 0.006153663620352745, "alpha_value": 0.01656416141536556, "duration": 5.375232696533203, "step": 25484}
{"episode_reward": -1.1601523945456764, "episode": 735.0, "batch_reward": 0.08775342876712482, "critic_loss": 0.09016130988796552, "ae_transition_loss": -1.1106069485346477, "ae_encoder_loss": 0.22294787069161734, "actor_loss": -0.5342211524645487, "actor_target_entropy": -2.0, "actor_entropy": -0.05629617472489675, "alpha_loss": 0.004272110410965979, "alpha_value": 0.016540728847048543, "duration": 7.324176788330078, "step": 25520}
{"episode_reward": 12.52563052639035, "episode": 736.0, "batch_reward": 0.11970627307891846, "critic_loss": 0.11566939949989319, "ae_transition_loss": -1.1233165264129639, "ae_encoder_loss": 0.28102388978004456, "actor_loss": -0.5801367163658142, "actor_target_entropy": -2.0, "actor_entropy": 0.37978121638298035, "alpha_loss": 0.007191692013293505, "alpha_value": 0.016525462339554275, "duration": 0.5171012878417969, "step": 25521}
{"episode_reward": -0.24446618714222468, "episode": 737.0, "duration": 0.22737550735473633, "step": 25522}
{"episode_reward": -0.5496740081456507, "episode": 738.0, "batch_reward": 0.06753427783648173, "critic_loss": 0.09210601945718129, "ae_transition_loss": -1.0598488251368205, "ae_encoder_loss": 0.3000367283821106, "actor_loss": -0.5411591529846191, "actor_target_entropy": -2.0, "actor_entropy": 0.341976523399353, "alpha_loss": 0.010305862408131361, "alpha_value": 0.01650757145027883, "duration": 6.246918678283691, "step": 25553}
{"episode_reward": -3.2065462614975844, "episode": 739.0, "duration": 0.20827412605285645, "step": 25554}
{"episode_reward": -0.30098879574660803, "episode": 740.0, "batch_reward": 0.11095191165804863, "critic_loss": 0.12120984420180321, "ae_transition_loss": -1.0611554861068726, "ae_encoder_loss": 0.23902569711208344, "actor_loss": -0.6042928814888, "actor_target_entropy": -2.0, "actor_entropy": 0.1977474197745323, "alpha_loss": 0.0010082545457407832, "alpha_value": 0.01646967500202957, "duration": 9.97614336013794, "step": 25601}
{"episode_reward": 11.685182196780655, "episode": 741.0, "batch_reward": 0.150798249989748, "critic_loss": 0.1364273801445961, "ae_transition_loss": -0.9914818108081818, "ae_encoder_loss": 0.222751185297966, "actor_loss": -0.7551456689834595, "actor_target_entropy": -2.0, "actor_entropy": -0.14242541417479515, "alpha_loss": 0.0014094315702095628, "alpha_value": 0.016443898594246373, "duration": 84.5549943447113, "step": 25625}
{"episode_reward": -2.852497268358067, "episode": 742.0, "batch_reward": 0.14099689253738948, "critic_loss": 0.12133007017629487, "ae_transition_loss": -0.9683621440614972, "ae_encoder_loss": 0.29016964776175364, "actor_loss": -0.6838441916874477, "actor_target_entropy": -2.0, "actor_entropy": 0.08905467284577233, "alpha_loss": 0.005438977536479277, "alpha_value": 0.016413572390893354, "duration": 14.703968286514282, "step": 25699}
{"episode_reward": -2.154054315377746, "episode": 743.0, "batch_reward": 0.14040017500519753, "critic_loss": 0.13027136027812958, "ae_transition_loss": -0.8915771692991257, "ae_encoder_loss": 0.27989112213253975, "actor_loss": -0.7032934725284576, "actor_target_entropy": -2.0, "actor_entropy": 0.0441088005900383, "alpha_loss": -0.0009270391310565174, "alpha_value": 0.016373283620976325, "duration": 7.255472183227539, "step": 25734}
{"episode_reward": 2.378427149681013, "episode": 744.0, "batch_reward": 0.09781105816364288, "critic_loss": 0.1085488349199295, "ae_transition_loss": -0.9407728910446167, "ae_encoder_loss": 0.219977667927742, "actor_loss": -0.545823484659195, "actor_target_entropy": -2.0, "actor_entropy": -0.10851574093103408, "alpha_loss": 0.0018187434412539004, "alpha_value": 0.016353903478866273, "duration": 10.154101371765137, "step": 25783}
{"episode_reward": 1.5576108485778384, "episode": 745.0, "batch_reward": 0.10956375946601232, "critic_loss": 0.13850250442822773, "ae_transition_loss": -0.9314892808596293, "ae_encoder_loss": 0.24743632872899374, "actor_loss": -0.6228018522262573, "actor_target_entropy": -2.0, "actor_entropy": 0.028512074053287505, "alpha_loss": 0.0019272632896900177, "alpha_value": 0.016317175725519613, "duration": 31.997698545455933, "step": 25939}
{"episode_reward": 38.16680381109169, "episode": 746.0, "batch_reward": 0.12136095017194748, "critic_loss": 0.1624589612086614, "ae_transition_loss": -1.0392106970151265, "ae_encoder_loss": 0.25937776764233905, "actor_loss": -0.6274556318918864, "actor_target_entropy": -2.0, "actor_entropy": 0.42759066820144653, "alpha_loss": 0.008255335269495845, "alpha_value": 0.016290661836858296, "duration": 5.484299182891846, "step": 25964}
{"episode_reward": -2.7061490484733928, "episode": 747.0, "batch_reward": 0.13084805011749268, "critic_loss": 0.21961134672164917, "ae_transition_loss": -1.0216220617294312, "ae_encoder_loss": 0.22042855620384216, "actor_loss": -0.7135076522827148, "actor_target_entropy": -2.0, "actor_entropy": 0.33799153566360474, "alpha_loss": 0.011756684631109238, "alpha_value": 0.016278821843685478, "duration": 3.479417085647583, "step": 25980}
{"episode_reward": 0.7167660743478387, "episode": 748.0, "batch_reward": 0.09786240011453629, "critic_loss": 0.11855243146419525, "ae_transition_loss": -1.0347885191440582, "ae_encoder_loss": 0.22705316543579102, "actor_loss": -0.6371968686580658, "actor_target_entropy": -2.0, "actor_entropy": 0.1833958476781845, "alpha_loss": 0.005720873363316059, "alpha_value": 0.016266542653716853, "duration": 4.279773712158203, "step": 25999}
{"episode_reward": -4.3460377610715195, "episode": 749.0, "batch_reward": 0.1295159508784612, "critic_loss": 0.16300707558790842, "ae_transition_loss": -0.8399673799673716, "ae_encoder_loss": 0.19722549617290497, "actor_loss": -0.6689567764600118, "actor_target_entropy": -2.0, "actor_entropy": -0.010701477527618408, "alpha_loss": 0.0043124755611643195, "alpha_value": 0.0162455605882463, "duration": 6.527579307556152, "step": 26030}
{"episode_reward": -2.7768655548244365, "episode": 750.0, "batch_reward": 0.10443851351737976, "critic_loss": 0.1336594969034195, "ae_transition_loss": -1.0399702787399292, "ae_encoder_loss": 0.18776294589042664, "actor_loss": -0.6919103860855103, "actor_target_entropy": -2.0, "actor_entropy": -0.08697391301393509, "alpha_loss": 8.953164797276258e-05, "alpha_value": 0.01622940112911598, "duration": 0.5349938869476318, "step": 26031}
{"episode_reward": -0.9903602600097656, "episode": 751.0, "batch_reward": 0.12738383747637272, "critic_loss": 0.11588742211461067, "ae_transition_loss": -1.126492977142334, "ae_encoder_loss": 0.23654135689139366, "actor_loss": -0.6899975091218948, "actor_target_entropy": -2.0, "actor_entropy": -0.12154132314026356, "alpha_loss": 0.0016516171817784198, "alpha_value": 0.01621174495589192, "duration": 107.50858044624329, "step": 26080}
{"episode_reward": 17.123605107084938, "episode": 752.0, "batch_reward": 0.08458635831872623, "critic_loss": 0.14314622928698859, "ae_transition_loss": -1.0989210208257039, "ae_encoder_loss": 0.2706444412469864, "actor_loss": -0.5317974885304769, "actor_target_entropy": -2.0, "actor_entropy": -0.1541296566526095, "alpha_loss": 0.0030437263970573745, "alpha_value": 0.01619153089950288, "duration": 5.032589912414551, "step": 26104}
{"episode_reward": 1.1967597968573216, "episode": 753.0, "duration": 0.21503591537475586, "step": 26105}
{"episode_reward": -0.2217209123730618, "episode": 754.0, "batch_reward": 0.10019579380750657, "critic_loss": 0.23666973710060119, "ae_transition_loss": -0.9346081018447876, "ae_encoder_loss": 0.21802906095981597, "actor_loss": -0.6095288395881653, "actor_target_entropy": -2.0, "actor_entropy": -0.18572434037923813, "alpha_loss": 0.0024314986541867254, "alpha_value": 0.016169733977629153, "duration": 10.579984664916992, "step": 26159}
{"episode_reward": 0.9081187930573434, "episode": 755.0, "batch_reward": 0.09572374554617065, "critic_loss": 0.1479807272553444, "ae_transition_loss": -0.6790782638958522, "ae_encoder_loss": 0.3134446548564093, "actor_loss": -0.6203338929585048, "actor_target_entropy": -2.0, "actor_entropy": 0.09181713525738035, "alpha_loss": 0.007145992081080165, "alpha_value": 0.01613702935715709, "duration": 13.414100408554077, "step": 26224}
{"episode_reward": 3.4785171188797293, "episode": 756.0, "batch_reward": 0.09274199791252613, "critic_loss": 0.13967538500825563, "ae_transition_loss": -0.7250769237677256, "ae_encoder_loss": 0.26491812616586685, "actor_loss": -0.6258340279261271, "actor_target_entropy": -2.0, "actor_entropy": 0.3726314604282379, "alpha_loss": 0.010392340637433032, "alpha_value": 0.016080723386014566, "duration": 11.869115591049194, "step": 26282}
{"episode_reward": 12.4295559690544, "episode": 757.0, "batch_reward": 0.10907525941729546, "critic_loss": 0.11024925671517849, "ae_transition_loss": -0.8078471273183823, "ae_encoder_loss": 0.1704547144472599, "actor_loss": -0.6143427193164825, "actor_target_entropy": -2.0, "actor_entropy": 0.29744335263967514, "alpha_loss": 0.0072142729768529534, "alpha_value": 0.01602074079978803, "duration": 8.331925630569458, "step": 26324}
{"episode_reward": 1.1404180105742001, "episode": 758.0, "batch_reward": 0.11885551363229752, "critic_loss": 0.11932950466871262, "ae_transition_loss": -0.7948093016942342, "ae_encoder_loss": 0.1680140644311905, "actor_loss": -0.6327077349026998, "actor_target_entropy": -2.0, "actor_entropy": 0.16846612840890884, "alpha_loss": 0.0036175578522185483, "alpha_value": 0.015977040375773164, "duration": 7.356289863586426, "step": 26360}
{"episode_reward": 0.9268677942161586, "episode": 759.0, "batch_reward": 0.1019625614086787, "critic_loss": 0.23147762815157572, "ae_transition_loss": -0.8233666022618612, "ae_encoder_loss": 0.29018648465474445, "actor_loss": -0.6816644271214803, "actor_target_entropy": -2.0, "actor_entropy": 0.17033625642458597, "alpha_loss": 0.0038837941053013005, "alpha_value": 0.01594439380176178, "duration": 4.568548202514648, "step": 26381}
{"episode_reward": -2.2819447564023654, "episode": 760.0, "batch_reward": 0.11706538498401642, "critic_loss": 0.0871105045080185, "ae_transition_loss": -0.9469727873802185, "ae_encoder_loss": 0.269944965839386, "actor_loss": -0.7426527738571167, "actor_target_entropy": -2.0, "actor_entropy": 0.20632314682006836, "alpha_loss": 0.006888831965625286, "alpha_value": 0.015924831733687854, "duration": 2.5726587772369385, "step": 26394}
{"episode_reward": -1.9931532072457332, "episode": 761.0, "batch_reward": 0.11914769038558007, "critic_loss": 0.1870916098356247, "ae_transition_loss": -0.8965580105781555, "ae_encoder_loss": 0.28786068856716157, "actor_loss": -0.7195300996303559, "actor_target_entropy": -2.0, "actor_entropy": 0.18292360603809357, "alpha_loss": 0.012542083486914634, "alpha_value": 0.015891829434607565, "duration": 67.53887915611267, "step": 26447}
{"episode_reward": 9.547018265812504, "episode": 762.0, "batch_reward": 0.08710922300815582, "critic_loss": 0.2147112563252449, "ae_transition_loss": -1.0059112012386322, "ae_encoder_loss": 0.21629579365253448, "actor_loss": -0.47111061215400696, "actor_target_entropy": -2.0, "actor_entropy": -0.08309805020689964, "alpha_loss": 0.015110572800040245, "alpha_value": 0.015844608851628295, "duration": 3.3253743648529053, "step": 26461}
{"episode_reward": -2.4774114931208144, "episode": 763.0, "batch_reward": 0.13628864536682764, "critic_loss": 0.09868837893009186, "ae_transition_loss": -1.0106634497642517, "ae_encoder_loss": 0.2084015111128489, "actor_loss": -0.7320677042007446, "actor_target_entropy": -2.0, "actor_entropy": 0.03620266169309616, "alpha_loss": 0.00929865644623836, "alpha_value": 0.015804769598210557, "duration": 7.8376123905181885, "step": 26499}
{"episode_reward": 0.44026291530754125, "episode": 764.0, "duration": 0.22332000732421875, "step": 26500}
{"episode_reward": -2.7431857387276857, "episode": 765.0, "batch_reward": 0.09628850221633911, "critic_loss": 0.22791169583797455, "ae_transition_loss": -0.9591012597084045, "ae_encoder_loss": 0.15820054709911346, "actor_loss": -0.5306980013847351, "actor_target_entropy": -2.0, "actor_entropy": 0.02149452269077301, "alpha_loss": 0.01486416719853878, "alpha_value": 0.01577291750939962, "duration": 2.1518964767456055, "step": 26510}
{"episode_reward": -3.216714001037029, "episode": 766.0, "batch_reward": 0.12623898684978485, "critic_loss": 0.13400094956159592, "ae_transition_loss": -1.0013729631900787, "ae_encoder_loss": 0.23998310789465904, "actor_loss": -0.6705693453550339, "actor_target_entropy": -2.0, "actor_entropy": -0.0241989865899086, "alpha_loss": 0.009179435670375824, "alpha_value": 0.015731288517463318, "duration": 7.665844678878784, "step": 26547}
{"episode_reward": 11.598912741236202, "episode": 767.0, "batch_reward": 0.10347018390893936, "critic_loss": 0.10083559527993202, "ae_transition_loss": -0.836310088634491, "ae_encoder_loss": 0.2933441251516342, "actor_loss": -0.769321858882904, "actor_target_entropy": -2.0, "actor_entropy": 0.34778913483023643, "alpha_loss": 0.007176876068115234, "alpha_value": 0.01568339168228075, "duration": 3.309575319290161, "step": 26561}
{"episode_reward": -2.9049178111593914, "episode": 768.0, "batch_reward": 0.08196719611684482, "critic_loss": 0.13333086172739664, "ae_transition_loss": -0.996139923731486, "ae_encoder_loss": 0.24825099607308707, "actor_loss": -0.7312945127487183, "actor_target_entropy": -2.0, "actor_entropy": -0.05375936130682627, "alpha_loss": -0.004897989798337221, "alpha_value": 0.015647091948233792, "duration": 7.0594282150268555, "step": 26594}
{"episode_reward": 6.016797818029391, "episode": 769.0, "batch_reward": 0.14673392474651337, "critic_loss": 0.1409672647714615, "ae_transition_loss": -0.8968765437602997, "ae_encoder_loss": 0.277819387614727, "actor_loss": -0.6681773066520691, "actor_target_entropy": -2.0, "actor_entropy": -0.38019222021102905, "alpha_loss": -0.012336899060755968, "alpha_value": 0.015622614155245098, "duration": 4.309455156326294, "step": 26614}
{"episode_reward": -3.1113940007444247, "episode": 770.0, "duration": 0.23445796966552734, "step": 26615}
{"episode_reward": 0.029429089552714283, "episode": 771.0, "batch_reward": 0.1266971118748188, "critic_loss": 0.16458219786485037, "ae_transition_loss": -0.9498813251654307, "ae_encoder_loss": 0.2352470507224401, "actor_loss": -0.7662090460459391, "actor_target_entropy": -2.0, "actor_entropy": -0.11335822691520055, "alpha_loss": -0.0012668703663318108, "alpha_value": 0.01561141617163909, "duration": 41.9240562915802, "step": 26680}
{"episode_reward": 14.507037530975579, "episode": 772.0, "batch_reward": 0.14768650382757187, "critic_loss": 0.07733428105711937, "ae_transition_loss": -1.0211867988109589, "ae_encoder_loss": 0.2674473598599434, "actor_loss": -0.9108115434646606, "actor_target_entropy": -2.0, "actor_entropy": 0.016315259039402008, "alpha_loss": -0.0027611987316049635, "alpha_value": 0.015606448668247118, "duration": 3.7680037021636963, "step": 26698}
{"episode_reward": 0.72418819065592, "episode": 773.0, "batch_reward": 0.12562387064099312, "critic_loss": 0.10017755627632141, "ae_transition_loss": -1.0438412427902222, "ae_encoder_loss": 0.24969999492168427, "actor_loss": -0.724886417388916, "actor_target_entropy": -2.0, "actor_entropy": 0.13426068052649498, "alpha_loss": 0.0027873486978933215, "alpha_value": 0.015607299597686192, "duration": 4.463582992553711, "step": 26720}
{"episode_reward": -0.10175599157546206, "episode": 774.0, "batch_reward": 0.1150834709405899, "critic_loss": 0.1757805049419403, "ae_transition_loss": -0.5278981924057007, "ae_encoder_loss": 0.332259863615036, "actor_loss": -0.7810606360435486, "actor_target_entropy": -2.0, "actor_entropy": 0.30621910095214844, "alpha_loss": 0.011427607387304306, "alpha_value": 0.015606859372549593, "duration": 1.9719419479370117, "step": 26729}
{"episode_reward": -2.737565390206389, "episode": 775.0, "duration": 0.22769474983215332, "step": 26730}
{"episode_reward": -0.48169992486881674, "episode": 776.0, "batch_reward": 0.10251234223445256, "critic_loss": 0.11793496211369832, "ae_transition_loss": -0.9736071427663168, "ae_encoder_loss": 0.2819307744503021, "actor_loss": -0.7063474059104919, "actor_target_entropy": -2.0, "actor_entropy": 0.07231800258159637, "alpha_loss": 0.010729517477254072, "alpha_value": 0.01559922359943415, "duration": 4.90730619430542, "step": 26753}
{"episode_reward": -2.9855440531257176, "episode": 777.0, "duration": 0.25159335136413574, "step": 26754}
{"episode_reward": -0.19779864764309069, "episode": 778.0, "batch_reward": 0.113236453384161, "critic_loss": 0.11322045773267746, "ae_transition_loss": -0.8664949178695679, "ae_encoder_loss": 0.25569706559181216, "actor_loss": -0.7292572855949402, "actor_target_entropy": -2.0, "actor_entropy": -0.06330295652151108, "alpha_loss": 0.004494595108553767, "alpha_value": 0.015574761390789458, "duration": 10.900428771972656, "step": 26805}
{"episode_reward": 11.814815056210879, "episode": 779.0, "batch_reward": 0.11127053449551265, "critic_loss": 0.20762928326924643, "ae_transition_loss": -0.7266273697217306, "ae_encoder_loss": 0.22996047139167786, "actor_loss": -0.7751502195994059, "actor_target_entropy": -2.0, "actor_entropy": 0.19658003250757852, "alpha_loss": 0.0055731179503103094, "alpha_value": 0.015549014055656394, "duration": 6.921658992767334, "step": 26837}
{"episode_reward": 6.564523818623027, "episode": 780.0, "batch_reward": 0.11404391005635262, "critic_loss": 0.12920907884836197, "ae_transition_loss": -0.750628799200058, "ae_encoder_loss": 0.25543883070349693, "actor_loss": -0.7703648805618286, "actor_target_entropy": -2.0, "actor_entropy": 0.370231568813324, "alpha_loss": 0.005691866943379864, "alpha_value": 0.015521539776788964, "duration": 8.374900102615356, "step": 26876}
{"episode_reward": 3.4312922229011247, "episode": 781.0, "batch_reward": 0.11335302144289017, "critic_loss": 0.0983652800321579, "ae_transition_loss": -0.7610231041908264, "ae_encoder_loss": 0.3586615025997162, "actor_loss": -0.7929867267608642, "actor_target_entropy": -2.0, "actor_entropy": -0.05364280641078949, "alpha_loss": 0.0027640827931463717, "alpha_value": 0.015486452432840778, "duration": 43.86092019081116, "step": 26924}
{"episode_reward": -1.3702625342349717, "episode": 782.0, "batch_reward": 0.10058239971597989, "critic_loss": 0.14574740578730902, "ae_transition_loss": -0.8175199230511984, "ae_encoder_loss": 0.1737796887755394, "actor_loss": -0.679940938949585, "actor_target_entropy": -2.0, "actor_entropy": 0.21082158635059992, "alpha_loss": 0.00923581764800474, "alpha_value": 0.015447678729259002, "duration": 13.465675354003906, "step": 26987}
{"episode_reward": -1.7779684708379233, "episode": 783.0, "batch_reward": 0.13725564877192178, "critic_loss": 0.1527091239889463, "ae_transition_loss": -0.6980425218741099, "ae_encoder_loss": 0.22889657815297446, "actor_loss": -0.8093257149060568, "actor_target_entropy": -2.0, "actor_entropy": 0.25245581070582074, "alpha_loss": 0.010333857809503874, "alpha_value": 0.015403844338523473, "duration": 5.815718412399292, "step": 27014}
{"episode_reward": -0.6000254579365637, "episode": 784.0, "batch_reward": 0.1140037551522255, "critic_loss": 0.3541274666786194, "ae_transition_loss": -0.6585536301136017, "ae_encoder_loss": 0.2855292707681656, "actor_loss": -0.7942805886268616, "actor_target_entropy": -2.0, "actor_entropy": 0.020181823521852493, "alpha_loss": 0.0026055165217258036, "alpha_value": 0.015373740725571258, "duration": 5.476104736328125, "step": 27040}
{"episode_reward": -0.5372024637762618, "episode": 785.0, "batch_reward": 0.12921127304434776, "critic_loss": 0.338662713766098, "ae_transition_loss": -0.7985611855983734, "ae_encoder_loss": 0.2373323142528534, "actor_loss": -0.677334725856781, "actor_target_entropy": -2.0, "actor_entropy": -0.015199385583400726, "alpha_loss": 0.0020725377835333347, "alpha_value": 0.015352252712135413, "duration": 4.175719499588013, "step": 27060}
{"episode_reward": -1.6019730785942146, "episode": 786.0, "batch_reward": 0.1034423727542162, "critic_loss": 0.20351307280361652, "ae_transition_loss": -0.7061236649751663, "ae_encoder_loss": 0.2965339124202728, "actor_loss": -0.8197430074214935, "actor_target_entropy": -2.0, "actor_entropy": -0.04272247850894928, "alpha_loss": 0.0039092228980734944, "alpha_value": 0.015324757728291699, "duration": 7.906240940093994, "step": 27098}
{"episode_reward": 4.855023320430647, "episode": 787.0, "duration": 0.2693443298339844, "step": 27099}
{"episode_reward": -0.6236838825184012, "episode": 788.0, "batch_reward": 0.10959896296262742, "critic_loss": 0.2620774179697037, "ae_transition_loss": -0.7894824147224426, "ae_encoder_loss": 0.31047815680503843, "actor_loss": -0.7773850917816162, "actor_target_entropy": -2.0, "actor_entropy": 0.07893796414136886, "alpha_loss": 0.001666010869666934, "alpha_value": 0.015289047319193413, "duration": 9.523637533187866, "step": 27146}
{"episode_reward": 1.4796336673596573, "episode": 789.0, "batch_reward": 0.10044215619564056, "critic_loss": 0.10737941414117813, "ae_transition_loss": -0.8483918607234955, "ae_encoder_loss": 0.33438897132873535, "actor_loss": -0.5871799886226654, "actor_target_entropy": -2.0, "actor_entropy": 0.38192443549633026, "alpha_loss": 0.007224347675219178, "alpha_value": 0.015267245165052897, "duration": 4.955757141113281, "step": 27170}
{"episode_reward": 3.053700377294075, "episode": 790.0, "batch_reward": 0.1454937495291233, "critic_loss": 0.14841643907129765, "ae_transition_loss": -0.9082063585519791, "ae_encoder_loss": 0.2520027570426464, "actor_loss": -0.8998150825500488, "actor_target_entropy": -2.0, "actor_entropy": 0.3610190153121948, "alpha_loss": 0.006701231293845922, "alpha_value": 0.015245364204898967, "duration": 6.897261142730713, "step": 27201}
{"episode_reward": 1.0012815111153115, "episode": 791.0, "duration": 97.07827877998352, "step": 27202}
{"episode_reward": -0.23506223603753237, "episode": 792.0, "batch_reward": 0.18209759891033173, "critic_loss": 0.13282883167266846, "ae_transition_loss": -0.8778802156448364, "ae_encoder_loss": 0.2565775513648987, "actor_loss": -1.0317407846450806, "actor_target_entropy": -2.0, "actor_entropy": 0.31345847249031067, "alpha_loss": 0.003036720212548971, "alpha_value": 0.01522543845923274, "duration": 3.107903242111206, "step": 27217}
{"episode_reward": -1.460955078417854, "episode": 793.0, "batch_reward": 0.08820385113358498, "critic_loss": 0.28315243621667224, "ae_transition_loss": -0.9736610253651937, "ae_encoder_loss": 0.2427787482738495, "actor_loss": -0.7805795868237814, "actor_target_entropy": -2.0, "actor_entropy": 0.2983635862668355, "alpha_loss": 0.0049819420867909985, "alpha_value": 0.015209373948903556, "duration": 5.508612155914307, "step": 27243}
{"episode_reward": 4.138651307206748, "episode": 794.0, "batch_reward": 0.11098665744066238, "critic_loss": 0.16012154147028923, "ae_transition_loss": -0.8563668131828308, "ae_encoder_loss": 0.29405124485492706, "actor_loss": -0.7669408172369003, "actor_target_entropy": -2.0, "actor_entropy": 0.282038077712059, "alpha_loss": 0.0064628360560163856, "alpha_value": 0.015181302944218373, "duration": 8.899098634719849, "step": 27287}
{"episode_reward": 7.183985060450398, "episode": 795.0, "duration": 0.18316912651062012, "step": 27288}
{"episode_reward": -0.7924881998472809, "episode": 796.0, "batch_reward": 0.12271122882763545, "critic_loss": 0.1369483694434166, "ae_transition_loss": -0.5538458327452341, "ae_encoder_loss": 0.28844011823336285, "actor_loss": -0.7666559418042501, "actor_target_entropy": -2.0, "actor_entropy": 0.22469915946324667, "alpha_loss": 0.005935165410240491, "alpha_value": 0.015150762959267317, "duration": 5.462244033813477, "step": 27315}
{"episode_reward": -0.8750341925582085, "episode": 797.0, "batch_reward": 0.10762213170528412, "critic_loss": 0.11222630739212036, "ae_transition_loss": -0.6300370693206787, "ae_encoder_loss": 0.2598992809653282, "actor_loss": -0.9172034859657288, "actor_target_entropy": -2.0, "actor_entropy": 0.18846574425697327, "alpha_loss": 0.006247370736673474, "alpha_value": 0.0151278958240899, "duration": 4.7657859325408936, "step": 27339}
{"episode_reward": -0.47643244690622993, "episode": 798.0, "batch_reward": 0.10505744318167369, "critic_loss": 0.17930116256078085, "ae_transition_loss": -0.4914372464021047, "ae_encoder_loss": 0.3431514998277028, "actor_loss": -0.7731360594431559, "actor_target_entropy": -2.0, "actor_entropy": 0.1647148703535398, "alpha_loss": 0.007729492848739028, "alpha_value": 0.015104576705893746, "duration": 5.060259819030762, "step": 27362}
{"episode_reward": 1.8258455883991664, "episode": 799.0, "batch_reward": 0.12058807164430618, "critic_loss": 0.11492644250392914, "ae_transition_loss": -0.5362654626369476, "ae_encoder_loss": 0.3850184231996536, "actor_loss": -0.7417404651641846, "actor_target_entropy": -2.0, "actor_entropy": -0.023455947637557983, "alpha_loss": 0.0067693491000682116, "alpha_value": 0.015080000455040102, "duration": 4.963391542434692, "step": 27387}
{"episode_reward": 2.517142040518368, "episode": 800.0, "batch_reward": 0.1018667877651751, "critic_loss": 0.13894648337736726, "ae_transition_loss": -0.5683474726974964, "ae_encoder_loss": 0.2508209068328142, "actor_loss": -0.7688513472676277, "actor_target_entropy": -2.0, "actor_entropy": 0.21770578995347023, "alpha_loss": 0.006934963457752019, "alpha_value": 0.015026678086511482, "duration": 15.795437574386597, "step": 27465}
{"episode_reward": 21.059256264459368, "episode": 801.0, "batch_reward": 0.09496902674436569, "critic_loss": 0.12088457867503166, "ae_transition_loss": -0.71570885181427, "ae_encoder_loss": 0.25533176958560944, "actor_loss": -0.8513433635234833, "actor_target_entropy": -2.0, "actor_entropy": 0.516460120677948, "alpha_loss": 0.009287357330322266, "alpha_value": 0.014973061172343757, "duration": 88.50450253486633, "step": 27489}
{"episode_reward": -0.09313474864452526, "episode": 802.0, "batch_reward": 0.11763429322413035, "critic_loss": 0.2784682789019176, "ae_transition_loss": -0.7395982316562107, "ae_encoder_loss": 0.2676928767136165, "actor_loss": -0.8238616926329476, "actor_target_entropy": -2.0, "actor_entropy": 0.3414210890020643, "alpha_loss": 0.008177104539104871, "alpha_value": 0.014918135538533064, "duration": 13.663575172424316, "step": 27556}
{"episode_reward": 4.110654506490357, "episode": 803.0, "batch_reward": 0.0830103022356828, "critic_loss": 0.31448793907960254, "ae_transition_loss": -0.6830103794733683, "ae_encoder_loss": 0.3457905948162079, "actor_loss": -0.8121596972147623, "actor_target_entropy": -2.0, "actor_entropy": 0.07034120211998622, "alpha_loss": -0.004061546254282196, "alpha_value": 0.014858445270679421, "duration": 5.435018301010132, "step": 27581}
{"episode_reward": 0.28157410343142897, "episode": 804.0, "batch_reward": 0.17636573314666748, "critic_loss": 0.24849294126033783, "ae_transition_loss": -0.7523048520088196, "ae_encoder_loss": 0.37486395239830017, "actor_loss": -0.8445663452148438, "actor_target_entropy": -2.0, "actor_entropy": -0.043430738151073456, "alpha_loss": -0.008652513846755028, "alpha_value": 0.014843333817179158, "duration": 2.5893759727478027, "step": 27593}
{"episode_reward": -1.3762783958567433, "episode": 805.0, "batch_reward": 0.12465149909257889, "critic_loss": 0.14450693130493164, "ae_transition_loss": -0.7847638428211212, "ae_encoder_loss": 0.25536517053842545, "actor_loss": -0.7139524519443512, "actor_target_entropy": -2.0, "actor_entropy": 0.012293431907892227, "alpha_loss": 0.0008184125181287527, "alpha_value": 0.014837245847062617, "duration": 3.978778600692749, "step": 27611}
{"episode_reward": -1.1872944440013147, "episode": 806.0, "duration": 0.19229388236999512, "step": 27612}
{"episode_reward": -0.07611304678396463, "episode": 807.0, "batch_reward": 0.1267985279361407, "critic_loss": 0.2751568754514058, "ae_transition_loss": -0.6939469377199808, "ae_encoder_loss": 0.2809397578239441, "actor_loss": -0.9413268367449442, "actor_target_entropy": -2.0, "actor_entropy": 0.24686979750792185, "alpha_loss": 0.004465380838761727, "alpha_value": 0.014827311410498234, "duration": 7.267566919326782, "step": 27647}
{"episode_reward": -1.4647629489389824, "episode": 808.0, "batch_reward": 0.11836947500705719, "critic_loss": 0.2016572169959545, "ae_transition_loss": -0.5721756517887115, "ae_encoder_loss": 0.2807972580194473, "actor_loss": -0.8529579639434814, "actor_target_entropy": -2.0, "actor_entropy": 0.4615405350923538, "alpha_loss": 0.007833558833226562, "alpha_value": 0.014816005388616339, "duration": 3.502169370651245, "step": 27661}
{"episode_reward": -2.035664932314795, "episode": 809.0, "batch_reward": 0.0877099446952343, "critic_loss": 0.14583596773445606, "ae_transition_loss": -0.7936060279607773, "ae_encoder_loss": 0.3362865597009659, "actor_loss": -0.7854164391756058, "actor_target_entropy": -2.0, "actor_entropy": 0.41411609947681427, "alpha_loss": 0.005620925570838153, "alpha_value": 0.014796982006143643, "duration": 8.932467222213745, "step": 27702}
{"episode_reward": 0.8119230219938152, "episode": 810.0, "duration": 1.4127061367034912, "step": 27709}
{"episode_reward": -1.5687652091313538, "episode": 811.0, "batch_reward": 0.09284695610404015, "critic_loss": 0.0750734843313694, "ae_transition_loss": -0.6492676436901093, "ae_encoder_loss": 0.24635685980319977, "actor_loss": -0.9061424136161804, "actor_target_entropy": -2.0, "actor_entropy": 0.4154316782951355, "alpha_loss": 0.00493981596082449, "alpha_value": 0.014775863803492387, "duration": 40.24778199195862, "step": 27730}
{"episode_reward": -0.4897331008392164, "episode": 812.0, "batch_reward": 0.15745846182107925, "critic_loss": 0.16424628347158432, "ae_transition_loss": -0.8784818351268768, "ae_encoder_loss": 0.21621377021074295, "actor_loss": -0.9481282234191895, "actor_target_entropy": -2.0, "actor_entropy": 0.4173349440097809, "alpha_loss": 0.0029480543453246355, "alpha_value": 0.014761413678387476, "duration": 4.217888832092285, "step": 27750}
{"episode_reward": -1.3510680700000302, "episode": 813.0, "batch_reward": 0.11412294581532478, "critic_loss": 0.1562366746366024, "ae_transition_loss": -0.7572590708732605, "ae_encoder_loss": 0.2605007402598858, "actor_loss": -0.8775917589664459, "actor_target_entropy": -2.0, "actor_entropy": 0.3851988688111305, "alpha_loss": 0.004483337514102459, "alpha_value": 0.014740692640317807, "duration": 7.292693853378296, "step": 27783}
{"episode_reward": 1.1381770337514345, "episode": 814.0, "duration": 1.116701364517212, "step": 27788}
{"episode_reward": -2.1131360389993596, "episode": 815.0, "batch_reward": 0.10582384467124939, "critic_loss": 0.1655838955193758, "ae_transition_loss": -0.6929373890161514, "ae_encoder_loss": 0.29438116401433945, "actor_loss": -0.8664485216140747, "actor_target_entropy": -2.0, "actor_entropy": 0.3890278786420822, "alpha_loss": 0.007999388384632766, "alpha_value": 0.014712763066541646, "duration": 8.395895719528198, "step": 27828}
{"episode_reward": 1.1029582528153967, "episode": 816.0, "batch_reward": 0.09772481769323349, "critic_loss": 0.1964081128438314, "ae_transition_loss": -0.6057381629943848, "ae_encoder_loss": 0.3932904005050659, "actor_loss": -0.8400569756825765, "actor_target_entropy": -2.0, "actor_entropy": 0.3633224467436473, "alpha_loss": 0.010010550574709972, "alpha_value": 0.01468307765572697, "duration": 5.658164739608765, "step": 27853}
{"episode_reward": 1.7404748094912397, "episode": 817.0, "batch_reward": 0.1238182820379734, "critic_loss": 0.16049061715602875, "ae_transition_loss": -0.6992315649986267, "ae_encoder_loss": 0.3797098249197006, "actor_loss": -0.9354661703109741, "actor_target_entropy": -2.0, "actor_entropy": 0.26551002264022827, "alpha_loss": 0.012228596955537796, "alpha_value": 0.014657116508320535, "duration": 5.183212041854858, "step": 27878}
{"episode_reward": 1.5592371194144614, "episode": 818.0, "batch_reward": 0.11440239995718002, "critic_loss": 0.3229254335165024, "ae_transition_loss": -0.5993303298950196, "ae_encoder_loss": 0.23631267249584198, "actor_loss": -0.7942019939422608, "actor_target_entropy": -2.0, "actor_entropy": 0.073402638733387, "alpha_loss": 0.006478290725499392, "alpha_value": 0.014615111472876988, "duration": 9.861976385116577, "step": 27926}
{"episode_reward": 6.659042851193999, "episode": 819.0, "batch_reward": 0.10490355392297109, "critic_loss": 0.2402445673942566, "ae_transition_loss": -0.44974320630232495, "ae_encoder_loss": 0.2535996089378993, "actor_loss": -0.8004640340805054, "actor_target_entropy": -2.0, "actor_entropy": -0.023593028386433918, "alpha_loss": 0.006902848991254966, "alpha_value": 0.014569585751099652, "duration": 5.359708547592163, "step": 27952}
{"episode_reward": -0.20713385313996674, "episode": 820.0, "duration": 1.608083963394165, "step": 27960}
{"episode_reward": -1.8116763354405545, "episode": 821.0, "batch_reward": 0.10650399923324586, "critic_loss": 0.2646337360143661, "ae_transition_loss": -0.5115349292755127, "ae_encoder_loss": 0.36156118512153623, "actor_loss": -0.8411648988723754, "actor_target_entropy": -2.0, "actor_entropy": 0.06536535620689392, "alpha_loss": 0.006684336066246033, "alpha_value": 0.0145250814480298, "duration": 106.01315331459045, "step": 28001}
{"episode_reward": 2.3274143339825843, "episode": 822.0, "batch_reward": 0.1622992604970932, "critic_loss": 0.28278928995132446, "ae_transition_loss": -0.5277471542358398, "ae_encoder_loss": 0.29271382093429565, "actor_loss": -0.9219634532928467, "actor_target_entropy": -2.0, "actor_entropy": 0.17947101593017578, "alpha_loss": 0.0056020705960690975, "alpha_value": 0.014491666845850506, "duration": 2.5289320945739746, "step": 28013}
{"episode_reward": 0.14656465460631785, "episode": 823.0, "batch_reward": 0.12390638639529546, "critic_loss": 0.1946836362282435, "ae_transition_loss": -0.475544532140096, "ae_encoder_loss": 0.33708296219507855, "actor_loss": -0.9061538775761923, "actor_target_entropy": -2.0, "actor_entropy": 0.2680375774701436, "alpha_loss": 0.0053997694825132685, "alpha_value": 0.01447105027987495, "duration": 6.457056522369385, "step": 28044}
{"episode_reward": 0.6849590324849162, "episode": 824.0, "batch_reward": 0.13620359947284064, "critic_loss": 0.18462442855040231, "ae_transition_loss": -0.5834370056788126, "ae_encoder_loss": 0.3357695738474528, "actor_loss": -0.945668896039327, "actor_target_entropy": -2.0, "actor_entropy": 0.46204011638959247, "alpha_loss": 0.006088122880707185, "alpha_value": 0.014441215943717951, "duration": 6.667837381362915, "step": 28077}
{"episode_reward": -1.2405600215897474, "episode": 825.0, "batch_reward": 0.11795669496059417, "critic_loss": 0.16804997026920318, "ae_transition_loss": -0.43909873962402346, "ae_encoder_loss": 0.23267466127872466, "actor_loss": -0.871830940246582, "actor_target_entropy": -2.0, "actor_entropy": 0.6863444209098816, "alpha_loss": 0.007037811772897839, "alpha_value": 0.014401787003449101, "duration": 9.22782826423645, "step": 28123}
{"episode_reward": 4.794517450302137, "episode": 826.0, "batch_reward": 0.09161251038312912, "critic_loss": 0.1592117746671041, "ae_transition_loss": -0.6710329254468282, "ae_encoder_loss": 0.31122856338818866, "actor_loss": -0.8803881605466207, "actor_target_entropy": -2.0, "actor_entropy": 0.6941225131352743, "alpha_loss": 0.0053885091717044515, "alpha_value": 0.014361414663138275, "duration": 7.035900354385376, "step": 28157}
{"episode_reward": 0.1337136998025803, "episode": 827.0, "batch_reward": 0.10456945498784383, "critic_loss": 0.22519545753796896, "ae_transition_loss": -0.6207161148389181, "ae_encoder_loss": 0.33781708776950836, "actor_loss": -0.8334725896517435, "actor_target_entropy": -2.0, "actor_entropy": 0.48959697286287945, "alpha_loss": 0.007597523741424084, "alpha_value": 0.014332131472559998, "duration": 6.355417728424072, "step": 28188}
{"episode_reward": 1.9985122681934653, "episode": 828.0, "duration": 0.22378015518188477, "step": 28189}
{"episode_reward": -0.8172483868305659, "episode": 829.0, "duration": 0.2315664291381836, "step": 28190}
{"episode_reward": -0.6315459133783231, "episode": 830.0, "batch_reward": 0.11024125516414643, "critic_loss": 0.2044305235147476, "ae_transition_loss": -0.7382032632827759, "ae_encoder_loss": 0.3023673206567764, "actor_loss": -0.8192890286445618, "actor_target_entropy": -2.0, "actor_entropy": 0.21256645023822784, "alpha_loss": 0.00923860352486372, "alpha_value": 0.014291187591124096, "duration": 8.709980726242065, "step": 28231}
{"episode_reward": -0.2658791963799047, "episode": 831.0, "batch_reward": 0.1029529223839442, "critic_loss": 0.19236423820257187, "ae_transition_loss": -0.7360126972198486, "ae_encoder_loss": 0.29063984751701355, "actor_loss": -0.872641384601593, "actor_target_entropy": -2.0, "actor_entropy": 0.02109868824481964, "alpha_loss": 0.008942818269133568, "alpha_value": 0.014245188852203055, "duration": 40.541924715042114, "step": 28267}
{"episode_reward": 2.725842533510789, "episode": 832.0, "batch_reward": 0.12024062871932983, "critic_loss": 0.32998429536819457, "ae_transition_loss": -0.665003776550293, "ae_encoder_loss": 0.2642898142337799, "actor_loss": -0.9275556802749634, "actor_target_entropy": -2.0, "actor_entropy": 0.02100357264280319, "alpha_loss": 0.00992584228515625, "alpha_value": 0.014194376440116225, "duration": 10.356220245361328, "step": 28318}
{"episode_reward": 23.44090217314564, "episode": 833.0, "batch_reward": 0.12385271489620209, "critic_loss": 0.2299314240614573, "ae_transition_loss": -0.676279882589976, "ae_encoder_loss": 0.2767458309729894, "actor_loss": -0.9274210929870605, "actor_target_entropy": -2.0, "actor_entropy": 0.1704247792561849, "alpha_loss": 0.00948264030739665, "alpha_value": 0.014141325904918428, "duration": 5.193406105041504, "step": 28341}
{"episode_reward": 4.65243905822982, "episode": 834.0, "batch_reward": 0.11480714753270149, "critic_loss": 0.1440487653017044, "ae_transition_loss": -0.7354860603809357, "ae_encoder_loss": 0.2970350831747055, "actor_loss": -0.952411413192749, "actor_target_entropy": -2.0, "actor_entropy": 0.3012455850839615, "alpha_loss": 0.010362822562456131, "alpha_value": 0.014107866863439612, "duration": 5.568613767623901, "step": 28369}
{"episode_reward": 1.7698704934761567, "episode": 835.0, "batch_reward": 0.10786193112532298, "critic_loss": 0.15754376103480658, "ae_transition_loss": -0.6384638746579488, "ae_encoder_loss": 0.34904244542121887, "actor_loss": -1.0004650155703227, "actor_target_entropy": -2.0, "actor_entropy": 0.4095318714777629, "alpha_loss": 0.007500012560437123, "alpha_value": 0.01407358161631365, "duration": 6.6290435791015625, "step": 28400}
{"episode_reward": 0.7679065689503934, "episode": 836.0, "batch_reward": 0.1437130868434906, "critic_loss": 0.17373137176036835, "ae_transition_loss": -0.5525383353233337, "ae_encoder_loss": 0.279653936624527, "actor_loss": -1.149113655090332, "actor_target_entropy": -2.0, "actor_entropy": 0.48907411098480225, "alpha_loss": 0.01043609157204628, "alpha_value": 0.01404696932209056, "duration": 0.5459420680999756, "step": 28401}
{"episode_reward": 0.028645644003378323, "episode": 837.0, "batch_reward": 0.08537624776363373, "critic_loss": 0.21660913030306497, "ae_transition_loss": -0.6173757115999857, "ae_encoder_loss": 0.303731972972552, "actor_loss": -0.8178858558336893, "actor_target_entropy": -2.0, "actor_entropy": 0.5512412587801615, "alpha_loss": 0.009532587292293707, "alpha_value": 0.01401947784416121, "duration": 6.450751304626465, "step": 28431}
{"episode_reward": 0.7475005570590245, "episode": 838.0, "duration": 0.19583392143249512, "step": 28432}
{"episode_reward": -0.043967218026208565, "episode": 839.0, "batch_reward": 0.10401714593172073, "critic_loss": 0.13944771885871887, "ae_transition_loss": -0.582831621170044, "ae_encoder_loss": 0.34520483016967773, "actor_loss": -0.8482959270477295, "actor_target_entropy": -2.0, "actor_entropy": 0.5481374263763428, "alpha_loss": 0.009792586788535118, "alpha_value": 0.013991991406002761, "duration": 3.4066214561462402, "step": 28448}
{"episode_reward": -2.044722341941142, "episode": 840.0, "batch_reward": 0.09520496055483818, "critic_loss": 0.19253974501043558, "ae_transition_loss": -0.4230610467493534, "ae_encoder_loss": 0.3259848915040493, "actor_loss": -1.0088467001914978, "actor_target_entropy": -2.0, "actor_entropy": 0.4845510572195053, "alpha_loss": 0.007410746533423662, "alpha_value": 0.013959383832961605, "duration": 7.995857238769531, "step": 28486}
{"episode_reward": 4.769948214902819, "episode": 841.0, "duration": 71.31145024299622, "step": 28487}
{"episode_reward": -0.1252862811088562, "episode": 842.0, "batch_reward": 0.13291958421468736, "critic_loss": 0.20601484328508377, "ae_transition_loss": -0.6171581983566284, "ae_encoder_loss": 0.3701753497123718, "actor_loss": -0.9930259346961975, "actor_target_entropy": -2.0, "actor_entropy": 0.36918655037879944, "alpha_loss": 0.009547725412994623, "alpha_value": 0.013901579572661226, "duration": 10.956031084060669, "step": 28538}
{"episode_reward": 5.640483884284942, "episode": 843.0, "batch_reward": 0.08288487046957016, "critic_loss": 0.10527768234411876, "ae_transition_loss": -0.5983653465906779, "ae_encoder_loss": 0.28671522935231525, "actor_loss": -0.7862288951873779, "actor_target_entropy": -2.0, "actor_entropy": 0.24395826955636343, "alpha_loss": 0.011419823703666529, "alpha_value": 0.013848468857243258, "duration": 6.01183009147644, "step": 28567}
{"episode_reward": 3.9226787557551224, "episode": 844.0, "batch_reward": 0.09580163657665253, "critic_loss": 0.17819059267640114, "ae_transition_loss": -0.6717822551727295, "ae_encoder_loss": 0.26246659457683563, "actor_loss": -0.8112167418003082, "actor_target_entropy": -2.0, "actor_entropy": 0.2402159422636032, "alpha_loss": 0.013949227519333363, "alpha_value": 0.013812992890536474, "duration": 4.591791391372681, "step": 28590}
{"episode_reward": 1.190937148926606, "episode": 845.0, "batch_reward": 0.10519425757229328, "critic_loss": 0.22425967920571566, "ae_transition_loss": -0.6147117912769318, "ae_encoder_loss": 0.3590224012732506, "actor_loss": -0.9080801159143448, "actor_target_entropy": -2.0, "actor_entropy": 0.3528366181999445, "alpha_loss": 0.010147117311134934, "alpha_value": 0.01373528357978034, "duration": 15.743686199188232, "step": 28668}
{"episode_reward": 21.634497980109753, "episode": 846.0, "batch_reward": 0.12357423454523087, "critic_loss": 0.21333745121955872, "ae_transition_loss": -0.428907185792923, "ae_encoder_loss": 0.3095322847366333, "actor_loss": -1.0953848361968994, "actor_target_entropy": -2.0, "actor_entropy": 0.5169313549995422, "alpha_loss": 0.0055725472047924995, "alpha_value": 0.013667531113217604, "duration": 2.0962016582489014, "step": 28678}
{"episode_reward": -0.4556398425763289, "episode": 847.0, "batch_reward": 0.12708375106255212, "critic_loss": 0.1332365075747172, "ae_transition_loss": -0.479179322719574, "ae_encoder_loss": 0.3441808720429738, "actor_loss": -1.058100163936615, "actor_target_entropy": -2.0, "actor_entropy": 0.5255234440167745, "alpha_loss": 0.004861869849264622, "alpha_value": 0.013640037687956047, "duration": 5.483193874359131, "step": 28704}
{"episode_reward": 1.7829311386179971, "episode": 848.0, "batch_reward": 0.08867184551698822, "critic_loss": 0.2593995769109045, "ae_transition_loss": -0.4108358940907887, "ae_encoder_loss": 0.3140899986028671, "actor_loss": -0.8844077587127686, "actor_target_entropy": -2.0, "actor_entropy": 0.5771484971046448, "alpha_loss": 0.011293602309056692, "alpha_value": 0.013575649345139081, "duration": 15.327903985977173, "step": 28778}
{"episode_reward": 17.221942670677564, "episode": 849.0, "batch_reward": 0.1262679725885391, "critic_loss": 0.19589565694332123, "ae_transition_loss": -0.4535342276096344, "ae_encoder_loss": 0.24638623595237732, "actor_loss": -1.0030851364135742, "actor_target_entropy": -2.0, "actor_entropy": 0.6628777861595154, "alpha_loss": 0.012599159963428974, "alpha_value": 0.013490683615013838, "duration": 9.719907760620117, "step": 28825}
{"episode_reward": 1.0714438437220215, "episode": 850.0, "batch_reward": 0.10509905343254407, "critic_loss": 0.30184630304574966, "ae_transition_loss": -0.4569057474533717, "ae_encoder_loss": 0.2775586172938347, "actor_loss": -0.9696274399757385, "actor_target_entropy": -2.0, "actor_entropy": 0.6695162355899811, "alpha_loss": 0.012582863370577494, "alpha_value": 0.013402915960392099, "duration": 12.331872940063477, "step": 28886}
{"episode_reward": -0.30982809863463506, "episode": 851.0, "duration": 47.83956170082092, "step": 28887}
{"episode_reward": -0.059990842580583126, "episode": 852.0, "batch_reward": 0.14516843669116497, "critic_loss": 0.33376872539520264, "ae_transition_loss": -0.5069203078746796, "ae_encoder_loss": 0.3678366467356682, "actor_loss": -1.1022410690784454, "actor_target_entropy": -2.0, "actor_entropy": 0.5016305446624756, "alpha_loss": 0.007416165841277689, "alpha_value": 0.013319973876699713, "duration": 8.643850088119507, "step": 28929}
{"episode_reward": 3.731124131257139, "episode": 853.0, "duration": 0.22019553184509277, "step": 28930}
{"episode_reward": 0.141319868575366, "episode": 854.0, "batch_reward": 0.11676572635769844, "critic_loss": 0.5500125214457512, "ae_transition_loss": -0.4856501892209053, "ae_encoder_loss": 0.3779352679848671, "actor_loss": -1.0179589241743088, "actor_target_entropy": -2.0, "actor_entropy": 0.3728007376194, "alpha_loss": 0.009130036109127104, "alpha_value": 0.013261355962925074, "duration": 7.7754738330841064, "step": 28967}
{"episode_reward": 1.1793837250402548, "episode": 855.0, "batch_reward": 0.12238487228751183, "critic_loss": 0.19753428362309933, "ae_transition_loss": -0.43655721098184586, "ae_encoder_loss": 0.26717057451605797, "actor_loss": -1.1329665184020996, "actor_target_entropy": -2.0, "actor_entropy": 0.33537937700748444, "alpha_loss": 0.010222977492958307, "alpha_value": 0.013205991764283123, "duration": 8.731720685958862, "step": 29010}
{"episode_reward": 4.63174451974598, "episode": 856.0, "batch_reward": 0.12339641749858857, "critic_loss": 0.25285743176937103, "ae_transition_loss": -0.3827876687049866, "ae_encoder_loss": 0.3883811295032501, "actor_loss": -1.0513176321983337, "actor_target_entropy": -2.0, "actor_entropy": 0.4227914035320282, "alpha_loss": 0.011095071211457253, "alpha_value": 0.013142910560663953, "duration": 10.019919157028198, "step": 29059}
{"episode_reward": 11.503631972435565, "episode": 857.0, "batch_reward": 0.10771183917919795, "critic_loss": 0.28736941888928413, "ae_transition_loss": -0.32312755783398944, "ae_encoder_loss": 0.35793331017096836, "actor_loss": -0.9433406790097555, "actor_target_entropy": -2.0, "actor_entropy": 0.5830433517694473, "alpha_loss": 0.011648799913624922, "alpha_value": 0.013062824839472539, "duration": 11.979777097702026, "step": 29118}
{"episode_reward": 12.783164322242817, "episode": 858.0, "batch_reward": 0.09952920178572337, "critic_loss": 0.18494311720132828, "ae_transition_loss": -0.2788240561882655, "ae_encoder_loss": 0.23114188015460968, "actor_loss": -0.9172585209210714, "actor_target_entropy": -2.0, "actor_entropy": 0.7156498829523722, "alpha_loss": 0.012280867745478949, "alpha_value": 0.01299556112056563, "duration": 5.6325414180755615, "step": 29144}
{"episode_reward": 1.0422123010699544, "episode": 859.0, "batch_reward": 0.10131483525037766, "critic_loss": 0.2718934714794159, "ae_transition_loss": -0.40113766491413116, "ae_encoder_loss": 0.274961493909359, "actor_loss": -0.8718913793563843, "actor_target_entropy": -2.0, "actor_entropy": 0.8149142563343048, "alpha_loss": 0.013063980732113123, "alpha_value": 0.012956908671093644, "duration": 5.318814516067505, "step": 29170}
{"episode_reward": -0.6877873700887748, "episode": 860.0, "batch_reward": 0.0893246129155159, "critic_loss": 0.31652906686067583, "ae_transition_loss": -0.2747541815042496, "ae_encoder_loss": 0.5653055846691132, "actor_loss": -0.9369854927062988, "actor_target_entropy": -2.0, "actor_entropy": 0.9331449627876282, "alpha_loss": 0.012485643103718757, "alpha_value": 0.012900759458054963, "duration": 9.751481771469116, "step": 29218}
{"episode_reward": 12.895074210220464, "episode": 861.0, "batch_reward": 0.09007166791707277, "critic_loss": 0.17419523000717163, "ae_transition_loss": -0.13682733848690987, "ae_encoder_loss": 0.2815620116889477, "actor_loss": -0.8819849640130997, "actor_target_entropy": -2.0, "actor_entropy": 1.053195983171463, "alpha_loss": 0.014259933028370142, "alpha_value": 0.012827203667108225, "duration": 81.81426167488098, "step": 29252}
{"episode_reward": 0.699015342563633, "episode": 862.0, "batch_reward": 0.12453724195559819, "critic_loss": 0.3947055737177531, "ae_transition_loss": -0.20388447244962057, "ae_encoder_loss": 0.24411699175834656, "actor_loss": -0.7862773736317953, "actor_target_entropy": -2.0, "actor_entropy": 1.0860265890757244, "alpha_loss": 0.014618641696870327, "alpha_value": 0.01276740582700799, "duration": 7.441598653793335, "step": 29289}
{"episode_reward": 0.08217209587371332, "episode": 863.0, "batch_reward": 0.11578741669654846, "critic_loss": 0.24393082658449808, "ae_transition_loss": -0.12360734740893047, "ae_encoder_loss": 0.25802792112032574, "actor_loss": -0.9647396405537924, "actor_target_entropy": -2.0, "actor_entropy": 1.1052696704864502, "alpha_loss": 0.016758122791846592, "alpha_value": 0.012713889872967302, "duration": 5.259339094161987, "step": 29314}
{"episode_reward": -1.7986727890577057, "episode": 864.0, "batch_reward": 0.12276038154959679, "critic_loss": 0.18997444957494736, "ae_transition_loss": -0.2359408363699913, "ae_encoder_loss": 0.2943532466888428, "actor_loss": -1.149438738822937, "actor_target_entropy": -2.0, "actor_entropy": 1.1242603063583374, "alpha_loss": 0.01403686124831438, "alpha_value": 0.012666996350301697, "duration": 4.55631947517395, "step": 29336}
{"episode_reward": -0.4448798083590385, "episode": 865.0, "batch_reward": 0.10326732943455379, "critic_loss": 0.5329501777887344, "ae_transition_loss": -0.23930209626754126, "ae_encoder_loss": 0.373488853375117, "actor_loss": -0.8568282326062521, "actor_target_entropy": -2.0, "actor_entropy": 1.1837093432744343, "alpha_loss": 0.018377625072995823, "alpha_value": 0.012619442227849659, "duration": 6.083787679672241, "step": 29366}
{"episode_reward": 1.960351738423393, "episode": 866.0, "batch_reward": 0.12921100854873657, "critic_loss": 0.5319535732269287, "ae_transition_loss": -0.22985610365867615, "ae_encoder_loss": 0.3658357858657837, "actor_loss": -0.8684012293815613, "actor_target_entropy": -2.0, "actor_entropy": 1.2106692790985107, "alpha_loss": 0.01563943549990654, "alpha_value": 0.012579853326130321, "duration": 2.2597591876983643, "step": 29377}
{"episode_reward": -1.3983951027346355, "episode": 867.0, "batch_reward": 0.1064492439230283, "critic_loss": 0.4879455268383026, "ae_transition_loss": -0.2891850024461746, "ae_encoder_loss": 0.29703190674384433, "actor_loss": -1.026672104994456, "actor_target_entropy": -2.0, "actor_entropy": 1.3155056238174438, "alpha_loss": 0.01637270099793871, "alpha_value": 0.01250960690757044, "duration": 12.323782205581665, "step": 29438}
{"episode_reward": 6.677209104822138, "episode": 868.0, "batch_reward": 0.10313304513692856, "critic_loss": 0.5178345118959745, "ae_transition_loss": -0.28248724713921547, "ae_encoder_loss": 0.27518943200508755, "actor_loss": -0.9371238052845001, "actor_target_entropy": -2.0, "actor_entropy": 1.4265408714612324, "alpha_loss": 0.01983622834086418, "alpha_value": 0.012385558261522664, "duration": 11.431188583374023, "step": 29493}
{"episode_reward": -3.8917769235369866, "episode": 869.0, "batch_reward": 0.14549585431814194, "critic_loss": 0.3036924401919047, "ae_transition_loss": -0.07760560760895412, "ae_encoder_loss": 0.5437328716119131, "actor_loss": -1.2363828818003337, "actor_target_entropy": -2.0, "actor_entropy": 1.5280636548995972, "alpha_loss": 0.021017589295903843, "alpha_value": 0.01228697742373964, "duration": 7.4045937061309814, "step": 29529}
{"episode_reward": -0.933198333228125, "episode": 870.0, "duration": 0.21994519233703613, "step": 29530}
{"episode_reward": -0.1225232418748036, "episode": 871.0, "batch_reward": 0.11198707173268001, "critic_loss": 0.35213757554690045, "ae_transition_loss": -0.10248983340958755, "ae_encoder_loss": 0.4196682274341583, "actor_loss": -0.786019484202067, "actor_target_entropy": -2.0, "actor_entropy": 1.580122749010722, "alpha_loss": 0.02226684180398782, "alpha_value": 0.012217024933752693, "duration": 49.751630783081055, "step": 29555}
{"episode_reward": -4.6655295395107, "episode": 872.0, "duration": 0.22746777534484863, "step": 29556}
{"episode_reward": -0.5656871588505106, "episode": 873.0, "batch_reward": 0.12180204937855403, "critic_loss": 0.2742098271846771, "ae_transition_loss": -0.08852665033191442, "ae_encoder_loss": 0.3635978003342946, "actor_loss": -1.1825805107752483, "actor_target_entropy": -2.0, "actor_entropy": 1.4637521505355835, "alpha_loss": 0.020169420788685482, "alpha_value": 0.012145029504087398, "duration": 7.092127084732056, "step": 29589}
{"episode_reward": 1.9367046534200574, "episode": 874.0, "batch_reward": 0.10258366912603378, "critic_loss": 0.276199442644914, "ae_transition_loss": -0.20450367778539658, "ae_encoder_loss": 0.27875400831302005, "actor_loss": -1.0024923185507457, "actor_target_entropy": -2.0, "actor_entropy": 1.3707182010014851, "alpha_loss": 0.02020251875122388, "alpha_value": 0.012037444168440754, "duration": 11.277923583984375, "step": 29644}
{"episode_reward": 4.775864770397198, "episode": 875.0, "batch_reward": 0.1076519638299942, "critic_loss": 0.49452096223831177, "ae_transition_loss": -0.18407858908176422, "ae_encoder_loss": 0.32688167691230774, "actor_loss": -1.1229627132415771, "actor_target_entropy": -2.0, "actor_entropy": 1.2658517360687256, "alpha_loss": 0.01989918202161789, "alpha_value": 0.011953906054324547, "duration": 2.9017138481140137, "step": 29657}
{"episode_reward": -3.1630008482255967, "episode": 876.0, "batch_reward": 0.09742846091588338, "critic_loss": 0.2526935438315074, "ae_transition_loss": -0.023999594151973724, "ae_encoder_loss": 0.3785506586233775, "actor_loss": -0.980129619439443, "actor_target_entropy": -2.0, "actor_entropy": 1.3220237493515015, "alpha_loss": 0.02087525837123394, "alpha_value": 0.011906096858646084, "duration": 5.725553035736084, "step": 29682}
{"episode_reward": -2.519563160543464, "episode": 877.0, "batch_reward": 0.09067244331041972, "critic_loss": 0.25202979147434235, "ae_transition_loss": -0.09313504584133625, "ae_encoder_loss": 0.465939998626709, "actor_loss": -0.9944683114687601, "actor_target_entropy": -2.0, "actor_entropy": 0.7794675230979919, "alpha_loss": 0.01101617810005943, "alpha_value": 0.011835684397749095, "duration": 7.345943212509155, "step": 29718}
{"episode_reward": 4.837306652450971, "episode": 878.0, "batch_reward": 0.08233657851815224, "critic_loss": 0.19348318874835968, "ae_transition_loss": -0.25643884390592575, "ae_encoder_loss": 0.3096437156200409, "actor_loss": -1.020660936832428, "actor_target_entropy": -2.0, "actor_entropy": 0.5200665593147278, "alpha_loss": 0.0060467582661658525, "alpha_value": 0.011783266187619844, "duration": 3.3954555988311768, "step": 29733}
{"episode_reward": -2.541175011026148, "episode": 879.0, "batch_reward": 0.09302835166454315, "critic_loss": 0.1549196094274521, "ae_transition_loss": -0.28112146258354187, "ae_encoder_loss": 0.3545675426721573, "actor_loss": -0.9022121727466583, "actor_target_entropy": -2.0, "actor_entropy": 0.3747827410697937, "alpha_loss": 0.003214231110177934, "alpha_value": 0.011747435344146875, "duration": 4.616976976394653, "step": 29755}
{"episode_reward": -0.24502487336732925, "episode": 880.0, "batch_reward": 0.11292839050292969, "critic_loss": 0.2355877235531807, "ae_transition_loss": -0.19372309185564518, "ae_encoder_loss": 0.27561892569065094, "actor_loss": -1.0534749031066895, "actor_target_entropy": -2.0, "actor_entropy": 0.31477947533130646, "alpha_loss": 0.0038771340041421354, "alpha_value": 0.011717020075369325, "duration": 4.435078382492065, "step": 29776}
{"episode_reward": -1.2108988134331282, "episode": 881.0, "batch_reward": 0.11160967350006104, "critic_loss": 0.4300744831562042, "ae_transition_loss": -0.1702856957912445, "ae_encoder_loss": 0.32109310030937194, "actor_loss": -0.8636017918586731, "actor_target_entropy": -2.0, "actor_entropy": 0.27035737633705137, "alpha_loss": 0.00604002452455461, "alpha_value": 0.011673570465627064, "duration": 50.027671098709106, "step": 29829}
{"episode_reward": -0.9978485050933765, "episode": 882.0, "batch_reward": 0.1084412687591144, "critic_loss": 0.33089531319481985, "ae_transition_loss": -0.24462597284998214, "ae_encoder_loss": 0.4637667579310281, "actor_loss": -0.974164639200483, "actor_target_entropy": -2.0, "actor_entropy": 0.44486019015312195, "alpha_loss": 0.008755178323813848, "alpha_value": 0.011609542807270208, "duration": 13.475690603256226, "step": 29895}
{"episode_reward": 14.401769360919467, "episode": 883.0, "batch_reward": 0.07228273650010426, "critic_loss": 0.23538754880428314, "ae_transition_loss": -0.2599403113126755, "ae_encoder_loss": 0.374425341685613, "actor_loss": -0.917935828367869, "actor_target_entropy": -2.0, "actor_entropy": 0.7257566849390665, "alpha_loss": 0.010604017414152622, "alpha_value": 0.011557030364275417, "duration": 5.567550897598267, "step": 29922}
{"episode_reward": -0.7599611559631243, "episode": 884.0, "batch_reward": 0.1017759417494138, "critic_loss": 0.3060743560393651, "ae_transition_loss": -0.31307926774024963, "ae_encoder_loss": 0.2504568099975586, "actor_loss": -0.8553155064582825, "actor_target_entropy": -2.0, "actor_entropy": 0.8744280934333801, "alpha_loss": 0.01216039371987184, "alpha_value": 0.011524234400378502, "duration": 6.411291837692261, "step": 29953}
{"episode_reward": -3.951874305159608, "episode": 885.0, "duration": 0.20204806327819824, "step": 29954}
{"episode_reward": -0.726209679879059, "episode": 886.0, "batch_reward": 0.10618732497096062, "critic_loss": 0.3420170322060585, "ae_transition_loss": -0.26988695561885834, "ae_encoder_loss": 0.33684058487415314, "actor_loss": -0.8259270787239075, "actor_target_entropy": -2.0, "actor_entropy": 0.995197594165802, "alpha_loss": 0.01105823926627636, "alpha_value": 0.011495670916188059, "duration": 5.266490459442139, "step": 29980}
{"episode_reward": -3.109662683435154, "episode": 887.0, "batch_reward": 0.08402618765830994, "critic_loss": 0.20340916514396667, "ae_transition_loss": -0.04800417646765709, "ae_encoder_loss": 0.3714255392551422, "actor_loss": -0.8503636121749878, "actor_target_entropy": -2.0, "actor_entropy": 1.090853214263916, "alpha_loss": 0.012306006625294685, "alpha_value": 0.011477992469191237, "duration": 2.0556490421295166, "step": 29990}
{"episode_reward": -2.7070082510201097, "episode": 888.0, "batch_reward": 0.09581143160661061, "critic_loss": 0.3406454920768738, "ae_transition_loss": -0.27044173578421277, "ae_encoder_loss": 0.3521980245908101, "actor_loss": -0.9199967583020529, "actor_target_entropy": -2.0, "actor_entropy": 1.1609995365142822, "alpha_loss": 0.012999909929931164, "alpha_value": 0.011453633906625018, "duration": 8.276525735855103, "step": 30011}
{"episode_reward": -2.825771544830274, "episode": 889.0, "duration": 0.21756577491760254, "step": 30012}
{"episode_reward": -0.23767834874810778, "episode": 890.0, "duration": 0.2015988826751709, "step": 30013}
{"episode_reward": -0.19189926413755412, "episode": 891.0, "batch_reward": 0.13598313927650452, "critic_loss": 0.17910581827163696, "ae_transition_loss": -0.2113831788301468, "ae_encoder_loss": 0.283253937959671, "actor_loss": -1.1255838871002197, "actor_target_entropy": -2.0, "actor_entropy": 1.2902982234954834, "alpha_loss": 0.012575162574648857, "alpha_value": 0.011428443991064028, "duration": 35.162415981292725, "step": 30030}
{"episode_reward": -1.5346245884437988, "episode": 892.0, "batch_reward": 0.1122310534119606, "critic_loss": 0.2981823906302452, "ae_transition_loss": -0.21955151483416557, "ae_encoder_loss": 0.41576385498046875, "actor_loss": -1.0987921357154846, "actor_target_entropy": -2.0, "actor_entropy": 1.3125182390213013, "alpha_loss": 0.013363020494580269, "alpha_value": 0.011409060024722539, "duration": 3.4889872074127197, "step": 30047}
{"episode_reward": -0.7629660146363287, "episode": 893.0, "batch_reward": 0.11705121397972107, "critic_loss": 0.2997617721557617, "ae_transition_loss": -0.20007155338923135, "ae_encoder_loss": 0.36638104915618896, "actor_loss": -1.0883046785990398, "actor_target_entropy": -2.0, "actor_entropy": 1.3195887406667073, "alpha_loss": 0.011808033722142378, "alpha_value": 0.011375866449636465, "duration": 5.372550964355469, "step": 30073}
{"episode_reward": -4.248295374441495, "episode": 894.0, "batch_reward": 0.08543327450752258, "critic_loss": 0.3208819031715393, "ae_transition_loss": 0.15430060029029846, "ae_encoder_loss": 0.3614262342453003, "actor_loss": -0.824608306090037, "actor_target_entropy": -2.0, "actor_entropy": 1.1968302726745605, "alpha_loss": 0.015067464982469877, "alpha_value": 0.011335895185530258, "duration": 6.83500599861145, "step": 30107}
{"episode_reward": -5.123813618317125, "episode": 895.0, "duration": 0.22380518913269043, "step": 30108}
{"episode_reward": -0.0648156954079479, "episode": 896.0, "batch_reward": 0.09939797967672348, "critic_loss": 0.5211428701877594, "ae_transition_loss": 0.08234293921850622, "ae_encoder_loss": 0.33724361658096313, "actor_loss": -0.9564046710729599, "actor_target_entropy": -2.0, "actor_entropy": 1.3274188935756683, "alpha_loss": 0.015224744565784931, "alpha_value": 0.011286586293557383, "duration": 7.511525630950928, "step": 30146}
{"episode_reward": 1.1552719624207604, "episode": 897.0, "batch_reward": 0.1401155572384596, "critic_loss": 0.3186856172978878, "ae_transition_loss": 0.12647679634392262, "ae_encoder_loss": 0.3231142833828926, "actor_loss": -1.2373435199260712, "actor_target_entropy": -2.0, "actor_entropy": 1.4069649875164032, "alpha_loss": 0.016602110117673874, "alpha_value": 0.011226402221190795, "duration": 7.5121238231658936, "step": 30183}
{"episode_reward": -5.807060275965856, "episode": 898.0, "duration": 0.26003336906433105, "step": 30184}
{"episode_reward": -0.12433424592018127, "episode": 899.0, "batch_reward": 0.07711599916219711, "critic_loss": 0.40568992495536804, "ae_transition_loss": -0.1494776040315628, "ae_encoder_loss": 0.33879387378692627, "actor_loss": -0.9203250288963318, "actor_target_entropy": -2.0, "actor_entropy": 1.4122998714447021, "alpha_loss": 0.016768884286284445, "alpha_value": 0.011154398231277915, "duration": 11.116355657577515, "step": 30238}
{"episode_reward": -6.248311083299488, "episode": 900.0, "batch_reward": 0.09936140105128288, "critic_loss": 0.40363859385252, "ae_transition_loss": 0.12129425629973412, "ae_encoder_loss": 0.31544381380081177, "actor_loss": -0.9785405695438385, "actor_target_entropy": -2.0, "actor_entropy": 1.3822818994522095, "alpha_loss": 0.019647755660116673, "alpha_value": 0.011096072676268578, "duration": 4.61505913734436, "step": 30260}
{"episode_reward": -2.6167324537962253, "episode": 901.0, "batch_reward": 0.1173937867085139, "critic_loss": 0.3091487338145574, "ae_transition_loss": -0.17423216501871744, "ae_encoder_loss": 0.3601635793844859, "actor_loss": -1.104543964068095, "actor_target_entropy": -2.0, "actor_entropy": 1.3830835421880086, "alpha_loss": 0.018964506064852078, "alpha_value": 0.011052198566284777, "duration": 40.09293818473816, "step": 30284}
{"episode_reward": -3.7600654106662774, "episode": 902.0, "batch_reward": 0.10906941257417202, "critic_loss": 0.2419043891131878, "ae_transition_loss": -0.15258931182324886, "ae_encoder_loss": 0.42799098044633865, "actor_loss": -1.0385723859071732, "actor_target_entropy": -2.0, "actor_entropy": 1.4218051433563232, "alpha_loss": 0.0210662093013525, "alpha_value": 0.010987913076899104, "duration": 7.950516223907471, "step": 30322}
{"episode_reward": -2.867144931775, "episode": 903.0, "batch_reward": 0.10735893249511719, "critic_loss": 0.17636120319366455, "ae_transition_loss": -0.0014613103121519089, "ae_encoder_loss": 0.27687716484069824, "actor_loss": -1.0362470149993896, "actor_target_entropy": -2.0, "actor_entropy": 1.5131175518035889, "alpha_loss": 0.01882326975464821, "alpha_value": 0.010939986345247487, "duration": 2.4718549251556396, "step": 30334}
{"episode_reward": -1.8084176739832714, "episode": 904.0, "batch_reward": 0.0948358029127121, "critic_loss": 0.21864467859268188, "ae_transition_loss": -0.1153506338596344, "ae_encoder_loss": 0.34794165194034576, "actor_loss": -1.0468037724494934, "actor_target_entropy": -2.0, "actor_entropy": 1.5631309747695923, "alpha_loss": 0.018896701745688915, "alpha_value": 0.010910863128906337, "duration": 4.856169700622559, "step": 30356}
{"episode_reward": -5.050710249778028, "episode": 905.0, "batch_reward": 0.09271164797246456, "critic_loss": 0.22616765461862087, "ae_transition_loss": -0.0907355286180973, "ae_encoder_loss": 0.29688869416713715, "actor_loss": -1.0133625864982605, "actor_target_entropy": -2.0, "actor_entropy": 1.6648523807525635, "alpha_loss": 0.020136185456067324, "alpha_value": 0.010853066346699781, "duration": 8.44761323928833, "step": 30396}
{"episode_reward": 0.342166373863836, "episode": 906.0, "batch_reward": 0.11927602688471477, "critic_loss": 0.186561552186807, "ae_transition_loss": 0.0732838253218991, "ae_encoder_loss": 0.3290194769700368, "actor_loss": -1.1170242230097454, "actor_target_entropy": -2.0, "actor_entropy": 1.4031283855438232, "alpha_loss": 0.018671538059910137, "alpha_value": 0.010784899143677014, "duration": 6.3197126388549805, "step": 30427}
{"episode_reward": -8.542480071270797, "episode": 907.0, "batch_reward": 0.10254811743895213, "critic_loss": 0.26449449360370636, "ae_transition_loss": -0.06809744595860441, "ae_encoder_loss": 0.37991036971410114, "actor_loss": -1.1006774703661601, "actor_target_entropy": -2.0, "actor_entropy": 1.477136492729187, "alpha_loss": 0.01734799239784479, "alpha_value": 0.010726865010858877, "duration": 6.023660659790039, "step": 30456}
{"episode_reward": -11.080002365725031, "episode": 908.0, "batch_reward": 0.07375226666529973, "critic_loss": 0.1548325171073278, "ae_transition_loss": -0.07951603333155315, "ae_encoder_loss": 0.34309156735738117, "actor_loss": -0.9550783236821493, "actor_target_entropy": -2.0, "actor_entropy": 1.5465832551320393, "alpha_loss": 0.019206281130512554, "alpha_value": 0.010670049502934728, "duration": 6.940088272094727, "step": 30490}
{"episode_reward": -5.830464733854187, "episode": 909.0, "batch_reward": 0.07905766740441322, "critic_loss": 0.13144880533218384, "ae_transition_loss": -0.21736184507608414, "ae_encoder_loss": 0.33055920898914337, "actor_loss": -0.9732857048511505, "actor_target_entropy": -2.0, "actor_entropy": 1.560602605342865, "alpha_loss": 0.0164856044575572, "alpha_value": 0.010622862489432738, "duration": 2.654697895050049, "step": 30501}
{"episode_reward": -1.199003113543236, "episode": 910.0, "batch_reward": 0.1253345012664795, "critic_loss": 0.2883162796497345, "ae_transition_loss": -0.32050514221191406, "ae_encoder_loss": 0.40229475498199463, "actor_loss": -1.032045841217041, "actor_target_entropy": -2.0, "actor_entropy": 1.5780695676803589, "alpha_loss": 0.018383629620075226, "alpha_value": 0.010595221374249264, "duration": 2.8328614234924316, "step": 30515}
{"episode_reward": -5.291703236725335, "episode": 911.0, "batch_reward": 0.10361733926194054, "critic_loss": 0.24269224277564458, "ae_transition_loss": -0.02680957317352295, "ae_encoder_loss": 0.33769991993904114, "actor_loss": -1.06660019499915, "actor_target_entropy": -2.0, "actor_entropy": 1.3832290513174874, "alpha_loss": 0.017466200781720027, "alpha_value": 0.010522383633354265, "duration": 79.61206769943237, "step": 30583}
{"episode_reward": -10.994882728106155, "episode": 912.0, "batch_reward": 0.11416544765233994, "critic_loss": 0.19514166936278343, "ae_transition_loss": 0.1712531764060259, "ae_encoder_loss": 0.29097265005111694, "actor_loss": -0.9304075390100479, "actor_target_entropy": -2.0, "actor_entropy": 0.9705790281295776, "alpha_loss": 0.01508875098079443, "alpha_value": 0.010425583620202763, "duration": 8.380002737045288, "step": 30623}
{"episode_reward": -3.5051880104726227, "episode": 913.0, "batch_reward": 0.12086152099072933, "critic_loss": 0.42094049230217934, "ae_transition_loss": 0.20585201680660248, "ae_encoder_loss": 0.2848726883530617, "actor_loss": -0.9811465293169022, "actor_target_entropy": -2.0, "actor_entropy": 0.8073209226131439, "alpha_loss": 0.013372932327911258, "alpha_value": 0.010360296951943807, "duration": 8.016064643859863, "step": 30661}
{"episode_reward": -4.646982088111458, "episode": 914.0, "batch_reward": 0.10851997137069702, "critic_loss": 0.36415722221136093, "ae_transition_loss": 0.045192962512373924, "ae_encoder_loss": 0.34645693004131317, "actor_loss": -1.1187278628349304, "actor_target_entropy": -2.0, "actor_entropy": 0.8173531293869019, "alpha_loss": 0.014416263671591878, "alpha_value": 0.010299820128379142, "duration": 8.547839403152466, "step": 30703}
{"episode_reward": -0.19098438972482287, "episode": 915.0, "batch_reward": 0.09221853613853455, "critic_loss": 0.24826165437698364, "ae_transition_loss": -0.038456478714942934, "ae_encoder_loss": 0.3019260287284851, "actor_loss": -1.0428300142288207, "actor_target_entropy": -2.0, "actor_entropy": 1.017060387134552, "alpha_loss": 0.01611597016453743, "alpha_value": 0.010233673194287963, "duration": 11.19063138961792, "step": 30758}
{"episode_reward": -4.172257696731102, "episode": 916.0, "batch_reward": 0.1212236687541008, "critic_loss": 0.2616221159696579, "ae_transition_loss": 0.1728396750986576, "ae_encoder_loss": 0.4709360897541046, "actor_loss": -1.1239056944847108, "actor_target_entropy": -2.0, "actor_entropy": 1.556772494316101, "alpha_loss": 0.017016162537038325, "alpha_value": 0.010159336560260418, "duration": 10.30779767036438, "step": 30810}
{"episode_reward": -20.530349945923096, "episode": 917.0, "batch_reward": 0.10918688029050827, "critic_loss": 0.24917979538440704, "ae_transition_loss": 0.2057853639125824, "ae_encoder_loss": 0.4377984404563904, "actor_loss": -0.9887155294418335, "actor_target_entropy": -2.0, "actor_entropy": 1.4120293855667114, "alpha_loss": 0.017543740570545197, "alpha_value": 0.010114164950541989, "duration": 2.131840944290161, "step": 30820}
{"episode_reward": -1.3502186970394023, "episode": 918.0, "batch_reward": 0.09376689791679382, "critic_loss": 0.28685374930500984, "ae_transition_loss": 0.08121931180357933, "ae_encoder_loss": 0.3541872501373291, "actor_loss": -1.015898734331131, "actor_target_entropy": -2.0, "actor_entropy": 1.3892309367656708, "alpha_loss": 0.015706052305176854, "alpha_value": 0.0100764242932154, "duration": 7.703758239746094, "step": 30857}
{"episode_reward": -7.109691659994569, "episode": 919.0, "batch_reward": 0.11039941757917404, "critic_loss": 0.43347581369536264, "ae_transition_loss": 0.044337031265188544, "ae_encoder_loss": 0.36100073371614727, "actor_loss": -1.05280487877982, "actor_target_entropy": -2.0, "actor_entropy": 1.7216452189854212, "alpha_loss": 0.01557078491896391, "alpha_value": 0.009995816820367926, "duration": 14.095820188522339, "step": 30925}
{"episode_reward": -9.476683040148313, "episode": 920.0, "batch_reward": 0.1216128741701444, "critic_loss": 0.25969911615053815, "ae_transition_loss": -0.03609233039120833, "ae_encoder_loss": 0.4223109781742096, "actor_loss": -1.262737472852071, "actor_target_entropy": -2.0, "actor_entropy": 1.9433569113413494, "alpha_loss": 0.017666473053395748, "alpha_value": 0.009923403790897444, "duration": 6.104361295700073, "step": 30954}
{"episode_reward": -4.0751529373018425, "episode": 921.0, "batch_reward": 0.10920824483036995, "critic_loss": 0.4191374182701111, "ae_transition_loss": 0.024358101189136505, "ae_encoder_loss": 0.42769239842891693, "actor_loss": -1.0159736275672913, "actor_target_entropy": -2.0, "actor_entropy": 1.8623188734054565, "alpha_loss": 0.01838899403810501, "alpha_value": 0.009886288436767685, "duration": 123.09322142601013, "step": 30972}
{"episode_reward": -1.750106257959618, "episode": 922.0, "duration": 1.637791633605957, "step": 30980}
{"episode_reward": -1.7666686634951512, "episode": 923.0, "batch_reward": 0.09050017036497593, "critic_loss": 0.25327202677726746, "ae_transition_loss": -0.14337537437677383, "ae_encoder_loss": 0.3943772614002228, "actor_loss": -1.0550323575735092, "actor_target_entropy": -2.0, "actor_entropy": 1.5747984945774078, "alpha_loss": 0.016983509063720703, "alpha_value": 0.009840852692012366, "duration": 6.619746446609497, "step": 31011}
{"episode_reward": -6.475536902934824, "episode": 924.0, "batch_reward": 0.09013397991657257, "critic_loss": 0.33151841163635254, "ae_transition_loss": -0.1116875633597374, "ae_encoder_loss": 0.36036428809165955, "actor_loss": -0.9813574552536011, "actor_target_entropy": -2.0, "actor_entropy": 1.7375942468643188, "alpha_loss": 0.02085968852043152, "alpha_value": 0.00980306267169521, "duration": 2.6638729572296143, "step": 31025}
{"episode_reward": -1.676910384173502, "episode": 925.0, "batch_reward": 0.09384392350912094, "critic_loss": 0.4464320808649063, "ae_transition_loss": 0.24000942558050156, "ae_encoder_loss": 0.4327523946762085, "actor_loss": -0.9392147898674011, "actor_target_entropy": -2.0, "actor_entropy": 1.5631367206573485, "alpha_loss": 0.015980605967342854, "alpha_value": 0.009757941942675302, "duration": 10.851755619049072, "step": 31078}
{"episode_reward": -6.3286531584307415, "episode": 926.0, "batch_reward": 0.06555793061852455, "critic_loss": 0.24506939947605133, "ae_transition_loss": 0.465916246175766, "ae_encoder_loss": 0.6901638805866241, "actor_loss": -0.9666837155818939, "actor_target_entropy": -2.0, "actor_entropy": 1.2100868225097656, "alpha_loss": 0.015178365632891655, "alpha_value": 0.009706374063554372, "duration": 4.3758227825164795, "step": 31100}
{"episode_reward": -6.299658800974207, "episode": 927.0, "batch_reward": 0.1182585097849369, "critic_loss": 0.2425415962934494, "ae_transition_loss": 0.5920255780220032, "ae_encoder_loss": 0.9506415128707886, "actor_loss": -1.103696197271347, "actor_target_entropy": -2.0, "actor_entropy": 1.1447048783302307, "alpha_loss": 0.013145437464118004, "alpha_value": 0.009677536157752558, "duration": 2.916036367416382, "step": 31113}
{"episode_reward": -2.7040466106078878, "episode": 928.0, "batch_reward": 0.13020585626363754, "critic_loss": 0.33491172790527346, "ae_transition_loss": 0.7685709953308105, "ae_encoder_loss": 0.5732037901878357, "actor_loss": -1.0102875709533692, "actor_target_entropy": -2.0, "actor_entropy": 1.4888875961303711, "alpha_loss": 0.01627358179539442, "alpha_value": 0.009628946784471237, "duration": 10.259426593780518, "step": 31162}
{"episode_reward": -22.04239921139861, "episode": 929.0, "batch_reward": 0.11906498670578003, "critic_loss": 0.2734805643558502, "ae_transition_loss": 0.6373767256736755, "ae_encoder_loss": 0.6691967844963074, "actor_loss": -1.3441038131713867, "actor_target_entropy": -2.0, "actor_entropy": 1.4952250719070435, "alpha_loss": 0.015472413040697575, "alpha_value": 0.009587355979923362, "duration": 2.4487855434417725, "step": 31174}
{"episode_reward": -4.673713618700532, "episode": 930.0, "batch_reward": 0.07589260364572208, "critic_loss": 0.3726523121198018, "ae_transition_loss": 0.5986616313457489, "ae_encoder_loss": 0.6098773082097372, "actor_loss": -0.9576833248138428, "actor_target_entropy": -2.0, "actor_entropy": 1.5477979183197021, "alpha_loss": 0.016582154668867588, "alpha_value": 0.009559505330506002, "duration": 6.73103141784668, "step": 31206}
{"episode_reward": -15.551187754842559, "episode": 931.0, "batch_reward": 0.07601191103458405, "critic_loss": 0.31354676683743793, "ae_transition_loss": 0.5960218012332916, "ae_encoder_loss": 0.628787080446879, "actor_loss": -0.9006816148757935, "actor_target_entropy": -2.0, "actor_entropy": 1.6858410437901814, "alpha_loss": 0.016982280338803928, "alpha_value": 0.00951773119957818, "duration": 104.15622138977051, "step": 31232}
{"episode_reward": -5.918983429626368, "episode": 932.0, "batch_reward": 0.09664469584822655, "critic_loss": 0.15436840802431107, "ae_transition_loss": 0.5820394307374954, "ae_encoder_loss": 0.44993455708026886, "actor_loss": -0.9824515581130981, "actor_target_entropy": -2.0, "actor_entropy": 1.8571569323539734, "alpha_loss": 0.01660316390916705, "alpha_value": 0.009482729146408719, "duration": 4.999373435974121, "step": 31256}
{"episode_reward": -9.76260526032714, "episode": 933.0, "duration": 0.22797632217407227, "step": 31257}
{"episode_reward": -0.2041359880221777, "episode": 934.0, "batch_reward": 0.09028425440192223, "critic_loss": 0.4475491791963577, "ae_transition_loss": 0.3081503063440323, "ae_encoder_loss": 0.43887414038181305, "actor_loss": -1.0442569255828857, "actor_target_entropy": -2.0, "actor_entropy": 1.9090374112129211, "alpha_loss": 0.016395272221416235, "alpha_value": 0.009454815780802601, "duration": 4.411581039428711, "step": 31278}
{"episode_reward": -6.96172903538156, "episode": 935.0, "batch_reward": 0.09831013530492783, "critic_loss": 0.23508170247077942, "ae_transition_loss": 0.23246659338474274, "ae_encoder_loss": 0.45067787170410156, "actor_loss": -1.1310542821884155, "actor_target_entropy": -2.0, "actor_entropy": 1.9388031959533691, "alpha_loss": 0.01577485166490078, "alpha_value": 0.009434026126820809, "duration": 1.8756670951843262, "step": 31286}
{"episode_reward": -4.14373671474721, "episode": 936.0, "batch_reward": 0.10257219647367795, "critic_loss": 0.4622128705183665, "ae_transition_loss": 0.31125562886397046, "ae_encoder_loss": 0.5083875755469004, "actor_loss": -0.9521052042643229, "actor_target_entropy": -2.0, "actor_entropy": 1.959335207939148, "alpha_loss": 0.016591100953519344, "alpha_value": 0.009406422262432634, "duration": 6.667958498001099, "step": 31318}
{"episode_reward": -9.275940949461113, "episode": 937.0, "batch_reward": 0.08779893567164739, "critic_loss": 0.20460414389769235, "ae_transition_loss": 0.30894388755162555, "ae_encoder_loss": 0.5357609987258911, "actor_loss": -1.0070369640986125, "actor_target_entropy": -2.0, "actor_entropy": 1.6553179423014324, "alpha_loss": 0.016586710698902607, "alpha_value": 0.00936506841583108, "duration": 4.934601545333862, "step": 31341}
{"episode_reward": -6.349069751716902, "episode": 938.0, "batch_reward": 0.09755891188979149, "critic_loss": 0.3133506625890732, "ae_transition_loss": 0.14805906265974045, "ae_encoder_loss": 0.48294633626937866, "actor_loss": -1.190055787563324, "actor_target_entropy": -2.0, "actor_entropy": 1.3474810123443604, "alpha_loss": 0.012223731260746717, "alpha_value": 0.009330943588111911, "duration": 4.789129972457886, "step": 31365}
{"episode_reward": -8.150291589237025, "episode": 939.0, "duration": 0.2367708683013916, "step": 31366}
{"episode_reward": -0.5886608289923321, "episode": 940.0, "batch_reward": 0.1227367768685023, "critic_loss": 0.29332112272580463, "ae_transition_loss": 0.23006304105122885, "ae_encoder_loss": 0.4020240406195323, "actor_loss": -1.1735027233759563, "actor_target_entropy": -2.0, "actor_entropy": 1.1883185307184856, "alpha_loss": 0.009922761159638563, "alpha_value": 0.009298824608406427, "duration": 5.382537126541138, "step": 31391}
{"episode_reward": -8.590984941965381, "episode": 941.0, "batch_reward": 0.10346099361777306, "critic_loss": 0.1611232509215673, "ae_transition_loss": 0.19848850447063646, "ae_encoder_loss": 0.3387832244237264, "actor_loss": -1.0016900102297466, "actor_target_entropy": -2.0, "actor_entropy": 1.0815937916437786, "alpha_loss": 0.00963161326944828, "alpha_value": 0.009263636802275724, "duration": 52.762726068496704, "step": 31421}
{"episode_reward": -6.547013097478221, "episode": 942.0, "batch_reward": 0.0976431593298912, "critic_loss": 0.6994180232286453, "ae_transition_loss": 0.009389983024448156, "ae_encoder_loss": 0.361225426197052, "actor_loss": -1.0353392958641052, "actor_target_entropy": -2.0, "actor_entropy": 1.1291159987449646, "alpha_loss": 0.009297565091401339, "alpha_value": 0.00923681137705305, "duration": 4.979004621505737, "step": 31444}
{"episode_reward": -3.8487616680390193, "episode": 943.0, "duration": 0.21779394149780273, "step": 31445}
{"episode_reward": -2.951909623449446, "episode": 944.0, "batch_reward": 0.09933743625879288, "critic_loss": 0.4856035113334656, "ae_transition_loss": 0.17279482819139957, "ae_encoder_loss": 0.3306087255477905, "actor_loss": -0.8984060883522034, "actor_target_entropy": -2.0, "actor_entropy": 1.118392288684845, "alpha_loss": 0.008525869343429804, "alpha_value": 0.009216720146385358, "duration": 4.147738218307495, "step": 31464}
{"episode_reward": -2.78542589437774, "episode": 945.0, "duration": 0.239654541015625, "step": 31465}
{"episode_reward": -0.12732428324042297, "episode": 946.0, "batch_reward": 0.1048042004307111, "critic_loss": 0.33598218361536664, "ae_transition_loss": 0.1380545925348997, "ae_encoder_loss": 0.37006013592084247, "actor_loss": -1.1582631667455037, "actor_target_entropy": -2.0, "actor_entropy": 1.1838395198186238, "alpha_loss": 0.011748892876009146, "alpha_value": 0.009193026380898148, "duration": 5.774673223495483, "step": 31491}
{"episode_reward": -3.9310836096040394, "episode": 947.0, "batch_reward": 0.0771717056632042, "critic_loss": 0.4167207032442093, "ae_transition_loss": 0.12082056142389774, "ae_encoder_loss": 0.42661723494529724, "actor_loss": -1.095127284526825, "actor_target_entropy": -2.0, "actor_entropy": 1.2852892875671387, "alpha_loss": 0.012468086555600166, "alpha_value": 0.009169393917452973, "duration": 4.576971530914307, "step": 31511}
{"episode_reward": -3.559631454467362, "episode": 948.0, "batch_reward": 0.11993419130643208, "critic_loss": 0.3022940953572591, "ae_transition_loss": 0.16786324108640352, "ae_encoder_loss": 0.27713586886723834, "actor_loss": -0.977643887201945, "actor_target_entropy": -2.0, "actor_entropy": 1.2935102383295696, "alpha_loss": 0.014821016850570837, "alpha_value": 0.009145138528297262, "duration": 6.7369561195373535, "step": 31542}
{"episode_reward": -5.195833744938493, "episode": 949.0, "batch_reward": 0.11106739938259125, "critic_loss": 0.39757681638002396, "ae_transition_loss": -0.005894846450246405, "ae_encoder_loss": 0.32870037853717804, "actor_loss": -1.1456078737974167, "actor_target_entropy": -2.0, "actor_entropy": 1.2542882561683655, "alpha_loss": 0.015003365464508533, "alpha_value": 0.009109134990709259, "duration": 8.861043214797974, "step": 31585}
{"episode_reward": -9.640751448436765, "episode": 950.0, "batch_reward": 0.10541850576798122, "critic_loss": 0.2168892820676168, "ae_transition_loss": 0.02522091567516327, "ae_encoder_loss": 0.31421900788942975, "actor_loss": -1.0796072880427043, "actor_target_entropy": -2.0, "actor_entropy": 1.3012248277664185, "alpha_loss": 0.013620380933086077, "alpha_value": 0.00907142262594873, "duration": 6.321543455123901, "step": 31616}
{"episode_reward": -7.716853891322612, "episode": 951.0, "batch_reward": 0.0668365191668272, "critic_loss": 0.41654640436172485, "ae_transition_loss": 0.08153732493519783, "ae_encoder_loss": 0.3841792345046997, "actor_loss": -0.7504348754882812, "actor_target_entropy": -2.0, "actor_entropy": 1.3081037998199463, "alpha_loss": 0.0150537034496665, "alpha_value": 0.00904421546033015, "duration": 49.999759674072266, "step": 31635}
{"episode_reward": -4.244768323950511, "episode": 952.0, "batch_reward": 0.07866677890221278, "critic_loss": 0.2087622880935669, "ae_transition_loss": 0.078354907532533, "ae_encoder_loss": 0.4905180831750234, "actor_loss": -0.9701210459073385, "actor_target_entropy": -2.0, "actor_entropy": 1.35886816183726, "alpha_loss": 0.013668613508343697, "alpha_value": 0.00901675861649255, "duration": 6.828052282333374, "step": 31669}
{"episode_reward": -6.839614731289352, "episode": 953.0, "duration": 0.25986409187316895, "step": 31670}
{"episode_reward": 0.046769768758381125, "episode": 954.0, "batch_reward": 0.08582719167073567, "critic_loss": 0.3301296532154083, "ae_transition_loss": 0.20566245913505554, "ae_encoder_loss": 0.45222609241803485, "actor_loss": -0.9540672500928243, "actor_target_entropy": -2.0, "actor_entropy": 1.2788949807484944, "alpha_loss": 0.013686960563063622, "alpha_value": 0.008983792685080297, "duration": 4.936350107192993, "step": 31694}
{"episode_reward": -7.579300095965748, "episode": 955.0, "batch_reward": 0.12426528334617615, "critic_loss": 0.35880998770395917, "ae_transition_loss": 0.23821057875951132, "ae_encoder_loss": 0.3947316110134125, "actor_loss": -1.0003629922866821, "actor_target_entropy": -2.0, "actor_entropy": 1.2574589252471924, "alpha_loss": 0.01404282171279192, "alpha_value": 0.008950873989506055, "duration": 5.854491710662842, "step": 31722}
{"episode_reward": -2.937707875303199, "episode": 956.0, "batch_reward": 0.0990016981959343, "critic_loss": 0.5265914797782898, "ae_transition_loss": 0.23807664215564728, "ae_encoder_loss": 0.4423729479312897, "actor_loss": -1.289783239364624, "actor_target_entropy": -2.0, "actor_entropy": 1.367232322692871, "alpha_loss": 0.012820984236896038, "alpha_value": 0.0089289060038, "duration": 2.3769326210021973, "step": 31733}
{"episode_reward": -2.160404457029454, "episode": 957.0, "duration": 0.19061779975891113, "step": 31734}
{"episode_reward": -0.18232630449901557, "episode": 958.0, "batch_reward": 0.0645296573638916, "critic_loss": 0.23630146185557047, "ae_transition_loss": 0.21141982078552246, "ae_encoder_loss": 0.33585312962532043, "actor_loss": -0.8861942291259766, "actor_target_entropy": -2.0, "actor_entropy": 1.4233470757802327, "alpha_loss": 0.015512607370813688, "alpha_value": 0.008907102769306157, "duration": 6.276485919952393, "step": 31764}
{"episode_reward": -4.828636122803697, "episode": 959.0, "batch_reward": 0.11810228725274403, "critic_loss": 0.3028288682301839, "ae_transition_loss": 0.07834313685695331, "ae_encoder_loss": 0.38343991835912067, "actor_loss": -1.2297701835632324, "actor_target_entropy": -2.0, "actor_entropy": 1.2257376909255981, "alpha_loss": 0.014937080753346285, "alpha_value": 0.008873666995291801, "duration": 6.6837146282196045, "step": 31797}
{"episode_reward": -3.3233772827306467, "episode": 960.0, "batch_reward": 0.1280139982700348, "critic_loss": 0.2739813029766083, "ae_transition_loss": 0.09922432899475098, "ae_encoder_loss": 0.3073353171348572, "actor_loss": -1.2896056175231934, "actor_target_entropy": -2.0, "actor_entropy": 0.8661381006240845, "alpha_loss": 0.01388649269938469, "alpha_value": 0.008851068703110374, "duration": 1.5668435096740723, "step": 31804}
{"episode_reward": -3.437341146245161, "episode": 961.0, "duration": 41.780447006225586, "step": 31805}
{"episode_reward": -1.730637982720162, "episode": 962.0, "batch_reward": 0.08527062212427457, "critic_loss": 0.250039001305898, "ae_transition_loss": 0.244192436337471, "ae_encoder_loss": 0.3313123782475789, "actor_loss": -0.8863462209701538, "actor_target_entropy": -2.0, "actor_entropy": 0.6682992875576019, "alpha_loss": 0.011078642991681894, "alpha_value": 0.008828923322365557, "duration": 5.750654697418213, "step": 31834}
{"episode_reward": -1.4704781375943956, "episode": 963.0, "batch_reward": 0.10022499226033688, "critic_loss": 0.3927568991978963, "ae_transition_loss": 0.16163763993730149, "ae_encoder_loss": 0.30366429686546326, "actor_loss": -1.0433570941289265, "actor_target_entropy": -2.0, "actor_entropy": 0.4380753735701243, "alpha_loss": 0.007291857929279407, "alpha_value": 0.008783695294541342, "duration": 12.629188537597656, "step": 31897}
{"episode_reward": 10.058331667052837, "episode": 964.0, "batch_reward": 0.074313685297966, "critic_loss": 0.5581320524215698, "ae_transition_loss": 0.11063798392812411, "ae_encoder_loss": 0.2852781464656194, "actor_loss": -0.8562358816464742, "actor_target_entropy": -2.0, "actor_entropy": 0.9641648928324381, "alpha_loss": 0.009961219194034735, "alpha_value": 0.008745169471068206, "duration": 5.41568398475647, "step": 31922}
{"episode_reward": -4.75722775890271, "episode": 965.0, "batch_reward": 0.08588272333145142, "critic_loss": 0.2554798126220703, "ae_transition_loss": 0.07686587423086166, "ae_encoder_loss": 0.2901773154735565, "actor_loss": -0.9373589158058167, "actor_target_entropy": -2.0, "actor_entropy": 1.34821617603302, "alpha_loss": 0.011545233428478241, "alpha_value": 0.008729200924411682, "duration": 2.1358208656311035, "step": 31932}
{"episode_reward": -3.0476042683227473, "episode": 966.0, "batch_reward": 0.08959083259105682, "critic_loss": 0.11349539458751678, "ae_transition_loss": 0.01954435184597969, "ae_encoder_loss": 0.297425240278244, "actor_loss": -1.1615136861801147, "actor_target_entropy": -2.0, "actor_entropy": 1.6182173490524292, "alpha_loss": 0.012126419693231583, "alpha_value": 0.008721051749992183, "duration": 3.25628924369812, "step": 31948}
{"episode_reward": -3.4367865564519495, "episode": 967.0, "batch_reward": 0.09624932333827019, "critic_loss": 0.3538971394300461, "ae_transition_loss": 0.09993157908320427, "ae_encoder_loss": 0.4698714017868042, "actor_loss": -1.1089972257614136, "actor_target_entropy": -2.0, "actor_entropy": 1.7563477158546448, "alpha_loss": 0.012150782160460949, "alpha_value": 0.008708659237334129, "duration": 3.3453662395477295, "step": 31964}
{"episode_reward": -4.4827314558757205, "episode": 968.0, "batch_reward": 0.10763201862573624, "critic_loss": 0.16121795773506165, "ae_transition_loss": -0.0019116532057523727, "ae_encoder_loss": 0.5060693025588989, "actor_loss": -0.9885213971138, "actor_target_entropy": -2.0, "actor_entropy": 1.7871894836425781, "alpha_loss": 0.014751777984201908, "alpha_value": 0.008696059891368582, "duration": 3.165848731994629, "step": 31979}
{"episode_reward": -3.7236580701156763, "episode": 969.0, "batch_reward": 0.08017176389694214, "critic_loss": 0.25331932306289673, "ae_transition_loss": 1.6892988681793213, "ae_encoder_loss": 0.44501975178718567, "actor_loss": -0.9564604759216309, "actor_target_entropy": -2.0, "actor_entropy": 1.7699272632598877, "alpha_loss": 0.014837667346000671, "alpha_value": 0.00868731109635989, "duration": 2.4578731060028076, "step": 31990}
{"episode_reward": -3.2314570125741304, "episode": 970.0, "batch_reward": 0.0938944121201833, "critic_loss": 0.46205952763557434, "ae_transition_loss": 0.44037144382794696, "ae_encoder_loss": 0.3651636044184367, "actor_loss": -1.1440365314483643, "actor_target_entropy": -2.0, "actor_entropy": 1.4709562460581462, "alpha_loss": 0.013845602050423622, "alpha_value": 0.008668927553109971, "duration": 4.85446310043335, "step": 32012}
{"episode_reward": -5.535756930716675, "episode": 971.0, "batch_reward": 0.13001609345277151, "critic_loss": 0.494379182656606, "ae_transition_loss": 0.4920973877112071, "ae_encoder_loss": 0.46352047721544903, "actor_loss": -1.2141036589940388, "actor_target_entropy": -2.0, "actor_entropy": 1.2463810841242473, "alpha_loss": 0.012741079243520895, "alpha_value": 0.00864063549216004, "duration": 36.88310766220093, "step": 32048}
{"episode_reward": -6.522561346111247, "episode": 972.0, "batch_reward": 0.10133666079491377, "critic_loss": 0.30920276045799255, "ae_transition_loss": 0.5299969986081123, "ae_encoder_loss": 0.6924362629652023, "actor_loss": -1.0729826539754868, "actor_target_entropy": -2.0, "actor_entropy": 1.0878845751285553, "alpha_loss": 0.014031903585419059, "alpha_value": 0.008607456328126163, "duration": 8.168013334274292, "step": 32086}
{"episode_reward": -5.917387867458654, "episode": 973.0, "duration": 0.2714238166809082, "step": 32087}
{"episode_reward": -0.7161738204963901, "episode": 974.0, "batch_reward": 0.07348408102989197, "critic_loss": 0.44974417686462403, "ae_transition_loss": 0.7283841967582703, "ae_encoder_loss": 0.6365082919597626, "actor_loss": -0.8529152512550354, "actor_target_entropy": -2.0, "actor_entropy": 1.0000095129013062, "alpha_loss": 0.014952950179576874, "alpha_value": 0.008563077193461069, "duration": 10.74398946762085, "step": 32138}
{"episode_reward": -7.801729810140742, "episode": 975.0, "batch_reward": 0.1264422982931137, "critic_loss": 0.29985634982585907, "ae_transition_loss": 0.5515584349632263, "ae_encoder_loss": 0.653351217508316, "actor_loss": -1.029799908399582, "actor_target_entropy": -2.0, "actor_entropy": 0.9869508743286133, "alpha_loss": 0.011728104669600725, "alpha_value": 0.008527245069507264, "duration": 4.259714126586914, "step": 32157}
{"episode_reward": -0.6600988701962557, "episode": 976.0, "batch_reward": 0.07594549842178822, "critic_loss": 0.32162870466709137, "ae_transition_loss": 0.5521354973316193, "ae_encoder_loss": 0.7295297682285309, "actor_loss": -1.0178872048854828, "actor_target_entropy": -2.0, "actor_entropy": 1.2601696252822876, "alpha_loss": 0.012758443132042885, "alpha_value": 0.008507027540229892, "duration": 4.6222617626190186, "step": 32179}
{"episode_reward": 2.1593591068557445, "episode": 977.0, "batch_reward": 0.09005620516836643, "critic_loss": 0.2626717947423458, "ae_transition_loss": 0.7869985848665237, "ae_encoder_loss": 0.4658436104655266, "actor_loss": -1.0086770802736282, "actor_target_entropy": -2.0, "actor_entropy": 1.2006402909755707, "alpha_loss": 0.00940368790179491, "alpha_value": 0.008477894349669, "duration": 7.953367233276367, "step": 32216}
{"episode_reward": -2.395113669252177, "episode": 978.0, "batch_reward": 0.0550095965154469, "critic_loss": 0.2946830689907074, "ae_transition_loss": 0.6297257989645004, "ae_encoder_loss": 0.39519427716732025, "actor_loss": -0.923958957195282, "actor_target_entropy": -2.0, "actor_entropy": 1.3158425688743591, "alpha_loss": 0.010777476476505399, "alpha_value": 0.008441915742877538, "duration": 7.92341423034668, "step": 32253}
{"episode_reward": 2.8291010286330156, "episode": 979.0, "batch_reward": 0.06496168300509453, "critic_loss": 0.24246594682335854, "ae_transition_loss": 0.40341441333293915, "ae_encoder_loss": 0.4030739292502403, "actor_loss": -0.9784757196903229, "actor_target_entropy": -2.0, "actor_entropy": 1.490242838859558, "alpha_loss": 0.013244764879345894, "alpha_value": 0.008406923499613566, "duration": 8.174969673156738, "step": 32291}
{"episode_reward": -7.7744240471649935, "episode": 980.0, "duration": 0.1919853687286377, "step": 32292}
{"episode_reward": 0.4201097378938192, "episode": 981.0, "batch_reward": 0.02188507840037346, "critic_loss": 0.43100348114967346, "ae_transition_loss": 0.31343311071395874, "ae_encoder_loss": 0.4569050073623657, "actor_loss": -0.9347636699676514, "actor_target_entropy": -2.0, "actor_entropy": 1.2411624193191528, "alpha_loss": 0.011556090787053108, "alpha_value": 0.008384482792635418, "duration": 103.11676383018494, "step": 32308}
{"episode_reward": -5.479946971786865, "episode": 982.0, "duration": 0.227752685546875, "step": 32309}
{"episode_reward": -0.07105729447569026, "episode": 983.0, "batch_reward": 0.09367822855710983, "critic_loss": 0.2962147295475006, "ae_transition_loss": 0.273609717686971, "ae_encoder_loss": 0.3827363948027293, "actor_loss": -1.1075239181518555, "actor_target_entropy": -2.0, "actor_entropy": 1.4137835105260212, "alpha_loss": 0.009998071938753128, "alpha_value": 0.008366911503372355, "duration": 6.172086000442505, "step": 32340}
{"episode_reward": -11.553510296873943, "episode": 984.0, "batch_reward": 0.0887541938573122, "critic_loss": 0.44250689446926117, "ae_transition_loss": 0.16956131532788277, "ae_encoder_loss": 0.3773879408836365, "actor_loss": -0.8861886858940125, "actor_target_entropy": -2.0, "actor_entropy": 1.5093092620372772, "alpha_loss": 0.012529788771644235, "alpha_value": 0.008337432435702513, "duration": 6.660457611083984, "step": 32371}
{"episode_reward": -6.732460978868265, "episode": 985.0, "duration": 0.20541095733642578, "step": 32372}
{"episode_reward": -0.2964059597430379, "episode": 986.0, "batch_reward": 0.06849958151578903, "critic_loss": 0.4333000719547272, "ae_transition_loss": 0.14614638835191726, "ae_encoder_loss": 0.3040771007537842, "actor_loss": -0.9719228267669677, "actor_target_entropy": -2.0, "actor_entropy": 1.2132796764373779, "alpha_loss": 0.013754200749099254, "alpha_value": 0.008298287306478294, "duration": 10.09599494934082, "step": 32422}
{"episode_reward": 1.6454901933715484, "episode": 987.0, "batch_reward": 0.08826333284378052, "critic_loss": 0.5569594204425812, "ae_transition_loss": 0.150908837094903, "ae_encoder_loss": 0.29582567512989044, "actor_loss": -0.9916336238384247, "actor_target_entropy": -2.0, "actor_entropy": 0.9735490679740906, "alpha_loss": 0.01230532443150878, "alpha_value": 0.008266373100403644, "duration": 5.253216505050659, "step": 32449}
{"episode_reward": -5.304631701174394, "episode": 988.0, "duration": 0.26372528076171875, "step": 32450}
{"episode_reward": 0.635953125598339, "episode": 989.0, "batch_reward": 0.08755846541713584, "critic_loss": 0.37922670353542676, "ae_transition_loss": 0.21672168441794135, "ae_encoder_loss": 0.3678524467078122, "actor_loss": -0.9837237759069963, "actor_target_entropy": -2.0, "actor_entropy": 0.9891303073276173, "alpha_loss": 0.010453196623447266, "alpha_value": 0.008209478271813266, "duration": 21.332050323486328, "step": 32555}
{"episode_reward": -6.770059904595525, "episode": 990.0, "batch_reward": 0.10369041629812935, "critic_loss": 0.45596757395700976, "ae_transition_loss": 0.21734562583945014, "ae_encoder_loss": 0.35986280983144586, "actor_loss": -1.180842941457575, "actor_target_entropy": -2.0, "actor_entropy": 1.4984966299750588, "alpha_loss": 0.01144118183715777, "alpha_value": 0.008119177289172485, "duration": 22.355552911758423, "step": 32668}
{"episode_reward": -43.638370336857456, "episode": 991.0, "batch_reward": 0.09453313499689102, "critic_loss": 0.23647522926330566, "ae_transition_loss": 0.1745002195239067, "ae_encoder_loss": 0.39956080317497256, "actor_loss": -1.1703513503074645, "actor_target_entropy": -2.0, "actor_entropy": 1.592796015739441, "alpha_loss": 0.012600407376885414, "alpha_value": 0.008054295733626699, "duration": 52.7379093170166, "step": 32711}
{"episode_reward": -10.367955977018214, "episode": 992.0, "duration": 0.21822905540466309, "step": 32712}
{"episode_reward": -0.4268887377354296, "episode": 993.0, "batch_reward": 0.04816322773694992, "critic_loss": 0.32557350397109985, "ae_transition_loss": 0.309813916683197, "ae_encoder_loss": 0.33145222067832947, "actor_loss": -0.8166020512580872, "actor_target_entropy": -2.0, "actor_entropy": 1.5405076742172241, "alpha_loss": 0.01323816180229187, "alpha_value": 0.008029895168661259, "duration": 3.555203914642334, "step": 32729}
{"episode_reward": -4.187938930192312, "episode": 994.0, "batch_reward": 0.11783377329508464, "critic_loss": 0.27136551837126416, "ae_transition_loss": 0.2361933688322703, "ae_encoder_loss": 0.3488330940405528, "actor_loss": -1.1918235619862874, "actor_target_entropy": -2.0, "actor_entropy": 1.5070663690567017, "alpha_loss": 0.0135958610723416, "alpha_value": 0.00801274449584711, "duration": 5.3331074714660645, "step": 32752}
{"episode_reward": -1.7493573286860784, "episode": 995.0, "batch_reward": 0.09685369953513145, "critic_loss": 0.5628711134195328, "ae_transition_loss": 0.2303660735487938, "ae_encoder_loss": 0.3598310500383377, "actor_loss": -1.0288769602775574, "actor_target_entropy": -2.0, "actor_entropy": 1.4701103568077087, "alpha_loss": 0.012697790749371052, "alpha_value": 0.007990956114376817, "duration": 4.079718351364136, "step": 32771}
{"episode_reward": -2.5931067672865633, "episode": 996.0, "batch_reward": 0.09124579429626464, "critic_loss": 0.2801370322704315, "ae_transition_loss": 0.23588945381343365, "ae_encoder_loss": 0.40808610916137694, "actor_loss": -1.1434672951698304, "actor_target_entropy": -2.0, "actor_entropy": 1.4130008935928344, "alpha_loss": 0.012755635008215905, "alpha_value": 0.007960330690824559, "duration": 10.83928108215332, "step": 32824}
{"episode_reward": -10.820201089351247, "episode": 997.0, "batch_reward": 0.1454198658466339, "critic_loss": 0.13300329446792603, "ae_transition_loss": 0.08434206992387772, "ae_encoder_loss": 0.3478372097015381, "actor_loss": -1.290895700454712, "actor_target_entropy": -2.0, "actor_entropy": 1.416351318359375, "alpha_loss": 0.011315904557704926, "alpha_value": 0.007934053392166168, "duration": 1.9711809158325195, "step": 32832}
{"episode_reward": -0.22437415069419653, "episode": 998.0, "batch_reward": 0.061021759361028674, "critic_loss": 0.3181522011756897, "ae_transition_loss": 0.09598196744918823, "ae_encoder_loss": 0.3919252395629883, "actor_loss": -0.962268841266632, "actor_target_entropy": -2.0, "actor_entropy": 1.1103613138198853, "alpha_loss": 0.010171429999172688, "alpha_value": 0.007908485133434888, "duration": 10.780502080917358, "step": 32883}
{"episode_reward": -10.54701626475808, "episode": 999.0, "batch_reward": 0.12354636192321777, "critic_loss": 0.3666895031929016, "ae_transition_loss": 0.24337398260831833, "ae_encoder_loss": 0.41946785151958466, "actor_loss": -1.3586748838424683, "actor_target_entropy": -2.0, "actor_entropy": 1.35292387008667, "alpha_loss": 0.011713683605194092, "alpha_value": 0.007880015606533976, "duration": 4.826989650726318, "step": 32906}
{"episode_reward": -5.60354817155869, "episode": 1000.0, "batch_reward": 0.10705607136090596, "critic_loss": 0.3508021632830302, "ae_transition_loss": 0.36426202952861786, "ae_encoder_loss": 0.41369137167930603, "actor_loss": -1.175266146659851, "actor_target_entropy": -2.0, "actor_entropy": 1.4573315382003784, "alpha_loss": 0.011639645012716452, "alpha_value": 0.007860112081238218, "duration": 5.825515270233154, "step": 32933}
{"episode_reward": -6.803573109202614, "episode": 1001.0, "batch_reward": 0.09246259741485119, "critic_loss": 0.4547400251030922, "ae_transition_loss": 0.2690202184021473, "ae_encoder_loss": 0.36964377015829086, "actor_loss": -1.1293000876903534, "actor_target_entropy": -2.0, "actor_entropy": 1.5285923779010773, "alpha_loss": 0.011411688523367047, "alpha_value": 0.007832150754133465, "duration": 40.844778060913086, "step": 32976}
{"episode_reward": -16.812083339372286, "episode": 1002.0, "duration": 0.26915717124938965, "step": 32977}
{"episode_reward": 0.061797090839858626, "episode": 1003.0, "batch_reward": 0.0837286189198494, "critic_loss": 0.22431525588035583, "ae_transition_loss": 0.36703502138455707, "ae_encoder_loss": 0.3883361220359802, "actor_loss": -1.0807167092959087, "actor_target_entropy": -2.0, "actor_entropy": 1.8639623721440632, "alpha_loss": 0.011582777835428715, "alpha_value": 0.0078043552381948005, "duration": 5.630078554153442, "step": 33004}
{"episode_reward": -8.997723613097955, "episode": 1004.0, "batch_reward": 0.07034158334136009, "critic_loss": 0.2136184275150299, "ae_transition_loss": 0.3347303817669551, "ae_encoder_loss": 0.3765779932339986, "actor_loss": -0.9072710474332174, "actor_target_entropy": -2.0, "actor_entropy": 1.71893576780955, "alpha_loss": 0.01155216433107853, "alpha_value": 0.007780540531952043, "duration": 7.137462615966797, "step": 33038}
{"episode_reward": -15.595278022431094, "episode": 1005.0, "duration": 0.2354578971862793, "step": 33039}
{"episode_reward": -0.4220329619838703, "episode": 1006.0, "batch_reward": 0.1040470078587532, "critic_loss": 0.5303907543420792, "ae_transition_loss": 0.15369882620871067, "ae_encoder_loss": 0.4008195623755455, "actor_loss": -1.25283882021904, "actor_target_entropy": -2.0, "actor_entropy": 1.2173756062984467, "alpha_loss": 0.004909804847557098, "alpha_value": 0.00775415931828818, "duration": 7.35313868522644, "step": 33072}
{"episode_reward": -12.432270303016889, "episode": 1007.0, "batch_reward": 0.09589929282665252, "critic_loss": 0.5170198857784272, "ae_transition_loss": 0.37049105763435364, "ae_encoder_loss": 0.3085217386484146, "actor_loss": -1.1548704147338866, "actor_target_entropy": -2.0, "actor_entropy": 1.7452852964401244, "alpha_loss": 0.0007740405853837729, "alpha_value": 0.007727775190136332, "duration": 10.616521120071411, "step": 33121}
{"episode_reward": -24.482109714531767, "episode": 1008.0, "batch_reward": 0.08105129934847355, "critic_loss": 0.29570259153842926, "ae_transition_loss": 0.5744113400578499, "ae_encoder_loss": 0.4247087687253952, "actor_loss": -1.1127440631389618, "actor_target_entropy": -2.0, "actor_entropy": 1.6610199809074402, "alpha_loss": 0.006162215955555439, "alpha_value": 0.007712969575926913, "duration": 4.982480525970459, "step": 33146}
{"episode_reward": -10.838415525485173, "episode": 1009.0, "batch_reward": 0.08844244480133057, "critic_loss": 0.21320070326328278, "ae_transition_loss": 0.3223979026079178, "ae_encoder_loss": 0.38144250214099884, "actor_loss": -1.2946966290473938, "actor_target_entropy": -2.0, "actor_entropy": 1.8429625034332275, "alpha_loss": 0.004859797656536102, "alpha_value": 0.007704954704469899, "duration": 3.8842782974243164, "step": 33164}
{"episode_reward": -10.209344230076212, "episode": 1010.0, "batch_reward": 0.08103916198015212, "critic_loss": 0.42358840703964235, "ae_transition_loss": 0.42335962057113646, "ae_encoder_loss": 0.3803543567657471, "actor_loss": -1.1325944542884827, "actor_target_entropy": -2.0, "actor_entropy": 1.889365315437317, "alpha_loss": 0.007316446211189031, "alpha_value": 0.007690593989659401, "duration": 10.1896071434021, "step": 33213}
{"episode_reward": -20.41492390200729, "episode": 1011.0, "batch_reward": 0.11402962356805801, "critic_loss": 0.6424506306648254, "ae_transition_loss": 0.45315635204315186, "ae_encoder_loss": 0.3144323229789734, "actor_loss": -1.2496697902679443, "actor_target_entropy": -2.0, "actor_entropy": 1.6046154499053955, "alpha_loss": 0.007291757967323065, "alpha_value": 0.007677706011257388, "duration": 37.022143602371216, "step": 33229}
{"episode_reward": -6.43710508503478, "episode": 1012.0, "batch_reward": 0.0800818532705307, "critic_loss": 0.3638716101646423, "ae_transition_loss": 0.47901442646980286, "ae_encoder_loss": 0.2989702045917511, "actor_loss": -1.0124423503875732, "actor_target_entropy": -2.0, "actor_entropy": 1.5600374937057495, "alpha_loss": 0.01089330380782485, "alpha_value": 0.007663782951303134, "duration": 9.04192042350769, "step": 33271}
{"episode_reward": -12.349241030786857, "episode": 1013.0, "batch_reward": 0.10900238528847694, "critic_loss": 0.3146028518676758, "ae_transition_loss": 0.4613758772611618, "ae_encoder_loss": 0.3239542096853256, "actor_loss": -1.2105597853660583, "actor_target_entropy": -2.0, "actor_entropy": 1.422290325164795, "alpha_loss": 0.011671982705593109, "alpha_value": 0.007645127262639656, "duration": 4.500006437301636, "step": 33292}
{"episode_reward": -5.813852253607779, "episode": 1014.0, "batch_reward": 0.04323064908385277, "critic_loss": 0.18741565942764282, "ae_transition_loss": 0.36337751150131226, "ae_encoder_loss": 0.3496808409690857, "actor_loss": -0.8346034288406372, "actor_target_entropy": -2.0, "actor_entropy": 1.3416790962219238, "alpha_loss": 0.011548319831490517, "alpha_value": 0.007636108391254245, "duration": 2.595510482788086, "step": 33304}
{"episode_reward": -1.5044366553937474, "episode": 1015.0, "batch_reward": 0.07841408252716064, "critic_loss": 0.23101921379566193, "ae_transition_loss": 0.3448243886232376, "ae_encoder_loss": 0.39930368959903717, "actor_loss": -1.0054888725280762, "actor_target_entropy": -2.0, "actor_entropy": 1.2336384057998657, "alpha_loss": 0.012025847565382719, "alpha_value": 0.007626601992670433, "duration": 4.816781044006348, "step": 33326}
{"episode_reward": -13.755470626713224, "episode": 1016.0, "batch_reward": 0.044216545298695564, "critic_loss": 0.3252723887562752, "ae_transition_loss": 0.3936533033847809, "ae_encoder_loss": 0.4126760810613632, "actor_loss": -1.0331227779388428, "actor_target_entropy": -2.0, "actor_entropy": 1.2184476256370544, "alpha_loss": 0.00997842475771904, "alpha_value": 0.0076134666030947895, "duration": 3.486563205718994, "step": 33341}
{"episode_reward": -3.3415722670936705, "episode": 1017.0, "duration": 0.18862128257751465, "step": 33342}
{"episode_reward": -0.4598868191242218, "episode": 1018.0, "batch_reward": 0.02672659419476986, "critic_loss": 0.2320074662566185, "ae_transition_loss": 0.2691655680537224, "ae_encoder_loss": 0.44889213144779205, "actor_loss": -0.8345304131507874, "actor_target_entropy": -2.0, "actor_entropy": 1.3463977575302124, "alpha_loss": 0.012477069161832333, "alpha_value": 0.007600197940839583, "duration": 4.373462200164795, "step": 33362}
{"episode_reward": -3.1596183723681484, "episode": 1019.0, "batch_reward": 0.12268009409308434, "critic_loss": 0.15723364427685738, "ae_transition_loss": 0.16525346785783768, "ae_encoder_loss": 0.41860993206501007, "actor_loss": -1.2398426532745361, "actor_target_entropy": -2.0, "actor_entropy": 1.5798311233520508, "alpha_loss": 0.010647334158420563, "alpha_value": 0.007586464288453179, "duration": 6.275521755218506, "step": 33390}
{"episode_reward": -4.547715167484799, "episode": 1020.0, "batch_reward": 0.09164096042513847, "critic_loss": 0.3841102222601573, "ae_transition_loss": 0.32557683313886326, "ae_encoder_loss": 0.3494771172602971, "actor_loss": -1.1556328932444255, "actor_target_entropy": -2.0, "actor_entropy": 1.5500232378641765, "alpha_loss": 0.011005561177929243, "alpha_value": 0.00755864082486928, "duration": 10.984036684036255, "step": 33441}
{"episode_reward": -14.8620523176533, "episode": 1021.0, "batch_reward": 0.09468335174024105, "critic_loss": 0.39456722140312195, "ae_transition_loss": 0.3907943397760391, "ae_encoder_loss": 0.34742295145988467, "actor_loss": -1.1082193732261658, "actor_target_entropy": -2.0, "actor_entropy": 1.7882102727890015, "alpha_loss": 0.011246776022017003, "alpha_value": 0.007519253824327089, "duration": 41.478572607040405, "step": 33496}
{"episode_reward": -27.041741227887897, "episode": 1022.0, "batch_reward": 0.10155794024467468, "critic_loss": 0.14504405856132507, "ae_transition_loss": 0.4248722791671753, "ae_encoder_loss": 0.38720205426216125, "actor_loss": -1.1239955425262451, "actor_target_entropy": -2.0, "actor_entropy": 1.6639180183410645, "alpha_loss": 0.010437482967972755, "alpha_value": 0.007497295898297503, "duration": 2.6079206466674805, "step": 33508}
{"episode_reward": -2.773251224374816, "episode": 1023.0, "batch_reward": 0.009983082301914692, "critic_loss": 0.46053144335746765, "ae_transition_loss": 0.33360883593559265, "ae_encoder_loss": 0.4520523250102997, "actor_loss": -1.0381163954734802, "actor_target_entropy": -2.0, "actor_entropy": 1.6086137294769287, "alpha_loss": 0.011544876731932163, "alpha_value": 0.007486509924342907, "duration": 3.7598390579223633, "step": 33525}
{"episode_reward": -3.47188537766513, "episode": 1024.0, "batch_reward": 0.05264166556298733, "critic_loss": 0.41932232677936554, "ae_transition_loss": 0.4213465303182602, "ae_encoder_loss": 0.3720495030283928, "actor_loss": -0.8239639103412628, "actor_target_entropy": -2.0, "actor_entropy": 1.3724718689918518, "alpha_loss": 0.011355924652889371, "alpha_value": 0.007464698707435845, "duration": 8.30854082107544, "step": 33564}
{"episode_reward": -13.9748853922114, "episode": 1025.0, "batch_reward": 0.0883453506976366, "critic_loss": 0.31140815652906895, "ae_transition_loss": 0.30857112631201744, "ae_encoder_loss": 0.31871531903743744, "actor_loss": -1.0768413245677948, "actor_target_entropy": -2.0, "actor_entropy": 1.6430690288543701, "alpha_loss": 0.010880665853619576, "alpha_value": 0.007435799179285885, "duration": 8.066713571548462, "step": 33603}
{"episode_reward": -13.808931943688945, "episode": 1026.0, "batch_reward": 0.06686379760503769, "critic_loss": 0.4774351517359416, "ae_transition_loss": 0.670433779557546, "ae_encoder_loss": 0.38085882862408954, "actor_loss": -1.2223450938860576, "actor_target_entropy": -2.0, "actor_entropy": 2.020125389099121, "alpha_loss": 0.007824333384633064, "alpha_value": 0.00741077693830981, "duration": 6.249483585357666, "step": 33632}
{"episode_reward": -11.774236852668551, "episode": 1027.0, "batch_reward": 0.07598928362131119, "critic_loss": 0.30009275674819946, "ae_transition_loss": 0.2034609615802765, "ae_encoder_loss": 0.36295077204704285, "actor_loss": -1.099287748336792, "actor_target_entropy": -2.0, "actor_entropy": 1.9726550579071045, "alpha_loss": 0.006743676029145718, "alpha_value": 0.007397141672641554, "duration": 3.218393087387085, "step": 33648}
{"episode_reward": -4.263173608944904, "episode": 1028.0, "batch_reward": 0.10779165849089622, "critic_loss": 0.3946559876203537, "ae_transition_loss": 0.33619287610054016, "ae_encoder_loss": 0.3774779140949249, "actor_loss": -1.3123455047607422, "actor_target_entropy": -2.0, "actor_entropy": 1.5735463500022888, "alpha_loss": 0.004121954552829266, "alpha_value": 0.0073876122812222625, "duration": 4.605669736862183, "step": 33670}
{"episode_reward": -5.853897561918601, "episode": 1029.0, "batch_reward": 0.08997271209955215, "critic_loss": 0.48967215418815613, "ae_transition_loss": 0.37517249584198, "ae_encoder_loss": 0.3142399787902832, "actor_loss": -1.1657178401947021, "actor_target_entropy": -2.0, "actor_entropy": 1.3206835985183716, "alpha_loss": 0.0061411550268530846, "alpha_value": 0.00737880933571243, "duration": 2.1312344074249268, "step": 33680}
{"episode_reward": -5.225398341387777, "episode": 1030.0, "batch_reward": 0.07157567888498306, "critic_loss": 0.3172123630841573, "ae_transition_loss": 0.3858920832475026, "ae_encoder_loss": 0.3706050217151642, "actor_loss": -1.2382380565007527, "actor_target_entropy": -2.0, "actor_entropy": 1.4328059355417888, "alpha_loss": 0.009412196775277456, "alpha_value": 0.00736761263159146, "duration": 4.651706695556641, "step": 33701}
{"episode_reward": -5.348309995878527, "episode": 1031.0, "batch_reward": 0.06928884983062744, "critic_loss": 0.5574838121732076, "ae_transition_loss": 0.5537033329407374, "ae_encoder_loss": 0.36453112959861755, "actor_loss": -1.009187897046407, "actor_target_entropy": -2.0, "actor_entropy": 1.6691242853800456, "alpha_loss": 0.009424599508444468, "alpha_value": 0.007350477197064127, "duration": 46.242488384246826, "step": 33734}
{"episode_reward": -10.77782181087234, "episode": 1032.0, "duration": 0.2518768310546875, "step": 33735}
{"episode_reward": -0.6744968207610563, "episode": 1033.0, "batch_reward": 0.09493243942658107, "critic_loss": 0.24723234275976816, "ae_transition_loss": 0.2013396049539248, "ae_encoder_loss": 0.3259747624397278, "actor_loss": -1.199597160021464, "actor_target_entropy": -2.0, "actor_entropy": 1.6795897881189983, "alpha_loss": 0.008829469792544842, "alpha_value": 0.007333090340034418, "duration": 5.704871416091919, "step": 33762}
{"episode_reward": -7.350644971370353, "episode": 1034.0, "batch_reward": 0.02456037327647209, "critic_loss": 0.4056199789047241, "ae_transition_loss": 0.5407342314720154, "ae_encoder_loss": 0.43665289878845215, "actor_loss": -1.1654853820800781, "actor_target_entropy": -2.0, "actor_entropy": 1.572370171546936, "alpha_loss": 0.008766110055148602, "alpha_value": 0.0073214826405633955, "duration": 2.662843942642212, "step": 33775}
{"episode_reward": -3.9203257176412336, "episode": 1035.0, "batch_reward": 0.10539355874061584, "critic_loss": 0.34750059247016907, "ae_transition_loss": 0.5307302623987198, "ae_encoder_loss": 0.40194620192050934, "actor_loss": -1.1264956593513489, "actor_target_entropy": -2.0, "actor_entropy": 1.4742707014083862, "alpha_loss": 0.009608280844986439, "alpha_value": 0.007312807717597914, "duration": 3.6778769493103027, "step": 33792}
{"episode_reward": -4.515543613503544, "episode": 1036.0, "batch_reward": 0.0684716198593378, "critic_loss": 0.40342243015766144, "ae_transition_loss": 0.5072304010391235, "ae_encoder_loss": 0.43019038438796997, "actor_loss": -1.0286760926246643, "actor_target_entropy": -2.0, "actor_entropy": 1.506029486656189, "alpha_loss": 0.007874804781749845, "alpha_value": 0.007301115515453112, "duration": 4.76172399520874, "step": 33816}
{"episode_reward": -4.998585501164112, "episode": 1037.0, "batch_reward": 0.0326301958411932, "critic_loss": 0.484554186463356, "ae_transition_loss": 0.4989733025431633, "ae_encoder_loss": 0.4363895505666733, "actor_loss": -0.9308295547962189, "actor_target_entropy": -2.0, "actor_entropy": 1.5156232118606567, "alpha_loss": 0.008759326301515102, "alpha_value": 0.007289639227629039, "duration": 3.776404857635498, "step": 33834}
{"episode_reward": -5.250554547956347, "episode": 1038.0, "batch_reward": 0.08185830861330032, "critic_loss": 0.3535916358232498, "ae_transition_loss": 0.4811085820198059, "ae_encoder_loss": 0.41082736253738406, "actor_loss": -1.2400272369384766, "actor_target_entropy": -2.0, "actor_entropy": 1.610615110397339, "alpha_loss": 0.00488217668607831, "alpha_value": 0.007270357868664331, "duration": 10.572593688964844, "step": 33883}
{"episode_reward": -27.010568200900938, "episode": 1039.0, "batch_reward": 0.0688805878162384, "critic_loss": 0.423542357981205, "ae_transition_loss": 0.44655968993902206, "ae_encoder_loss": 0.3890135660767555, "actor_loss": -1.0674358308315277, "actor_target_entropy": -2.0, "actor_entropy": 1.232454240322113, "alpha_loss": 0.0038893769815331325, "alpha_value": 0.00724870970607811, "duration": 9.37796401977539, "step": 33929}
{"episode_reward": -29.00227589032673, "episode": 1040.0, "batch_reward": 0.08611804495255153, "critic_loss": 0.49505340059598285, "ae_transition_loss": 0.4043782949447632, "ae_encoder_loss": 0.3387382725874583, "actor_loss": -1.1233889659245808, "actor_target_entropy": -2.0, "actor_entropy": 1.395807941754659, "alpha_loss": 0.0006577592187871536, "alpha_value": 0.007234999349533341, "duration": 6.584043979644775, "step": 33960}
{"episode_reward": -6.1982904926224744, "episode": 1041.0, "batch_reward": 0.10353273339569569, "critic_loss": 0.6654704213142395, "ae_transition_loss": 0.4189269319176674, "ae_encoder_loss": 0.3397211730480194, "actor_loss": -1.2641248404979706, "actor_target_entropy": -2.0, "actor_entropy": 1.4547054171562195, "alpha_loss": 0.005435665254481137, "alpha_value": 0.007224462910362607, "duration": 48.572065591812134, "step": 33997}
{"episode_reward": -15.777295531595565, "episode": 1042.0, "batch_reward": 0.05645384391148885, "critic_loss": 0.3032022217909495, "ae_transition_loss": 0.4554196198781331, "ae_encoder_loss": 0.3949335316816966, "actor_loss": -1.0819336970647175, "actor_target_entropy": -2.0, "actor_entropy": 0.8622874220212301, "alpha_loss": 0.008150966372340918, "alpha_value": 0.0072134359221873645, "duration": 5.689377784729004, "step": 34024}
{"episode_reward": -5.9805991026065115, "episode": 1043.0, "batch_reward": 0.06712140701711178, "critic_loss": 0.39701753482222557, "ae_transition_loss": 0.35275883972644806, "ae_encoder_loss": 0.3311121240258217, "actor_loss": -1.034812092781067, "actor_target_entropy": -2.0, "actor_entropy": 0.9527531266212463, "alpha_loss": 0.008781250449828804, "alpha_value": 0.007200203569957034, "duration": 8.281617164611816, "step": 34064}
{"episode_reward": -6.316604103118957, "episode": 1044.0, "batch_reward": 0.10025892779231071, "critic_loss": 0.33395835757255554, "ae_transition_loss": 0.44417960941791534, "ae_encoder_loss": 0.4566278010606766, "actor_loss": -1.2572041749954224, "actor_target_entropy": -2.0, "actor_entropy": 1.07652086019516, "alpha_loss": 0.009628372732549906, "alpha_value": 0.007187319032009006, "duration": 4.400228023529053, "step": 34086}
{"episode_reward": -2.7388334856525223, "episode": 1045.0, "batch_reward": 0.05200849659740925, "critic_loss": 0.35427863895893097, "ae_transition_loss": 0.5871589481830597, "ae_encoder_loss": 0.4734187424182892, "actor_loss": -1.0941143035888672, "actor_target_entropy": -2.0, "actor_entropy": 1.331689476966858, "alpha_loss": 0.011368290055543184, "alpha_value": 0.007177852022515387, "duration": 3.6907384395599365, "step": 34102}
{"episode_reward": -3.332944155278701, "episode": 1046.0, "batch_reward": 0.08166923746466637, "critic_loss": 0.38668856769800186, "ae_transition_loss": 0.5118138194084167, "ae_encoder_loss": 0.3690342754125595, "actor_loss": -1.1027834713459015, "actor_target_entropy": -2.0, "actor_entropy": 1.538357675075531, "alpha_loss": 0.009048497071489692, "alpha_value": 0.007162216793210626, "duration": 8.727515935897827, "step": 34144}
{"episode_reward": -23.17182565044982, "episode": 1047.0, "batch_reward": 0.0739512951778514, "critic_loss": 0.39982761442661285, "ae_transition_loss": 0.6760269488607135, "ae_encoder_loss": 0.36820490871156963, "actor_loss": -1.0304211037499564, "actor_target_entropy": -2.0, "actor_entropy": 1.3249502522604806, "alpha_loss": 0.0070596992570374694, "alpha_value": 0.007133308921647871, "duration": 15.277087211608887, "step": 34220}
{"episode_reward": -50.81563393348912, "episode": 1048.0, "batch_reward": 0.07618207484483719, "critic_loss": 0.3239591121673584, "ae_transition_loss": 0.6093623042106628, "ae_encoder_loss": 0.3753083050251007, "actor_loss": -1.1030688285827637, "actor_target_entropy": -2.0, "actor_entropy": 1.5067856311798096, "alpha_loss": 0.010001863352954388, "alpha_value": 0.00711088878483604, "duration": 3.1236696243286133, "step": 34234}
{"episode_reward": -2.8821376508950607, "episode": 1049.0, "batch_reward": 0.07084137666970491, "critic_loss": 0.33175115287303925, "ae_transition_loss": 0.7186227291822433, "ae_encoder_loss": 0.5061806216835976, "actor_loss": -1.1696171462535858, "actor_target_entropy": -2.0, "actor_entropy": 1.4426833987236023, "alpha_loss": 0.007940821349620819, "alpha_value": 0.007095152555117877, "duration": 8.323853492736816, "step": 34274}
{"episode_reward": -17.220370499691594, "episode": 1050.0, "batch_reward": 0.05256335437297821, "critic_loss": 0.38817161321640015, "ae_transition_loss": 0.6006393432617188, "ae_encoder_loss": 0.7411532402038574, "actor_loss": -1.2184416055679321, "actor_target_entropy": -2.0, "actor_entropy": 1.1078763008117676, "alpha_loss": 0.0024200142361223698, "alpha_value": 0.0070820645466599655, "duration": 2.863779067993164, "step": 34287}
{"episode_reward": -3.6608960019221604, "episode": 1051.0, "batch_reward": 0.07868252694606781, "critic_loss": 0.3420945405960083, "ae_transition_loss": 0.6984978020191193, "ae_encoder_loss": 0.4707411080598831, "actor_loss": -1.1697807908058167, "actor_target_entropy": -2.0, "actor_entropy": 1.4071660041809082, "alpha_loss": 0.0017603150336071849, "alpha_value": 0.007075120027351072, "duration": 38.180007219314575, "step": 34306}
{"episode_reward": -5.2003667222131185, "episode": 1052.0, "duration": 0.26592373847961426, "step": 34307}
{"episode_reward": -0.6209475692258166, "episode": 1053.0, "batch_reward": 0.06535717286169529, "critic_loss": 0.38850679993629456, "ae_transition_loss": 0.5398687720298767, "ae_encoder_loss": 0.4130026698112488, "actor_loss": -1.142109990119934, "actor_target_entropy": -2.0, "actor_entropy": 2.0673991441726685, "alpha_loss": 0.003956058993935585, "alpha_value": 0.007066862355223639, "duration": 4.48409366607666, "step": 34327}
{"episode_reward": -5.6992534225081535, "episode": 1054.0, "batch_reward": 0.08899597823619843, "critic_loss": 0.21280232071876526, "ae_transition_loss": 0.5300785303115845, "ae_encoder_loss": 0.4156931936740875, "actor_loss": -1.371630311012268, "actor_target_entropy": -2.0, "actor_entropy": 2.206258773803711, "alpha_loss": 0.007020692806690931, "alpha_value": 0.007059144555519375, "duration": 3.7844579219818115, "step": 34343}
{"episode_reward": -4.53310462605672, "episode": 1055.0, "batch_reward": 0.05675579483310381, "critic_loss": 0.3324393530686696, "ae_transition_loss": 0.7306182781855265, "ae_encoder_loss": 0.5288853247960409, "actor_loss": -1.031408965587616, "actor_target_entropy": -2.0, "actor_entropy": 1.7192952632904053, "alpha_loss": 0.00888960932691892, "alpha_value": 0.007049168069644722, "duration": 6.563666105270386, "step": 34372}
{"episode_reward": -9.422505290840672, "episode": 1056.0, "batch_reward": 0.0817847028374672, "critic_loss": 0.3769783675670624, "ae_transition_loss": 0.5400588810443878, "ae_encoder_loss": 0.43718843162059784, "actor_loss": -1.064037561416626, "actor_target_entropy": -2.0, "actor_entropy": 1.4380282759666443, "alpha_loss": 0.008291790960356593, "alpha_value": 0.007038316836461194, "duration": 4.9464943408966064, "step": 34394}
{"episode_reward": -13.195396339222528, "episode": 1057.0, "batch_reward": 0.056924587943487696, "critic_loss": 0.45843231015735203, "ae_transition_loss": 0.5275189446078407, "ae_encoder_loss": 0.640727870994144, "actor_loss": -0.9981473551856147, "actor_target_entropy": -2.0, "actor_entropy": 1.5967891481187608, "alpha_loss": 0.007295648463898235, "alpha_value": 0.0070125089891601555, "duration": 19.39805793762207, "step": 34488}
{"episode_reward": -69.65374190157343, "episode": 1058.0, "batch_reward": 0.13247865438461304, "critic_loss": 0.4617077708244324, "ae_transition_loss": 0.6137825846672058, "ae_encoder_loss": 0.7163609266281128, "actor_loss": -1.1828665733337402, "actor_target_entropy": -2.0, "actor_entropy": 1.8577934503555298, "alpha_loss": 0.007550584152340889, "alpha_value": 0.006989367297353093, "duration": 1.3511087894439697, "step": 34493}
{"episode_reward": -1.6994144024684008, "episode": 1059.0, "batch_reward": 0.1134093888103962, "critic_loss": 0.9148306846618652, "ae_transition_loss": 0.21512281149625778, "ae_encoder_loss": 0.6574155688285828, "actor_loss": -1.4763434529304504, "actor_target_entropy": -2.0, "actor_entropy": 1.6837611198425293, "alpha_loss": 0.004743614699691534, "alpha_value": 0.006982720696366773, "duration": 5.364529848098755, "step": 34519}
{"episode_reward": -20.148178950894557, "episode": 1060.0, "duration": 0.25164103507995605, "step": 34520}
{"episode_reward": -0.38031441390080867, "episode": 1061.0, "batch_reward": 0.09744219854474068, "critic_loss": 0.3588859438896179, "ae_transition_loss": 0.3963034972548485, "ae_encoder_loss": 0.5441760718822479, "actor_loss": -1.2179967761039734, "actor_target_entropy": -2.0, "actor_entropy": 1.5960864424705505, "alpha_loss": 0.005097681190818548, "alpha_value": 0.006974324834131226, "duration": 76.81400108337402, "step": 34533}
{"episode_reward": -3.704349746798045, "episode": 1062.0, "batch_reward": 0.07718504890799523, "critic_loss": 0.5870151281356811, "ae_transition_loss": 0.32455130070447924, "ae_encoder_loss": 0.5143603205680847, "actor_loss": -1.0928783535957336, "actor_target_entropy": -2.0, "actor_entropy": 1.9960136890411377, "alpha_loss": 0.0062946024350821975, "alpha_value": 0.006960284740298914, "duration": 10.69783091545105, "step": 34587}
{"episode_reward": -28.4596866692304, "episode": 1063.0, "batch_reward": 0.014669358730316162, "critic_loss": 0.5481475591659546, "ae_transition_loss": 1.2740055322647095, "ae_encoder_loss": 0.485635906457901, "actor_loss": -1.1908032894134521, "actor_target_entropy": -2.0, "actor_entropy": 2.232959747314453, "alpha_loss": 0.007283346727490425, "alpha_value": 0.006948242101318181, "duration": 2.5795087814331055, "step": 34600}
{"episode_reward": -6.985721655686472, "episode": 1064.0, "batch_reward": 0.06444315612316132, "critic_loss": 0.8033230602741241, "ae_transition_loss": 0.23289058357477188, "ae_encoder_loss": 0.463961660861969, "actor_loss": -1.3072328567504883, "actor_target_entropy": -2.0, "actor_entropy": 2.282951831817627, "alpha_loss": 0.0059654139913618565, "alpha_value": 0.006942147852870492, "duration": 2.7232911586761475, "step": 34612}
{"episode_reward": -5.4219725661655795, "episode": 1065.0, "batch_reward": 0.029823895078152418, "critic_loss": 0.4261670410633087, "ae_transition_loss": 0.40847165882587433, "ae_encoder_loss": 0.43614253401756287, "actor_loss": -1.0107793509960175, "actor_target_entropy": -2.0, "actor_entropy": 2.1551462411880493, "alpha_loss": 0.00876667071133852, "alpha_value": 0.006934002185799182, "duration": 4.556599855422974, "step": 34635}
{"episode_reward": -7.798248470289523, "episode": 1066.0, "batch_reward": 0.06612679362297058, "critic_loss": 0.3466845154762268, "ae_transition_loss": 0.22634679824113846, "ae_encoder_loss": 0.3966633230447769, "actor_loss": -1.1922915577888489, "actor_target_entropy": -2.0, "actor_entropy": 1.9144798517227173, "alpha_loss": 0.009434605482965708, "alpha_value": 0.006925340783521885, "duration": 3.9117324352264404, "step": 34654}
{"episode_reward": -6.721730659562153, "episode": 1067.0, "batch_reward": 0.11589493105808894, "critic_loss": 0.5928138395150503, "ae_transition_loss": 0.35372456908226013, "ae_encoder_loss": 0.48093367616335553, "actor_loss": -1.3069591522216797, "actor_target_entropy": -2.0, "actor_entropy": 1.9232862790425618, "alpha_loss": 0.0096118471895655, "alpha_value": 0.006913638696353794, "duration": 5.7596845626831055, "step": 34681}
{"episode_reward": -19.475664207191908, "episode": 1068.0, "batch_reward": 0.05793005786836147, "critic_loss": 0.5425201058387756, "ae_transition_loss": 0.8599880933761597, "ae_encoder_loss": 0.5080839991569519, "actor_loss": -0.9867500066757202, "actor_target_entropy": -2.0, "actor_entropy": 1.679283320903778, "alpha_loss": 0.009134211344644427, "alpha_value": 0.0069012348862506605, "duration": 5.263777256011963, "step": 34708}
{"episode_reward": -13.726292012835138, "episode": 1069.0, "batch_reward": 0.0663814228028059, "critic_loss": 0.5482937842607498, "ae_transition_loss": 0.296109177172184, "ae_encoder_loss": 0.49741584062576294, "actor_loss": -1.0486227869987488, "actor_target_entropy": -2.0, "actor_entropy": 1.5477773547172546, "alpha_loss": 0.008270907681435347, "alpha_value": 0.006891009353523984, "duration": 3.241420030593872, "step": 34723}
{"episode_reward": -8.345783569938522, "episode": 1070.0, "batch_reward": 0.060343799740076066, "critic_loss": 0.7508867740631103, "ae_transition_loss": 0.4687308847904205, "ae_encoder_loss": 0.6619382381439209, "actor_loss": -1.2156464815139771, "actor_target_entropy": -2.0, "actor_entropy": 1.5554488182067872, "alpha_loss": 0.0065948700997978445, "alpha_value": 0.006873360817027062, "duration": 10.188017845153809, "step": 34772}
{"episode_reward": -33.834995874305754, "episode": 1071.0, "batch_reward": 0.06429935991764069, "critic_loss": 0.6548187732696533, "ae_transition_loss": 0.4586479961872101, "ae_encoder_loss": 0.5710347890853882, "actor_loss": -1.1395492553710938, "actor_target_entropy": -2.0, "actor_entropy": 1.5471187829971313, "alpha_loss": 0.00532415509223938, "alpha_value": 0.006858809336281938, "duration": 78.71808695793152, "step": 34790}
{"episode_reward": -4.95566173747541, "episode": 1072.0, "batch_reward": 0.048173288465477526, "critic_loss": 0.5845373049378395, "ae_transition_loss": 0.39572273567318916, "ae_encoder_loss": 0.596153974533081, "actor_loss": -1.04136610776186, "actor_target_entropy": -2.0, "actor_entropy": 1.9620919227600098, "alpha_loss": 0.006802445917855948, "alpha_value": 0.006838902064601606, "duration": 15.354028463363647, "step": 34864}
{"episode_reward": -38.68708638344998, "episode": 1073.0, "batch_reward": 0.07644828781485558, "critic_loss": 0.6226250529289246, "ae_transition_loss": 0.4603666514158249, "ae_encoder_loss": 0.5398109257221222, "actor_loss": -1.1812059879302979, "actor_target_entropy": -2.0, "actor_entropy": 1.266616702079773, "alpha_loss": 0.005832730093970895, "alpha_value": 0.006816857509928441, "duration": 4.801673650741577, "step": 34887}
{"episode_reward": -10.448170317194867, "episode": 1074.0, "batch_reward": 0.06150795519351959, "critic_loss": 0.501480795443058, "ae_transition_loss": 0.45840298384428024, "ae_encoder_loss": 0.5199423581361771, "actor_loss": -1.0420663356781006, "actor_target_entropy": -2.0, "actor_entropy": 1.290710300207138, "alpha_loss": 0.006870239623822272, "alpha_value": 0.006804115401583002, "duration": 8.61983609199524, "step": 34928}
{"episode_reward": -15.626622620811707, "episode": 1075.0, "batch_reward": 0.09380365908145905, "critic_loss": 0.26870837807655334, "ae_transition_loss": 0.5169865638017654, "ae_encoder_loss": 0.5265431553125381, "actor_loss": -1.3519654273986816, "actor_target_entropy": -2.0, "actor_entropy": 1.6647781133651733, "alpha_loss": 0.008797349873930216, "alpha_value": 0.006791284117042344, "duration": 3.1520068645477295, "step": 34941}
{"episode_reward": -2.464976142398828, "episode": 1076.0, "batch_reward": 0.039553724229335785, "critic_loss": 0.49446672201156616, "ae_transition_loss": 0.5431703527768453, "ae_encoder_loss": 0.5431359708309174, "actor_loss": -1.224339485168457, "actor_target_entropy": -2.0, "actor_entropy": 2.0546682675679526, "alpha_loss": 0.008890917679915825, "alpha_value": 0.006779959091802189, "duration": 6.400942087173462, "step": 34971}
{"episode_reward": -9.850350243696097, "episode": 1077.0, "batch_reward": 0.05520249903202057, "critic_loss": 0.4128342568874359, "ae_transition_loss": 0.8696364164352417, "ae_encoder_loss": 0.5004664858182272, "actor_loss": -1.083364486694336, "actor_target_entropy": -2.0, "actor_entropy": 2.1328059832255044, "alpha_loss": 0.008846011012792587, "alpha_value": 0.0067657256576554815, "duration": 7.778388738632202, "step": 35009}
{"episode_reward": -15.734392261931625, "episode": 1078.0, "batch_reward": 0.09931216575205326, "critic_loss": 0.6134042106568813, "ae_transition_loss": 0.4963247701525688, "ae_encoder_loss": 0.5529490634799004, "actor_loss": -1.2970035374164581, "actor_target_entropy": -2.0, "actor_entropy": 1.747400552034378, "alpha_loss": 0.007676909561268985, "alpha_value": 0.006748594166709698, "duration": 7.1748433113098145, "step": 35042}
{"episode_reward": -8.181413041756043, "episode": 1079.0, "batch_reward": 0.034165085293352604, "critic_loss": 0.5151776373386383, "ae_transition_loss": 0.519005686044693, "ae_encoder_loss": 0.6493322849273682, "actor_loss": -0.8871219754219055, "actor_target_entropy": -2.0, "actor_entropy": 1.7170888185501099, "alpha_loss": 0.008823238778859377, "alpha_value": 0.006733887726226859, "duration": 4.920647382736206, "step": 35067}
{"episode_reward": -7.50470484875031, "episode": 1080.0, "batch_reward": 0.06472128753860791, "critic_loss": 0.4570397138595581, "ae_transition_loss": 0.3412392735481262, "ae_encoder_loss": 0.45447253187497455, "actor_loss": -1.1148387789726257, "actor_target_entropy": -2.0, "actor_entropy": 1.8294659058252971, "alpha_loss": 0.0065454477444291115, "alpha_value": 0.006721502429821331, "duration": 6.360057592391968, "step": 35098}
{"episode_reward": -8.656077305945551, "episode": 1081.0, "batch_reward": 0.05883307009935379, "critic_loss": 0.2732461839914322, "ae_transition_loss": 0.5846620947122574, "ae_encoder_loss": 0.5737477540969849, "actor_loss": -1.098392367362976, "actor_target_entropy": -2.0, "actor_entropy": 1.946136474609375, "alpha_loss": 0.007064183708280325, "alpha_value": 0.006709571982720284, "duration": 134.6998279094696, "step": 35118}
{"episode_reward": -9.032301815024004, "episode": 1082.0, "batch_reward": 0.07417023802797, "critic_loss": 0.3737009863058726, "ae_transition_loss": 0.2641315112511317, "ae_encoder_loss": 0.5677116314570109, "actor_loss": -1.216240684191386, "actor_target_entropy": -2.0, "actor_entropy": 1.839133858680725, "alpha_loss": 0.008413884012649456, "alpha_value": 0.006697774834019061, "duration": 5.091881990432739, "step": 35141}
{"episode_reward": -8.64095875548708, "episode": 1083.0, "batch_reward": 0.09798209369182587, "critic_loss": 0.3526157736778259, "ae_transition_loss": 0.4911227226257324, "ae_encoder_loss": 0.5658026933670044, "actor_loss": -1.2439639568328857, "actor_target_entropy": -2.0, "actor_entropy": 1.738203763961792, "alpha_loss": 0.006651993840932846, "alpha_value": 0.006688162556788634, "duration": 2.3654489517211914, "step": 35152}
{"episode_reward": -1.7350692547917825, "episode": 1084.0, "batch_reward": 0.028369042091071606, "critic_loss": 0.4874065965414047, "ae_transition_loss": 0.6028220057487488, "ae_encoder_loss": 0.5172514021396637, "actor_loss": -1.1022576093673706, "actor_target_entropy": -2.0, "actor_entropy": 1.6762995719909668, "alpha_loss": 0.008007453521713614, "alpha_value": 0.0066810540110069615, "duration": 4.690119028091431, "step": 35175}
{"episode_reward": -10.245513056665132, "episode": 1085.0, "batch_reward": 0.11920702457427979, "critic_loss": 0.8487416505813599, "ae_transition_loss": 0.40850162506103516, "ae_encoder_loss": 0.5210460424423218, "actor_loss": -1.1556652784347534, "actor_target_entropy": -2.0, "actor_entropy": 1.478031873703003, "alpha_loss": 0.009494262747466564, "alpha_value": 0.006673911866847551, "duration": 3.3352859020233154, "step": 35190}
{"episode_reward": -3.6520124756907233, "episode": 1086.0, "batch_reward": 0.0729652876034379, "critic_loss": 0.5943434834480286, "ae_transition_loss": 0.4109138399362564, "ae_encoder_loss": 0.5333748459815979, "actor_loss": -1.211752474308014, "actor_target_entropy": -2.0, "actor_entropy": 1.3586577773094177, "alpha_loss": 0.008300724206492305, "alpha_value": 0.0066666236526571245, "duration": 2.6487879753112793, "step": 35201}
{"episode_reward": -4.15505171974685, "episode": 1087.0, "batch_reward": 0.06922670640051365, "critic_loss": 0.7558871110280355, "ae_transition_loss": 0.39431797464688617, "ae_encoder_loss": 0.4938775599002838, "actor_loss": -1.1489566564559937, "actor_target_entropy": -2.0, "actor_entropy": 1.306604226430257, "alpha_loss": 0.007550839334726334, "alpha_value": 0.006654371737024709, "duration": 7.462806463241577, "step": 35238}
{"episode_reward": -18.798981615026904, "episode": 1088.0, "batch_reward": 0.06971524376422167, "critic_loss": 0.47983649373054504, "ae_transition_loss": 0.2078929344813029, "ae_encoder_loss": 0.4708685874938965, "actor_loss": -1.2332515319188435, "actor_target_entropy": -2.0, "actor_entropy": 1.5289920965830486, "alpha_loss": 0.004964649677276611, "alpha_value": 0.006640148613925888, "duration": 6.163158416748047, "step": 35268}
{"episode_reward": -9.133406983165655, "episode": 1089.0, "batch_reward": 0.0119711235165596, "critic_loss": 0.4929351583123207, "ae_transition_loss": 0.6552048623561859, "ae_encoder_loss": 0.5464144945144653, "actor_loss": -0.9998650550842285, "actor_target_entropy": -2.0, "actor_entropy": 1.810020089149475, "alpha_loss": 0.005461792694404721, "alpha_value": 0.006629229062143464, "duration": 4.39238166809082, "step": 35289}
{"episode_reward": -5.773468178262329, "episode": 1090.0, "batch_reward": 0.1128707192838192, "critic_loss": 0.44883865118026733, "ae_transition_loss": 0.23793163895606995, "ae_encoder_loss": 0.4126405864953995, "actor_loss": -1.301876962184906, "actor_target_entropy": -2.0, "actor_entropy": 1.7532649040222168, "alpha_loss": 0.005535169970244169, "alpha_value": 0.006620927256155459, "duration": 4.405308485031128, "step": 35310}
{"episode_reward": -4.146700621885435, "episode": 1091.0, "batch_reward": 0.07001906012495358, "critic_loss": 0.4748315711816152, "ae_transition_loss": 0.377238392829895, "ae_encoder_loss": 0.4665041466554006, "actor_loss": -1.1743621428807576, "actor_target_entropy": -2.0, "actor_entropy": 1.5659713347752888, "alpha_loss": 0.007382933360834916, "alpha_value": 0.006610815602428938, "duration": 36.22479009628296, "step": 35335}
{"episode_reward": -4.255605215488252, "episode": 1092.0, "batch_reward": 0.0604599229991436, "critic_loss": 0.3663579821586609, "ae_transition_loss": 0.3709282800555229, "ae_encoder_loss": 0.46635502576828003, "actor_loss": -1.3169703483581543, "actor_target_entropy": -2.0, "actor_entropy": 1.4368096590042114, "alpha_loss": 0.008366577560082078, "alpha_value": 0.006600452493218455, "duration": 3.6416711807250977, "step": 35351}
{"episode_reward": -4.5244843824248955, "episode": 1093.0, "batch_reward": 0.01830472983419895, "critic_loss": 0.1455104500055313, "ae_transition_loss": 0.5732641220092773, "ae_encoder_loss": 0.5395897030830383, "actor_loss": -0.6938703656196594, "actor_target_entropy": -2.0, "actor_entropy": 1.6217414140701294, "alpha_loss": 0.009194224141538143, "alpha_value": 0.006594006305801875, "duration": 3.2715003490448, "step": 35367}
{"episode_reward": -3.2049467850782616, "episode": 1094.0, "batch_reward": 0.0422595115378499, "critic_loss": 0.5918347388505936, "ae_transition_loss": 0.7496221959590912, "ae_encoder_loss": 0.5916532278060913, "actor_loss": -1.117613136768341, "actor_target_entropy": -2.0, "actor_entropy": 1.652140200138092, "alpha_loss": 0.007919386960566044, "alpha_value": 0.00658730930597127, "duration": 3.667391777038574, "step": 35383}
{"episode_reward": -3.365333597189336, "episode": 1095.0, "batch_reward": 0.06419657915830612, "critic_loss": 0.7084129750728607, "ae_transition_loss": 0.3309244066476822, "ae_encoder_loss": 0.48741739988327026, "actor_loss": -1.188169002532959, "actor_target_entropy": -2.0, "actor_entropy": 1.7515268325805664, "alpha_loss": 0.007046197075396776, "alpha_value": 0.0065782961451126285, "duration": 5.114778518676758, "step": 35408}
{"episode_reward": -7.8627754315505936, "episode": 1096.0, "duration": 0.22918248176574707, "step": 35409}
{"episode_reward": -0.8823657035827637, "episode": 1097.0, "batch_reward": 0.04865529714152217, "critic_loss": 0.3839147500693798, "ae_transition_loss": 0.44673192501068115, "ae_encoder_loss": 0.5060498118400574, "actor_loss": -1.1996721029281616, "actor_target_entropy": -2.0, "actor_entropy": 1.816619098186493, "alpha_loss": 0.006646605907008052, "alpha_value": 0.006565043431904297, "duration": 8.00394344329834, "step": 35446}
{"episode_reward": -11.440019705861916, "episode": 1098.0, "batch_reward": 0.035678423941135406, "critic_loss": 0.5397898952166239, "ae_transition_loss": 0.39485472440719604, "ae_encoder_loss": 0.5061487952868143, "actor_loss": -0.9053913752237955, "actor_target_entropy": -2.0, "actor_entropy": 1.5873337586720784, "alpha_loss": 0.008126447908580303, "alpha_value": 0.006549847697436921, "duration": 5.858473539352417, "step": 35473}
{"episode_reward": -8.408699051839847, "episode": 1099.0, "duration": 0.24669861793518066, "step": 35474}
{"episode_reward": -0.14798749030447095, "episode": 1100.0, "batch_reward": 0.08439646288752556, "critic_loss": 0.8409129977226257, "ae_transition_loss": 0.5444750040769577, "ae_encoder_loss": 0.4673674702644348, "actor_loss": -1.1379650831222534, "actor_target_entropy": -2.0, "actor_entropy": 1.3786874413490295, "alpha_loss": 0.0076830347534269094, "alpha_value": 0.006538688663075915, "duration": 5.026005744934082, "step": 35498}
{"episode_reward": -7.655564417819261, "episode": 1101.0, "batch_reward": 0.027804933488368988, "critic_loss": 0.39057186245918274, "ae_transition_loss": 0.25155677646398544, "ae_encoder_loss": 0.5155075937509537, "actor_loss": -1.118921160697937, "actor_target_entropy": -2.0, "actor_entropy": 1.4296073913574219, "alpha_loss": 0.00932364771142602, "alpha_value": 0.006529577631008236, "duration": 48.051971197128296, "step": 35517}
{"episode_reward": -5.5000960335246, "episode": 1102.0, "batch_reward": 0.1371006965637207, "critic_loss": 0.4619511067867279, "ae_transition_loss": 0.15736332535743713, "ae_encoder_loss": 0.39737510681152344, "actor_loss": -1.5129156112670898, "actor_target_entropy": -2.0, "actor_entropy": 1.3433518409729004, "alpha_loss": 0.005565870553255081, "alpha_value": 0.006522509416539824, "duration": 2.695779323577881, "step": 35530}
{"episode_reward": -5.741463854648156, "episode": 1103.0, "batch_reward": 0.11503185828526814, "critic_loss": 0.29172784090042114, "ae_transition_loss": 0.41313616434733075, "ae_encoder_loss": 0.5268816451231638, "actor_loss": -1.2926878134409587, "actor_target_entropy": -2.0, "actor_entropy": 1.469474991162618, "alpha_loss": 0.007074818015098572, "alpha_value": 0.006513208202783685, "duration": 4.656489610671997, "step": 35552}
{"episode_reward": -4.378029427629264, "episode": 1104.0, "batch_reward": 0.04251980036497116, "critic_loss": 0.41457313299179077, "ae_transition_loss": 0.20478256046772003, "ae_encoder_loss": 0.6302496790885925, "actor_loss": -1.1300663948059082, "actor_target_entropy": -2.0, "actor_entropy": 1.3796648979187012, "alpha_loss": 0.007630285806953907, "alpha_value": 0.006504045859796544, "duration": 3.495143175125122, "step": 35570}
{"episode_reward": -4.357271388807505, "episode": 1105.0, "batch_reward": 0.14916004985570908, "critic_loss": 0.8539941310882568, "ae_transition_loss": 0.3640177994966507, "ae_encoder_loss": 0.5784870982170105, "actor_loss": -1.3092963695526123, "actor_target_entropy": -2.0, "actor_entropy": 1.3636908531188965, "alpha_loss": 0.008096772711724043, "alpha_value": 0.006497259930740022, "duration": 3.5796914100646973, "step": 35588}
{"episode_reward": -2.0978959982605176, "episode": 1106.0, "batch_reward": 0.053197240456938744, "critic_loss": 0.3453729450702667, "ae_transition_loss": 0.1740555725991726, "ae_encoder_loss": 0.6373927891254425, "actor_loss": -0.9967716336250305, "actor_target_entropy": -2.0, "actor_entropy": 1.1992199420928955, "alpha_loss": 0.008591377642005682, "alpha_value": 0.006488035385054642, "duration": 3.6438372135162354, "step": 35605}
{"episode_reward": -3.979979942636715, "episode": 1107.0, "batch_reward": 0.044554535299539566, "critic_loss": 0.6355728705724081, "ae_transition_loss": 0.3597139318784078, "ae_encoder_loss": 0.5512373646100363, "actor_loss": -1.2196066776911418, "actor_target_entropy": -2.0, "actor_entropy": 1.2259551286697388, "alpha_loss": 0.0076799664335946245, "alpha_value": 0.006476284690730741, "duration": 6.863616704940796, "step": 35639}
{"episode_reward": -1.9369528818899253, "episode": 1108.0, "duration": 0.2316899299621582, "step": 35640}
{"episode_reward": -0.8011936412642842, "episode": 1109.0, "batch_reward": 0.0752483606338501, "critic_loss": 0.3645801395177841, "ae_transition_loss": 0.5912694334983826, "ae_encoder_loss": 0.590326264500618, "actor_loss": -1.133041501045227, "actor_target_entropy": -2.0, "actor_entropy": 1.2999361753463745, "alpha_loss": 0.006597000639885664, "alpha_value": 0.0064645682604060365, "duration": 2.9466097354888916, "step": 35654}
{"episode_reward": -4.718007675184679, "episode": 1110.0, "batch_reward": 0.07303356255094211, "critic_loss": 0.5862265030543009, "ae_transition_loss": 0.43569280703862506, "ae_encoder_loss": 0.5498784780502319, "actor_loss": -1.1716322302818298, "actor_target_entropy": -2.0, "actor_entropy": 1.2669086058934529, "alpha_loss": 0.005840468841294448, "alpha_value": 0.006453183192100055, "duration": 5.977555274963379, "step": 35682}
{"episode_reward": -9.11942141659356, "episode": 1111.0, "batch_reward": 0.008922260254621506, "critic_loss": 0.297429621219635, "ae_transition_loss": 0.41961896419525146, "ae_encoder_loss": 0.5605461597442627, "actor_loss": -1.1337577104568481, "actor_target_entropy": -2.0, "actor_entropy": 1.345784068107605, "alpha_loss": 0.0024553609546273947, "alpha_value": 0.0064444653925643195, "duration": 28.103418827056885, "step": 35696}
{"episode_reward": -5.144404962178949, "episode": 1112.0, "duration": 0.22756719589233398, "step": 35697}
{"episode_reward": -0.6332072471022451, "episode": 1113.0, "batch_reward": 0.06953430362045765, "critic_loss": 0.2835081070661545, "ae_transition_loss": 0.3476053327322006, "ae_encoder_loss": 0.617417573928833, "actor_loss": -1.291457712650299, "actor_target_entropy": -2.0, "actor_entropy": 1.3584457039833069, "alpha_loss": 0.002957313321530819, "alpha_value": 0.006438583160413902, "duration": 3.7880725860595703, "step": 35716}
{"episode_reward": -8.071249995657515, "episode": 1114.0, "batch_reward": 0.06057588569819927, "critic_loss": 0.36500170826911926, "ae_transition_loss": 0.39885413646698, "ae_encoder_loss": 0.41047124564647675, "actor_loss": -1.1908591389656067, "actor_target_entropy": -2.0, "actor_entropy": 1.7543904781341553, "alpha_loss": -0.002038336475379765, "alpha_value": 0.0064315739773048546, "duration": 3.574580192565918, "step": 35732}
{"episode_reward": -10.517805378151944, "episode": 1115.0, "batch_reward": 0.0777834877371788, "critic_loss": 0.3866797536611557, "ae_transition_loss": 0.3446481227874756, "ae_encoder_loss": 0.5210140347480774, "actor_loss": -1.0846205353736877, "actor_target_entropy": -2.0, "actor_entropy": 1.493177354335785, "alpha_loss": -0.006076869089156389, "alpha_value": 0.006426410536665309, "duration": 4.558482646942139, "step": 35753}
{"episode_reward": -10.178140582016884, "episode": 1116.0, "batch_reward": 0.09774753451347351, "critic_loss": 0.39420539140701294, "ae_transition_loss": 0.5405711531639099, "ae_encoder_loss": 0.6371389627456665, "actor_loss": -1.0615513324737549, "actor_target_entropy": -2.0, "actor_entropy": 1.5954927206039429, "alpha_loss": 0.0008496057125739753, "alpha_value": 0.006423989643390124, "duration": 2.866191864013672, "step": 35766}
{"episode_reward": -8.50559183664663, "episode": 1117.0, "duration": 0.23987388610839844, "step": 35767}
{"episode_reward": -0.03568699039053064, "episode": 1118.0, "batch_reward": 0.04101175628602505, "critic_loss": 0.5840016305446625, "ae_transition_loss": 0.5840574949979782, "ae_encoder_loss": 0.48623938858509064, "actor_loss": -0.934391975402832, "actor_target_entropy": -2.0, "actor_entropy": 2.3206886053085327, "alpha_loss": -0.0006886183109600097, "alpha_value": 0.006422045850849013, "duration": 3.4477927684783936, "step": 35784}
{"episode_reward": -10.555398290234507, "episode": 1119.0, "duration": 0.21958589553833008, "step": 35785}
{"episode_reward": -0.432914187111892, "episode": 1120.0, "batch_reward": 0.06599444523453712, "critic_loss": 0.4198904484510422, "ae_transition_loss": 0.45517031848430634, "ae_encoder_loss": 0.48800690472126007, "actor_loss": -1.0548133254051208, "actor_target_entropy": -2.0, "actor_entropy": 1.5749911665916443, "alpha_loss": -0.0063094813376665115, "alpha_value": 0.006420164954321159, "duration": 3.626171350479126, "step": 35801}
{"episode_reward": -7.488076238963598, "episode": 1121.0, "batch_reward": 0.06551890075206757, "critic_loss": 0.3044050931930542, "ae_transition_loss": 0.30537107586860657, "ae_encoder_loss": 0.5144863128662109, "actor_loss": -0.9192991256713867, "actor_target_entropy": -2.0, "actor_entropy": 1.7477396726608276, "alpha_loss": -0.001558460877276957, "alpha_value": 0.006419795007638391, "duration": 34.37529468536377, "step": 35814}
{"episode_reward": -8.869302572868204, "episode": 1122.0, "batch_reward": 0.06749115884304047, "critic_loss": 0.5393941402435303, "ae_transition_loss": 0.4478991627693176, "ae_encoder_loss": 0.5723615884780884, "actor_loss": -1.2988609075546265, "actor_target_entropy": -2.0, "actor_entropy": 2.1771631240844727, "alpha_loss": -0.00058129639364779, "alpha_value": 0.006419802064334701, "duration": 2.156437635421753, "step": 35823}
{"episode_reward": -4.330209936457943, "episode": 1123.0, "duration": 0.2095797061920166, "step": 35824}
{"episode_reward": -0.4168427585084177, "episode": 1124.0, "batch_reward": 0.08902449905872345, "critic_loss": 0.4929620772600174, "ae_transition_loss": 0.4272584617137909, "ae_encoder_loss": 0.5986080169677734, "actor_loss": -1.0193561613559723, "actor_target_entropy": -2.0, "actor_entropy": 1.8397381901741028, "alpha_loss": 0.0037605338147841394, "alpha_value": 0.006419852771890902, "duration": 4.539675235748291, "step": 35846}
{"episode_reward": -6.060303762133575, "episode": 1125.0, "batch_reward": 0.053106321642796196, "critic_loss": 0.4726590911547343, "ae_transition_loss": 0.5834741493066152, "ae_encoder_loss": 0.6043554345766703, "actor_loss": -1.189462939898173, "actor_target_entropy": -2.0, "actor_entropy": 1.782020926475525, "alpha_loss": 0.007046134987225135, "alpha_value": 0.006418599437654041, "duration": 5.480885028839111, "step": 35872}
{"episode_reward": -6.708352848444084, "episode": 1126.0, "batch_reward": 0.050942654410998024, "critic_loss": 0.6119236424565315, "ae_transition_loss": 0.6665376226107279, "ae_encoder_loss": 0.4784420033295949, "actor_loss": -1.1608901421229045, "actor_target_entropy": -2.0, "actor_entropy": 1.3521647453308105, "alpha_loss": 0.006246664250890414, "alpha_value": 0.006410901548916548, "duration": 12.798705816268921, "step": 35935}
{"episode_reward": -16.07886356799439, "episode": 1127.0, "batch_reward": 0.06333410926163197, "critic_loss": 0.4469668120145798, "ae_transition_loss": 0.7505529671907425, "ae_encoder_loss": 0.554174967110157, "actor_loss": -1.108148217201233, "actor_target_entropy": -2.0, "actor_entropy": 1.6955133378505707, "alpha_loss": 0.006932687130756676, "alpha_value": 0.006398743095019234, "duration": 8.063483715057373, "step": 35973}
{"episode_reward": -6.896143305002999, "episode": 1128.0, "batch_reward": 0.052745502442121506, "critic_loss": 0.8232836127281189, "ae_transition_loss": 0.8013027012348175, "ae_encoder_loss": 0.7574320733547211, "actor_loss": -0.888599693775177, "actor_target_entropy": -2.0, "actor_entropy": 1.311119556427002, "alpha_loss": 0.009600715711712837, "alpha_value": 0.006389886715749241, "duration": 4.648375749588013, "step": 35995}
{"episode_reward": -3.386714323832734, "episode": 1129.0, "batch_reward": 0.023088307740787666, "critic_loss": 0.4570688207944234, "ae_transition_loss": 0.6871277689933777, "ae_encoder_loss": 0.686232308546702, "actor_loss": -1.0847137769063313, "actor_target_entropy": -2.0, "actor_entropy": 1.4790326356887817, "alpha_loss": 0.008571912224094072, "alpha_value": 0.00638076243490953, "duration": 5.895564079284668, "step": 36021}
{"episode_reward": -3.21277609610509, "episode": 1130.0, "batch_reward": 0.0034672976471483707, "critic_loss": 0.6191262304782867, "ae_transition_loss": 0.5597120523452759, "ae_encoder_loss": 0.7945780456066132, "actor_loss": -0.8283157348632812, "actor_target_entropy": -2.0, "actor_entropy": 1.2317762970924377, "alpha_loss": 0.008088545873761177, "alpha_value": 0.0063707729566068235, "duration": 4.897025108337402, "step": 36045}
{"episode_reward": -4.277253121274995, "episode": 1131.0, "duration": 42.89444422721863, "step": 36046}
{"episode_reward": -1.0393212078089817, "episode": 1132.0, "batch_reward": 0.051292429119348525, "critic_loss": 0.8749215364456177, "ae_transition_loss": 0.7159257292747497, "ae_encoder_loss": 0.6185321986675263, "actor_loss": -1.0152779340744018, "actor_target_entropy": -2.0, "actor_entropy": 1.737963318824768, "alpha_loss": 0.007868638355284929, "alpha_value": 0.006356078419625051, "duration": 9.526175498962402, "step": 36091}
{"episode_reward": -9.045677009552895, "episode": 1133.0, "duration": 0.21087861061096191, "step": 36092}
{"episode_reward": 0.0040332615482641665, "episode": 1134.0, "duration": 0.20079421997070312, "step": 36093}
{"episode_reward": -0.6303574849157663, "episode": 1135.0, "batch_reward": 0.07659104280173779, "critic_loss": 0.5441402643918991, "ae_transition_loss": 0.521579846739769, "ae_encoder_loss": 0.6837179660797119, "actor_loss": -1.0396654903888702, "actor_target_entropy": -2.0, "actor_entropy": 1.7723442316055298, "alpha_loss": 0.00859844358637929, "alpha_value": 0.0063408867388762, "duration": 4.677595376968384, "step": 36115}
{"episode_reward": -4.426188748071215, "episode": 1136.0, "batch_reward": 0.08804012089967728, "critic_loss": 0.7886548042297363, "ae_transition_loss": 0.40359389781951904, "ae_encoder_loss": 0.5523456931114197, "actor_loss": -1.0316545963287354, "actor_target_entropy": -2.0, "actor_entropy": 1.6755205392837524, "alpha_loss": 0.009871777147054672, "alpha_value": 0.00633406183922626, "duration": 2.591658592224121, "step": 36127}
{"episode_reward": -1.5560166969129723, "episode": 1137.0, "batch_reward": -0.0004884470254182816, "critic_loss": 0.519212543964386, "ae_transition_loss": 0.635226845741272, "ae_encoder_loss": 0.66705122590065, "actor_loss": -0.9447730779647827, "actor_target_entropy": -2.0, "actor_entropy": 1.9114635586738586, "alpha_loss": 0.009913939516991377, "alpha_value": 0.006326972321557767, "duration": 3.672405481338501, "step": 36145}
{"episode_reward": -3.8866149468565454, "episode": 1138.0, "batch_reward": 0.04624768408636252, "critic_loss": 0.518100380897522, "ae_transition_loss": 0.797203262646993, "ae_encoder_loss": 0.6600450078646342, "actor_loss": -1.1389336585998535, "actor_target_entropy": -2.0, "actor_entropy": 1.9132581949234009, "alpha_loss": 0.010044853202998638, "alpha_value": 0.006314491924035922, "duration": 5.594274044036865, "step": 36171}
{"episode_reward": -6.86660190366425, "episode": 1139.0, "batch_reward": 0.04041202925145626, "critic_loss": 0.4096747934818268, "ae_transition_loss": 0.6612590849399567, "ae_encoder_loss": 0.5806565284729004, "actor_loss": -1.077454686164856, "actor_target_entropy": -2.0, "actor_entropy": 1.311697781085968, "alpha_loss": 0.008770674001425505, "alpha_value": 0.006301455298608127, "duration": 4.519294261932373, "step": 36194}
{"episode_reward": -7.435509640050181, "episode": 1140.0, "batch_reward": 0.0707409679889679, "critic_loss": 0.3030392900109291, "ae_transition_loss": 0.5175247639417648, "ae_encoder_loss": 0.5116305202245712, "actor_loss": -1.1867520213127136, "actor_target_entropy": -2.0, "actor_entropy": 1.4173292517662048, "alpha_loss": 0.007024369202554226, "alpha_value": 0.006291033460920386, "duration": 4.6692163944244385, "step": 36216}
{"episode_reward": -8.376878537224318, "episode": 1141.0, "batch_reward": 0.08724369357029597, "critic_loss": 0.4538051684697469, "ae_transition_loss": 0.5571128328641256, "ae_encoder_loss": 0.3818354904651642, "actor_loss": -1.3241737683614094, "actor_target_entropy": -2.0, "actor_entropy": 1.8562512397766113, "alpha_loss": 0.00528203168263038, "alpha_value": 0.0062786317122257495, "duration": 55.47988748550415, "step": 36250}
{"episode_reward": -11.43037078308191, "episode": 1142.0, "batch_reward": 0.08115759491920471, "critic_loss": 0.34827451407909393, "ae_transition_loss": 0.398207426071167, "ae_encoder_loss": 0.35656797885894775, "actor_loss": -0.9616059064865112, "actor_target_entropy": -2.0, "actor_entropy": 1.2958816289901733, "alpha_loss": 0.004547786898910999, "alpha_value": 0.006267226706108532, "duration": 3.6956450939178467, "step": 36268}
{"episode_reward": -4.767101317423214, "episode": 1143.0, "duration": 0.23587822914123535, "step": 36269}
{"episode_reward": 0.10885347886362334, "episode": 1144.0, "batch_reward": 0.06705742329359055, "critic_loss": 0.6202834248542786, "ae_transition_loss": 1.0067430933316548, "ae_encoder_loss": 0.4627150297164917, "actor_loss": -1.1174084544181824, "actor_target_entropy": -2.0, "actor_entropy": 1.3703906933466594, "alpha_loss": -0.0003895391710102558, "alpha_value": 0.006257217201439243, "duration": 6.211805105209351, "step": 36300}
{"episode_reward": -12.513807467024533, "episode": 1145.0, "batch_reward": 0.09202894568443298, "critic_loss": 0.5266201496124268, "ae_transition_loss": 0.5759010314941406, "ae_encoder_loss": 0.8262637257575989, "actor_loss": -1.0932116508483887, "actor_target_entropy": -2.0, "actor_entropy": 1.7890045642852783, "alpha_loss": 0.00017890706658363342, "alpha_value": 0.006250702318043564, "duration": 0.5393004417419434, "step": 36301}
{"episode_reward": -0.33879593011725034, "episode": 1146.0, "batch_reward": 0.08954378217458725, "critic_loss": 0.614966094493866, "ae_transition_loss": 0.5053906440734863, "ae_encoder_loss": 0.5887590497732162, "actor_loss": -1.2764573097229004, "actor_target_entropy": -2.0, "actor_entropy": 1.8157123923301697, "alpha_loss": 0.0028010052628815174, "alpha_value": 0.006246741685680709, "duration": 5.376275062561035, "step": 36329}
{"episode_reward": -10.247119036889021, "episode": 1147.0, "batch_reward": 0.02101642390092214, "critic_loss": 0.5868203441301981, "ae_transition_loss": 0.5368487934271494, "ae_encoder_loss": 0.7526898185412089, "actor_loss": -0.8211337725321451, "actor_target_entropy": -2.0, "actor_entropy": 1.4105634291966755, "alpha_loss": 0.0061028993998964625, "alpha_value": 0.006240369909746778, "duration": 4.9738311767578125, "step": 36353}
{"episode_reward": -7.996466973567683, "episode": 1148.0, "batch_reward": 0.07208099340399106, "critic_loss": 0.32609889904658, "ae_transition_loss": 0.7318955063819885, "ae_encoder_loss": 1.0324461261431377, "actor_loss": -1.1376649936040242, "actor_target_entropy": -2.0, "actor_entropy": 2.114954153696696, "alpha_loss": 0.005796975611398618, "alpha_value": 0.006232113756426021, "duration": 6.392519950866699, "step": 36383}
{"episode_reward": -10.865411465886835, "episode": 1149.0, "batch_reward": 0.05362929590046406, "critic_loss": 0.43045923113822937, "ae_transition_loss": 0.639774739742279, "ae_encoder_loss": 1.0878888666629791, "actor_loss": -1.3487762212753296, "actor_target_entropy": -2.0, "actor_entropy": 1.3365707993507385, "alpha_loss": 0.0012596869783010334, "alpha_value": 0.006224833117898072, "duration": 4.953184366226196, "step": 36407}
{"episode_reward": -8.40573593769384, "episode": 1150.0, "batch_reward": -0.006226223427802324, "critic_loss": 0.7396855503320694, "ae_transition_loss": 0.782007098197937, "ae_encoder_loss": 1.2204389572143555, "actor_loss": -0.9179158806800842, "actor_target_entropy": -2.0, "actor_entropy": 0.9590566158294678, "alpha_loss": -0.00028049800312146544, "alpha_value": 0.006219694757614823, "duration": 3.208811044692993, "step": 36421}
{"episode_reward": -5.604477354141519, "episode": 1151.0, "batch_reward": 0.07877467758953571, "critic_loss": 0.6701792180538177, "ae_transition_loss": 0.7562283575534821, "ae_encoder_loss": 1.2024895250797272, "actor_loss": -1.0102584064006805, "actor_target_entropy": -2.0, "actor_entropy": 1.2568483352661133, "alpha_loss": 0.0015185308293439448, "alpha_value": 0.006215588074621262, "duration": 76.31873631477356, "step": 36448}
{"episode_reward": -14.670592712521291, "episode": 1152.0, "batch_reward": 0.04554786533117294, "critic_loss": 0.3828452229499817, "ae_transition_loss": 0.9196805953979492, "ae_encoder_loss": 1.033305287361145, "actor_loss": -1.1225779056549072, "actor_target_entropy": -2.0, "actor_entropy": 1.5531959533691406, "alpha_loss": 0.003261532634496689, "alpha_value": 0.0062128557825280786, "duration": 2.039947271347046, "step": 36457}
{"episode_reward": -2.376053909005086, "episode": 1153.0, "batch_reward": 0.05476563051342964, "critic_loss": 0.5056674182415009, "ae_transition_loss": 0.7159348726272583, "ae_encoder_loss": 0.9778577983379364, "actor_loss": -1.1586150527000427, "actor_target_entropy": -2.0, "actor_entropy": 1.7816500067710876, "alpha_loss": 0.0038801380433142185, "alpha_value": 0.0062101018751668955, "duration": 3.66239595413208, "step": 36474}
{"episode_reward": -6.997277288109058, "episode": 1154.0, "batch_reward": 0.01805190183222294, "critic_loss": 0.665589451789856, "ae_transition_loss": 0.7478401064872742, "ae_encoder_loss": 0.9382818937301636, "actor_loss": -0.7229026556015015, "actor_target_entropy": -2.0, "actor_entropy": 1.6291823387145996, "alpha_loss": 0.006756650749593973, "alpha_value": 0.0062072521815284155, "duration": 2.717973470687866, "step": 36486}
{"episode_reward": -5.353088587899474, "episode": 1155.0, "batch_reward": 0.09344856441020966, "critic_loss": 0.4141055941581726, "ae_transition_loss": 0.7818883061408997, "ae_encoder_loss": 0.7940071225166321, "actor_loss": -0.938715934753418, "actor_target_entropy": -2.0, "actor_entropy": 1.5264931917190552, "alpha_loss": 0.007311642169952393, "alpha_value": 0.006205113086560682, "duration": 2.443053722381592, "step": 36497}
{"episode_reward": -5.340269526744072, "episode": 1156.0, "duration": 0.23154067993164062, "step": 36498}
{"episode_reward": -0.7099203194569881, "episode": 1157.0, "batch_reward": 0.03902053614505208, "critic_loss": 0.6120110864822681, "ae_transition_loss": 0.6680105993380914, "ae_encoder_loss": 0.9960270982522231, "actor_loss": -1.019333683527433, "actor_target_entropy": -2.0, "actor_entropy": 1.4284034325526311, "alpha_loss": 0.006560678737094769, "alpha_value": 0.0061833551148659715, "duration": 25.964879274368286, "step": 36622}
{"episode_reward": -66.73635609418281, "episode": 1158.0, "batch_reward": 0.060487107187509534, "critic_loss": 0.7206164956092834, "ae_transition_loss": 1.041277825832367, "ae_encoder_loss": 0.7161967754364014, "actor_loss": -0.7228353500366211, "actor_target_entropy": -2.0, "actor_entropy": 1.4159619569778443, "alpha_loss": 0.008513264171779156, "alpha_value": 0.006152577412254364, "duration": 10.906067609786987, "step": 36672}
{"episode_reward": -21.924761447944416, "episode": 1159.0, "batch_reward": 0.02897222712635994, "critic_loss": 0.5643545587857565, "ae_transition_loss": 1.1130102078119914, "ae_encoder_loss": 0.5909031629562378, "actor_loss": -0.9178354938824972, "actor_target_entropy": -2.0, "actor_entropy": 1.70720636844635, "alpha_loss": 0.01101869655152162, "alpha_value": 0.006137064724194233, "duration": 6.334868669509888, "step": 36702}
{"episode_reward": -7.890876433176512, "episode": 1160.0, "duration": 0.21950125694274902, "step": 36703}
{"episode_reward": -0.2896847885104108, "episode": 1161.0, "batch_reward": 0.04941102862358093, "critic_loss": 0.4429604411125183, "ae_transition_loss": 1.0602788925170898, "ae_encoder_loss": 0.516811192035675, "actor_loss": -1.167746663093567, "actor_target_entropy": -2.0, "actor_entropy": 1.531438946723938, "alpha_loss": 0.010522367432713509, "alpha_value": 0.006127992953737927, "duration": 48.9379198551178, "step": 36716}
{"episode_reward": -1.099128331351284, "episode": 1162.0, "batch_reward": 0.044622459138433136, "critic_loss": 0.4278465112050374, "ae_transition_loss": 1.0190381705760956, "ae_encoder_loss": 0.5987758586804072, "actor_loss": -0.9241192638874054, "actor_target_entropy": -2.0, "actor_entropy": 1.3209789395332336, "alpha_loss": 0.006328181053201358, "alpha_value": 0.006111019733305881, "duration": 12.631571054458618, "step": 36775}
{"episode_reward": -21.115753633411344, "episode": 1163.0, "batch_reward": 0.03884107060730457, "critic_loss": 0.6668428182601929, "ae_transition_loss": 0.794592946767807, "ae_encoder_loss": 0.5026227384805679, "actor_loss": -0.9825701117515564, "actor_target_entropy": -2.0, "actor_entropy": 1.4409322142601013, "alpha_loss": 0.0024057748960331082, "alpha_value": 0.006093177037791159, "duration": 5.271851062774658, "step": 36800}
{"episode_reward": -7.837680987649256, "episode": 1164.0, "batch_reward": -0.09134042263031006, "critic_loss": 0.8463252782821655, "ae_transition_loss": 0.9792336821556091, "ae_encoder_loss": 0.8167541027069092, "actor_loss": -0.8996528387069702, "actor_target_entropy": -2.0, "actor_entropy": 1.5870156288146973, "alpha_loss": 0.0018542982870712876, "alpha_value": 0.0060875977573245955, "duration": 0.621514081954956, "step": 36801}
{"episode_reward": -0.7866436982764567, "episode": 1165.0, "batch_reward": 0.04173382557928562, "critic_loss": 0.2969030290842056, "ae_transition_loss": 0.7428461909294128, "ae_encoder_loss": 0.5569133559862772, "actor_loss": -0.8712163766225179, "actor_target_entropy": -2.0, "actor_entropy": 1.6880757411321003, "alpha_loss": 0.004809964448213577, "alpha_value": 0.006080882221011549, "duration": 6.617197513580322, "step": 36832}
{"episode_reward": -5.3165289700364875, "episode": 1166.0, "batch_reward": -0.0024177031591534615, "critic_loss": 0.39975618322690326, "ae_transition_loss": 0.9590590596199036, "ae_encoder_loss": 0.5669987003008524, "actor_loss": -0.7844604055086771, "actor_target_entropy": -2.0, "actor_entropy": 1.8612210750579834, "alpha_loss": 0.006608817415932815, "alpha_value": 0.006071071004682065, "duration": 6.7450034618377686, "step": 36865}
{"episode_reward": -10.024384513748368, "episode": 1167.0, "duration": 0.2549893856048584, "step": 36866}
{"episode_reward": -0.7278293955741603, "episode": 1168.0, "batch_reward": -0.009781425818800926, "critic_loss": 0.33561960856119794, "ae_transition_loss": 0.8988548119862875, "ae_encoder_loss": 0.5555810530980428, "actor_loss": -0.7670647899309794, "actor_target_entropy": -2.0, "actor_entropy": 1.9965997139612834, "alpha_loss": 0.007722638547420502, "alpha_value": 0.0060607945060890565, "duration": 5.792878150939941, "step": 36893}
{"episode_reward": -6.987922409523899, "episode": 1169.0, "batch_reward": 0.012710921466350555, "critic_loss": 0.47612062096595764, "ae_transition_loss": 0.8710842430591583, "ae_encoder_loss": 0.5909150838851929, "actor_loss": -0.7093347609043121, "actor_target_entropy": -2.0, "actor_entropy": 2.0297285318374634, "alpha_loss": 0.006521683651953936, "alpha_value": 0.0060516098066007405, "duration": 4.515366077423096, "step": 36913}
{"episode_reward": -4.428692121920863, "episode": 1170.0, "batch_reward": 0.08560757959882419, "critic_loss": 0.35870060324668884, "ae_transition_loss": 1.0194706519444783, "ae_encoder_loss": 0.5098423858483633, "actor_loss": -1.2042624950408936, "actor_target_entropy": -2.0, "actor_entropy": 1.957716464996338, "alpha_loss": 0.0066624560082952184, "alpha_value": 0.006042200979390604, "duration": 7.517221450805664, "step": 36949}
{"episode_reward": -13.576120264541952, "episode": 1171.0, "batch_reward": 0.05437281789879004, "critic_loss": 0.4518827299276988, "ae_transition_loss": 0.9140379428863525, "ae_encoder_loss": 0.5001976390679678, "actor_loss": -1.0250838994979858, "actor_target_entropy": -2.0, "actor_entropy": 1.5081870555877686, "alpha_loss": 0.007111317788561185, "alpha_value": 0.0060307760093346666, "duration": 40.61881160736084, "step": 36978}
{"episode_reward": -4.8140508510653035, "episode": 1172.0, "batch_reward": 0.14243635535240173, "critic_loss": 0.2160046398639679, "ae_transition_loss": 0.817836582660675, "ae_encoder_loss": 0.4690163731575012, "actor_loss": -1.3223931789398193, "actor_target_entropy": -2.0, "actor_entropy": 1.2617883682250977, "alpha_loss": 0.0019359284779056907, "alpha_value": 0.006023014551092434, "duration": 1.9431390762329102, "step": 36986}
{"episode_reward": -2.291310555904113, "episode": 1173.0, "batch_reward": 0.07726559415459633, "critic_loss": 0.6082142442464828, "ae_transition_loss": 0.8707896173000336, "ae_encoder_loss": 0.5827205777168274, "actor_loss": -1.0200498402118683, "actor_target_entropy": -2.0, "actor_entropy": 1.1452220678329468, "alpha_loss": 0.004011824261397123, "alpha_value": 0.006017703252339267, "duration": 4.720146179199219, "step": 37008}
{"episode_reward": -4.809076592825522, "episode": 1174.0, "duration": 0.24398350715637207, "step": 37009}
{"episode_reward": -0.2896770774800336, "episode": 1175.0, "batch_reward": 0.026788931339979172, "critic_loss": 0.2787119150161743, "ae_transition_loss": 0.8301704823970795, "ae_encoder_loss": 0.5589963346719742, "actor_loss": -0.9589393138885498, "actor_target_entropy": -2.0, "actor_entropy": 1.2896706461906433, "alpha_loss": 0.004616337362676859, "alpha_value": 0.00601098741439453, "duration": 4.079290866851807, "step": 37029}
{"episode_reward": -3.896942958357868, "episode": 1176.0, "batch_reward": 0.005569783349831899, "critic_loss": 0.5143294334411621, "ae_transition_loss": 0.8584069808324178, "ae_encoder_loss": 0.7056904236475626, "actor_loss": -0.9748430252075195, "actor_target_entropy": -2.0, "actor_entropy": 1.4291361967722576, "alpha_loss": 0.003665441880002618, "alpha_value": 0.006003020482928615, "duration": 5.0623486042022705, "step": 37051}
{"episode_reward": -9.095644278620966, "episode": 1177.0, "batch_reward": 0.0657489150762558, "critic_loss": 0.6502134799957275, "ae_transition_loss": 0.9850230813026428, "ae_encoder_loss": 0.5629044771194458, "actor_loss": -0.793752650419871, "actor_target_entropy": -2.0, "actor_entropy": 1.5149342616399128, "alpha_loss": 0.004623318401475747, "alpha_value": 0.005994141882466775, "duration": 6.3182923793792725, "step": 37081}
{"episode_reward": -10.702209775219918, "episode": 1178.0, "duration": 0.2183387279510498, "step": 37082}
{"episode_reward": -0.061520417182300835, "episode": 1179.0, "batch_reward": 0.045256299898028374, "critic_loss": 0.44905543327331543, "ae_transition_loss": 0.8907942473888397, "ae_encoder_loss": 0.5148060023784637, "actor_loss": -0.9284453690052032, "actor_target_entropy": -2.0, "actor_entropy": 1.509874939918518, "alpha_loss": 0.00915780640207231, "alpha_value": 0.005986852337261093, "duration": 5.116201162338257, "step": 37107}
{"episode_reward": -3.0104440207162573, "episode": 1180.0, "batch_reward": 0.03437656722962856, "critic_loss": 0.420162558555603, "ae_transition_loss": 0.8823628127574921, "ae_encoder_loss": 0.49784883856773376, "actor_loss": -0.9769479930400848, "actor_target_entropy": -2.0, "actor_entropy": 1.330379843711853, "alpha_loss": 0.008868567645549774, "alpha_value": 0.005980193802666401, "duration": 4.535951614379883, "step": 37129}
{"episode_reward": -5.598707794857968, "episode": 1181.0, "duration": 31.51181173324585, "step": 37130}
{"episode_reward": -0.32697353488579933, "episode": 1182.0, "batch_reward": 0.04736134658257166, "critic_loss": 0.37506617108980816, "ae_transition_loss": 0.7573451399803162, "ae_encoder_loss": 0.4630826413631439, "actor_loss": -0.8883453210194906, "actor_target_entropy": -2.0, "actor_entropy": 1.183894435564677, "alpha_loss": 0.008332721889019012, "alpha_value": 0.005970823851528732, "duration": 5.783728361129761, "step": 37158}
{"episode_reward": -4.093886770496761, "episode": 1183.0, "batch_reward": 0.049651894718408585, "critic_loss": 0.4879438479741414, "ae_transition_loss": 0.8239131569862366, "ae_encoder_loss": 0.4503990908463796, "actor_loss": -1.0505529344081879, "actor_target_entropy": -2.0, "actor_entropy": 1.624964952468872, "alpha_loss": 0.011177601913611094, "alpha_value": 0.005951698333494967, "duration": 12.197238445281982, "step": 37216}
{"episode_reward": -18.575312739112025, "episode": 1184.0, "batch_reward": -0.016857028007507324, "critic_loss": 0.24792714416980743, "ae_transition_loss": 0.5316466689109802, "ae_encoder_loss": 0.49003496766090393, "actor_loss": -0.687041163444519, "actor_target_entropy": -2.0, "actor_entropy": 2.2369637489318848, "alpha_loss": 0.011559141799807549, "alpha_value": 0.005934660468011504, "duration": 1.7687065601348877, "step": 37223}
{"episode_reward": -3.0618938705803775, "episode": 1185.0, "batch_reward": 0.02067868411540985, "critic_loss": 0.4894150495529175, "ae_transition_loss": 0.538242518901825, "ae_encoder_loss": 0.3443012237548828, "actor_loss": -1.0149129629135132, "actor_target_entropy": -2.0, "actor_entropy": 2.307361364364624, "alpha_loss": 0.009887970983982086, "alpha_value": 0.0059293297093436625, "duration": 3.481431722640991, "step": 37240}
{"episode_reward": -5.111706699606707, "episode": 1186.0, "batch_reward": 0.048272766172885895, "critic_loss": 0.27264852325121564, "ae_transition_loss": 0.6223311424255371, "ae_encoder_loss": 0.434918741385142, "actor_loss": -0.9795945088068644, "actor_target_entropy": -2.0, "actor_entropy": 2.0717606941858926, "alpha_loss": 0.010051693767309189, "alpha_value": 0.005918530784118817, "duration": 4.768206357955933, "step": 37262}
{"episode_reward": -6.546186158857066, "episode": 1187.0, "batch_reward": 0.0499150063842535, "critic_loss": 0.2782164216041565, "ae_transition_loss": 0.9493733048439026, "ae_encoder_loss": 0.48500746488571167, "actor_loss": -1.026129961013794, "actor_target_entropy": -2.0, "actor_entropy": 1.4818965196609497, "alpha_loss": 0.009381145238876343, "alpha_value": 0.005904882620048886, "duration": 4.123157739639282, "step": 37281}
{"episode_reward": -4.91311784422529, "episode": 1188.0, "batch_reward": 0.033488843900461994, "critic_loss": 0.39870671431223553, "ae_transition_loss": 0.5452182789643606, "ae_encoder_loss": 0.4168350100517273, "actor_loss": -0.9921072522799174, "actor_target_entropy": -2.0, "actor_entropy": 1.0669538577397664, "alpha_loss": 0.007103632049014171, "alpha_value": 0.0058913629509844126, "duration": 6.381725549697876, "step": 37312}
{"episode_reward": -4.298724654215117, "episode": 1189.0, "batch_reward": 0.06063476093113422, "critic_loss": 0.7056098282337189, "ae_transition_loss": 0.6629072546958923, "ae_encoder_loss": 0.5675524234771728, "actor_loss": -1.0737192153930664, "actor_target_entropy": -2.0, "actor_entropy": 0.9618216633796692, "alpha_loss": 0.005380372051149607, "alpha_value": 0.005871429994027429, "duration": 11.326183557510376, "step": 37367}
{"episode_reward": -1.2079607743283807, "episode": 1190.0, "batch_reward": 0.0648971622188886, "critic_loss": 0.6070057054360708, "ae_transition_loss": 0.9645500977834066, "ae_encoder_loss": 0.571900486946106, "actor_loss": -0.9728067715962728, "actor_target_entropy": -2.0, "actor_entropy": 1.874696175257365, "alpha_loss": 0.005739815688381593, "alpha_value": 0.005853965917617019, "duration": 5.601037502288818, "step": 37394}
{"episode_reward": -3.9429638668377627, "episode": 1191.0, "batch_reward": 0.07861258089542389, "critic_loss": 0.3962882161140442, "ae_transition_loss": 0.8485037982463837, "ae_encoder_loss": 0.5922303199768066, "actor_loss": -1.2488398551940918, "actor_target_entropy": -2.0, "actor_entropy": 1.706127643585205, "alpha_loss": 0.0066789123229682446, "alpha_value": 0.005843997415538319, "duration": 39.49663686752319, "step": 37413}
{"episode_reward": -2.6537117273765425, "episode": 1192.0, "batch_reward": 0.03596713331838449, "critic_loss": 0.3727618058522542, "ae_transition_loss": 0.9759169618288676, "ae_encoder_loss": 0.5356671015421549, "actor_loss": -0.8489237229029337, "actor_target_entropy": -2.0, "actor_entropy": 1.4226159652074177, "alpha_loss": 0.006394418266912301, "alpha_value": 0.005834251787978539, "duration": 6.633478879928589, "step": 37446}
{"episode_reward": -5.450198659094924, "episode": 1193.0, "batch_reward": 0.04950568048904339, "critic_loss": 0.6223564545313517, "ae_transition_loss": 0.9068456888198853, "ae_encoder_loss": 0.7112470666567484, "actor_loss": -1.0916944742202759, "actor_target_entropy": -2.0, "actor_entropy": 1.4905245304107666, "alpha_loss": 0.006343478492150704, "alpha_value": 0.005822655711805645, "duration": 5.437463998794556, "step": 37472}
{"episode_reward": -5.335324199571668, "episode": 1194.0, "batch_reward": 0.051239004358649254, "critic_loss": 0.4863940179347992, "ae_transition_loss": 0.8391874730587006, "ae_encoder_loss": 0.6524073481559753, "actor_loss": -1.0172368884086609, "actor_target_entropy": -2.0, "actor_entropy": 1.58623468875885, "alpha_loss": 0.006863229908049107, "alpha_value": 0.005813027720085205, "duration": 5.090376377105713, "step": 37496}
{"episode_reward": -3.712279249181015, "episode": 1195.0, "batch_reward": 0.014206042140722274, "critic_loss": 0.4200703799724579, "ae_transition_loss": 0.9249395847320556, "ae_encoder_loss": 0.6644455909729003, "actor_loss": -0.8857176303863525, "actor_target_entropy": -2.0, "actor_entropy": 1.4945680141448974, "alpha_loss": 0.009313822723925114, "alpha_value": 0.005799108695472536, "duration": 10.183716773986816, "step": 37547}
{"episode_reward": -12.40708391567792, "episode": 1196.0, "batch_reward": 0.04355630620072285, "critic_loss": 0.43534907698631287, "ae_transition_loss": 0.8210142056147257, "ae_encoder_loss": 0.6578847368558248, "actor_loss": -0.8305724461873373, "actor_target_entropy": -2.0, "actor_entropy": 1.3503785928090413, "alpha_loss": 0.009195718914270401, "alpha_value": 0.005781650579673447, "duration": 6.207586765289307, "step": 37577}
{"episode_reward": -13.508690386372622, "episode": 1197.0, "batch_reward": -0.004344106962283452, "critic_loss": 0.4749000420173009, "ae_transition_loss": 0.9326172669728597, "ae_encoder_loss": 0.5869726737340292, "actor_loss": -0.7042291363080343, "actor_target_entropy": -2.0, "actor_entropy": 0.9956331849098206, "alpha_loss": 0.0072560956080754595, "alpha_value": 0.005767959962493398, "duration": 5.216840505599976, "step": 37601}
{"episode_reward": -2.1770107676000223, "episode": 1198.0, "batch_reward": 0.009623903315514326, "critic_loss": 0.44639773666858673, "ae_transition_loss": 1.1216419339179993, "ae_encoder_loss": 0.6717117130756378, "actor_loss": -0.8956538736820221, "actor_target_entropy": -2.0, "actor_entropy": 0.8299403786659241, "alpha_loss": 0.00720506114885211, "alpha_value": 0.005756764877715046, "duration": 5.442848205566406, "step": 37629}
{"episode_reward": -3.5022259181892235, "episode": 1199.0, "batch_reward": 0.045221962966024876, "critic_loss": 0.3381113260984421, "ae_transition_loss": 0.8284395039081573, "ae_encoder_loss": 0.535601019859314, "actor_loss": -1.1111945509910583, "actor_target_entropy": -2.0, "actor_entropy": 0.7563864886760712, "alpha_loss": 0.006978760007768869, "alpha_value": 0.005747990062810335, "duration": 3.443779468536377, "step": 37645}
{"episode_reward": -2.4000193167685517, "episode": 1200.0, "batch_reward": -0.014841318596154451, "critic_loss": 1.035908430814743, "ae_transition_loss": 0.928554356098175, "ae_encoder_loss": 0.5227058529853821, "actor_loss": -0.9805331826210022, "actor_target_entropy": -2.0, "actor_entropy": 0.826168030500412, "alpha_loss": 0.00696801021695137, "alpha_value": 0.005739360039685368, "duration": 4.66779088973999, "step": 37667}
{"episode_reward": -2.0752992561212094, "episode": 1201.0, "batch_reward": 0.11042724549770355, "critic_loss": 0.4142543077468872, "ae_transition_loss": 0.6928594708442688, "ae_encoder_loss": 0.7351875305175781, "actor_loss": -1.3157631158828735, "actor_target_entropy": -2.0, "actor_entropy": 0.7739381790161133, "alpha_loss": 0.004547039978206158, "alpha_value": 0.00573297044503427, "duration": 58.77985167503357, "step": 37676}
{"episode_reward": -1.7259777928078033, "episode": 1202.0, "batch_reward": 0.03821033965796232, "critic_loss": 0.5747345447540283, "ae_transition_loss": 0.7591651678085327, "ae_encoder_loss": 0.5894231200218201, "actor_loss": -0.9208983659744263, "actor_target_entropy": -2.0, "actor_entropy": 0.7472232460975647, "alpha_loss": 0.007186697144061327, "alpha_value": 0.00572076170881333, "duration": 10.340078592300415, "step": 37726}
{"episode_reward": 8.951616926054403, "episode": 1203.0, "batch_reward": 0.004286520183086395, "critic_loss": 0.863945871591568, "ae_transition_loss": 1.4786408146222432, "ae_encoder_loss": 0.5707579851150513, "actor_loss": -0.9888322154680887, "actor_target_entropy": -2.0, "actor_entropy": 0.7551619211832682, "alpha_loss": 0.0046745532502730685, "alpha_value": 0.0057045499882220135, "duration": 5.967624187469482, "step": 37755}
{"episode_reward": -6.402530074088697, "episode": 1204.0, "batch_reward": 0.029744518920779228, "critic_loss": 0.32016050815582275, "ae_transition_loss": 0.9075278043746948, "ae_encoder_loss": 0.5032190680503845, "actor_loss": -0.7725094556808472, "actor_target_entropy": -2.0, "actor_entropy": 1.8558104038238525, "alpha_loss": 0.006729488726705313, "alpha_value": 0.00569703189243842, "duration": 2.4276578426361084, "step": 37767}
{"episode_reward": -2.4587447280450863, "episode": 1205.0, "batch_reward": 0.05958384461700916, "critic_loss": 0.4706566035747528, "ae_transition_loss": 0.7858771979808807, "ae_encoder_loss": 0.4543585628271103, "actor_loss": -0.8062031865119934, "actor_target_entropy": -2.0, "actor_entropy": 1.6546446681022644, "alpha_loss": 0.00644260086119175, "alpha_value": 0.005691566784087264, "duration": 3.569850444793701, "step": 37783}
{"episode_reward": -2.7889125700584025, "episode": 1206.0, "batch_reward": 0.026472884230315685, "critic_loss": 0.4317088723182678, "ae_transition_loss": 0.945001870393753, "ae_encoder_loss": 0.49788592755794525, "actor_loss": -0.9453306794166565, "actor_target_entropy": -2.0, "actor_entropy": 0.8848392367362976, "alpha_loss": 0.006486863596364856, "alpha_value": 0.005684252186472747, "duration": 4.753850698471069, "step": 37806}
{"episode_reward": -1.2433856543486903, "episode": 1207.0, "batch_reward": 0.03231034800410271, "critic_loss": 0.757927656173706, "ae_transition_loss": 0.7930928468704224, "ae_encoder_loss": 0.5660189986228943, "actor_loss": -0.9694638252258301, "actor_target_entropy": -2.0, "actor_entropy": 0.4477292001247406, "alpha_loss": 0.004260042682290077, "alpha_value": 0.005678725951093792, "duration": 1.9837384223937988, "step": 37815}
{"episode_reward": -2.663874119281045, "episode": 1208.0, "batch_reward": -0.012431089766323566, "critic_loss": 0.2858571708202362, "ae_transition_loss": 0.9741461873054504, "ae_encoder_loss": 0.535141795873642, "actor_loss": -0.8005456328392029, "actor_target_entropy": -2.0, "actor_entropy": 0.5881280899047852, "alpha_loss": 0.006479289149865508, "alpha_value": 0.0056734737303774305, "duration": 4.751787424087524, "step": 37838}
{"episode_reward": -2.801002483682008, "episode": 1209.0, "batch_reward": 0.0688273599371314, "critic_loss": 0.3676624968647957, "ae_transition_loss": 0.9148930162191391, "ae_encoder_loss": 0.5948225855827332, "actor_loss": -1.036916360259056, "actor_target_entropy": -2.0, "actor_entropy": 1.5288203656673431, "alpha_loss": 0.0050344314076937735, "alpha_value": 0.0056631112411943164, "duration": 8.459788084030151, "step": 37878}
{"episode_reward": -8.758166738985976, "episode": 1210.0, "batch_reward": 0.05032704025506973, "critic_loss": 0.35195744037628174, "ae_transition_loss": 0.8287596106529236, "ae_encoder_loss": 0.8387623429298401, "actor_loss": -0.956821620464325, "actor_target_entropy": -2.0, "actor_entropy": 1.7612900733947754, "alpha_loss": 0.0036743890959769487, "alpha_value": 0.00565480225163109, "duration": 1.3168010711669922, "step": 37883}
{"episode_reward": -0.9833988410629265, "episode": 1211.0, "batch_reward": 0.08191028982400894, "critic_loss": 0.34693543612957, "ae_transition_loss": 0.8158877193927765, "ae_encoder_loss": 0.7322224974632263, "actor_loss": -1.2484885454177856, "actor_target_entropy": -2.0, "actor_entropy": 1.2884880304336548, "alpha_loss": 0.0033571930835023522, "alpha_value": 0.005650054388874014, "duration": 51.54301333427429, "step": 37905}
{"episode_reward": -3.3069965673046617, "episode": 1212.0, "batch_reward": 0.021220979280769825, "critic_loss": 0.35460661351680756, "ae_transition_loss": 1.091266930103302, "ae_encoder_loss": 0.9887686371803284, "actor_loss": -1.0120421051979065, "actor_target_entropy": -2.0, "actor_entropy": 0.9140485525131226, "alpha_loss": 0.005011209286749363, "alpha_value": 0.005644077781830574, "duration": 4.532536506652832, "step": 37926}
{"episode_reward": -2.7978807731016824, "episode": 1213.0, "batch_reward": -0.0056498972699046135, "critic_loss": 0.38303595781326294, "ae_transition_loss": 1.5283572375774384, "ae_encoder_loss": 0.7643901705741882, "actor_loss": -0.8648049235343933, "actor_target_entropy": -2.0, "actor_entropy": 0.9380282759666443, "alpha_loss": 0.006274965591728687, "alpha_value": 0.0056381621109644585, "duration": 4.554858684539795, "step": 37948}
{"episode_reward": -6.11201511517442, "episode": 1214.0, "batch_reward": 0.04306832961738109, "critic_loss": 0.45245036482810974, "ae_transition_loss": 1.0190922141075134, "ae_encoder_loss": 0.530468636751175, "actor_loss": -0.9546267032623291, "actor_target_entropy": -2.0, "actor_entropy": 1.2050790309906005, "alpha_loss": 0.005571640934795142, "alpha_value": 0.00562745544943054, "duration": 9.85109567642212, "step": 37993}
{"episode_reward": -14.629423243111964, "episode": 1215.0, "batch_reward": 0.050967506443460785, "critic_loss": 0.601410706837972, "ae_transition_loss": 0.9982336362202963, "ae_encoder_loss": 0.7377658486366272, "actor_loss": -1.2153857151667278, "actor_target_entropy": -2.0, "actor_entropy": 1.8649903933207195, "alpha_loss": 0.00504028572080036, "alpha_value": 0.005615123533118239, "duration": 6.708458662033081, "step": 38026}
{"episode_reward": -12.674037003509136, "episode": 1216.0, "batch_reward": -0.005140737164765596, "critic_loss": 0.28134268522262573, "ae_transition_loss": 1.0893185436725616, "ae_encoder_loss": 0.7716323733329773, "actor_loss": -0.7598208487033844, "actor_target_entropy": -2.0, "actor_entropy": 1.9555859565734863, "alpha_loss": 0.007601176854223013, "alpha_value": 0.005607438963508678, "duration": 4.823151588439941, "step": 38048}
{"episode_reward": -6.471339136310414, "episode": 1217.0, "batch_reward": 0.04152725590392947, "critic_loss": 0.34633904695510864, "ae_transition_loss": 0.9229617863893509, "ae_encoder_loss": 0.9687715172767639, "actor_loss": -1.0555808544158936, "actor_target_entropy": -2.0, "actor_entropy": 1.4483915865421295, "alpha_loss": 0.004023023939225823, "alpha_value": 0.005598002924324708, "duration": 8.048725366592407, "step": 38087}
{"episode_reward": -24.805398270017044, "episode": 1218.0, "batch_reward": 0.04521544463932514, "critic_loss": 0.29607532421747845, "ae_transition_loss": 0.9340413212776184, "ae_encoder_loss": 0.9568264285723368, "actor_loss": -0.7850294907887777, "actor_target_entropy": -2.0, "actor_entropy": 1.1839356025060017, "alpha_loss": 0.004672317688042919, "alpha_value": 0.005587756331760865, "duration": 5.6745216846466064, "step": 38114}
{"episode_reward": -9.287088515103054, "episode": 1219.0, "duration": 0.20490121841430664, "step": 38115}
{"episode_reward": -0.8181114792823792, "episode": 1220.0, "batch_reward": 0.03012458731730779, "critic_loss": 0.4524310827255249, "ae_transition_loss": 0.8979508678118387, "ae_encoder_loss": 0.7765003045399984, "actor_loss": -0.9664742946624756, "actor_target_entropy": -2.0, "actor_entropy": 1.4364327192306519, "alpha_loss": 0.005799128363529841, "alpha_value": 0.0055793106106017095, "duration": 6.555522203445435, "step": 38146}
{"episode_reward": -12.474385686168308, "episode": 1221.0, "batch_reward": 0.03394152596592903, "critic_loss": 0.31287981569767, "ae_transition_loss": 1.055752158164978, "ae_encoder_loss": 0.6711374521255493, "actor_loss": -1.1877117156982422, "actor_target_entropy": -2.0, "actor_entropy": 1.3945947885513306, "alpha_loss": 0.005886147264391184, "alpha_value": 0.005571993155044438, "duration": 42.48815107345581, "step": 38166}
{"episode_reward": -5.3225715501787985, "episode": 1222.0, "batch_reward": 0.025378331542015076, "critic_loss": 0.32809486985206604, "ae_transition_loss": 0.7950602769851685, "ae_encoder_loss": 0.6989631950855255, "actor_loss": -1.1399509906768799, "actor_target_entropy": -2.0, "actor_entropy": 1.5577847957611084, "alpha_loss": 0.005300005432218313, "alpha_value": 0.005565990033342014, "duration": 4.315556764602661, "step": 38187}
{"episode_reward": -6.8555748797558165, "episode": 1223.0, "batch_reward": 0.01300865551456809, "critic_loss": 0.27150778472423553, "ae_transition_loss": 0.6872864961624146, "ae_encoder_loss": 0.534895658493042, "actor_loss": -0.8087367713451385, "actor_target_entropy": -2.0, "actor_entropy": 1.5700965523719788, "alpha_loss": 0.007275963202118874, "alpha_value": 0.005559946422697574, "duration": 3.468716859817505, "step": 38204}
{"episode_reward": -6.378982753191927, "episode": 1224.0, "batch_reward": 0.036800442263484, "critic_loss": 0.5657738149166107, "ae_transition_loss": 0.9338334798812866, "ae_encoder_loss": 0.7221249341964722, "actor_loss": -1.1926114559173584, "actor_target_entropy": -2.0, "actor_entropy": 1.6180083751678467, "alpha_loss": 0.006064083427190781, "alpha_value": 0.0055536249956629575, "duration": 4.387141466140747, "step": 38225}
{"episode_reward": -4.004460447250443, "episode": 1225.0, "batch_reward": 0.11452902480959892, "critic_loss": 0.3150070905685425, "ae_transition_loss": 0.6797260940074921, "ae_encoder_loss": 0.7870533168315887, "actor_loss": -1.0464078187942505, "actor_target_entropy": -2.0, "actor_entropy": 1.6082772016525269, "alpha_loss": 0.006851449841633439, "alpha_value": 0.005547172274585621, "duration": 5.019487380981445, "step": 38250}
{"episode_reward": -10.00189192026561, "episode": 1226.0, "batch_reward": 0.021557366475462914, "critic_loss": 0.35099315643310547, "ae_transition_loss": 0.6715036034584045, "ae_encoder_loss": 0.6197061538696289, "actor_loss": -0.9457654654979706, "actor_target_entropy": -2.0, "actor_entropy": 1.592834234237671, "alpha_loss": 0.008711950853466988, "alpha_value": 0.005540396387886682, "duration": 4.155860662460327, "step": 38270}
{"episode_reward": -3.918334067180686, "episode": 1227.0, "batch_reward": 0.03553643388052782, "critic_loss": 0.4580364525318146, "ae_transition_loss": 0.7356689174969991, "ae_encoder_loss": 0.5559722582499186, "actor_loss": -0.9393341143925985, "actor_target_entropy": -2.0, "actor_entropy": 1.4045430421829224, "alpha_loss": 0.008468208213647207, "alpha_value": 0.005531213521460912, "duration": 4.893076419830322, "step": 38294}
{"episode_reward": -4.738314960605825, "episode": 1228.0, "batch_reward": 0.0768044317762057, "critic_loss": 0.4003581404685974, "ae_transition_loss": 1.0630056659380596, "ae_encoder_loss": 0.5146408379077911, "actor_loss": -1.1249312957127888, "actor_target_entropy": -2.0, "actor_entropy": 1.3187053203582764, "alpha_loss": 0.007323828215400378, "alpha_value": 0.005519582466545121, "duration": 6.038549423217773, "step": 38324}
{"episode_reward": -4.148009884272625, "episode": 1229.0, "batch_reward": 0.012279404560104012, "critic_loss": 0.6365440785884857, "ae_transition_loss": 1.224794328212738, "ae_encoder_loss": 0.503138467669487, "actor_loss": -1.1121526062488556, "actor_target_entropy": -2.0, "actor_entropy": 1.4398999512195587, "alpha_loss": 0.006071795942261815, "alpha_value": 0.005505869531609095, "duration": 8.06067419052124, "step": 38363}
{"episode_reward": -9.804896480679728, "episode": 1230.0, "duration": 0.19654369354248047, "step": 38364}
{"episode_reward": -0.3908616602420807, "episode": 1231.0, "batch_reward": -0.0017774440348148346, "critic_loss": 0.8281229734420776, "ae_transition_loss": 0.8690106272697449, "ae_encoder_loss": 0.4372560679912567, "actor_loss": -0.7660056948661804, "actor_target_entropy": -2.0, "actor_entropy": 1.337620735168457, "alpha_loss": 0.00819559209048748, "alpha_value": 0.005496304741967853, "duration": 27.63335394859314, "step": 38372}
{"episode_reward": -2.64422528173555, "episode": 1232.0, "batch_reward": 0.01455975603312254, "critic_loss": 0.5298334956169128, "ae_transition_loss": 1.2816928625106812, "ae_encoder_loss": 0.4830128103494644, "actor_loss": -0.7904379367828369, "actor_target_entropy": -2.0, "actor_entropy": 1.231285810470581, "alpha_loss": 0.007219668012112379, "alpha_value": 0.005490571082161489, "duration": 5.160562992095947, "step": 38398}
{"episode_reward": -6.993485980717201, "episode": 1233.0, "batch_reward": 0.013566357083618641, "critic_loss": 0.34690725058317184, "ae_transition_loss": 1.0468535423278809, "ae_encoder_loss": 0.4280206114053726, "actor_loss": -0.9148737788200378, "actor_target_entropy": -2.0, "actor_entropy": 1.2417065501213074, "alpha_loss": 0.007791529875248671, "alpha_value": 0.005482866541165656, "duration": 4.011859178543091, "step": 38416}
{"episode_reward": -2.395996084670605, "episode": 1234.0, "batch_reward": 0.020976420491933823, "critic_loss": 1.220611572265625, "ae_transition_loss": 1.077499508857727, "ae_encoder_loss": 0.5198085308074951, "actor_loss": -1.008061408996582, "actor_target_entropy": -2.0, "actor_entropy": 1.255114197731018, "alpha_loss": 0.007409044541418552, "alpha_value": 0.005476987207786999, "duration": 2.8758132457733154, "step": 38430}
{"episode_reward": -4.081439586450549, "episode": 1235.0, "batch_reward": 0.025277242064476013, "critic_loss": 0.35755513111750287, "ae_transition_loss": 0.9677725235621134, "ae_encoder_loss": 0.47112823526064557, "actor_loss": -0.9198535879453024, "actor_target_entropy": -2.0, "actor_entropy": 1.3548226753870647, "alpha_loss": 0.007321188226342201, "alpha_value": 0.0054690520605116645, "duration": 5.095715284347534, "step": 38455}
{"episode_reward": -2.776802864789201, "episode": 1236.0, "batch_reward": -0.010474230162799358, "critic_loss": 0.5694605112075806, "ae_transition_loss": 1.1242710947990417, "ae_encoder_loss": 0.4166282117366791, "actor_loss": -0.914635419845581, "actor_target_entropy": -2.0, "actor_entropy": 1.4455150961875916, "alpha_loss": 0.005354105262085795, "alpha_value": 0.005459143102785977, "duration": 4.543798446655273, "step": 38477}
{"episode_reward": -5.381898971299258, "episode": 1237.0, "batch_reward": 0.031057517044246197, "critic_loss": 0.4063420444726944, "ae_transition_loss": 1.0187180042266846, "ae_encoder_loss": 0.35275396704673767, "actor_loss": -1.103357195854187, "actor_target_entropy": -2.0, "actor_entropy": 1.3223708868026733, "alpha_loss": 0.003961337264627218, "alpha_value": 0.005451553765606445, "duration": 3.7159159183502197, "step": 38496}
{"episode_reward": -7.033228156256952, "episode": 1238.0, "duration": 0.22756743431091309, "step": 38497}
{"episode_reward": 0.18487302801135397, "episode": 1239.0, "batch_reward": 0.04025975614786148, "critic_loss": 0.6866796910762787, "ae_transition_loss": 1.9399143755435944, "ae_encoder_loss": 0.33444948494434357, "actor_loss": -1.1243066787719727, "actor_target_entropy": -2.0, "actor_entropy": 1.1886219382286072, "alpha_loss": 0.0025381767190992832, "alpha_value": 0.005444619822927538, "duration": 3.7721307277679443, "step": 38515}
{"episode_reward": -4.252617473605024, "episode": 1240.0, "batch_reward": 0.009662799909710884, "critic_loss": 0.3781276881694794, "ae_transition_loss": 1.1749677300453185, "ae_encoder_loss": 0.5655693709850311, "actor_loss": -0.9734624028205872, "actor_target_entropy": -2.0, "actor_entropy": 1.2156970262527467, "alpha_loss": 0.0032409552950412035, "alpha_value": 0.0054343959617107656, "duration": 10.763644933700562, "step": 38568}
{"episode_reward": -12.642151908291725, "episode": 1241.0, "duration": 50.991546392440796, "step": 38569}
{"episode_reward": -1.0373025900790767, "episode": 1242.0, "duration": 0.22810578346252441, "step": 38570}
{"episode_reward": -1.0459389614519972, "episode": 1243.0, "batch_reward": -0.01222088405241569, "critic_loss": 0.29070664942264557, "ae_transition_loss": 0.9018406470616659, "ae_encoder_loss": 0.6756070256233215, "actor_loss": -0.7234770556290945, "actor_target_entropy": -2.0, "actor_entropy": 1.4362259705861409, "alpha_loss": 0.0039240481952826185, "alpha_value": 0.0054239065244024295, "duration": 5.1905646324157715, "step": 38594}
{"episode_reward": -2.028984484312668, "episode": 1244.0, "batch_reward": 0.08168830536305904, "critic_loss": 0.36120474338531494, "ae_transition_loss": 0.9581252038478851, "ae_encoder_loss": 0.7922502756118774, "actor_loss": -1.0250657796859741, "actor_target_entropy": -2.0, "actor_entropy": 1.3432883024215698, "alpha_loss": 0.005513234995305538, "alpha_value": 0.005417655941000949, "duration": 4.940734624862671, "step": 38618}
{"episode_reward": -5.942585493822935, "episode": 1245.0, "batch_reward": 0.035202588265140854, "critic_loss": 0.7081921448310217, "ae_transition_loss": 1.1951477726300557, "ae_encoder_loss": 0.9932573139667511, "actor_loss": -0.8705166180928549, "actor_target_entropy": -2.0, "actor_entropy": 1.4244602521260579, "alpha_loss": 0.004686657533360024, "alpha_value": 0.005407350721682284, "duration": 12.604285478591919, "step": 38678}
{"episode_reward": -13.773877697416555, "episode": 1246.0, "batch_reward": 0.007931090891361237, "critic_loss": 0.5139400810003281, "ae_transition_loss": 1.4147097766399384, "ae_encoder_loss": 0.976814329624176, "actor_loss": -0.8649652898311615, "actor_target_entropy": -2.0, "actor_entropy": 1.6421444714069366, "alpha_loss": 0.005735559621825814, "alpha_value": 0.005394486817281288, "duration": 7.555438280105591, "step": 38712}
{"episode_reward": -14.481948241038026, "episode": 1247.0, "batch_reward": 0.05609696886191765, "critic_loss": 0.6855507493019104, "ae_transition_loss": 1.043647567431132, "ae_encoder_loss": 0.8801576495170593, "actor_loss": -1.1436415910720825, "actor_target_entropy": -2.0, "actor_entropy": 1.3192243178685505, "alpha_loss": 0.005270130001008511, "alpha_value": 0.005384847506680988, "duration": 6.746299743652344, "step": 38744}
{"episode_reward": -1.2094895973778732, "episode": 1248.0, "batch_reward": 0.015109068403641382, "critic_loss": 0.3534325957298279, "ae_transition_loss": 1.1077862580617268, "ae_encoder_loss": 1.209413965543111, "actor_loss": -0.8888101379076639, "actor_target_entropy": -2.0, "actor_entropy": 0.8078286250432333, "alpha_loss": 0.00471346623574694, "alpha_value": 0.005376439865755822, "duration": 6.86426043510437, "step": 38778}
{"episode_reward": -1.0021914151164608, "episode": 1249.0, "batch_reward": 0.017432781246801216, "critic_loss": 0.4255373386873139, "ae_transition_loss": 1.0947413312064276, "ae_encoder_loss": 1.0219594306415982, "actor_loss": -0.9440806408723196, "actor_target_entropy": -2.0, "actor_entropy": 0.8940467602676816, "alpha_loss": 0.004399398703955942, "alpha_value": 0.005347763833363678, "duration": 36.59295630455017, "step": 38952}
{"episode_reward": -33.76434205077908, "episode": 1250.0, "batch_reward": -0.012022087971369425, "critic_loss": 0.5283041795094808, "ae_transition_loss": 0.9588265220324198, "ae_encoder_loss": 0.4787720839182536, "actor_loss": -0.8698978424072266, "actor_target_entropy": -2.0, "actor_entropy": 0.9453200300534567, "alpha_loss": 0.005539188161492348, "alpha_value": 0.005321145819246, "duration": 6.844106674194336, "step": 38985}
{"episode_reward": -2.769861595234732, "episode": 1251.0, "batch_reward": 0.04358447715640068, "critic_loss": 0.5862878113985062, "ae_transition_loss": 0.7159345299005508, "ae_encoder_loss": 0.4897288605570793, "actor_loss": -1.0683254599571228, "actor_target_entropy": -2.0, "actor_entropy": 1.8813632130622864, "alpha_loss": 0.008261106675490737, "alpha_value": 0.005312022964522517, "duration": 85.79153108596802, "step": 39025}
{"episode_reward": -16.084010440235215, "episode": 1252.0, "batch_reward": -0.013495555147528648, "critic_loss": 0.7240955233573914, "ae_transition_loss": 0.6985653042793274, "ae_encoder_loss": 0.48425543308258057, "actor_loss": -0.7311124801635742, "actor_target_entropy": -2.0, "actor_entropy": 1.5944743156433105, "alpha_loss": 0.007699360139667988, "alpha_value": 0.00530437864016886, "duration": 2.119826316833496, "step": 39035}
{"episode_reward": -2.0697300184187246, "episode": 1253.0, "batch_reward": 0.04957123287022114, "critic_loss": 1.420916497707367, "ae_transition_loss": 0.5423299372196198, "ae_encoder_loss": 0.36842967569828033, "actor_loss": -0.8447973132133484, "actor_target_entropy": -2.0, "actor_entropy": 0.9715026617050171, "alpha_loss": 0.006801148876547813, "alpha_value": 0.005299366149131231, "duration": 4.053374290466309, "step": 39054}
{"episode_reward": -4.937775416218113, "episode": 1254.0, "batch_reward": -0.005651701241731644, "critic_loss": 0.5959535241127014, "ae_transition_loss": 0.5088757276535034, "ae_encoder_loss": 0.4342285096645355, "actor_loss": -0.8598861694335938, "actor_target_entropy": -2.0, "actor_entropy": 0.5786821246147156, "alpha_loss": 0.004564223811030388, "alpha_value": 0.005294282561257026, "duration": 2.478184223175049, "step": 39066}
{"episode_reward": -1.8557060960888676, "episode": 1255.0, "batch_reward": 0.02192828559782356, "critic_loss": 0.6363231912255287, "ae_transition_loss": 0.4182140901684761, "ae_encoder_loss": 0.49939529597759247, "actor_loss": -0.7574533075094223, "actor_target_entropy": -2.0, "actor_entropy": 0.6532936692237854, "alpha_loss": 0.005130878649652004, "alpha_value": 0.005286261552201721, "duration": 7.866517066955566, "step": 39103}
{"episode_reward": -2.876938069410321, "episode": 1256.0, "batch_reward": 0.10630113631486893, "critic_loss": 0.25813543796539307, "ae_transition_loss": 1.1254044771194458, "ae_encoder_loss": 0.5045338869094849, "actor_loss": -1.188133955001831, "actor_target_entropy": -2.0, "actor_entropy": 0.9500300884246826, "alpha_loss": 0.004205901641398668, "alpha_value": 0.005278425860695986, "duration": 2.525798797607422, "step": 39116}
{"episode_reward": -1.158934186521185, "episode": 1257.0, "batch_reward": 0.03342842236161232, "critic_loss": 0.6522164940834045, "ae_transition_loss": 1.0535767555236817, "ae_encoder_loss": 0.5216689109802246, "actor_loss": -0.9642468452453613, "actor_target_entropy": -2.0, "actor_entropy": 1.279755187034607, "alpha_loss": 0.004504222422838211, "alpha_value": 0.005269533380403153, "duration": 9.82001543045044, "step": 39164}
{"episode_reward": -1.7400264493410436, "episode": 1258.0, "batch_reward": 0.02812735674281915, "critic_loss": 0.6491035322348276, "ae_transition_loss": 0.9456454714139303, "ae_encoder_loss": 0.7558969656626383, "actor_loss": -1.0691197315851848, "actor_target_entropy": -2.0, "actor_entropy": 1.4711530605951946, "alpha_loss": 0.0029021649000545344, "alpha_value": 0.005258234155930522, "duration": 6.458985090255737, "step": 39195}
{"episode_reward": -1.9041604162129966, "episode": 1259.0, "batch_reward": 0.09490270912647247, "critic_loss": 0.9306811690330505, "ae_transition_loss": 1.019574373960495, "ae_encoder_loss": 0.6508754193782806, "actor_loss": -1.6087196469306946, "actor_target_entropy": -2.0, "actor_entropy": 1.5422859191894531, "alpha_loss": 0.0018592162523418665, "alpha_value": 0.005251957299180446, "duration": 3.653496503829956, "step": 39211}
{"episode_reward": -6.055381670887223, "episode": 1260.0, "batch_reward": 0.01033102534711361, "critic_loss": 0.8723828792572021, "ae_transition_loss": 1.1419870853424072, "ae_encoder_loss": 0.811897873878479, "actor_loss": -1.1513102054595947, "actor_target_entropy": -2.0, "actor_entropy": 1.4979631900787354, "alpha_loss": 0.003524584462866187, "alpha_value": 0.005248595890575237, "duration": 3.314004421234131, "step": 39228}
{"episode_reward": -5.2304014184449565, "episode": 1261.0, "duration": 34.151395320892334, "step": 39229}
{"episode_reward": -0.3242436647415161, "episode": 1262.0, "batch_reward": 0.01884435908868909, "critic_loss": 0.4844430387020111, "ae_transition_loss": 1.05761057138443, "ae_encoder_loss": 0.8882706761360168, "actor_loss": -0.7792230844497681, "actor_target_entropy": -2.0, "actor_entropy": 1.4437459111213684, "alpha_loss": 0.001426566916052252, "alpha_value": 0.005245393441327894, "duration": 4.07224440574646, "step": 39248}
{"episode_reward": -2.1414640936400513, "episode": 1263.0, "batch_reward": 0.05107022053562105, "critic_loss": 0.4417315647006035, "ae_transition_loss": 0.9268087297677994, "ae_encoder_loss": 0.6919762194156647, "actor_loss": -1.1394242197275162, "actor_target_entropy": -2.0, "actor_entropy": 1.1391271352767944, "alpha_loss": 0.0035559929674491286, "alpha_value": 0.00523964429711276, "duration": 7.609178066253662, "step": 39285}
{"episode_reward": 0.4076931594400717, "episode": 1264.0, "duration": 0.23752856254577637, "step": 39286}
{"episode_reward": -0.3198691308678495, "episode": 1265.0, "batch_reward": 0.015269150026142597, "critic_loss": 0.7923586368560791, "ae_transition_loss": 0.8713192343711853, "ae_encoder_loss": 0.8624963164329529, "actor_loss": -0.8084602952003479, "actor_target_entropy": -2.0, "actor_entropy": 1.003131628036499, "alpha_loss": 0.004326220136135817, "alpha_value": 0.00523491874482269, "duration": 2.748891830444336, "step": 39299}
{"episode_reward": -4.7679062248585335, "episode": 1266.0, "batch_reward": 0.06002004941304525, "critic_loss": 0.5200203557809194, "ae_transition_loss": 1.1497239470481873, "ae_encoder_loss": 0.7070634365081787, "actor_loss": -0.9677762985229492, "actor_target_entropy": -2.0, "actor_entropy": 1.0274400909741719, "alpha_loss": 0.004392907489091158, "alpha_value": 0.005230912862287014, "duration": 5.501075983047485, "step": 39326}
{"episode_reward": 1.8568171752037745, "episode": 1267.0, "batch_reward": 0.006687933579087257, "critic_loss": 0.3084270656108856, "ae_transition_loss": 1.0318399369716644, "ae_encoder_loss": 1.1268061399459839, "actor_loss": -0.7002561688423157, "actor_target_entropy": -2.0, "actor_entropy": 1.092909574508667, "alpha_loss": 0.006226913072168827, "alpha_value": 0.005225679181774242, "duration": 4.969935178756714, "step": 39350}
{"episode_reward": 0.6154706371238203, "episode": 1268.0, "batch_reward": -0.011685729026794434, "critic_loss": 1.00557808081309, "ae_transition_loss": 1.0056499242782593, "ae_encoder_loss": 0.8117349545160929, "actor_loss": -0.7028691371281942, "actor_target_entropy": -2.0, "actor_entropy": 1.2028521299362183, "alpha_loss": 0.006801761531581481, "alpha_value": 0.00521979362067133, "duration": 5.033595561981201, "step": 39373}
{"episode_reward": -2.986496438181979, "episode": 1269.0, "batch_reward": 0.013559574261307716, "critic_loss": 0.9016644557317098, "ae_transition_loss": 0.9346087177594503, "ae_encoder_loss": 0.9160592158635458, "actor_loss": -0.5827325483163198, "actor_target_entropy": -2.0, "actor_entropy": 1.287376602490743, "alpha_loss": 0.007823305670171976, "alpha_value": 0.005211561491982375, "duration": 5.955123424530029, "step": 39401}
{"episode_reward": -3.295641325742983, "episode": 1270.0, "batch_reward": 0.05062933126464486, "critic_loss": 0.7515045925974846, "ae_transition_loss": 1.4832594990730286, "ae_encoder_loss": 0.6049320548772812, "actor_loss": -1.1781569719314575, "actor_target_entropy": -2.0, "actor_entropy": 1.366155207157135, "alpha_loss": 0.006835448904894292, "alpha_value": 0.005200652562095143, "duration": 8.73062539100647, "step": 39445}
{"episode_reward": 0.21193007958582866, "episode": 1271.0, "duration": 45.967785358428955, "step": 39446}
{"episode_reward": -0.4316830409203215, "episode": 1272.0, "batch_reward": 0.02388021000660956, "critic_loss": 0.717736005783081, "ae_transition_loss": 1.2683090269565582, "ae_encoder_loss": 0.6582837551832199, "actor_loss": -0.7712253332138062, "actor_target_entropy": -2.0, "actor_entropy": 1.483288288116455, "alpha_loss": 0.007071127882227302, "alpha_value": 0.0051873022164160894, "duration": 7.7800068855285645, "step": 39485}
{"episode_reward": -3.8882770085160927, "episode": 1273.0, "batch_reward": -0.017617605005701382, "critic_loss": 0.4746810992558797, "ae_transition_loss": 1.270809809366862, "ae_encoder_loss": 0.8078197439511617, "actor_loss": -0.8005566398302714, "actor_target_entropy": -2.0, "actor_entropy": 1.6625181039174397, "alpha_loss": 0.006672326785822709, "alpha_value": 0.0051750443703714516, "duration": 6.2237184047698975, "step": 39516}
{"episode_reward": -5.27538616684809, "episode": 1274.0, "duration": 0.9514455795288086, "step": 39520}
{"episode_reward": -1.5527750330012438, "episode": 1275.0, "batch_reward": 0.012535850517451763, "critic_loss": 0.4369087666273117, "ae_transition_loss": 1.2474310994148254, "ae_encoder_loss": 0.778409481048584, "actor_loss": -0.7972438335418701, "actor_target_entropy": -2.0, "actor_entropy": 1.804338812828064, "alpha_loss": 0.00570805580355227, "alpha_value": 0.005166152006467783, "duration": 3.3681204319000244, "step": 39536}
{"episode_reward": -4.743268134074533, "episode": 1276.0, "batch_reward": 0.026973657310009003, "critic_loss": 0.5240058302879333, "ae_transition_loss": 1.0849359035491943, "ae_encoder_loss": 0.7630818784236908, "actor_loss": -0.8067593574523926, "actor_target_entropy": -2.0, "actor_entropy": 1.959697961807251, "alpha_loss": 0.0043214327888563275, "alpha_value": 0.00515929355038826, "duration": 4.559697866439819, "step": 39559}
{"episode_reward": -5.642513642390749, "episode": 1277.0, "batch_reward": 0.03301750794053078, "critic_loss": 0.6753604352474213, "ae_transition_loss": 0.8852824926376343, "ae_encoder_loss": 0.5336457967758179, "actor_loss": -1.028735303878784, "actor_target_entropy": -2.0, "actor_entropy": 2.108439064025879, "alpha_loss": 0.006564806215465069, "alpha_value": 0.0051479060935409274, "duration": 9.498632669448853, "step": 39606}
{"episode_reward": -7.905501949575659, "episode": 1278.0, "batch_reward": 0.018863629549741745, "critic_loss": 0.6691249907016754, "ae_transition_loss": 0.8464902937412262, "ae_encoder_loss": 0.49022020399570465, "actor_loss": -0.9155825674533844, "actor_target_entropy": -2.0, "actor_entropy": 1.9545485973358154, "alpha_loss": 0.006765004247426987, "alpha_value": 0.00513632195418611, "duration": 3.6770310401916504, "step": 39623}
{"episode_reward": -4.821229831445508, "episode": 1279.0, "duration": 0.24554109573364258, "step": 39624}
{"episode_reward": 1.0370991440365762, "episode": 1280.0, "batch_reward": 0.046434225514531136, "critic_loss": 0.45918509364128113, "ae_transition_loss": 0.7920803129673004, "ae_encoder_loss": 0.6011681854724884, "actor_loss": -1.0727491080760956, "actor_target_entropy": -2.0, "actor_entropy": 1.5994791388511658, "alpha_loss": 0.007321417797356844, "alpha_value": 0.005129456589798678, "duration": 5.101811647415161, "step": 39648}
{"episode_reward": -2.6337331424342967, "episode": 1281.0, "batch_reward": 0.04055303024748961, "critic_loss": 0.4099910358587901, "ae_transition_loss": 1.2030768791834514, "ae_encoder_loss": 0.4819042682647705, "actor_loss": -1.0920343399047852, "actor_target_entropy": -2.0, "actor_entropy": 1.26303764184316, "alpha_loss": 0.008023465983569622, "alpha_value": 0.005120534375063667, "duration": 172.02826714515686, "step": 39676}
{"episode_reward": -6.974138107242366, "episode": 1282.0, "batch_reward": 0.04994945973157883, "critic_loss": 0.5711694955825806, "ae_transition_loss": 0.5311560034751892, "ae_encoder_loss": 0.48787975311279297, "actor_loss": -1.1443617343902588, "actor_target_entropy": -2.0, "actor_entropy": 0.9206427335739136, "alpha_loss": 0.006531735882163048, "alpha_value": 0.005113163854406073, "duration": 2.559546709060669, "step": 39688}
{"episode_reward": -5.930436767688047, "episode": 1283.0, "batch_reward": 0.02737343544140458, "critic_loss": 0.6873858422040939, "ae_transition_loss": 0.9362836182117462, "ae_encoder_loss": 0.4904530383646488, "actor_loss": -0.8544249460101128, "actor_target_entropy": -2.0, "actor_entropy": 1.9751246869564056, "alpha_loss": 0.001948086399352178, "alpha_value": 0.005097656129296508, "duration": 15.813932657241821, "step": 39762}
{"episode_reward": -55.37685510901208, "episode": 1284.0, "batch_reward": 0.03903527930378914, "critic_loss": 0.36073505878448486, "ae_transition_loss": 0.9661611914634705, "ae_encoder_loss": 0.512283444404602, "actor_loss": -1.1384007930755615, "actor_target_entropy": -2.0, "actor_entropy": 2.0447521209716797, "alpha_loss": 0.0040199412032961845, "alpha_value": 0.005085619206489087, "duration": 3.3453097343444824, "step": 39779}
{"episode_reward": -9.214294520284893, "episode": 1285.0, "batch_reward": -0.0012171277776360512, "critic_loss": 0.704186350107193, "ae_transition_loss": 0.8154749870300293, "ae_encoder_loss": 0.49459798634052277, "actor_loss": -0.7305274903774261, "actor_target_entropy": -2.0, "actor_entropy": 1.9371321201324463, "alpha_loss": 0.006459754891693592, "alpha_value": 0.005082508546687467, "duration": 3.7161097526550293, "step": 39796}
{"episode_reward": -9.449197845184413, "episode": 1286.0, "batch_reward": 0.009963484480977058, "critic_loss": 0.5286852121353149, "ae_transition_loss": 0.8145153522491455, "ae_encoder_loss": 0.6079823076725006, "actor_loss": -1.164576530456543, "actor_target_entropy": -2.0, "actor_entropy": 1.537412405014038, "alpha_loss": 0.005605337442830205, "alpha_value": 0.005077941667313829, "duration": 4.727571725845337, "step": 39819}
{"episode_reward": -11.482010011124748, "episode": 1287.0, "batch_reward": -0.01700324658304453, "critic_loss": 0.4344780743122101, "ae_transition_loss": 0.8336489200592041, "ae_encoder_loss": 0.4902147203683853, "actor_loss": -0.8540356457233429, "actor_target_entropy": -2.0, "actor_entropy": 1.3900503516197205, "alpha_loss": 0.006579458247870207, "alpha_value": 0.0050730712501112895, "duration": 3.3934061527252197, "step": 39835}
{"episode_reward": -5.87045021274022, "episode": 1288.0, "batch_reward": 0.021850479766726494, "critic_loss": 0.3849818706512451, "ae_transition_loss": 0.6954765915870667, "ae_encoder_loss": 0.4357808232307434, "actor_loss": -1.026332139968872, "actor_target_entropy": -2.0, "actor_entropy": 1.4115819931030273, "alpha_loss": 0.005292830523103476, "alpha_value": 0.005069170759874994, "duration": 1.82033371925354, "step": 39843}
{"episode_reward": -1.665911399751551, "episode": 1289.0, "batch_reward": 0.021691311988979577, "critic_loss": 0.5096064269542694, "ae_transition_loss": 0.7643463492393494, "ae_encoder_loss": 0.4091100633144379, "actor_loss": -0.9838912487030029, "actor_target_entropy": -2.0, "actor_entropy": 1.473181462287903, "alpha_loss": 0.004112421628087759, "alpha_value": 0.005061246827809241, "duration": 10.417069911956787, "step": 39892}
{"episode_reward": -11.086768332870955, "episode": 1290.0, "batch_reward": -0.051198482513427734, "critic_loss": 0.33153074979782104, "ae_transition_loss": 0.6577301025390625, "ae_encoder_loss": 0.42735809087753296, "actor_loss": -0.5516479015350342, "actor_target_entropy": -2.0, "actor_entropy": 1.4255950450897217, "alpha_loss": 0.004320346750319004, "alpha_value": 0.00505361417781542, "duration": 2.8246405124664307, "step": 39906}
{"episode_reward": -5.153211857620482, "episode": 1291.0, "batch_reward": 0.00282379612326622, "critic_loss": 0.6333951354026794, "ae_transition_loss": 0.6702236458659172, "ae_encoder_loss": 0.3847748041152954, "actor_loss": -0.8924690037965775, "actor_target_entropy": -2.0, "actor_entropy": 1.2250688970088959, "alpha_loss": 0.0023765854130033404, "alpha_value": 0.005047845188255489, "duration": 48.35978150367737, "step": 39947}
{"episode_reward": -16.39990050993253, "episode": 1292.0, "batch_reward": 0.029542363435029983, "critic_loss": 0.3149129331111908, "ae_transition_loss": 0.5972216844558715, "ae_encoder_loss": 0.39790584444999694, "actor_loss": -1.0305845737457275, "actor_target_entropy": -2.0, "actor_entropy": 1.4962811708450316, "alpha_loss": 0.003646547719836235, "alpha_value": 0.0050384473067304385, "duration": 10.223611116409302, "step": 39998}
{"episode_reward": -23.60071356784766, "episode": 1293.0, "duration": 0.28096699714660645, "step": 39999}
{"episode_reward": -0.9395353789595119, "episode": 1294.0, "batch_reward": 0.031188595108687878, "critic_loss": 0.33339570462703705, "ae_transition_loss": 0.7741521596908569, "ae_encoder_loss": 0.510573148727417, "actor_loss": -1.1770498752593994, "actor_target_entropy": -2.0, "actor_entropy": 1.8178116083145142, "alpha_loss": 0.0049412057269364595, "alpha_value": 0.0050313067774055, "duration": 7.9225380420684814, "step": 40020}
{"episode_reward": -10.290750700462109, "episode": 1295.0, "batch_reward": 0.06046471372246742, "critic_loss": 0.14231207966804504, "ae_transition_loss": 0.6887067556381226, "ae_encoder_loss": 0.3885394334793091, "actor_loss": -0.9652349948883057, "actor_target_entropy": -2.0, "actor_entropy": 1.5885441303253174, "alpha_loss": 0.0043520741164684296, "alpha_value": 0.005028140723842405, "duration": 1.6518890857696533, "step": 40027}
{"episode_reward": -2.405239165542657, "episode": 1296.0, "batch_reward": -0.0067256735637784, "critic_loss": 0.6964623232682546, "ae_transition_loss": 0.8427713215351105, "ae_encoder_loss": 0.5181009819110235, "actor_loss": -0.7812374333540598, "actor_target_entropy": -2.0, "actor_entropy": 1.5582033793131511, "alpha_loss": 0.0047812989602486295, "alpha_value": 0.005020525262436233, "duration": 11.943864107131958, "step": 40085}
{"episode_reward": -36.54551767242163, "episode": 1297.0, "batch_reward": -0.010745295323431492, "critic_loss": 0.8732897341251373, "ae_transition_loss": 0.8660306036472321, "ae_encoder_loss": 0.5097505152225494, "actor_loss": -0.7414232194423676, "actor_target_entropy": -2.0, "actor_entropy": 2.109015703201294, "alpha_loss": 0.004449161933735013, "alpha_value": 0.005011321400462768, "duration": 3.889888048171997, "step": 40103}
{"episode_reward": -9.302413148284831, "episode": 1298.0, "batch_reward": 0.003284973092377186, "critic_loss": 0.29396139085292816, "ae_transition_loss": 0.7249239981174469, "ae_encoder_loss": 0.42643459141254425, "actor_loss": -0.8583284616470337, "actor_target_entropy": -2.0, "actor_entropy": 2.279187321662903, "alpha_loss": 0.0045830863527953625, "alpha_value": 0.005006567920239777, "duration": 5.401569843292236, "step": 40130}
{"episode_reward": -14.768205384288674, "episode": 1299.0, "batch_reward": 0.005273791216313839, "critic_loss": 0.5386855681737264, "ae_transition_loss": 1.0230417092641195, "ae_encoder_loss": 0.5245762725671133, "actor_loss": -0.9495218435923258, "actor_target_entropy": -2.0, "actor_entropy": 1.922521432240804, "alpha_loss": 0.00608881803539892, "alpha_value": 0.004984719353908914, "duration": 30.3079833984375, "step": 40279}
{"episode_reward": -76.81690905594442, "episode": 1300.0, "batch_reward": 0.028960375115275383, "critic_loss": 0.3290670122951269, "ae_transition_loss": 0.8268213123083115, "ae_encoder_loss": 0.40574944019317627, "actor_loss": -1.029131218791008, "actor_target_entropy": -2.0, "actor_entropy": 1.576121374964714, "alpha_loss": 0.003913712214853149, "alpha_value": 0.0049503436592041525, "duration": 16.495580673217773, "step": 40358}
{"episode_reward": -54.09940869081023, "episode": 1301.0, "batch_reward": -0.006812877953052521, "critic_loss": 0.42029969394207, "ae_transition_loss": 0.9143154323101044, "ae_encoder_loss": 0.5654643774032593, "actor_loss": -0.7723156213760376, "actor_target_entropy": -2.0, "actor_entropy": 1.7958979606628418, "alpha_loss": 0.004076128592714667, "alpha_value": 0.004936609083687989, "duration": 38.523924589157104, "step": 40377}
{"episode_reward": -9.726916310547512, "episode": 1302.0, "batch_reward": 0.010318820364773273, "critic_loss": 0.3403199017047882, "ae_transition_loss": 1.0549772381782532, "ae_encoder_loss": 0.5341907441616058, "actor_loss": -0.8676369488239288, "actor_target_entropy": -2.0, "actor_entropy": 2.0310486555099487, "alpha_loss": 0.005130583303980529, "alpha_value": 0.004931874517150522, "duration": 3.757042169570923, "step": 40394}
{"episode_reward": -6.693730484443872, "episode": 1303.0, "batch_reward": 0.0012694094330072403, "critic_loss": 0.4460941056410472, "ae_transition_loss": 1.0375590523084004, "ae_encoder_loss": 0.46654019753138226, "actor_loss": -0.9721078475316366, "actor_target_entropy": -2.0, "actor_entropy": 2.1239206790924072, "alpha_loss": 0.005086115561425686, "alpha_value": 0.004925732415329776, "duration": 5.871474027633667, "step": 40422}
{"episode_reward": -17.660777573427325, "episode": 1304.0, "batch_reward": 0.011167285963892937, "critic_loss": 0.6106919348239899, "ae_transition_loss": 1.0507635474205017, "ae_encoder_loss": 0.42461059987545013, "actor_loss": -0.7744860947132111, "actor_target_entropy": -2.0, "actor_entropy": 2.0817973613739014, "alpha_loss": 0.005989603931084275, "alpha_value": 0.004919408532324394, "duration": 5.130807399749756, "step": 40447}
{"episode_reward": -11.586327649083866, "episode": 1305.0, "batch_reward": -0.03237600438296795, "critic_loss": 0.3142580986022949, "ae_transition_loss": 0.7855356335639954, "ae_encoder_loss": 0.48250260949134827, "actor_loss": -0.7699673175811768, "actor_target_entropy": -2.0, "actor_entropy": 2.0745218992233276, "alpha_loss": 0.007046613376587629, "alpha_value": 0.004914119227438061, "duration": 3.6423447132110596, "step": 40462}
{"episode_reward": -6.813495105659336, "episode": 1306.0, "batch_reward": 0.03979697450995445, "critic_loss": 0.8335598707199097, "ae_transition_loss": 0.7476602792739868, "ae_encoder_loss": 0.4363937973976135, "actor_loss": -1.0826605558395386, "actor_target_entropy": -2.0, "actor_entropy": 1.7744897603988647, "alpha_loss": 0.00740860216319561, "alpha_value": 0.004909893730052163, "duration": 2.1157383918762207, "step": 40471}
{"episode_reward": -5.207832121086644, "episode": 1307.0, "batch_reward": -0.053590803407132626, "critic_loss": 0.44709089398384094, "ae_transition_loss": 0.8092646598815918, "ae_encoder_loss": 0.4403965622186661, "actor_loss": -0.873567521572113, "actor_target_entropy": -2.0, "actor_entropy": 1.5528634786605835, "alpha_loss": 0.005676366854459047, "alpha_value": 0.0049054148000121115, "duration": 5.277225494384766, "step": 40497}
{"episode_reward": -12.429682308487031, "episode": 1308.0, "duration": 0.23556995391845703, "step": 40498}
{"episode_reward": -0.5449769820128005, "episode": 1309.0, "batch_reward": 0.008754802867770195, "critic_loss": 0.41467317938804626, "ae_transition_loss": 1.036005288362503, "ae_encoder_loss": 0.5447370409965515, "actor_loss": -0.8822430968284607, "actor_target_entropy": -2.0, "actor_entropy": 1.2912496328353882, "alpha_loss": 0.0026391962310299277, "alpha_value": 0.004899497816531831, "duration": 3.7245280742645264, "step": 40515}
{"episode_reward": -9.188644251221113, "episode": 1310.0, "batch_reward": 0.029786520404741168, "critic_loss": 0.4751742109656334, "ae_transition_loss": 0.8024033010005951, "ae_encoder_loss": 0.5878057777881622, "actor_loss": -1.2926775217056274, "actor_target_entropy": -2.0, "actor_entropy": 1.325060784816742, "alpha_loss": 0.001998534455196932, "alpha_value": 0.0048941980430326475, "duration": 4.751444578170776, "step": 40538}
{"episode_reward": -7.614590244959241, "episode": 1311.0, "batch_reward": -0.015100515757997831, "critic_loss": 0.4031370282173157, "ae_transition_loss": 1.2858248353004456, "ae_encoder_loss": 0.5434789061546326, "actor_loss": -0.7753828565279642, "actor_target_entropy": -2.0, "actor_entropy": 1.8427762587865193, "alpha_loss": 0.00427701766602695, "alpha_value": 0.004888192032610946, "duration": 31.85848593711853, "step": 40564}
{"episode_reward": -10.935699363512297, "episode": 1312.0, "batch_reward": 0.017280539497733116, "critic_loss": 0.48780880123376846, "ae_transition_loss": 0.9801693558692932, "ae_encoder_loss": 0.6918806731700897, "actor_loss": -0.9158717393875122, "actor_target_entropy": -2.0, "actor_entropy": 2.165639281272888, "alpha_loss": 0.003703193971887231, "alpha_value": 0.0048822783114952665, "duration": 5.296936750411987, "step": 40590}
{"episode_reward": -12.109042492857483, "episode": 1313.0, "batch_reward": -0.05005329102277756, "critic_loss": 0.3765769600868225, "ae_transition_loss": 1.081054925918579, "ae_encoder_loss": 0.7590556740760803, "actor_loss": -0.7480329275131226, "actor_target_entropy": -2.0, "actor_entropy": 2.2900586128234863, "alpha_loss": 0.004043657798320055, "alpha_value": 0.004878859081158731, "duration": 0.6303081512451172, "step": 40591}
{"episode_reward": 0.18692113015452128, "episode": 1314.0, "batch_reward": -0.022296424955129623, "critic_loss": 0.5925185680389404, "ae_transition_loss": 1.0443085432052612, "ae_encoder_loss": 0.6516696810722351, "actor_loss": -0.9486720561981201, "actor_target_entropy": -2.0, "actor_entropy": 2.2859954833984375, "alpha_loss": 0.004508310928940773, "alpha_value": 0.004876609385499783, "duration": 2.2347817420959473, "step": 40601}
{"episode_reward": -6.496338901005648, "episode": 1315.0, "batch_reward": 0.010109900496900082, "critic_loss": 0.5125827491283417, "ae_transition_loss": 0.9986067861318588, "ae_encoder_loss": 0.8531617075204849, "actor_loss": -1.010831356048584, "actor_target_entropy": -2.0, "actor_entropy": 1.8035314977169037, "alpha_loss": 0.0024485127942170948, "alpha_value": 0.00487092407393587, "duration": 8.282782077789307, "step": 40641}
{"episode_reward": -19.142996321897254, "episode": 1316.0, "duration": 0.20230889320373535, "step": 40642}
{"episode_reward": -0.730668073381275, "episode": 1317.0, "batch_reward": 0.0016312492627869634, "critic_loss": 0.4440963040379917, "ae_transition_loss": 0.9557994463864494, "ae_encoder_loss": 0.6256119784186868, "actor_loss": -0.9001582580454209, "actor_target_entropy": -2.0, "actor_entropy": 1.7051536826526417, "alpha_loss": 0.0029912987374700606, "alpha_value": 0.004855181532187475, "duration": 36.369046449661255, "step": 40815}
{"episode_reward": -118.47029018273626, "episode": 1318.0, "batch_reward": -0.021375178049008053, "critic_loss": 0.38730335235595703, "ae_transition_loss": 0.9844218293825785, "ae_encoder_loss": 0.6740082303682963, "actor_loss": -0.9079001148541769, "actor_target_entropy": -2.0, "actor_entropy": 1.7632229725519817, "alpha_loss": 0.003906412748619914, "alpha_value": 0.004838487747207001, "duration": 6.069002866744995, "step": 40844}
{"episode_reward": -15.255008203861818, "episode": 1319.0, "batch_reward": -0.03063128888607025, "critic_loss": 0.44477468729019165, "ae_transition_loss": 1.5880104303359985, "ae_encoder_loss": 0.6900565028190613, "actor_loss": -1.0153331756591797, "actor_target_entropy": -2.0, "actor_entropy": 1.829660177230835, "alpha_loss": 0.0051748366095125675, "alpha_value": 0.004834279227051424, "duration": 2.177353620529175, "step": 40854}
{"episode_reward": -4.446831869544818, "episode": 1320.0, "batch_reward": -0.002847151830792427, "critic_loss": 0.430876225233078, "ae_transition_loss": 0.957019031047821, "ae_encoder_loss": 0.5766705870628357, "actor_loss": -0.8136126399040222, "actor_target_entropy": -2.0, "actor_entropy": 1.6653451919555664, "alpha_loss": 0.004060875624418259, "alpha_value": 0.004832115230643608, "duration": 2.772829055786133, "step": 40867}
{"episode_reward": -4.4038886339414525, "episode": 1321.0, "batch_reward": 0.040619365870952606, "critic_loss": 0.32473987340927124, "ae_transition_loss": 1.0627819299697876, "ae_encoder_loss": 0.4949566423892975, "actor_loss": -0.9608229398727417, "actor_target_entropy": -2.0, "actor_entropy": 1.6292868852615356, "alpha_loss": 0.004185485653579235, "alpha_value": 0.004829951368686601, "duration": 44.92486882209778, "step": 40871}
{"episode_reward": -1.3986654724843448, "episode": 1322.0, "batch_reward": 0.022532443865202367, "critic_loss": 0.3387781232595444, "ae_transition_loss": 0.9230727404356003, "ae_encoder_loss": 0.5308899655938148, "actor_loss": -1.1410210728645325, "actor_target_entropy": -2.0, "actor_entropy": 1.6940557062625885, "alpha_loss": 0.0029343616915866733, "alpha_value": 0.004824678965923462, "duration": 9.182996273040771, "step": 40918}
{"episode_reward": -23.173671101343462, "episode": 1323.0, "batch_reward": 0.017328604124486446, "critic_loss": 0.46162283420562744, "ae_transition_loss": 0.9525671899318695, "ae_encoder_loss": 0.4325500577688217, "actor_loss": -0.9965862929821014, "actor_target_entropy": -2.0, "actor_entropy": 1.8773646354675293, "alpha_loss": 0.004153362940996885, "alpha_value": 0.004818700468230528, "duration": 2.9186789989471436, "step": 40931}
{"episode_reward": -4.779202250108468, "episode": 1324.0, "duration": 0.7801578044891357, "step": 40935}
{"episode_reward": -1.199101038284564, "episode": 1325.0, "batch_reward": -0.007290656678378582, "critic_loss": 0.3935438506305218, "ae_transition_loss": 1.0124743729829788, "ae_encoder_loss": 0.5692924335598946, "actor_loss": -0.8755682557821274, "actor_target_entropy": -2.0, "actor_entropy": 2.0598867535591125, "alpha_loss": 0.004956354619935155, "alpha_value": 0.004812684527505148, "duration": 8.13642430305481, "step": 40975}
{"episode_reward": -19.35659751509728, "episode": 1326.0, "batch_reward": 0.013273903634399176, "critic_loss": 0.54437655210495, "ae_transition_loss": 0.9521210193634033, "ae_encoder_loss": 0.48290060460567474, "actor_loss": -0.9752407670021057, "actor_target_entropy": -2.0, "actor_entropy": 1.9574918150901794, "alpha_loss": 0.004715650691650808, "alpha_value": 0.004806176605188752, "duration": 3.682469606399536, "step": 40992}
{"episode_reward": -5.094981533170045, "episode": 1327.0, "batch_reward": 0.02819254994392395, "critic_loss": 0.6515282392501831, "ae_transition_loss": 1.1951146125793457, "ae_encoder_loss": 0.43244490027427673, "actor_loss": -0.9823907017707825, "actor_target_entropy": -2.0, "actor_entropy": 1.893038034439087, "alpha_loss": 0.0033796830102801323, "alpha_value": 0.004802705386585904, "duration": 2.74086332321167, "step": 41005}
{"episode_reward": -3.6086111250012736, "episode": 1328.0, "duration": 0.23588323593139648, "step": 41006}
{"episode_reward": -0.1923173936537391, "episode": 1329.0, "batch_reward": 0.03403436951339245, "critic_loss": 0.650969609618187, "ae_transition_loss": 0.8010281622409821, "ae_encoder_loss": 0.5563481152057648, "actor_loss": -1.010825514793396, "actor_target_entropy": -2.0, "actor_entropy": 1.839259684085846, "alpha_loss": 0.004514022031798959, "alpha_value": 0.0047993342501392935, "duration": 4.291845321655273, "step": 41027}
{"episode_reward": -5.977837612572143, "episode": 1330.0, "duration": 0.24799633026123047, "step": 41028}
{"episode_reward": 0.20718610397064632, "episode": 1331.0, "batch_reward": -0.012808924540877342, "critic_loss": 0.5447057783603668, "ae_transition_loss": 0.968216061592102, "ae_encoder_loss": 0.5142592042684555, "actor_loss": -0.9145036935806274, "actor_target_entropy": -2.0, "actor_entropy": 1.7672582268714905, "alpha_loss": 0.0038858780171722174, "alpha_value": 0.004794781783600751, "duration": 31.962196350097656, "step": 41045}
{"episode_reward": -8.410741645415946, "episode": 1332.0, "batch_reward": 0.0005302764475345612, "critic_loss": 0.5372216701507568, "ae_transition_loss": 1.394887089729309, "ae_encoder_loss": 0.5391287207603455, "actor_loss": -1.0083626508712769, "actor_target_entropy": -2.0, "actor_entropy": 1.736097812652588, "alpha_loss": 0.005131318233907223, "alpha_value": 0.004791394375131922, "duration": 2.485105514526367, "step": 41056}
{"episode_reward": -3.6034489168100783, "episode": 1333.0, "batch_reward": -0.05893237516283989, "critic_loss": 0.3709757924079895, "ae_transition_loss": 1.4878019094467163, "ae_encoder_loss": 0.7275176048278809, "actor_loss": -0.7578250169754028, "actor_target_entropy": -2.0, "actor_entropy": 1.7359987497329712, "alpha_loss": 0.0040940879844129086, "alpha_value": 0.004789108042870939, "duration": 2.547839879989624, "step": 41068}
{"episode_reward": -6.233551428107123, "episode": 1334.0, "batch_reward": 0.002797875553369522, "critic_loss": 0.8310583829879761, "ae_transition_loss": 1.1153002381324768, "ae_encoder_loss": 0.9294154644012451, "actor_loss": -0.9424700438976288, "actor_target_entropy": -2.0, "actor_entropy": 1.747764527797699, "alpha_loss": 0.004592953249812126, "alpha_value": 0.004785684642022746, "duration": 2.987468957901001, "step": 41081}
{"episode_reward": -4.450970499942564, "episode": 1335.0, "batch_reward": 0.044265205040574074, "critic_loss": 0.5767256021499634, "ae_transition_loss": 1.0402524173259735, "ae_encoder_loss": 0.7161154747009277, "actor_loss": -1.0744712352752686, "actor_target_entropy": -2.0, "actor_entropy": 1.739366054534912, "alpha_loss": 0.004149925196543336, "alpha_value": 0.004781076989327958, "duration": 4.4563963413238525, "step": 41104}
{"episode_reward": -8.280607374403834, "episode": 1336.0, "batch_reward": 0.013018457219004631, "critic_loss": 0.5418376326560974, "ae_transition_loss": 1.0356547236442566, "ae_encoder_loss": 0.7880840301513672, "actor_loss": -1.0708918273448944, "actor_target_entropy": -2.0, "actor_entropy": 1.8118197321891785, "alpha_loss": 0.003953505540266633, "alpha_value": 0.004776458243180362, "duration": 3.8974313735961914, "step": 41121}
{"episode_reward": -6.346980371517981, "episode": 1337.0, "batch_reward": 0.016862820833921432, "critic_loss": 0.7621872425079346, "ae_transition_loss": 0.8977023363113403, "ae_encoder_loss": 0.6084865927696228, "actor_loss": -0.7439091205596924, "actor_target_entropy": -2.0, "actor_entropy": 1.8483619689941406, "alpha_loss": 0.004081696271896362, "alpha_value": 0.0047730368361542964, "duration": 3.6742382049560547, "step": 41140}
{"episode_reward": -10.387489600294026, "episode": 1338.0, "batch_reward": -0.009781178086996078, "critic_loss": 0.6024090945720673, "ae_transition_loss": 1.139501690864563, "ae_encoder_loss": 0.5403524190187454, "actor_loss": -0.707245409488678, "actor_target_entropy": -2.0, "actor_entropy": 1.9007807970046997, "alpha_loss": 0.005323468940332532, "alpha_value": 0.004769640228958772, "duration": 3.663522720336914, "step": 41158}
{"episode_reward": -6.334890322834688, "episode": 1339.0, "batch_reward": 0.032348742708563805, "critic_loss": 0.5457090437412262, "ae_transition_loss": 0.9596392512321472, "ae_encoder_loss": 0.7550759315490723, "actor_loss": -1.0490419268608093, "actor_target_entropy": -2.0, "actor_entropy": 1.9311526417732239, "alpha_loss": 0.0031252314802259207, "alpha_value": 0.0047649853408853185, "duration": 4.5359296798706055, "step": 41180}
{"episode_reward": -9.935516003201347, "episode": 1340.0, "batch_reward": 0.027996469909946125, "critic_loss": 0.35580362876256305, "ae_transition_loss": 0.9972950418790182, "ae_encoder_loss": 0.5008472502231598, "actor_loss": -1.0873418649037678, "actor_target_entropy": -2.0, "actor_entropy": 1.9574386676152546, "alpha_loss": 0.0033052638173103333, "alpha_value": 0.0047594190591774355, "duration": 4.812862157821655, "step": 41201}
{"episode_reward": -10.444547154940333, "episode": 1341.0, "batch_reward": -0.008234292268753052, "critic_loss": 0.28193485736846924, "ae_transition_loss": 0.9637893438339233, "ae_encoder_loss": 0.6340799033641815, "actor_loss": -0.7930175065994263, "actor_target_entropy": -2.0, "actor_entropy": 1.8058047890663147, "alpha_loss": 0.004475477850064635, "alpha_value": 0.004754066788010445, "duration": 36.49457812309265, "step": 41225}
{"episode_reward": -10.232830432582954, "episode": 1342.0, "duration": 0.2396552562713623, "step": 41226}
{"episode_reward": -0.19781937708538228, "episode": 1343.0, "batch_reward": -0.011645881459116936, "critic_loss": 0.4778788685798645, "ae_transition_loss": 1.5934487581253052, "ae_encoder_loss": 0.6134417653083801, "actor_loss": -0.9757841229438782, "actor_target_entropy": -2.0, "actor_entropy": 1.666799783706665, "alpha_loss": 0.001306565827690065, "alpha_value": 0.0047508696663466, "duration": 2.419889450073242, "step": 41237}
{"episode_reward": -6.895901861821277, "episode": 1344.0, "batch_reward": 0.00688115693628788, "critic_loss": 0.509147897362709, "ae_transition_loss": 0.9086881875991821, "ae_encoder_loss": 0.7403200268745422, "actor_loss": -0.8444257080554962, "actor_target_entropy": -2.0, "actor_entropy": 1.648321509361267, "alpha_loss": 0.0031521921046078205, "alpha_value": 0.004747930506384284, "duration": 3.426063060760498, "step": 41253}
{"episode_reward": -6.589313689286006, "episode": 1345.0, "batch_reward": 0.010643609799444675, "critic_loss": 0.44225847721099854, "ae_transition_loss": 1.0013695359230042, "ae_encoder_loss": 0.6237813234329224, "actor_loss": -0.9266677498817444, "actor_target_entropy": -2.0, "actor_entropy": 1.6903239488601685, "alpha_loss": 0.0035213682567700744, "alpha_value": 0.004744080836247848, "duration": 4.6195971965789795, "step": 41274}
{"episode_reward": -8.459662773168645, "episode": 1346.0, "batch_reward": 0.043798189610242844, "critic_loss": 0.6679437011480331, "ae_transition_loss": 1.0557082891464233, "ae_encoder_loss": 0.9125203192234039, "actor_loss": -1.198136806488037, "actor_target_entropy": -2.0, "actor_entropy": 1.7687918543815613, "alpha_loss": 0.003744265763089061, "alpha_value": 0.004740219065875613, "duration": 4.6457202434539795, "step": 41295}
{"episode_reward": -9.182398895426758, "episode": 1347.0, "batch_reward": -0.04966819907228152, "critic_loss": 0.3581880231698354, "ae_transition_loss": 0.947288433710734, "ae_encoder_loss": 0.5698827107747396, "actor_loss": -0.8097469409306844, "actor_target_entropy": -2.0, "actor_entropy": 1.419456919034322, "alpha_loss": 0.0015308823591719072, "alpha_value": 0.004735382665768212, "duration": 6.2194664478302, "step": 41325}
{"episode_reward": -13.499415405972709, "episode": 1348.0, "batch_reward": -0.02114715799689293, "critic_loss": 0.44663554430007935, "ae_transition_loss": 0.9210783243179321, "ae_encoder_loss": 0.5843700170516968, "actor_loss": -0.5935525894165039, "actor_target_entropy": -2.0, "actor_entropy": 1.367915153503418, "alpha_loss": -0.0017336730379611254, "alpha_value": 0.004731908355836563, "duration": 3.204554796218872, "step": 41340}
{"episode_reward": -8.533906855561051, "episode": 1349.0, "batch_reward": 0.003098397981375456, "critic_loss": 0.49047842621803284, "ae_transition_loss": 0.8932039141654968, "ae_encoder_loss": 0.5434808433055878, "actor_loss": -0.972357988357544, "actor_target_entropy": -2.0, "actor_entropy": 1.541231393814087, "alpha_loss": -0.0032119833631440997, "alpha_value": 0.004730035003940803, "duration": 3.3476102352142334, "step": 41355}
{"episode_reward": -4.438915152762444, "episode": 1350.0, "duration": 0.23556923866271973, "step": 41356}
{"episode_reward": -0.4979425157659889, "episode": 1351.0, "batch_reward": 0.013745409126083056, "critic_loss": 0.3647557894388835, "ae_transition_loss": 0.8927356998125712, "ae_encoder_loss": 0.7558997372786204, "actor_loss": -0.9422347545623779, "actor_target_entropy": -2.0, "actor_entropy": 1.9109657605489094, "alpha_loss": -0.0020781148438497135, "alpha_value": 0.004728313199978642, "duration": 49.731740951538086, "step": 41388}
{"episode_reward": -19.913210515572263, "episode": 1352.0, "batch_reward": -0.04938979819417, "critic_loss": 0.6982935667037964, "ae_transition_loss": 0.9388760328292847, "ae_encoder_loss": 0.6244938373565674, "actor_loss": -0.3677748441696167, "actor_target_entropy": -2.0, "actor_entropy": 2.119126319885254, "alpha_loss": 0.00153740169480443, "alpha_value": 0.00472766207173953, "duration": 2.000298023223877, "step": 41397}
{"episode_reward": -5.453783199709778, "episode": 1353.0, "duration": 0.23136377334594727, "step": 41398}
{"episode_reward": -0.4980292052454826, "episode": 1354.0, "batch_reward": -0.028917034389451146, "critic_loss": 0.9639456868171692, "ae_transition_loss": 1.146875023841858, "ae_encoder_loss": 0.5694001317024231, "actor_loss": -0.6579295992851257, "actor_target_entropy": -2.0, "actor_entropy": 2.0940818786621094, "alpha_loss": 0.0020792463328689337, "alpha_value": 0.004727119828080721, "duration": 3.2840237617492676, "step": 41412}
{"episode_reward": -9.359479883467094, "episode": 1355.0, "batch_reward": -0.01643084269016981, "critic_loss": 0.44160497188568115, "ae_transition_loss": 1.5896548628807068, "ae_encoder_loss": 0.5477203875780106, "actor_loss": -0.36518776416778564, "actor_target_entropy": -2.0, "actor_entropy": 1.77428138256073, "alpha_loss": 0.0036114337854087353, "alpha_value": 0.004726093498464225, "duration": 4.803675651550293, "step": 41435}
{"episode_reward": -6.876023604850099, "episode": 1356.0, "duration": 0.23712825775146484, "step": 41436}
{"episode_reward": -0.5224329805195496, "episode": 1357.0, "batch_reward": 0.05956721305847168, "critic_loss": 0.7233015298843384, "ae_transition_loss": 1.321557104587555, "ae_encoder_loss": 0.6652039885520935, "actor_loss": -1.068851351737976, "actor_target_entropy": -2.0, "actor_entropy": 1.313530445098877, "alpha_loss": 0.003046876983717084, "alpha_value": 0.004724584468333351, "duration": 3.6078124046325684, "step": 41452}
{"episode_reward": -7.376952821635841, "episode": 1358.0, "batch_reward": -0.058205559849739075, "critic_loss": 0.6834360361099243, "ae_transition_loss": 0.9766963124275208, "ae_encoder_loss": 0.8908814787864685, "actor_loss": -0.8195140957832336, "actor_target_entropy": -2.0, "actor_entropy": 1.3779489994049072, "alpha_loss": 0.00453121168538928, "alpha_value": 0.00472324561958844, "duration": 3.542398691177368, "step": 41470}
{"episode_reward": -4.528857409026412, "episode": 1359.0, "batch_reward": 0.004986977204680443, "critic_loss": 0.4758094648520152, "ae_transition_loss": 1.2509105602900188, "ae_encoder_loss": 0.7742689847946167, "actor_loss": -0.896864136060079, "actor_target_entropy": -2.0, "actor_entropy": 1.46312681833903, "alpha_loss": 0.004610325830678145, "alpha_value": 0.004720945430649961, "duration": 5.151832818984985, "step": 41494}
{"episode_reward": -6.56809898703147, "episode": 1360.0, "batch_reward": 0.007792087038978934, "critic_loss": 0.5135027468204498, "ae_transition_loss": 1.2131131788094838, "ae_encoder_loss": 0.7178800702095032, "actor_loss": -0.8759082158406576, "actor_target_entropy": -2.0, "actor_entropy": 1.804591526587804, "alpha_loss": 0.0046987669775262475, "alpha_value": 0.004708220710980255, "duration": 25.903865337371826, "step": 41618}
{"episode_reward": -74.46831653127796, "episode": 1361.0, "batch_reward": -0.03742466727271676, "critic_loss": 0.35114091634750366, "ae_transition_loss": 0.9843320548534393, "ae_encoder_loss": 0.6797488033771515, "actor_loss": -0.43516772985458374, "actor_target_entropy": -2.0, "actor_entropy": 1.988279402256012, "alpha_loss": 0.007142056943848729, "alpha_value": 0.004693658426766355, "duration": 40.96363306045532, "step": 41638}
{"episode_reward": -4.888553083764843, "episode": 1362.0, "batch_reward": 0.035843283558885254, "critic_loss": 0.40732061366240185, "ae_transition_loss": 1.3351073265075684, "ae_encoder_loss": 0.508549302816391, "actor_loss": -0.6862985491752625, "actor_target_entropy": -2.0, "actor_entropy": 1.781124512354533, "alpha_loss": 0.005816337497284015, "alpha_value": 0.004687431191199953, "duration": 6.723868370056152, "step": 41670}
{"episode_reward": -12.52969203394238, "episode": 1363.0, "batch_reward": 0.013504795730113983, "critic_loss": 0.7007976174354553, "ae_transition_loss": 1.0403159856796265, "ae_encoder_loss": 0.5290415287017822, "actor_loss": -0.7734122276306152, "actor_target_entropy": -2.0, "actor_entropy": 1.7401959896087646, "alpha_loss": 0.00572551041841507, "alpha_value": 0.004682204559286068, "duration": 0.5732016563415527, "step": 41671}
{"episode_reward": 0.0014712066982145167, "episode": 1364.0, "batch_reward": -0.025049922056496143, "critic_loss": 0.7063126266002655, "ae_transition_loss": 1.3026018738746643, "ae_encoder_loss": 0.3698797821998596, "actor_loss": -0.962296336889267, "actor_target_entropy": -2.0, "actor_entropy": 1.7347960472106934, "alpha_loss": 0.006987840868532658, "alpha_value": 0.004678143689602432, "duration": 5.194335460662842, "step": 41697}
{"episode_reward": -8.593246771868033, "episode": 1365.0, "duration": 0.231705904006958, "step": 41698}
{"episode_reward": -0.17300919321585057, "episode": 1366.0, "batch_reward": -0.014233473688364029, "critic_loss": 0.6591094732284546, "ae_transition_loss": 0.9369181990623474, "ae_encoder_loss": 0.4403570393721263, "actor_loss": -0.7643830180168152, "actor_target_entropy": -2.0, "actor_entropy": 1.5822995503743489, "alpha_loss": 0.007309422207375367, "alpha_value": 0.004670798004570042, "duration": 6.5040223598480225, "step": 41729}
{"episode_reward": -6.465111116391338, "episode": 1367.0, "duration": 0.22383475303649902, "step": 41730}
{"episode_reward": -0.6414250570256965, "episode": 1368.0, "batch_reward": -0.012138591768840948, "critic_loss": 0.534992535909017, "ae_transition_loss": 1.1425718863805134, "ae_encoder_loss": 0.6077027320861816, "actor_loss": -0.8075155715147654, "actor_target_entropy": -2.0, "actor_entropy": 1.6773301164309184, "alpha_loss": 0.006363905733451247, "alpha_value": 0.0046565963741448035, "duration": 11.831726789474487, "step": 41786}
{"episode_reward": -12.360860629977273, "episode": 1369.0, "batch_reward": -0.028230810537934303, "critic_loss": 0.6127167642116547, "ae_transition_loss": 1.0227835476398468, "ae_encoder_loss": 0.5327075570821762, "actor_loss": -0.638011246919632, "actor_target_entropy": -2.0, "actor_entropy": 1.3854402303695679, "alpha_loss": 0.007226768182590604, "alpha_value": 0.004643609713124738, "duration": 4.067852258682251, "step": 41805}
{"episode_reward": -3.450101008348981, "episode": 1370.0, "batch_reward": 0.033283178228884935, "critic_loss": 0.6347427815198898, "ae_transition_loss": 0.9237462133169174, "ae_encoder_loss": 0.5560169070959091, "actor_loss": -1.0217535942792892, "actor_target_entropy": -2.0, "actor_entropy": 1.3816786110401154, "alpha_loss": 0.007675500120967627, "alpha_value": 0.004633436946688822, "duration": 8.591761827468872, "step": 41848}
{"episode_reward": -2.837524910243713, "episode": 1371.0, "batch_reward": -0.01950421743094921, "critic_loss": 0.5507930517196655, "ae_transition_loss": 1.0212275981903076, "ae_encoder_loss": 0.6751551628112793, "actor_loss": -0.9040566682815552, "actor_target_entropy": -2.0, "actor_entropy": 1.2026238441467285, "alpha_loss": 0.005520011764019728, "alpha_value": 0.004624640309544583, "duration": 80.15981650352478, "step": 41857}
{"episode_reward": -3.2690915714528113, "episode": 1372.0, "batch_reward": -0.0011432478204369545, "critic_loss": 1.1586509943008423, "ae_transition_loss": 0.7767004370689392, "ae_encoder_loss": 0.5174909830093384, "actor_loss": -0.7359596490859985, "actor_target_entropy": -2.0, "actor_entropy": 0.8072412014007568, "alpha_loss": 0.004754513502120972, "alpha_value": 0.0046210956663404155, "duration": 2.087827444076538, "step": 41867}
{"episode_reward": -5.441242644720321, "episode": 1373.0, "batch_reward": -0.014116901283462843, "critic_loss": 1.1150386730829875, "ae_transition_loss": 1.172354280948639, "ae_encoder_loss": 0.6427858670552572, "actor_loss": -0.8079345424969991, "actor_target_entropy": -2.0, "actor_entropy": 2.0293109814325967, "alpha_loss": -0.0004202142930201565, "alpha_value": 0.004614551551893532, "duration": 6.543703317642212, "step": 41899}
{"episode_reward": -25.76124759541391, "episode": 1374.0, "duration": 0.24380922317504883, "step": 41900}
{"episode_reward": -0.4031615235293151, "episode": 1375.0, "batch_reward": -0.017222979106009007, "critic_loss": 0.3463376760482788, "ae_transition_loss": 1.2762634754180908, "ae_encoder_loss": 0.6142854690551758, "actor_loss": -0.8185461759567261, "actor_target_entropy": -2.0, "actor_entropy": 2.1699576377868652, "alpha_loss": -0.002913480391725898, "alpha_value": 0.004608167538686488, "duration": 3.807767391204834, "step": 41917}
{"episode_reward": -11.853045935615063, "episode": 1376.0, "batch_reward": 0.030496691539883613, "critic_loss": 0.5741116613149643, "ae_transition_loss": 1.0460638642311095, "ae_encoder_loss": 0.9561895370483399, "actor_loss": -0.8617298483848572, "actor_target_entropy": -2.0, "actor_entropy": 1.20652596950531, "alpha_loss": 0.004032149573322386, "alpha_value": 0.004602304775161884, "duration": 10.513333320617676, "step": 41967}
{"episode_reward": -25.20269772598039, "episode": 1377.0, "batch_reward": -0.016593877226114273, "critic_loss": 0.691998153924942, "ae_transition_loss": 1.0097133219242096, "ae_encoder_loss": 0.6423285603523254, "actor_loss": -1.102877140045166, "actor_target_entropy": -2.0, "actor_entropy": 1.2188840508460999, "alpha_loss": 0.004115795833058655, "alpha_value": 0.0045960603993710795, "duration": 3.954404830932617, "step": 41986}
{"episode_reward": -2.503736003646271, "episode": 1378.0, "duration": 0.23145675659179688, "step": 41987}
{"episode_reward": -0.5149201858932609, "episode": 1379.0, "batch_reward": -0.002845853567123413, "critic_loss": 0.32882565756638843, "ae_transition_loss": 1.1344496011734009, "ae_encoder_loss": 0.967495858669281, "actor_loss": -0.6989459792772929, "actor_target_entropy": -2.0, "actor_entropy": 1.4048860470453899, "alpha_loss": 0.005443318436543147, "alpha_value": 0.004591028140917358, "duration": 6.116189956665039, "step": 42016}
{"episode_reward": -9.880059746092362, "episode": 1380.0, "batch_reward": -0.0255028884857893, "critic_loss": 0.6140850782394409, "ae_transition_loss": 0.9615811109542847, "ae_encoder_loss": 0.84189772605896, "actor_loss": -1.1326239109039307, "actor_target_entropy": -2.0, "actor_entropy": 1.7388628721237183, "alpha_loss": 0.004972167778760195, "alpha_value": 0.0045867346648162536, "duration": 2.031667709350586, "step": 42025}
{"episode_reward": -2.978974613817812, "episode": 1381.0, "batch_reward": -0.024481515400111675, "critic_loss": 1.2923478484153748, "ae_transition_loss": 1.0424652397632599, "ae_encoder_loss": 0.7105942219495773, "actor_loss": -0.8138964474201202, "actor_target_entropy": -2.0, "actor_entropy": 1.908461570739746, "alpha_loss": 0.006309133721515536, "alpha_value": 0.004583296850414635, "duration": 32.036619901657104, "step": 42050}
{"episode_reward": -8.348815020932092, "episode": 1382.0, "batch_reward": 0.025429442059248686, "critic_loss": 0.5943269938230514, "ae_transition_loss": 1.0832762718200684, "ae_encoder_loss": 0.8191502809524536, "actor_loss": -0.9237600088119506, "actor_target_entropy": -2.0, "actor_entropy": 1.9074624061584473, "alpha_loss": 0.006992970639839768, "alpha_value": 0.0045665452597527315, "duration": 19.54201078414917, "step": 42144}
{"episode_reward": -54.036079660090564, "episode": 1383.0, "batch_reward": -0.044716330245137215, "critic_loss": 0.41479937732219696, "ae_transition_loss": 1.0336195528507233, "ae_encoder_loss": 0.8333385586738586, "actor_loss": -0.8392496705055237, "actor_target_entropy": -2.0, "actor_entropy": 1.6055272221565247, "alpha_loss": 0.002415038034087047, "alpha_value": 0.004547649137234824, "duration": 3.9372060298919678, "step": 42161}
{"episode_reward": -6.359042302631069, "episode": 1384.0, "batch_reward": 0.027088030707091093, "critic_loss": 0.6236050128936768, "ae_transition_loss": 1.283132255077362, "ae_encoder_loss": 0.6379920542240143, "actor_loss": -0.7831920683383942, "actor_target_entropy": -2.0, "actor_entropy": 1.6791710257530212, "alpha_loss": 0.001315994537435472, "alpha_value": 0.00454209506580395, "duration": 4.299777507781982, "step": 42182}
{"episode_reward": -7.112908672546342, "episode": 1385.0, "duration": 1.527442455291748, "step": 42190}
{"episode_reward": -3.3214015886671318, "episode": 1386.0, "batch_reward": -0.0040526920929551125, "critic_loss": 0.5028773248195648, "ae_transition_loss": 1.3355006575584412, "ae_encoder_loss": 1.3315615355968475, "actor_loss": -0.867002934217453, "actor_target_entropy": -2.0, "actor_entropy": 1.8802980184555054, "alpha_loss": 0.0014511977205984294, "alpha_value": 0.0045373711787146985, "duration": 3.17393159866333, "step": 42205}
{"episode_reward": -5.915223276853166, "episode": 1387.0, "batch_reward": 0.0013096518814563751, "critic_loss": 0.5331357754766941, "ae_transition_loss": 1.187816858291626, "ae_encoder_loss": 0.7110097855329514, "actor_loss": -0.918327234685421, "actor_target_entropy": -2.0, "actor_entropy": 1.5256249010562897, "alpha_loss": 0.0037343925796449184, "alpha_value": 0.004526812948964988, "duration": 15.66248345375061, "step": 42284}
{"episode_reward": -43.13306185017903, "episode": 1388.0, "batch_reward": 0.00028765760362148285, "critic_loss": 0.9873455166816711, "ae_transition_loss": 1.263124942779541, "ae_encoder_loss": 0.6390645802021027, "actor_loss": -0.6669670045375824, "actor_target_entropy": -2.0, "actor_entropy": 1.3997609615325928, "alpha_loss": 0.004401803715154529, "alpha_value": 0.004516467088893861, "duration": 4.690990686416626, "step": 42306}
{"episode_reward": -7.022488895512694, "episode": 1389.0, "duration": 0.21973824501037598, "step": 42307}
{"episode_reward": -0.49740378279654174, "episode": 1390.0, "batch_reward": -0.10852823406457901, "critic_loss": 0.36108657717704773, "ae_transition_loss": 0.9885552525520325, "ae_encoder_loss": 0.847105085849762, "actor_loss": -0.4179551303386688, "actor_target_entropy": -2.0, "actor_entropy": 1.4469213485717773, "alpha_loss": 0.005477943457663059, "alpha_value": 0.004513450196475026, "duration": 1.9359095096588135, "step": 42316}
{"episode_reward": -3.3286725817803218, "episode": 1391.0, "batch_reward": -0.06384457647800446, "critic_loss": 0.39732617139816284, "ae_transition_loss": 0.9322112798690796, "ae_encoder_loss": 0.4156619906425476, "actor_loss": -0.6267369985580444, "actor_target_entropy": -2.0, "actor_entropy": 1.3798165321350098, "alpha_loss": 0.0044358475133776665, "alpha_value": 0.004511351804350994, "duration": 38.55965185165405, "step": 42328}
{"episode_reward": -5.158313217469904, "episode": 1392.0, "batch_reward": -0.005611926317214966, "critic_loss": 0.6882426738739014, "ae_transition_loss": 1.1650283932685852, "ae_encoder_loss": 0.5429150462150574, "actor_loss": -0.85271817445755, "actor_target_entropy": -2.0, "actor_entropy": 1.546170711517334, "alpha_loss": 0.004199110437184572, "alpha_value": 0.004508155659051856, "duration": 3.318185806274414, "step": 42343}
{"episode_reward": -7.642660376275762, "episode": 1393.0, "batch_reward": -0.00987463304772973, "critic_loss": 0.7320078611373901, "ae_transition_loss": 1.1194885075092316, "ae_encoder_loss": 0.5416962951421738, "actor_loss": -1.1224453449249268, "actor_target_entropy": -2.0, "actor_entropy": 1.5959098935127258, "alpha_loss": 0.001768226531567052, "alpha_value": 0.004503977092854555, "duration": 4.12500524520874, "step": 42361}
{"episode_reward": -7.270143293472965, "episode": 1394.0, "batch_reward": 0.004125770181417465, "critic_loss": 0.40656983852386475, "ae_transition_loss": 0.8294187784194946, "ae_encoder_loss": 0.4973464906215668, "actor_loss": -0.725826621055603, "actor_target_entropy": -2.0, "actor_entropy": 1.6000165939331055, "alpha_loss": 0.0028870233800262213, "alpha_value": 0.004501096148862368, "duration": 3.408384323120117, "step": 42378}
{"episode_reward": -8.238226185313298, "episode": 1395.0, "batch_reward": -0.02345698792487383, "critic_loss": 0.6247456073760986, "ae_transition_loss": 0.9606232345104218, "ae_encoder_loss": 0.6822121888399124, "actor_loss": -0.9786795675754547, "actor_target_entropy": -2.0, "actor_entropy": 1.5812524557113647, "alpha_loss": 0.0026652616215869784, "alpha_value": 0.00449830535799471, "duration": 3.7637317180633545, "step": 42396}
{"episode_reward": -8.100696362159912, "episode": 1396.0, "batch_reward": -0.0038212500512599945, "critic_loss": 0.2993564208348592, "ae_transition_loss": 0.9343884388605753, "ae_encoder_loss": 0.5742461085319519, "actor_loss": -0.7715117136637369, "actor_target_entropy": -2.0, "actor_entropy": 1.709668795267741, "alpha_loss": 0.0035076523199677467, "alpha_value": 0.004493844313433345, "duration": 5.50830340385437, "step": 42421}
{"episode_reward": -7.77784200016655, "episode": 1397.0, "batch_reward": -0.038894880563020706, "critic_loss": 0.26336121559143066, "ae_transition_loss": 0.6509953737258911, "ae_encoder_loss": 0.5409120321273804, "actor_loss": -0.4426516890525818, "actor_target_entropy": -2.0, "actor_entropy": 1.8209991455078125, "alpha_loss": 0.006238805130124092, "alpha_value": 0.00449032412715475, "duration": 2.6196765899658203, "step": 42435}
{"episode_reward": -3.992287221950542, "episode": 1398.0, "duration": 0.23950910568237305, "step": 42436}
{"episode_reward": -0.9952623844146729, "episode": 1399.0, "batch_reward": 0.005112056906979818, "critic_loss": 0.622976697408236, "ae_transition_loss": 1.0423152721845186, "ae_encoder_loss": 0.6984494282649114, "actor_loss": -0.8594556267444904, "actor_target_entropy": -2.0, "actor_entropy": 1.0049313306808472, "alpha_loss": 0.004328640428586648, "alpha_value": 0.004474871400389964, "duration": 25.788817167282104, "step": 42563}
{"episode_reward": -22.474856933269706, "episode": 1400.0, "batch_reward": 0.03676045686006546, "critic_loss": 0.7119566798210144, "ae_transition_loss": 0.9101935625076294, "ae_encoder_loss": 0.8462855219841003, "actor_loss": -0.4573865532875061, "actor_target_entropy": -2.0, "actor_entropy": 0.7412101626396179, "alpha_loss": 0.00417710654437542, "alpha_value": 0.0044594289793560525, "duration": 2.794537305831909, "step": 42576}
{"episode_reward": -2.265647789227776, "episode": 1401.0, "batch_reward": -0.06275289878249168, "critic_loss": 0.8839104771614075, "ae_transition_loss": 1.0215562880039215, "ae_encoder_loss": 0.8074398636817932, "actor_loss": -0.5417909622192383, "actor_target_entropy": -2.0, "actor_entropy": 0.8381614685058594, "alpha_loss": 0.0056619890965521336, "alpha_value": 0.004456358901536672, "duration": 93.37575507164001, "step": 42600}
{"episode_reward": -4.430967080684344, "episode": 1402.0, "batch_reward": 0.020506930770352483, "critic_loss": 0.43180009722709656, "ae_transition_loss": 1.030012607574463, "ae_encoder_loss": 0.6917954385280609, "actor_loss": -0.8307710289955139, "actor_target_entropy": -2.0, "actor_entropy": 0.9636450409889221, "alpha_loss": 0.005601225886493921, "alpha_value": 0.004451967504397211, "duration": 3.619844675064087, "step": 42617}
{"episode_reward": -4.162915296973358, "episode": 1403.0, "duration": 0.2276473045349121, "step": 42618}
{"episode_reward": -0.21550766639116037, "episode": 1404.0, "batch_reward": 0.014807829819619655, "critic_loss": 0.9636624693870545, "ae_transition_loss": 1.1828365087509156, "ae_encoder_loss": 0.5735188484191894, "actor_loss": -0.9890655398368835, "actor_target_entropy": -2.0, "actor_entropy": 1.3769654989242555, "alpha_loss": 0.007282171212136745, "alpha_value": 0.0044434179971115624, "duration": 10.460153579711914, "step": 42668}
{"episode_reward": -5.138806717197657, "episode": 1405.0, "batch_reward": 0.019059554939823493, "critic_loss": 0.5821517620767865, "ae_transition_loss": 0.9578333582196917, "ae_encoder_loss": 0.626887572663171, "actor_loss": -0.9930005967617035, "actor_target_entropy": -2.0, "actor_entropy": 1.386543597493853, "alpha_loss": -0.0007686234977362412, "alpha_value": 0.004426472069677852, "duration": 14.895689725875854, "step": 42738}
{"episode_reward": -48.70666049138734, "episode": 1406.0, "batch_reward": -0.014792652614414693, "critic_loss": 0.5349543988704681, "ae_transition_loss": 1.350097131729126, "ae_encoder_loss": 0.6430543720722198, "actor_loss": -0.6103384256362915, "actor_target_entropy": -2.0, "actor_entropy": 2.4075128555297853, "alpha_loss": -0.005097870039753616, "alpha_value": 0.004419067897474713, "duration": 10.047847270965576, "step": 42787}
{"episode_reward": -33.18121277007717, "episode": 1407.0, "batch_reward": -0.043950616692503296, "critic_loss": 0.7079843084017435, "ae_transition_loss": 1.4333968957265217, "ae_encoder_loss": 0.6138212780157725, "actor_loss": -0.6546186804771423, "actor_target_entropy": -2.0, "actor_entropy": 1.7092307806015015, "alpha_loss": 0.005691966041922569, "alpha_value": 0.004420744710968857, "duration": 5.403561115264893, "step": 42812}
{"episode_reward": -13.935696921940451, "episode": 1408.0, "batch_reward": -0.012171168345957994, "critic_loss": 0.6114013269543648, "ae_transition_loss": 1.4837074875831604, "ae_encoder_loss": 0.6664704829454422, "actor_loss": -0.8662941455841064, "actor_target_entropy": -2.0, "actor_entropy": 1.869583249092102, "alpha_loss": 0.0067960883025079966, "alpha_value": 0.004418769595011509, "duration": 8.412728786468506, "step": 42852}
{"episode_reward": -22.18287552397341, "episode": 1409.0, "batch_reward": -0.03363169729709625, "critic_loss": 0.4296514689922333, "ae_transition_loss": 1.2284035086631775, "ae_encoder_loss": 0.6371392607688904, "actor_loss": -0.8535540103912354, "actor_target_entropy": -2.0, "actor_entropy": 1.9933916330337524, "alpha_loss": 0.00589810311794281, "alpha_value": 0.004414687724018523, "duration": 4.4635796546936035, "step": 42874}
{"episode_reward": -7.3571538721033765, "episode": 1410.0, "batch_reward": -0.023333115503191948, "critic_loss": 0.6877308785915375, "ae_transition_loss": 1.3158636808395385, "ae_encoder_loss": 0.8075395345687866, "actor_loss": -0.7099393367767334, "actor_target_entropy": -2.0, "actor_entropy": 1.753931450843811, "alpha_loss": 0.005631512217223644, "alpha_value": 0.004407802538789522, "duration": 10.277270793914795, "step": 42924}
{"episode_reward": -19.897803571809078, "episode": 1411.0, "batch_reward": 0.04451162243882815, "critic_loss": 1.1288517713546753, "ae_transition_loss": 1.6223068634668987, "ae_encoder_loss": 0.8911845684051514, "actor_loss": -1.1550554831822712, "actor_target_entropy": -2.0, "actor_entropy": 1.8746219078699748, "alpha_loss": 0.005442900427927573, "alpha_value": 0.004398857218922086, "duration": 55.95760107040405, "step": 42958}
{"episode_reward": -18.163765381531697, "episode": 1412.0, "batch_reward": -0.04333837081988653, "critic_loss": 0.809047798315684, "ae_transition_loss": 1.1395300229390461, "ae_encoder_loss": 0.6943250894546509, "actor_loss": -0.5884114901224772, "actor_target_entropy": -2.0, "actor_entropy": 1.9726013739903767, "alpha_loss": 0.0063982427430649596, "alpha_value": 0.004391600567542629, "duration": 5.915988922119141, "step": 42987}
{"episode_reward": -19.98344378489192, "episode": 1413.0, "batch_reward": -0.060003433376550674, "critic_loss": 1.3471509218215942, "ae_transition_loss": 1.2043207883834839, "ae_encoder_loss": 0.7199022769927979, "actor_loss": -0.5183517336845398, "actor_target_entropy": -2.0, "actor_entropy": 1.7514344453811646, "alpha_loss": 0.006827475968748331, "alpha_value": 0.004386396986750361, "duration": 2.6040079593658447, "step": 43000}
{"episode_reward": -3.979119883863633, "episode": 1414.0, "batch_reward": -0.03785070156057676, "critic_loss": 0.5037276744842529, "ae_transition_loss": 1.7663041353225708, "ae_encoder_loss": 0.775780995686849, "actor_loss": -0.7755827705065409, "actor_target_entropy": -2.0, "actor_entropy": 1.7018186648686726, "alpha_loss": 0.00651340822999676, "alpha_value": 0.004380759158272682, "duration": 5.699561357498169, "step": 43028}
{"episode_reward": -5.720769619103366, "episode": 1415.0, "batch_reward": -0.05549425631761551, "critic_loss": 0.5657567381858826, "ae_transition_loss": 1.3825677633285522, "ae_encoder_loss": 0.7570357918739319, "actor_loss": -0.8304803967475891, "actor_target_entropy": -2.0, "actor_entropy": 1.9622297286987305, "alpha_loss": 0.005233965814113617, "alpha_value": 0.004374963781365875, "duration": 2.123711109161377, "step": 43038}
{"episode_reward": -5.3469535303675615, "episode": 1416.0, "batch_reward": -0.04098706506192684, "critic_loss": 0.4899919480085373, "ae_transition_loss": 1.367855727672577, "ae_encoder_loss": 0.6448466777801514, "actor_loss": -0.7034173607826233, "actor_target_entropy": -2.0, "actor_entropy": 2.041494607925415, "alpha_loss": 0.0068392211105674505, "alpha_value": 0.004370620822068807, "duration": 3.6520397663116455, "step": 43056}
{"episode_reward": -6.945987758808164, "episode": 1417.0, "batch_reward": -0.05338281082610289, "critic_loss": 0.5307508210341135, "ae_transition_loss": 1.2975263198216755, "ae_encoder_loss": 0.6925995151201884, "actor_loss": -0.7197200655937195, "actor_target_entropy": -2.0, "actor_entropy": 2.0199579000473022, "alpha_loss": 0.004650347090015809, "alpha_value": 0.004363255052966559, "duration": 6.0083489418029785, "step": 43084}
{"episode_reward": -11.492171906800667, "episode": 1418.0, "batch_reward": -0.0318816639482975, "critic_loss": 0.5071258544921875, "ae_transition_loss": 1.39225435256958, "ae_encoder_loss": 0.7106989622116089, "actor_loss": -0.830139696598053, "actor_target_entropy": -2.0, "actor_entropy": 1.967759609222412, "alpha_loss": 0.004418049938976765, "alpha_value": 0.00435754194640631, "duration": 2.7150652408599854, "step": 43096}
{"episode_reward": -2.1276601687177776, "episode": 1419.0, "batch_reward": -0.03804313763976097, "critic_loss": 0.539413571357727, "ae_transition_loss": 1.3376946449279785, "ae_encoder_loss": 0.6695126295089722, "actor_loss": -1.0313982963562012, "actor_target_entropy": -2.0, "actor_entropy": 1.8410731554031372, "alpha_loss": 0.003792029805481434, "alpha_value": 0.00435475941410679, "duration": 2.8759210109710693, "step": 43110}
{"episode_reward": -7.08270669911937, "episode": 1420.0, "batch_reward": -0.020152592565864325, "critic_loss": 1.027695894241333, "ae_transition_loss": 1.499456524848938, "ae_encoder_loss": 0.796942263841629, "actor_loss": -0.9887703657150269, "actor_target_entropy": -2.0, "actor_entropy": 1.5471343994140625, "alpha_loss": 0.004583334783092141, "alpha_value": 0.0043507225170576255, "duration": 3.5877485275268555, "step": 43128}
{"episode_reward": -7.320021699672905, "episode": 1421.0, "batch_reward": 0.005362851545214653, "critic_loss": 0.4970345397790273, "ae_transition_loss": 1.2863279581069946, "ae_encoder_loss": 0.6405778924624125, "actor_loss": -0.7669041554133097, "actor_target_entropy": -2.0, "actor_entropy": 1.610687255859375, "alpha_loss": 0.005319538215796153, "alpha_value": 0.004344067157179474, "duration": 40.314409017562866, "step": 43151}
{"episode_reward": -8.452181102182983, "episode": 1422.0, "duration": 0.9171230792999268, "step": 43156}
{"episode_reward": -2.2377791416431387, "episode": 1423.0, "batch_reward": -0.0011513902184863885, "critic_loss": 0.5846684873104095, "ae_transition_loss": 1.232947548230489, "ae_encoder_loss": 0.5402158300081888, "actor_loss": -0.6784219443798065, "actor_target_entropy": -2.0, "actor_entropy": 1.8903300364812214, "alpha_loss": 0.00492634034405152, "alpha_value": 0.004336048997507488, "duration": 7.0440354347229, "step": 43190}
{"episode_reward": -12.449328198276719, "episode": 1424.0, "batch_reward": 0.0033334060572087765, "critic_loss": 0.329963078101476, "ae_transition_loss": 1.2282324234644573, "ae_encoder_loss": 0.5324666500091553, "actor_loss": -0.8726979692776998, "actor_target_entropy": -2.0, "actor_entropy": 1.996716817220052, "alpha_loss": 0.004710811500747998, "alpha_value": 0.0043282331424520345, "duration": 6.247676849365234, "step": 43220}
{"episode_reward": -11.577678267041914, "episode": 1425.0, "batch_reward": 0.016008820850402117, "critic_loss": 0.44249429553747177, "ae_transition_loss": 1.1485829949378967, "ae_encoder_loss": 0.6361424624919891, "actor_loss": -0.7764531299471855, "actor_target_entropy": -2.0, "actor_entropy": 1.9407381415367126, "alpha_loss": 0.0041265812469646335, "alpha_value": 0.0043194982158013435, "duration": 8.175864219665527, "step": 43258}
{"episode_reward": -18.679612995549228, "episode": 1426.0, "batch_reward": -0.03148610843345523, "critic_loss": 0.8793222308158875, "ae_transition_loss": 1.0340312520662944, "ae_encoder_loss": 0.5217350622018179, "actor_loss": -0.748033881187439, "actor_target_entropy": -2.0, "actor_entropy": 2.0364697774251304, "alpha_loss": 0.004635602080573638, "alpha_value": 0.004310947334895773, "duration": 5.46997594833374, "step": 43284}
{"episode_reward": -10.781223803933441, "episode": 1427.0, "duration": 0.2331092357635498, "step": 43285}
{"episode_reward": -0.3378818948715552, "episode": 1428.0, "batch_reward": -0.03911043703556061, "critic_loss": 0.27186131477355957, "ae_transition_loss": 0.8660164475440979, "ae_encoder_loss": 0.5281432867050171, "actor_loss": -0.6725671291351318, "actor_target_entropy": -2.0, "actor_entropy": 1.8373687267303467, "alpha_loss": 0.004049364477396011, "alpha_value": 0.004306028340871178, "duration": 3.01204776763916, "step": 43300}
{"episode_reward": -7.17212972314659, "episode": 1429.0, "batch_reward": -0.004403652157634497, "critic_loss": 0.4637197181582451, "ae_transition_loss": 1.0736165195703506, "ae_encoder_loss": 0.6121558248996735, "actor_loss": -0.9115055203437805, "actor_target_entropy": -2.0, "actor_entropy": 1.6149255633354187, "alpha_loss": 0.002276452236401383, "alpha_value": 0.004300181651725422, "duration": 8.151973247528076, "step": 43339}
{"episode_reward": -20.710164866999502, "episode": 1430.0, "batch_reward": -0.009272572894891104, "critic_loss": 0.5479389826456705, "ae_transition_loss": 1.3378280798594158, "ae_encoder_loss": 0.65416552623113, "actor_loss": -0.7066376606623331, "actor_target_entropy": -2.0, "actor_entropy": 1.66925315062205, "alpha_loss": 0.0019458143506199121, "alpha_value": 0.004293113043079156, "duration": 4.87409234046936, "step": 43361}
{"episode_reward": -9.248645823801466, "episode": 1431.0, "batch_reward": 0.02368953637778759, "critic_loss": 0.5421140789985657, "ae_transition_loss": 1.038181334733963, "ae_encoder_loss": 0.6104320883750916, "actor_loss": -0.8428142368793488, "actor_target_entropy": -2.0, "actor_entropy": 1.3630449175834656, "alpha_loss": 0.0011859811638714746, "alpha_value": 0.004288831716712406, "duration": 39.6783664226532, "step": 43384}
{"episode_reward": -8.110919456562794, "episode": 1432.0, "batch_reward": 0.02059321478009224, "critic_loss": 0.37237048149108887, "ae_transition_loss": 1.4112273454666138, "ae_encoder_loss": 0.6377261281013489, "actor_loss": -0.6510777473449707, "actor_target_entropy": -2.0, "actor_entropy": 1.227762222290039, "alpha_loss": 0.0013423592317849398, "alpha_value": 0.00428656525804658, "duration": 2.7150309085845947, "step": 43396}
{"episode_reward": -6.409898475180125, "episode": 1433.0, "batch_reward": 0.007779379064838092, "critic_loss": 0.45716074109077454, "ae_transition_loss": 0.9633267720540365, "ae_encoder_loss": 0.6555474996566772, "actor_loss": -0.8695153792699178, "actor_target_entropy": -2.0, "actor_entropy": 1.3957237402598064, "alpha_loss": 0.0006684442632831633, "alpha_value": 0.004283942952119357, "duration": 5.8737146854400635, "step": 43424}
{"episode_reward": -15.482650726772784, "episode": 1434.0, "batch_reward": -0.020758303813636303, "critic_loss": 0.5730075836181641, "ae_transition_loss": 2.143850803375244, "ae_encoder_loss": 0.6307516694068909, "actor_loss": -0.5138785392045975, "actor_target_entropy": -2.0, "actor_entropy": 1.9832200407981873, "alpha_loss": 0.0029663044260814786, "alpha_value": 0.004281054558192823, "duration": 5.3318774700164795, "step": 43449}
{"episode_reward": -12.083966841020946, "episode": 1435.0, "batch_reward": 0.0224766672278444, "critic_loss": 0.4669433186451594, "ae_transition_loss": 1.4983741839726765, "ae_encoder_loss": 0.7696638305981954, "actor_loss": -0.871103972196579, "actor_target_entropy": -2.0, "actor_entropy": 2.0251389543215432, "alpha_loss": 0.0031247844841952124, "alpha_value": 0.004276020614219417, "duration": 12.68974232673645, "step": 43510}
{"episode_reward": -39.38392406054834, "episode": 1436.0, "batch_reward": 0.016297502908855677, "critic_loss": 0.8736208081245422, "ae_transition_loss": 1.3687324523925781, "ae_encoder_loss": 0.48024097830057144, "actor_loss": -1.095870390534401, "actor_target_entropy": -2.0, "actor_entropy": 1.6558898985385895, "alpha_loss": 0.002436101669445634, "alpha_value": 0.004269219771816452, "duration": 7.252223253250122, "step": 43544}
{"episode_reward": -18.246359765618283, "episode": 1437.0, "batch_reward": -0.08518214523792267, "critic_loss": 0.5615646839141846, "ae_transition_loss": 1.2340065240859985, "ae_encoder_loss": 0.40434396266937256, "actor_loss": -0.7159319519996643, "actor_target_entropy": -2.0, "actor_entropy": 1.3453710079193115, "alpha_loss": 0.0020555800292640924, "alpha_value": 0.004265857722613485, "duration": 2.827209234237671, "step": 43558}
{"episode_reward": -7.383604926192572, "episode": 1438.0, "batch_reward": 0.02711666002869606, "critic_loss": 0.8068415522575378, "ae_transition_loss": 1.0986754894256592, "ae_encoder_loss": 0.6609603762626648, "actor_loss": -0.7948393821716309, "actor_target_entropy": -2.0, "actor_entropy": 1.1022380590438843, "alpha_loss": 0.0013279016129672527, "alpha_value": 0.00426456392050365, "duration": 2.4238247871398926, "step": 43570}
{"episode_reward": -4.165320336215899, "episode": 1439.0, "batch_reward": -0.02478969655930996, "critic_loss": 0.448335736989975, "ae_transition_loss": 1.076560616493225, "ae_encoder_loss": 0.4581223130226135, "actor_loss": -0.6616511940956116, "actor_target_entropy": -2.0, "actor_entropy": 0.9589623212814331, "alpha_loss": 0.0008885899442248046, "alpha_value": 0.004263330875284289, "duration": 0.5889856815338135, "step": 43571}
{"episode_reward": -0.05291824115954841, "episode": 1440.0, "batch_reward": -0.016567040234804153, "critic_loss": 0.4458073377609253, "ae_transition_loss": 1.0251208543777466, "ae_encoder_loss": 0.5000765919685364, "actor_loss": -0.8547166585922241, "actor_target_entropy": -2.0, "actor_entropy": 0.9136927127838135, "alpha_loss": -0.0005890942411497235, "alpha_value": 0.0042621751128901625, "duration": 2.6346850395202637, "step": 43585}
{"episode_reward": -6.8952222286096125, "episode": 1441.0, "batch_reward": -0.10645900666713715, "critic_loss": 0.5944288372993469, "ae_transition_loss": 1.074154019355774, "ae_encoder_loss": 0.7252244353294373, "actor_loss": -0.5301624536514282, "actor_target_entropy": -2.0, "actor_entropy": 1.1358530521392822, "alpha_loss": -0.00019738427363336086, "alpha_value": 0.0042611650224606695, "duration": 47.43171167373657, "step": 43599}
{"episode_reward": -6.819613960705242, "episode": 1442.0, "batch_reward": -0.0354273309931159, "critic_loss": 0.691243439912796, "ae_transition_loss": 1.0188129246234894, "ae_encoder_loss": 0.6651023924350739, "actor_loss": -0.9070238471031189, "actor_target_entropy": -2.0, "actor_entropy": 1.3468595147132874, "alpha_loss": -0.0012663275992963463, "alpha_value": 0.004259907674870391, "duration": 3.831801414489746, "step": 43617}
{"episode_reward": -8.781281444082024, "episode": 1443.0, "batch_reward": -0.06582944840192795, "critic_loss": 0.36294734477996826, "ae_transition_loss": 0.8766653537750244, "ae_encoder_loss": 0.8215640783309937, "actor_loss": -0.6982036828994751, "actor_target_entropy": -2.0, "actor_entropy": 1.5912082195281982, "alpha_loss": -0.0011252284748479724, "alpha_value": 0.0042589420136908045, "duration": 2.851982593536377, "step": 43630}
{"episode_reward": -5.700518460349582, "episode": 1444.0, "batch_reward": -0.010942148510366678, "critic_loss": 0.6047927886247635, "ae_transition_loss": 1.001553475856781, "ae_encoder_loss": 0.8991908431053162, "actor_loss": -0.89625084400177, "actor_target_entropy": -2.0, "actor_entropy": 1.8240683674812317, "alpha_loss": -0.001296827627811581, "alpha_value": 0.004258266129033929, "duration": 3.095790386199951, "step": 43644}
{"episode_reward": -5.330025385227232, "episode": 1445.0, "batch_reward": 0.00672109704464674, "critic_loss": 0.5121247842907906, "ae_transition_loss": 1.261718362569809, "ae_encoder_loss": 0.7613923251628876, "actor_loss": -0.600843995809555, "actor_target_entropy": -2.0, "actor_entropy": 1.8955342173576355, "alpha_loss": -3.879671567119658e-05, "alpha_value": 0.004257676034290203, "duration": 5.2475810050964355, "step": 43669}
{"episode_reward": -9.197555368616138, "episode": 1446.0, "batch_reward": -0.01757689006626606, "critic_loss": 0.8550688028335571, "ae_transition_loss": 1.4752468466758728, "ae_encoder_loss": 0.6841081976890564, "actor_loss": -0.7393534481525421, "actor_target_entropy": -2.0, "actor_entropy": 1.764667570590973, "alpha_loss": 0.0020157650869805366, "alpha_value": 0.004257155516034175, "duration": 3.471764326095581, "step": 43686}
{"episode_reward": -7.42311947700099, "episode": 1447.0, "batch_reward": -0.01173121714964509, "critic_loss": 0.5095567852258682, "ae_transition_loss": 1.069061055779457, "ae_encoder_loss": 0.8176475167274475, "actor_loss": -0.704192690551281, "actor_target_entropy": -2.0, "actor_entropy": 1.84093576669693, "alpha_loss": 0.0027070624055340886, "alpha_value": 0.004255907356284451, "duration": 7.706847667694092, "step": 43721}
{"episode_reward": -14.065324961748999, "episode": 1448.0, "batch_reward": -0.020310501257578533, "critic_loss": 0.5084415276845297, "ae_transition_loss": 1.2358378171920776, "ae_encoder_loss": 1.2055919567743938, "actor_loss": -0.7983503937721252, "actor_target_entropy": -2.0, "actor_entropy": 2.0636564095815024, "alpha_loss": 0.004155186237767339, "alpha_value": 0.004253403705162573, "duration": 7.308963060379028, "step": 43756}
{"episode_reward": -17.01758810928445, "episode": 1449.0, "batch_reward": -0.04797380045056343, "critic_loss": 0.50699482858181, "ae_transition_loss": 1.269692838191986, "ae_encoder_loss": 0.898719310760498, "actor_loss": -0.5722338110208511, "actor_target_entropy": -2.0, "actor_entropy": 2.0699336528778076, "alpha_loss": 0.005023639649152756, "alpha_value": 0.004250693329805412, "duration": 3.632929801940918, "step": 43772}
{"episode_reward": -8.247943559885908, "episode": 1450.0, "batch_reward": 0.03178378939628601, "critic_loss": 0.47157102823257446, "ae_transition_loss": 1.0814082622528076, "ae_encoder_loss": 0.6440953016281128, "actor_loss": -1.2132055759429932, "actor_target_entropy": -2.0, "actor_entropy": 1.8326656818389893, "alpha_loss": 0.00412987545132637, "alpha_value": 0.004248684149431313, "duration": 3.6627390384674072, "step": 43790}
{"episode_reward": -9.563087244568491, "episode": 1451.0, "batch_reward": -0.05782037973403931, "critic_loss": 0.8919952511787415, "ae_transition_loss": 1.6767022609710693, "ae_encoder_loss": 0.7739083170890808, "actor_loss": -0.860612154006958, "actor_target_entropy": -2.0, "actor_entropy": 1.773833155632019, "alpha_loss": 0.0053010908886790276, "alpha_value": 0.004247207768620427, "duration": 39.69969177246094, "step": 43799}
{"episode_reward": -4.829817095297073, "episode": 1452.0, "batch_reward": -0.0005806451663374901, "critic_loss": 0.5326853096485138, "ae_transition_loss": 1.2480226755142212, "ae_encoder_loss": 0.7456624805927277, "actor_loss": -0.8287592232227325, "actor_target_entropy": -2.0, "actor_entropy": 1.6206127405166626, "alpha_loss": 0.004347867798060179, "alpha_value": 0.004244781300327001, "duration": 3.4020907878875732, "step": 43814}
{"episode_reward": -7.44006390092006, "episode": 1453.0, "batch_reward": -0.00924418494105339, "critic_loss": 0.5782706141471863, "ae_transition_loss": 1.2530729373296101, "ae_encoder_loss": 0.8958438833554586, "actor_loss": -0.9113764961560568, "actor_target_entropy": -2.0, "actor_entropy": 1.598936398824056, "alpha_loss": 0.005478921656807263, "alpha_value": 0.004240300760107347, "duration": 6.460886478424072, "step": 43844}
{"episode_reward": -12.181655683737215, "episode": 1454.0, "duration": 0.2601778507232666, "step": 43845}
{"episode_reward": 0.25953483938574373, "episode": 1455.0, "batch_reward": -0.013159436173737049, "critic_loss": 0.3220655471086502, "ae_transition_loss": 1.1340001821517944, "ae_encoder_loss": 1.1269097924232483, "actor_loss": -0.8626187741756439, "actor_target_entropy": -2.0, "actor_entropy": 1.8397136330604553, "alpha_loss": 0.006503167096525431, "alpha_value": 0.004235257786649731, "duration": 4.192716598510742, "step": 43864}
{"episode_reward": -4.872971436289809, "episode": 1456.0, "duration": 0.22303366661071777, "step": 43865}
{"episode_reward": 0.16122315334100168, "episode": 1457.0, "batch_reward": -0.016779496024052303, "critic_loss": 0.44125617543856305, "ae_transition_loss": 1.3044941624005635, "ae_encoder_loss": 0.8025652567545573, "actor_loss": -0.7261786262194315, "actor_target_entropy": -2.0, "actor_entropy": 1.8774502277374268, "alpha_loss": 0.005770568115015824, "alpha_value": 0.004229562403387372, "duration": 5.854568004608154, "step": 43893}
{"episode_reward": -15.957932978884198, "episode": 1458.0, "batch_reward": -0.03781185857951641, "critic_loss": 0.719666987657547, "ae_transition_loss": 1.3778923749923706, "ae_encoder_loss": 1.0963750183582306, "actor_loss": -0.5790347456932068, "actor_target_entropy": -2.0, "actor_entropy": 1.6766083240509033, "alpha_loss": 0.005653484025970101, "alpha_value": 0.004223424063151719, "duration": 4.878075361251831, "step": 43914}
{"episode_reward": -5.48014697338731, "episode": 1459.0, "batch_reward": -0.04742513503879309, "critic_loss": 1.0723663568496704, "ae_transition_loss": 2.0749577283859253, "ae_encoder_loss": 0.9175956547260284, "actor_loss": -0.7720348834991455, "actor_target_entropy": -2.0, "actor_entropy": 1.405457854270935, "alpha_loss": 0.0059883499052375555, "alpha_value": 0.004218261928436693, "duration": 4.438305139541626, "step": 43934}
{"episode_reward": -5.226896668243299, "episode": 1460.0, "batch_reward": -0.12035255879163742, "critic_loss": 1.0170931816101074, "ae_transition_loss": 1.216526985168457, "ae_encoder_loss": 1.0355409383773804, "actor_loss": -0.5008315443992615, "actor_target_entropy": -2.0, "actor_entropy": 1.208832859992981, "alpha_loss": 0.005059768911451101, "alpha_value": 0.004214299530967747, "duration": 3.3442790508270264, "step": 43950}
{"episode_reward": -3.0239219945251996, "episode": 1461.0, "batch_reward": 0.023651525378227234, "critic_loss": 0.3663540482521057, "ae_transition_loss": 1.132538080215454, "ae_encoder_loss": 0.8564376831054688, "actor_loss": -0.9701452851295471, "actor_target_entropy": -2.0, "actor_entropy": 1.0999419689178467, "alpha_loss": 0.0041541894897818565, "alpha_value": 0.00421166125432059, "duration": 28.0278799533844, "step": 43959}
{"episode_reward": -4.305742081491783, "episode": 1462.0, "batch_reward": -0.06808288767933846, "critic_loss": 0.5647242069244385, "ae_transition_loss": 1.1872648000717163, "ae_encoder_loss": 1.0205067098140717, "actor_loss": -0.4917186200618744, "actor_target_entropy": -2.0, "actor_entropy": 1.125739336013794, "alpha_loss": 0.004648023750633001, "alpha_value": 0.00420777284490245, "duration": 3.375781774520874, "step": 43974}
{"episode_reward": -2.7022277366297587, "episode": 1463.0, "batch_reward": 0.003997200168669224, "critic_loss": 0.5951482057571411, "ae_transition_loss": 1.364675760269165, "ae_encoder_loss": 0.8407329320907593, "actor_loss": -0.9091782569885254, "actor_target_entropy": -2.0, "actor_entropy": 1.1229755878448486, "alpha_loss": 0.0029673567041754723, "alpha_value": 0.004203925151844783, "duration": 2.117682695388794, "step": 43982}
{"episode_reward": -1.8911483811686294, "episode": 1464.0, "duration": 0.18585920333862305, "step": 43983}
{"episode_reward": -0.5502261422846686, "episode": 1465.0, "batch_reward": 0.030547858215868473, "critic_loss": 0.5345665216445923, "ae_transition_loss": 1.4111531376838684, "ae_encoder_loss": 0.9386313855648041, "actor_loss": -1.109260380268097, "actor_target_entropy": -2.0, "actor_entropy": 1.1936760544776917, "alpha_loss": 0.003486814210191369, "alpha_value": 0.004200296906171789, "duration": 4.8558268547058105, "step": 44006}
{"episode_reward": -3.297312754705243, "episode": 1466.0, "batch_reward": -0.006336678750813007, "critic_loss": 0.715605154633522, "ae_transition_loss": 1.6163088083267212, "ae_encoder_loss": 1.0775285512208939, "actor_loss": -0.8338437080383301, "actor_target_entropy": -2.0, "actor_entropy": 1.173248529434204, "alpha_loss": 0.0037829360808245838, "alpha_value": 0.004193366208816192, "duration": 7.465596914291382, "step": 44042}
{"episode_reward": -4.427144555302262, "episode": 1467.0, "batch_reward": 0.04760732501745224, "critic_loss": 0.5552354454994202, "ae_transition_loss": 1.3560528755187988, "ae_encoder_loss": 0.8738829493522644, "actor_loss": -0.8055325746536255, "actor_target_entropy": -2.0, "actor_entropy": 1.1568474769592285, "alpha_loss": 0.005614306777715683, "alpha_value": 0.004187801892241197, "duration": 3.4780521392822266, "step": 44060}
{"episode_reward": -3.5550300359408245, "episode": 1468.0, "batch_reward": -0.05035463099678358, "critic_loss": 0.6373545924822489, "ae_transition_loss": 1.5128830273946126, "ae_encoder_loss": 1.020544747511546, "actor_loss": -0.7457346717516581, "actor_target_entropy": -2.0, "actor_entropy": 1.4014217058817546, "alpha_loss": 0.005059968990584214, "alpha_value": 0.004183289290414587, "duration": 6.099946975708008, "step": 44090}
{"episode_reward": -7.58497061698918, "episode": 1469.0, "batch_reward": -0.040540751069784164, "critic_loss": 0.5868505537509918, "ae_transition_loss": 1.3923928141593933, "ae_encoder_loss": 0.8069442510604858, "actor_loss": -0.7956464886665344, "actor_target_entropy": -2.0, "actor_entropy": 1.6313437223434448, "alpha_loss": 0.005390370264649391, "alpha_value": 0.0041774505467773605, "duration": 2.669499635696411, "step": 44101}
{"episode_reward": -2.7836862572686965, "episode": 1470.0, "batch_reward": -0.029133733361959457, "critic_loss": 0.981991171836853, "ae_transition_loss": 1.2095924615859985, "ae_encoder_loss": 0.6776483058929443, "actor_loss": -0.8181707262992859, "actor_target_entropy": -2.0, "actor_entropy": 1.7106473445892334, "alpha_loss": 0.005945580545812845, "alpha_value": 0.0041738102694181415, "duration": 2.490997076034546, "step": 44114}
{"episode_reward": -6.706574687533887, "episode": 1471.0, "batch_reward": 0.021277687046676874, "critic_loss": 0.7343668043613434, "ae_transition_loss": 1.2166510820388794, "ae_encoder_loss": 0.6415209770202637, "actor_loss": -0.9409219324588776, "actor_target_entropy": -2.0, "actor_entropy": 1.7846739888191223, "alpha_loss": 0.0052891497034579515, "alpha_value": 0.004170038654140274, "duration": 39.96705937385559, "step": 44134}
{"episode_reward": -6.657294738620834, "episode": 1472.0, "batch_reward": -0.03851276524364948, "critic_loss": 0.6523724913597106, "ae_transition_loss": 1.343445324897766, "ae_encoder_loss": 1.101596176624298, "actor_loss": -0.7726753711700439, "actor_target_entropy": -2.0, "actor_entropy": 1.8077958583831788, "alpha_loss": 0.00563052324578166, "alpha_value": 0.004161087560029133, "duration": 10.035035133361816, "step": 44182}
{"episode_reward": -19.829254320807745, "episode": 1473.0, "batch_reward": -0.012341423658654094, "critic_loss": 0.6370069980621338, "ae_transition_loss": 1.3286239504814148, "ae_encoder_loss": 0.9710095226764679, "actor_loss": -0.4401845932006836, "actor_target_entropy": -2.0, "actor_entropy": 1.5829177498817444, "alpha_loss": 0.005429073004052043, "alpha_value": 0.004151831872924743, "duration": 4.944261074066162, "step": 44206}
{"episode_reward": -6.153586712385532, "episode": 1474.0, "batch_reward": -0.049861110746860504, "critic_loss": 0.8590952157974243, "ae_transition_loss": 1.4515607357025146, "ae_encoder_loss": 0.9708266854286194, "actor_loss": -0.29280900955200195, "actor_target_entropy": -2.0, "actor_entropy": 1.4387447834014893, "alpha_loss": 0.003033069195225835, "alpha_value": 0.004147790499084794, "duration": 2.787855386734009, "step": 44220}
{"episode_reward": -3.146137546236865, "episode": 1475.0, "batch_reward": 0.0073093659011647105, "critic_loss": 0.8758418709039688, "ae_transition_loss": 1.1432454288005829, "ae_encoder_loss": 0.8495098650455475, "actor_loss": -1.0719004124403, "actor_target_entropy": -2.0, "actor_entropy": 1.3897012770175934, "alpha_loss": 0.0042178238509222865, "alpha_value": 0.004141458085867305, "duration": 7.783670663833618, "step": 44258}
{"episode_reward": -10.231879238860643, "episode": 1476.0, "batch_reward": -0.014833252876996994, "critic_loss": 0.8029350837071737, "ae_transition_loss": 1.5469985008239746, "ae_encoder_loss": 0.8925813436508179, "actor_loss": -0.8374855319658915, "actor_target_entropy": -2.0, "actor_entropy": 1.4694143931070964, "alpha_loss": 0.0040011173114180565, "alpha_value": 0.004132929696894983, "duration": 5.504029750823975, "step": 44285}
{"episode_reward": -9.302877930807563, "episode": 1477.0, "batch_reward": -0.0035430341958999634, "critic_loss": 0.690745989481608, "ae_transition_loss": 1.4377320210138957, "ae_encoder_loss": 1.1065124869346619, "actor_loss": -0.7795157631238302, "actor_target_entropy": -2.0, "actor_entropy": 1.6543803612391155, "alpha_loss": 0.004249807990466555, "alpha_value": 0.004125876387390612, "duration": 5.507498502731323, "step": 44311}
{"episode_reward": -4.31163673685194, "episode": 1478.0, "batch_reward": -0.10189865529537201, "critic_loss": 0.4634348750114441, "ae_transition_loss": 1.3217763900756836, "ae_encoder_loss": 0.7300310134887695, "actor_loss": -0.4377763867378235, "actor_target_entropy": -2.0, "actor_entropy": 1.8465979099273682, "alpha_loss": 0.0063431598246097565, "alpha_value": 0.0041212383793533735, "duration": 3.4440598487854004, "step": 44329}
{"episode_reward": -7.190815434515667, "episode": 1479.0, "batch_reward": -0.026088967608908813, "critic_loss": 0.5607529232899348, "ae_transition_loss": 1.6466840704282124, "ae_encoder_loss": 0.9069408476352692, "actor_loss": -0.8420579036076864, "actor_target_entropy": -2.0, "actor_entropy": 1.8331040143966675, "alpha_loss": 0.006173970488210519, "alpha_value": 0.004112396324003315, "duration": 11.403687953948975, "step": 44385}
{"episode_reward": -21.41832125973877, "episode": 1480.0, "batch_reward": -0.04503694921731949, "critic_loss": 0.7254758477210999, "ae_transition_loss": 1.4994888305664062, "ae_encoder_loss": 1.1083156267801921, "actor_loss": -0.3668193221092224, "actor_target_entropy": -2.0, "actor_entropy": 1.8072369893391926, "alpha_loss": 0.0065218014642596245, "alpha_value": 0.004100250395863015, "duration": 6.543651342391968, "step": 44417}
{"episode_reward": -4.797184928388257, "episode": 1481.0, "batch_reward": 0.02648868535955747, "critic_loss": 1.3415271043777466, "ae_transition_loss": 1.3993159929911296, "ae_encoder_loss": 0.7379218737284342, "actor_loss": -0.6936810811360677, "actor_target_entropy": -2.0, "actor_entropy": 1.7864757776260376, "alpha_loss": 0.00595482112839818, "alpha_value": 0.00409167102062977, "duration": 30.516506671905518, "step": 44441}
{"episode_reward": -6.156377878951269, "episode": 1482.0, "duration": 0.24877643585205078, "step": 44442}
{"episode_reward": -0.4566970947786331, "episode": 1483.0, "batch_reward": -0.019435781985521317, "critic_loss": 0.775306224822998, "ae_transition_loss": 1.3012218475341797, "ae_encoder_loss": 0.6063315868377686, "actor_loss": -0.8521085977554321, "actor_target_entropy": -2.0, "actor_entropy": 1.7728559970855713, "alpha_loss": 0.0058575039729475975, "alpha_value": 0.004085873313910474, "duration": 3.4621846675872803, "step": 44459}
{"episode_reward": -4.764778646224468, "episode": 1484.0, "batch_reward": -0.012161615304648876, "critic_loss": 1.2205381393432617, "ae_transition_loss": 1.2252967357635498, "ae_encoder_loss": 1.1348415613174438, "actor_loss": -1.1144704818725586, "actor_target_entropy": -2.0, "actor_entropy": 1.7282614707946777, "alpha_loss": 0.005777641199529171, "alpha_value": 0.004082949505497679, "duration": 2.1838812828063965, "step": 44469}
{"episode_reward": -2.3649269971270446, "episode": 1485.0, "batch_reward": -0.015792142134159803, "critic_loss": 0.7970513552427292, "ae_transition_loss": 1.5508366227149963, "ae_encoder_loss": 0.8550191819667816, "actor_loss": -0.8044022172689438, "actor_target_entropy": -2.0, "actor_entropy": 1.7480018734931946, "alpha_loss": 0.0064016623655334115, "alpha_value": 0.004075549473894222, "duration": 7.164078712463379, "step": 44504}
{"episode_reward": -9.06484963573761, "episode": 1486.0, "batch_reward": -0.10327646136283875, "critic_loss": 0.530132532119751, "ae_transition_loss": 1.8055496215820312, "ae_encoder_loss": 1.2139216661453247, "actor_loss": -0.6498891115188599, "actor_target_entropy": -2.0, "actor_entropy": 1.6454397439956665, "alpha_loss": 0.005861543118953705, "alpha_value": 0.0040680236651942205, "duration": 2.6556010246276855, "step": 44516}
{"episode_reward": -2.962107076986195, "episode": 1487.0, "batch_reward": -0.014252873603254557, "critic_loss": 0.42124801874160767, "ae_transition_loss": 1.2886459231376648, "ae_encoder_loss": 0.782997727394104, "actor_loss": -0.5799155831336975, "actor_target_entropy": -2.0, "actor_entropy": 1.658801257610321, "alpha_loss": 0.006652934243902564, "alpha_value": 0.004063478353673755, "duration": 4.067740440368652, "step": 44536}
{"episode_reward": -7.710084882022141, "episode": 1488.0, "duration": 0.24792242050170898, "step": 44537}
{"episode_reward": -0.21982424841871095, "episode": 1489.0, "batch_reward": -0.021390148671343923, "critic_loss": 0.6747414991259575, "ae_transition_loss": 1.3440059423446655, "ae_encoder_loss": 1.0578797906637192, "actor_loss": -0.7524923384189606, "actor_target_entropy": -2.0, "actor_entropy": 1.7584530413150787, "alpha_loss": 0.0067126271314918995, "alpha_value": 0.004054148716910221, "duration": 7.487967014312744, "step": 44573}
{"episode_reward": -4.722695453210382, "episode": 1490.0, "batch_reward": -0.06648530066013336, "critic_loss": 0.4030964970588684, "ae_transition_loss": 1.1250489950180054, "ae_encoder_loss": 0.9092515110969543, "actor_loss": -0.508624255657196, "actor_target_entropy": -2.0, "actor_entropy": 1.7020183801651, "alpha_loss": 0.005930191837251186, "alpha_value": 0.0040462222220460356, "duration": 2.6155245304107666, "step": 44586}
{"episode_reward": -4.626428055508525, "episode": 1491.0, "batch_reward": -0.05323321061829726, "critic_loss": 0.6551342010498047, "ae_transition_loss": 1.8062760432561238, "ae_encoder_loss": 0.9915525913238525, "actor_loss": -0.8631054162979126, "actor_target_entropy": -2.0, "actor_entropy": 1.8448988199234009, "alpha_loss": 0.006620936561375856, "alpha_value": 0.004039839942431746, "duration": 63.91574048995972, "step": 44618}
{"episode_reward": -8.376773919869239, "episode": 1492.0, "batch_reward": 0.01608170010149479, "critic_loss": 0.630450427532196, "ae_transition_loss": 1.3226110339164734, "ae_encoder_loss": 1.1483361721038818, "actor_loss": -0.9193045496940613, "actor_target_entropy": -2.0, "actor_entropy": 1.8569623827934265, "alpha_loss": 0.005310439970344305, "alpha_value": 0.004031878071811648, "duration": 3.931697130203247, "step": 44637}
{"episode_reward": -4.507644005198499, "episode": 1493.0, "batch_reward": -0.04174887537956238, "critic_loss": 0.6197192788124084, "ae_transition_loss": 1.183432364463806, "ae_encoder_loss": 0.8793573498725891, "actor_loss": -0.6083798944950104, "actor_target_entropy": -2.0, "actor_entropy": 1.6746666431427002, "alpha_loss": 0.005015348177403211, "alpha_value": 0.004021183568696575, "duration": 10.439905881881714, "step": 44687}
{"episode_reward": -11.566960821314998, "episode": 1494.0, "batch_reward": -0.01887967127064864, "critic_loss": 0.4910834680000941, "ae_transition_loss": 1.296337882677714, "ae_encoder_loss": 0.7168164948622385, "actor_loss": -0.6829180916150411, "actor_target_entropy": -2.0, "actor_entropy": 1.8519978920618694, "alpha_loss": 0.004968510940670967, "alpha_value": 0.004005501960289954, "duration": 11.193535566329956, "step": 44741}
{"episode_reward": -8.928272559876842, "episode": 1495.0, "batch_reward": -0.029870115406811237, "critic_loss": 0.9346076488494873, "ae_transition_loss": 1.2921376705169678, "ae_encoder_loss": 0.7324148058891297, "actor_loss": -0.5904661118984222, "actor_target_entropy": -2.0, "actor_entropy": 1.553211236000061, "alpha_loss": 0.0028744502225890754, "alpha_value": 0.003991071974245448, "duration": 10.726223468780518, "step": 44793}
{"episode_reward": -12.458424838416907, "episode": 1496.0, "batch_reward": -0.060396401584148406, "critic_loss": 0.4249035567045212, "ae_transition_loss": 1.2626136779785155, "ae_encoder_loss": 0.952980387210846, "actor_loss": -0.5671746253967285, "actor_target_entropy": -2.0, "actor_entropy": 1.9197331428527833, "alpha_loss": 0.005201037507504225, "alpha_value": 0.003979844941225342, "duration": 10.979772329330444, "step": 44845}
{"episode_reward": -13.18305633496486, "episode": 1497.0, "batch_reward": -0.016963609866797923, "critic_loss": 0.5170230388641357, "ae_transition_loss": 1.1839916467666627, "ae_encoder_loss": 0.8362383484840393, "actor_loss": -0.7719959497451783, "actor_target_entropy": -2.0, "actor_entropy": 1.4781905174255372, "alpha_loss": 0.004034083895385265, "alpha_value": 0.003968284852613978, "duration": 10.807758808135986, "step": 44898}
{"episode_reward": -7.206128587009803, "episode": 1498.0, "batch_reward": 0.005949350073933601, "critic_loss": 0.4590155929327011, "ae_transition_loss": 1.1451849937438965, "ae_encoder_loss": 0.6725444048643112, "actor_loss": -0.9130651503801346, "actor_target_entropy": -2.0, "actor_entropy": 1.183268129825592, "alpha_loss": 0.00332664413144812, "alpha_value": 0.003958304017685423, "duration": 7.859874248504639, "step": 44936}
{"episode_reward": -7.305011310024357, "episode": 1499.0, "batch_reward": -0.01709585642674938, "critic_loss": 0.8384123332798481, "ae_transition_loss": 1.141353540122509, "ae_encoder_loss": 0.6965762972831726, "actor_loss": -0.8104207254946232, "actor_target_entropy": -2.0, "actor_entropy": 1.5930249989032745, "alpha_loss": 0.0035577265080064535, "alpha_value": 0.003946400168290627, "duration": 16.51170253753662, "step": 45017}
{"episode_reward": -23.181747320776843, "episode": 1500.0, "batch_reward": -0.007841819897294044, "critic_loss": 0.4837735593318939, "ae_transition_loss": 1.4851632118225098, "ae_encoder_loss": 0.6518847346305847, "actor_loss": -0.6984882950782776, "actor_target_entropy": -2.0, "actor_entropy": 1.6691489219665527, "alpha_loss": 0.003668420482426882, "alpha_value": 0.003937833009066151, "duration": 2.091693639755249, "step": 45027}
{"episode_reward": -2.061171847855073, "episode": 1501.0, "batch_reward": -0.04974702559411526, "critic_loss": 0.46406133969624835, "ae_transition_loss": 1.3985851009686787, "ae_encoder_loss": 0.9625773926575979, "actor_loss": -0.5689854323863983, "actor_target_entropy": -2.0, "actor_entropy": 1.533057947953542, "alpha_loss": 0.004834817606024444, "alpha_value": 0.003931245744958486, "duration": 149.05859088897705, "step": 45083}
{"episode_reward": -7.719859544710583, "episode": 1502.0, "batch_reward": -0.024212087349345286, "critic_loss": 0.4901509831349055, "ae_transition_loss": 1.3026841481526692, "ae_encoder_loss": 0.7788087129592896, "actor_loss": -0.8155917376279831, "actor_target_entropy": -2.0, "actor_entropy": 1.3507272203763325, "alpha_loss": 0.00474982305119435, "alpha_value": 0.003918591455945961, "duration": 16.830734729766846, "step": 45147}
{"episode_reward": -10.69400804886971, "episode": 1503.0, "batch_reward": -0.03519517555832863, "critic_loss": 0.5364516317844391, "ae_transition_loss": 1.1988013982772827, "ae_encoder_loss": 0.8930941820144653, "actor_loss": -0.8842100381851197, "actor_target_entropy": -2.0, "actor_entropy": 1.296231460571289, "alpha_loss": 0.0037483614403754474, "alpha_value": 0.003906193934633825, "duration": 9.702012538909912, "step": 45196}
{"episode_reward": -6.48733017539737, "episode": 1504.0, "batch_reward": -0.025640059262514114, "critic_loss": 0.5613061487674713, "ae_transition_loss": 1.1776070495446522, "ae_encoder_loss": 0.6059800138076147, "actor_loss": -0.7543163994948069, "actor_target_entropy": -2.0, "actor_entropy": 1.448584496974945, "alpha_loss": 0.0005281237584616368, "alpha_value": 0.003895570789229735, "duration": 12.782289266586304, "step": 45260}
{"episode_reward": -12.772152661472594, "episode": 1505.0, "batch_reward": -0.018090937700536516, "critic_loss": 0.5814897682931688, "ae_transition_loss": 1.1983010239071317, "ae_encoder_loss": 0.764120532406701, "actor_loss": -0.7024608386887444, "actor_target_entropy": -2.0, "actor_entropy": 1.2273841235372756, "alpha_loss": 0.004444927313468522, "alpha_value": 0.003884872572959907, "duration": 16.915762186050415, "step": 45343}
{"episode_reward": 8.222816739792634, "episode": 1506.0, "batch_reward": -0.05342354206368327, "critic_loss": 0.7487699389457703, "ae_transition_loss": 1.2206611037254333, "ae_encoder_loss": 0.9033894836902618, "actor_loss": -0.6518837511539459, "actor_target_entropy": -2.0, "actor_entropy": 0.9298867881298065, "alpha_loss": 0.004970888374373317, "alpha_value": 0.0038755083070950644, "duration": 4.625422477722168, "step": 45365}
{"episode_reward": -5.081908979114271, "episode": 1507.0, "batch_reward": -0.013925614301115274, "critic_loss": 0.5202281400561333, "ae_transition_loss": 1.171445056796074, "ae_encoder_loss": 0.905021145939827, "actor_loss": -0.7230930179357529, "actor_target_entropy": -2.0, "actor_entropy": 0.9963263422250748, "alpha_loss": 0.004800220369361341, "alpha_value": 0.00386961106142263, "duration": 9.071928024291992, "step": 45410}
{"episode_reward": -6.41298492561006, "episode": 1508.0, "batch_reward": -0.006033654635151227, "critic_loss": 0.49229174852371216, "ae_transition_loss": 1.2422253688176472, "ae_encoder_loss": 0.9086562593777975, "actor_loss": -1.0875062147776287, "actor_target_entropy": -2.0, "actor_entropy": 1.323941429456075, "alpha_loss": 0.0047892082172135515, "alpha_value": 0.0038622942069093218, "duration": 5.139975070953369, "step": 45434}
{"episode_reward": -1.8016932318636698, "episode": 1509.0, "batch_reward": -0.030454596918490198, "critic_loss": 0.5507723755306668, "ae_transition_loss": 1.1255023545689053, "ae_encoder_loss": 0.7697121169832017, "actor_loss": -0.6264497439066569, "actor_target_entropy": -2.0, "actor_entropy": 0.8843840095731947, "alpha_loss": 0.00363142229616642, "alpha_value": 0.0038494855712973178, "duration": 18.237637281417847, "step": 45523}
{"episode_reward": -20.02307653993265, "episode": 1510.0, "batch_reward": -0.021074456721544267, "critic_loss": 0.6941305577754975, "ae_transition_loss": 1.1578908205032348, "ae_encoder_loss": 1.0290948033332825, "actor_loss": -0.8198315739631653, "actor_target_entropy": -2.0, "actor_entropy": 1.8008777618408203, "alpha_loss": 0.004143804032355547, "alpha_value": 0.003835814106563075, "duration": 10.552210092544556, "step": 45572}
{"episode_reward": -13.968505090639484, "episode": 1511.0, "duration": 30.45762825012207, "step": 45580}
{"episode_reward": -1.8039249390301717, "episode": 1512.0, "batch_reward": -0.028667053606893336, "critic_loss": 0.5115237789494651, "ae_transition_loss": 1.1111351081303187, "ae_encoder_loss": 1.1003557443618774, "actor_loss": -0.6643148107188088, "actor_target_entropy": -2.0, "actor_entropy": 1.372692584991455, "alpha_loss": 0.003101816600454705, "alpha_value": 0.0038241359452306964, "duration": 13.26726770401001, "step": 45643}
{"episode_reward": -18.530080891893025, "episode": 1513.0, "batch_reward": -0.021709125861525534, "critic_loss": 0.7161128163337708, "ae_transition_loss": 0.9727760553359985, "ae_encoder_loss": 0.8939411640167236, "actor_loss": -0.7854722499847412, "actor_target_entropy": -2.0, "actor_entropy": 0.9551388502120972, "alpha_loss": 0.002083230158314109, "alpha_value": 0.003813486082803808, "duration": 10.740078926086426, "step": 45694}
{"episode_reward": -13.284243756097002, "episode": 1514.0, "batch_reward": -0.05466321110725403, "critic_loss": 1.0871749222278595, "ae_transition_loss": 1.1644003987312317, "ae_encoder_loss": 0.7308877408504486, "actor_loss": -0.7975257635116577, "actor_target_entropy": -2.0, "actor_entropy": 0.8280979990959167, "alpha_loss": 0.0008336290047736838, "alpha_value": 0.00380825203843952, "duration": 5.18685507774353, "step": 45717}
{"episode_reward": -4.6112859010555285, "episode": 1515.0, "duration": 0.23644614219665527, "step": 45718}
{"episode_reward": -0.30867905330332335, "episode": 1516.0, "batch_reward": -0.0284855409214894, "critic_loss": 0.6103450457255045, "ae_transition_loss": 1.0057955980300903, "ae_encoder_loss": 0.9756943384806315, "actor_loss": -0.8953606883684794, "actor_target_entropy": -2.0, "actor_entropy": 1.4635526339213054, "alpha_loss": -0.0002810160319010417, "alpha_value": 0.003805319642880646, "duration": 5.200708866119385, "step": 45742}
{"episode_reward": -7.707735616271422, "episode": 1517.0, "batch_reward": 0.014438439160585403, "critic_loss": 0.7383729219436646, "ae_transition_loss": 0.9493906199932098, "ae_encoder_loss": 0.6548566967248917, "actor_loss": -0.9272986054420471, "actor_target_entropy": -2.0, "actor_entropy": 1.9691113233566284, "alpha_loss": -0.002117317810188979, "alpha_value": 0.0038030942424946102, "duration": 4.734795808792114, "step": 45763}
{"episode_reward": -10.795833177329056, "episode": 1518.0, "duration": 0.9517672061920166, "step": 45767}
{"episode_reward": -0.6265869524958492, "episode": 1519.0, "batch_reward": -0.04264383902773261, "critic_loss": 0.5894501283764839, "ae_transition_loss": 1.1932431012392044, "ae_encoder_loss": 0.8902750164270401, "actor_loss": -0.6696431338787079, "actor_target_entropy": -2.0, "actor_entropy": 1.09263214468956, "alpha_loss": -0.004691973445005715, "alpha_value": 0.0038019680762764515, "duration": 7.5825347900390625, "step": 45801}
{"episode_reward": -18.73057717898684, "episode": 1520.0, "batch_reward": -0.00945064052939415, "critic_loss": 0.6833914518356323, "ae_transition_loss": 1.0507439374923706, "ae_encoder_loss": 0.8173575401306152, "actor_loss": -0.820462703704834, "actor_target_entropy": -2.0, "actor_entropy": 0.8226869106292725, "alpha_loss": -0.004534482024610043, "alpha_value": 0.0038024843358949083, "duration": 3.4856696128845215, "step": 45818}
{"episode_reward": -6.567471218415679, "episode": 1521.0, "batch_reward": -0.05690845971306165, "critic_loss": 0.4802299340565999, "ae_transition_loss": 1.199847936630249, "ae_encoder_loss": 1.4809149106343586, "actor_loss": -0.8953210910161337, "actor_target_entropy": -2.0, "actor_entropy": 1.3696581919987996, "alpha_loss": -0.001633947288307051, "alpha_value": 0.0038039798059669987, "duration": 61.01539182662964, "step": 45845}
{"episode_reward": -14.713963628166036, "episode": 1522.0, "batch_reward": -0.008718682453036308, "critic_loss": 0.8252183794975281, "ae_transition_loss": 0.9435359835624695, "ae_encoder_loss": 1.1659762859344482, "actor_loss": -1.019360065460205, "actor_target_entropy": -2.0, "actor_entropy": 1.5980970859527588, "alpha_loss": 0.00217617629095912, "alpha_value": 0.003805508120249257, "duration": 3.071765661239624, "step": 45860}
{"episode_reward": -8.47317476222341, "episode": 1523.0, "batch_reward": -0.06154695153236389, "critic_loss": 0.9833589494228363, "ae_transition_loss": 1.0826227068901062, "ae_encoder_loss": 0.7924816906452179, "actor_loss": -0.8297848105430603, "actor_target_entropy": -2.0, "actor_entropy": 1.0895734429359436, "alpha_loss": 0.0010901485366048291, "alpha_value": 0.003806209388808571, "duration": 3.3503191471099854, "step": 45876}
{"episode_reward": -5.791427424064614, "episode": 1524.0, "batch_reward": -0.029864286072552204, "critic_loss": 0.9247058629989624, "ae_transition_loss": 1.021312803030014, "ae_encoder_loss": 0.9226563572883606, "actor_loss": -1.0631504952907562, "actor_target_entropy": -2.0, "actor_entropy": 0.8435037136077881, "alpha_loss": -0.0029634159873239696, "alpha_value": 0.0038069051718387743, "duration": 3.529330015182495, "step": 45892}
{"episode_reward": -5.23666014052973, "episode": 1525.0, "batch_reward": 0.00106903538107872, "critic_loss": 0.5670655965805054, "ae_transition_loss": 0.8828201293945312, "ae_encoder_loss": 1.0166490077972412, "actor_loss": -0.90234375, "actor_target_entropy": -2.0, "actor_entropy": 0.9743960499763489, "alpha_loss": -0.004767832346260548, "alpha_value": 0.0038076405972716, "duration": 3.467763900756836, "step": 45908}
{"episode_reward": -5.249292082685352, "episode": 1526.0, "duration": 0.2624664306640625, "step": 45909}
{"episode_reward": 0.10555063105439697, "episode": 1527.0, "batch_reward": -0.03925414445499579, "critic_loss": 0.722766637802124, "ae_transition_loss": 1.1183346112569172, "ae_encoder_loss": 1.0416894555091858, "actor_loss": -0.5111535688241323, "actor_target_entropy": -2.0, "actor_entropy": 1.4665831327438354, "alpha_loss": -0.002289827913045883, "alpha_value": 0.0038091939555773354, "duration": 5.881256580352783, "step": 45937}
{"episode_reward": -12.068003897078547, "episode": 1528.0, "batch_reward": -0.009068474173545837, "critic_loss": 0.8207568824291229, "ae_transition_loss": 0.9216856956481934, "ae_encoder_loss": 1.188558042049408, "actor_loss": -0.5071970969438553, "actor_target_entropy": -2.0, "actor_entropy": 1.9787679314613342, "alpha_loss": -0.0003634137101471424, "alpha_value": 0.00381127555604321, "duration": 4.567493915557861, "step": 45959}
{"episode_reward": -11.210110107918187, "episode": 1529.0, "duration": 0.24745559692382812, "step": 45960}
{"episode_reward": -0.17085467238568203, "episode": 1530.0, "batch_reward": -0.017110543558374047, "critic_loss": 0.6126577854156494, "ae_transition_loss": 1.0847477316856384, "ae_encoder_loss": 1.0543307662010193, "actor_loss": -0.6028194427490234, "actor_target_entropy": -2.0, "actor_entropy": 2.0256844758987427, "alpha_loss": 0.000745748431654647, "alpha_value": 0.003812660344380257, "duration": 3.0247273445129395, "step": 45973}
{"episode_reward": -7.7910106509230905, "episode": 1531.0, "batch_reward": 0.012521009892225266, "critic_loss": 1.4746426343917847, "ae_transition_loss": 1.0477458238601685, "ae_encoder_loss": 0.6075332760810852, "actor_loss": -1.2276616096496582, "actor_target_entropy": -2.0, "actor_entropy": 2.203263282775879, "alpha_loss": 0.0007045229431241751, "alpha_value": 0.0038134521006924415, "duration": 36.60720133781433, "step": 45986}
{"episode_reward": -7.383732938124624, "episode": 1532.0, "duration": 0.23166108131408691, "step": 45987}
{"episode_reward": -0.02859218377545497, "episode": 1533.0, "batch_reward": -0.034079591976478696, "critic_loss": 1.1562380343675613, "ae_transition_loss": 1.0889251977205276, "ae_encoder_loss": 0.943566232919693, "actor_loss": -0.8074506372213364, "actor_target_entropy": -2.0, "actor_entropy": 1.8838927447795868, "alpha_loss": 0.0028103216318413615, "alpha_value": 0.0038140516882987593, "duration": 7.150829315185547, "step": 46021}
{"episode_reward": -16.18301900053693, "episode": 1534.0, "batch_reward": -0.05503502984841665, "critic_loss": 1.2654325564702351, "ae_transition_loss": 1.0379682183265686, "ae_encoder_loss": 0.8598426183064779, "actor_loss": -0.7912315626939138, "actor_target_entropy": -2.0, "actor_entropy": 1.6147728363672893, "alpha_loss": 0.0035815092269331217, "alpha_value": 0.0038134673493532886, "duration": 5.998187303543091, "step": 46051}
{"episode_reward": -9.665983295080721, "episode": 1535.0, "batch_reward": -0.04426092281937599, "critic_loss": 0.829945519566536, "ae_transition_loss": 1.107784926891327, "ae_encoder_loss": 0.8659569621086121, "actor_loss": -0.6008584871888161, "actor_target_entropy": -2.0, "actor_entropy": 1.7871358394622803, "alpha_loss": 0.001045526791131124, "alpha_value": 0.003811375404619446, "duration": 8.753995180130005, "step": 46093}
{"episode_reward": -4.0501126813747295, "episode": 1536.0, "batch_reward": -0.01686722661058108, "critic_loss": 1.4165143767992656, "ae_transition_loss": 1.4135375221570332, "ae_encoder_loss": 0.9888591965039571, "actor_loss": -0.5326258142789205, "actor_target_entropy": -2.0, "actor_entropy": 2.599351723988851, "alpha_loss": 0.0008277975818297515, "alpha_value": 0.0038092744693415427, "duration": 6.221648454666138, "step": 46122}
{"episode_reward": -21.986211746724667, "episode": 1537.0, "batch_reward": -0.03125113993883133, "critic_loss": 0.9500457406044006, "ae_transition_loss": 1.2073195934295655, "ae_encoder_loss": 0.9308240294456482, "actor_loss": -0.5697679877281189, "actor_target_entropy": -2.0, "actor_entropy": 1.6936840057373046, "alpha_loss": 0.004003214673139155, "alpha_value": 0.003806801965632601, "duration": 10.260797023773193, "step": 46171}
{"episode_reward": -38.3949347875452, "episode": 1538.0, "batch_reward": -0.04307757318019867, "critic_loss": 0.9837112426757812, "ae_transition_loss": 0.9843499660491943, "ae_encoder_loss": 0.7994396090507507, "actor_loss": -0.6465173959732056, "actor_target_entropy": -2.0, "actor_entropy": 2.1167566776275635, "alpha_loss": 0.005826757289469242, "alpha_value": 0.003803932860183724, "duration": 3.514806032180786, "step": 46189}
{"episode_reward": -7.0317424750588, "episode": 1539.0, "duration": 0.25079870223999023, "step": 46190}
{"episode_reward": 0.0950193846265388, "episode": 1540.0, "batch_reward": -0.11611592769622803, "critic_loss": 0.6500500440597534, "ae_transition_loss": 1.8822882175445557, "ae_encoder_loss": 1.0011781454086304, "actor_loss": -0.5332288146018982, "actor_target_entropy": -2.0, "actor_entropy": 2.0837204456329346, "alpha_loss": 0.005728152580559254, "alpha_value": 0.003802561313708209, "duration": 0.5391488075256348, "step": 46191}
{"episode_reward": 0.3999725455090748, "episode": 1541.0, "batch_reward": 0.00433315010741353, "critic_loss": 0.27254486083984375, "ae_transition_loss": 1.241956353187561, "ae_encoder_loss": 0.5935288071632385, "actor_loss": -0.7831188440322876, "actor_target_entropy": -2.0, "actor_entropy": 2.0090742111206055, "alpha_loss": 0.0030951430089771748, "alpha_value": 0.0038010385515043397, "duration": 89.07208943367004, "step": 46207}
{"episode_reward": -9.58227786436525, "episode": 1542.0, "duration": 0.26060962677001953, "step": 46208}
{"episode_reward": -0.6023842187334072, "episode": 1543.0, "batch_reward": -0.04711201786994934, "critic_loss": 0.8561543524265289, "ae_transition_loss": 1.3628475069999695, "ae_encoder_loss": 0.7914005815982819, "actor_loss": -0.8545723259449005, "actor_target_entropy": -2.0, "actor_entropy": 2.0006924867630005, "alpha_loss": 0.004099599434994161, "alpha_value": 0.003797135408206271, "duration": 8.26342511177063, "step": 46249}
{"episode_reward": -20.837203276666813, "episode": 1544.0, "batch_reward": -0.061467078514397144, "critic_loss": 1.1369605660438538, "ae_transition_loss": 1.2807457447052002, "ae_encoder_loss": 0.9388132989406586, "actor_loss": -0.8445282429456711, "actor_target_entropy": -2.0, "actor_entropy": 1.578851342201233, "alpha_loss": 0.0037754696095362306, "alpha_value": 0.0037903233513769496, "duration": 7.871502161026001, "step": 46288}
{"episode_reward": 0.5652313058455485, "episode": 1545.0, "batch_reward": -0.0622020848095417, "critic_loss": 1.3631784915924072, "ae_transition_loss": 1.3117672204971313, "ae_encoder_loss": 0.7650212049484253, "actor_loss": -0.6842737197875977, "actor_target_entropy": -2.0, "actor_entropy": 1.7581377029418945, "alpha_loss": 0.003077307716012001, "alpha_value": 0.00378586698647094, "duration": 1.4483702182769775, "step": 46294}
{"episode_reward": -1.894794301111656, "episode": 1546.0, "batch_reward": -0.0881735309958458, "critic_loss": 1.0895085334777832, "ae_transition_loss": 1.1708195209503174, "ae_encoder_loss": 0.8645674586296082, "actor_loss": -0.401081383228302, "actor_target_entropy": -2.0, "actor_entropy": 1.6152033805847168, "alpha_loss": 0.0035291095264256, "alpha_value": 0.003784117451132737, "duration": 3.247246742248535, "step": 46309}
{"episode_reward": -4.688734925792996, "episode": 1547.0, "batch_reward": -0.006220401264727116, "critic_loss": 0.9581237435340881, "ae_transition_loss": 0.9937241971492767, "ae_encoder_loss": 0.8265249133110046, "actor_loss": -0.9926170408725739, "actor_target_entropy": -2.0, "actor_entropy": 1.1121752262115479, "alpha_loss": 0.005682025104761124, "alpha_value": 0.00378145096412355, "duration": 3.3435018062591553, "step": 46325}
{"episode_reward": -4.916482141113809, "episode": 1548.0, "duration": 0.2556915283203125, "step": 46326}
{"episode_reward": -0.5010514220307978, "episode": 1549.0, "batch_reward": 0.009215231984853745, "critic_loss": 0.9204413890838623, "ae_transition_loss": 1.127076268196106, "ae_encoder_loss": 0.6672309637069702, "actor_loss": -1.293087363243103, "actor_target_entropy": -2.0, "actor_entropy": 1.811134696006775, "alpha_loss": 0.0036411599721759558, "alpha_value": 0.0037785716154400987, "duration": 1.8197600841522217, "step": 46334}
{"episode_reward": -5.517067730462315, "episode": 1550.0, "batch_reward": -0.026932477951049805, "critic_loss": 1.6865167617797852, "ae_transition_loss": 0.8402520418167114, "ae_encoder_loss": 0.6383784413337708, "actor_loss": -0.6344227194786072, "actor_target_entropy": -2.0, "actor_entropy": 2.4899861812591553, "alpha_loss": 0.002240082947537303, "alpha_value": 0.0037766201879413275, "duration": 2.576875925064087, "step": 46346}
{"episode_reward": -5.8646073336330495, "episode": 1551.0, "batch_reward": -0.044627898663748056, "critic_loss": 0.7669775411486626, "ae_transition_loss": 1.2586994394659996, "ae_encoder_loss": 1.0419077053666115, "actor_loss": -0.513027360662818, "actor_target_entropy": -2.0, "actor_entropy": 2.0202040523290634, "alpha_loss": 0.0022022644479875453, "alpha_value": 0.0037693103402216682, "duration": 131.61504983901978, "step": 46430}
{"episode_reward": -66.97082601070989, "episode": 1552.0, "batch_reward": -0.06770025007426739, "critic_loss": 0.8728803396224976, "ae_transition_loss": 1.1069656312465668, "ae_encoder_loss": 0.951246976852417, "actor_loss": -0.2548148091882467, "actor_target_entropy": -2.0, "actor_entropy": 2.748999834060669, "alpha_loss": -7.372618711087853e-05, "alpha_value": 0.0037617874352086703, "duration": 3.475865602493286, "step": 46446}
{"episode_reward": -9.259875777230057, "episode": 1553.0, "batch_reward": -0.01608326844871044, "critic_loss": 0.8747033178806305, "ae_transition_loss": 1.0624947547912598, "ae_encoder_loss": 0.8430905044078827, "actor_loss": -0.7447323799133301, "actor_target_entropy": -2.0, "actor_entropy": 1.988479495048523, "alpha_loss": 0.002649830188602209, "alpha_value": 0.0037593322217925247, "duration": 4.847984552383423, "step": 46470}
{"episode_reward": -17.872728706039705, "episode": 1554.0, "batch_reward": -0.09507914632558823, "critic_loss": 0.624862790107727, "ae_transition_loss": 0.9727282524108887, "ae_encoder_loss": 0.776683509349823, "actor_loss": -0.21779195964336395, "actor_target_entropy": -2.0, "actor_entropy": 1.4974162578582764, "alpha_loss": 0.004318932071328163, "alpha_value": 0.0037575121437599976, "duration": 1.9234848022460938, "step": 46479}
{"episode_reward": -5.206934083834898, "episode": 1555.0, "batch_reward": -0.02782745659351349, "critic_loss": 0.6633917093276978, "ae_transition_loss": 1.0434450507164001, "ae_encoder_loss": 1.1659846901893616, "actor_loss": -0.797653079032898, "actor_target_entropy": -2.0, "actor_entropy": 1.2925807237625122, "alpha_loss": 0.00464965938590467, "alpha_value": 0.003755497269456819, "duration": 2.8339455127716064, "step": 46491}
{"episode_reward": -5.317965887816913, "episode": 1556.0, "batch_reward": -0.034670883789658546, "critic_loss": 0.9080595374107361, "ae_transition_loss": 1.1902015805244446, "ae_encoder_loss": 0.8966624140739441, "actor_loss": -0.7743092179298401, "actor_target_entropy": -2.0, "actor_entropy": 1.7211490273475647, "alpha_loss": 0.0057528947945684195, "alpha_value": 0.0037524719927108235, "duration": 4.977806806564331, "step": 46517}
{"episode_reward": -15.090246507002432, "episode": 1557.0, "batch_reward": -0.03644324839115143, "critic_loss": 0.6466836134592692, "ae_transition_loss": 1.1459044615427654, "ae_encoder_loss": 0.9515160918235779, "actor_loss": -0.5592259565989176, "actor_target_entropy": -2.0, "actor_entropy": 2.454681396484375, "alpha_loss": 0.0038907629592965045, "alpha_value": 0.003747995973890094, "duration": 6.691863775253296, "step": 46549}
{"episode_reward": -11.12875144157165, "episode": 1558.0, "batch_reward": -0.05366110180815061, "critic_loss": 0.6973819136619568, "ae_transition_loss": 1.3000897566477458, "ae_encoder_loss": 0.7275171279907227, "actor_loss": -0.47501354416211444, "actor_target_entropy": -2.0, "actor_entropy": 1.9285732905069988, "alpha_loss": 0.004352574857572715, "alpha_value": 0.003742423569163631, "duration": 5.285672903060913, "step": 46573}
{"episode_reward": -6.1436094259261536, "episode": 1559.0, "duration": 1.2137670516967773, "step": 46579}
{"episode_reward": -2.0000595614424515, "episode": 1560.0, "batch_reward": -0.010705135762691498, "critic_loss": 0.968610425790151, "ae_transition_loss": 1.0598559379577637, "ae_encoder_loss": 0.726189653078715, "actor_loss": -0.868821938832601, "actor_target_entropy": -2.0, "actor_entropy": 1.0544945001602173, "alpha_loss": 0.00471798578898112, "alpha_value": 0.0037366884264966663, "duration": 5.020301580429077, "step": 46603}
{"episode_reward": -3.774417938984144, "episode": 1561.0, "batch_reward": -0.07287492603063583, "critic_loss": 0.8839520215988159, "ae_transition_loss": 1.2895550727844238, "ae_encoder_loss": 0.8606950044631958, "actor_loss": -1.012148141860962, "actor_target_entropy": -2.0, "actor_entropy": 1.1184256076812744, "alpha_loss": 0.005115615203976631, "alpha_value": 0.0037326848163286566, "duration": 128.54723525047302, "step": 46614}
{"episode_reward": -3.475899445203333, "episode": 1562.0, "batch_reward": -0.0632244125008583, "critic_loss": 0.4763615131378174, "ae_transition_loss": 1.1170659065246582, "ae_encoder_loss": 0.9825646281242371, "actor_loss": -0.45757824182510376, "actor_target_entropy": -2.0, "actor_entropy": 1.5538101196289062, "alpha_loss": 0.0053435321897268295, "alpha_value": 0.003730590954580854, "duration": 2.891956329345703, "step": 46627}
{"episode_reward": -4.165572437187132, "episode": 1563.0, "duration": 0.2198939323425293, "step": 46628}
{"episode_reward": 0.06206753268326337, "episode": 1564.0, "batch_reward": 0.011539469473063946, "critic_loss": 1.0959355235099792, "ae_transition_loss": 1.2059252262115479, "ae_encoder_loss": 0.8622587025165558, "actor_loss": -0.9249826669692993, "actor_target_entropy": -2.0, "actor_entropy": 2.1839998960494995, "alpha_loss": 0.0050264080055058, "alpha_value": 0.003727319365614669, "duration": 3.7966830730438232, "step": 46646}
{"episode_reward": -5.8520731786407065, "episode": 1565.0, "batch_reward": -0.005700388845677177, "critic_loss": 0.9505774776140848, "ae_transition_loss": 1.4796662330627441, "ae_encoder_loss": 0.6854031880696615, "actor_loss": -0.6797659993171692, "actor_target_entropy": -2.0, "actor_entropy": 2.542322317759196, "alpha_loss": 0.005467160915335019, "alpha_value": 0.0037217125825112197, "duration": 5.515266418457031, "step": 46672}
{"episode_reward": -9.40580515670605, "episode": 1566.0, "batch_reward": -0.02591042034327984, "critic_loss": 0.8092727065086365, "ae_transition_loss": 0.9539395868778229, "ae_encoder_loss": 0.7335325479507446, "actor_loss": -0.9191458523273468, "actor_target_entropy": -2.0, "actor_entropy": 1.969666838645935, "alpha_loss": 0.005657681729644537, "alpha_value": 0.00371586859656055, "duration": 4.41668963432312, "step": 46692}
{"episode_reward": -5.269107089226842, "episode": 1567.0, "batch_reward": 0.048676036298274994, "critic_loss": 0.9014391899108887, "ae_transition_loss": 1.274164080619812, "ae_encoder_loss": 0.6086188554763794, "actor_loss": -1.3097048997879028, "actor_target_entropy": -2.0, "actor_entropy": 1.4547905921936035, "alpha_loss": 0.006021494045853615, "alpha_value": 0.0037122291476891097, "duration": 3.594370126724243, "step": 46710}
{"episode_reward": -9.098871622435542, "episode": 1568.0, "batch_reward": -0.04343145340681076, "critic_loss": 1.34488578637441, "ae_transition_loss": 1.1191859642664592, "ae_encoder_loss": 0.8833429217338562, "actor_loss": -0.8907057841618856, "actor_target_entropy": -2.0, "actor_entropy": 1.3153139750162761, "alpha_loss": 0.00409977479527394, "alpha_value": 0.0037072350533023553, "duration": 5.735920667648315, "step": 46737}
{"episode_reward": -4.917505975785465, "episode": 1569.0, "batch_reward": -0.02165475580841303, "critic_loss": 0.5901068150997162, "ae_transition_loss": 1.2094047665596008, "ae_encoder_loss": 0.6944913268089294, "actor_loss": -0.5108145922422409, "actor_target_entropy": -2.0, "actor_entropy": 1.6283850073814392, "alpha_loss": 0.005353361368179321, "alpha_value": 0.003701161448917876, "duration": 3.2398252487182617, "step": 46751}
{"episode_reward": -5.0222124189874675, "episode": 1570.0, "batch_reward": -0.0856802687048912, "critic_loss": 0.884344220161438, "ae_transition_loss": 1.1761937141418457, "ae_encoder_loss": 0.8245425224304199, "actor_loss": -0.180794820189476, "actor_target_entropy": -2.0, "actor_entropy": 1.8866941332817078, "alpha_loss": 0.003897337010130286, "alpha_value": 0.003696317538443265, "duration": 4.312662839889526, "step": 46771}
{"episode_reward": -4.245186966081178, "episode": 1571.0, "batch_reward": -0.054188554330418505, "critic_loss": 1.1351127823193867, "ae_transition_loss": 1.270841081937154, "ae_encoder_loss": 0.4875597457091014, "actor_loss": -0.647209882736206, "actor_target_entropy": -2.0, "actor_entropy": 1.7746559778849285, "alpha_loss": 0.005042999361952146, "alpha_value": 0.003690447432044311, "duration": 46.07481050491333, "step": 46802}
{"episode_reward": -14.145260699564172, "episode": 1572.0, "batch_reward": -0.029976357705891132, "critic_loss": 0.922791987657547, "ae_transition_loss": 1.0998887419700623, "ae_encoder_loss": 0.5704955458641052, "actor_loss": -0.7144901156425476, "actor_target_entropy": -2.0, "actor_entropy": 1.5006915926933289, "alpha_loss": 0.004813056671991944, "alpha_value": 0.003684523183006721, "duration": 4.487869024276733, "step": 46824}
{"episode_reward": -6.52050362244438, "episode": 1573.0, "batch_reward": -0.00621021818369627, "critic_loss": 0.77108433842659, "ae_transition_loss": 1.1132946014404297, "ae_encoder_loss": 0.5803564488887787, "actor_loss": -0.7536205947399139, "actor_target_entropy": -2.0, "actor_entropy": 1.458703637123108, "alpha_loss": 0.004291906021535397, "alpha_value": 0.003679764703667092, "duration": 3.980048894882202, "step": 46842}
{"episode_reward": -1.3809058140477029, "episode": 1574.0, "batch_reward": -0.0409059077501297, "critic_loss": 0.6387723088264465, "ae_transition_loss": 1.0844571590423584, "ae_encoder_loss": 0.6689341589808464, "actor_loss": -0.6333407610654831, "actor_target_entropy": -2.0, "actor_entropy": 1.640268474817276, "alpha_loss": 0.0035817965399473906, "alpha_value": 0.0036728779920640387, "duration": 8.27135181427002, "step": 46881}
{"episode_reward": -6.3896760907527845, "episode": 1575.0, "batch_reward": -0.03159459959715605, "critic_loss": 0.6316936761140823, "ae_transition_loss": 1.1474820971488953, "ae_encoder_loss": 0.5814917534589767, "actor_loss": -0.8391885161399841, "actor_target_entropy": -2.0, "actor_entropy": 1.8910164833068848, "alpha_loss": 0.0044933652970939875, "alpha_value": 0.0036663445755011196, "duration": 4.377814531326294, "step": 46902}
{"episode_reward": -8.894678081308875, "episode": 1576.0, "batch_reward": -0.02520407037809491, "critic_loss": 0.459655225276947, "ae_transition_loss": 1.04606431722641, "ae_encoder_loss": 0.6924275457859039, "actor_loss": -0.49892206490039825, "actor_target_entropy": -2.0, "actor_entropy": 2.065062403678894, "alpha_loss": 0.0053959370125085115, "alpha_value": 0.003662015313470949, "duration": 4.912137269973755, "step": 46926}
{"episode_reward": -4.411462174241915, "episode": 1577.0, "batch_reward": -0.0493695312179625, "critic_loss": 0.7001480460166931, "ae_transition_loss": 1.2774949967861176, "ae_encoder_loss": 0.7939766123890877, "actor_loss": -0.5206533707678318, "actor_target_entropy": -2.0, "actor_entropy": 1.4950231611728668, "alpha_loss": 0.006107558612711728, "alpha_value": 0.0036551533146508166, "duration": 7.800946235656738, "step": 46963}
{"episode_reward": -0.13650787743167617, "episode": 1578.0, "batch_reward": -0.017743136112888653, "critic_loss": 0.9061496605475744, "ae_transition_loss": 1.1855292717615764, "ae_encoder_loss": 0.9060276945432028, "actor_loss": -0.7451329628626505, "actor_target_entropy": -2.0, "actor_entropy": 1.2912084658940632, "alpha_loss": 0.00599792009840409, "alpha_value": 0.0036464582772042526, "duration": 6.696460247039795, "step": 46995}
{"episode_reward": -5.351188736009965, "episode": 1579.0, "batch_reward": -0.07775155454874039, "critic_loss": 0.6353451013565063, "ae_transition_loss": 1.1483242511749268, "ae_encoder_loss": 0.5261597037315369, "actor_loss": -0.5382574796676636, "actor_target_entropy": -2.0, "actor_entropy": 1.714980125427246, "alpha_loss": 0.0041076429188251495, "alpha_value": 0.00364122399562706, "duration": 2.999873161315918, "step": 47009}
{"episode_reward": -6.189861246001585, "episode": 1580.0, "batch_reward": 0.0028408709913492203, "critic_loss": 0.6752098997433981, "ae_transition_loss": 0.9695483048756918, "ae_encoder_loss": 0.6954004168510437, "actor_loss": -0.5779029627641042, "actor_target_entropy": -2.0, "actor_entropy": 1.9853114287058513, "alpha_loss": 0.004875301926707228, "alpha_value": 0.0036361186126141498, "duration": 5.6317973136901855, "step": 47035}
{"episode_reward": -12.712993072383643, "episode": 1581.0, "batch_reward": 0.0007221587002277374, "critic_loss": 0.7382419109344482, "ae_transition_loss": 1.2402678728103638, "ae_encoder_loss": 0.45005255937576294, "actor_loss": -0.8585454225540161, "actor_target_entropy": -2.0, "actor_entropy": 2.260486602783203, "alpha_loss": 0.004390244837850332, "alpha_value": 0.0036310412196678184, "duration": 34.167744398117065, "step": 47049}
{"episode_reward": -2.351652525837497, "episode": 1582.0, "batch_reward": -0.042925224329034485, "critic_loss": 0.5196392436822256, "ae_transition_loss": 1.0512841542561848, "ae_encoder_loss": 0.59617547194163, "actor_loss": -0.6113619208335876, "actor_target_entropy": -2.0, "actor_entropy": 2.029899080594381, "alpha_loss": 0.005693478199342887, "alpha_value": 0.0036259640852171963, "duration": 5.1024675369262695, "step": 47071}
{"episode_reward": -1.1276285471949536, "episode": 1583.0, "batch_reward": -0.052414754405617714, "critic_loss": 0.702362447977066, "ae_transition_loss": 1.288742482662201, "ae_encoder_loss": 0.6218061447143555, "actor_loss": -0.4427984431385994, "actor_target_entropy": -2.0, "actor_entropy": 1.4580416679382324, "alpha_loss": 0.005263360450044274, "alpha_value": 0.003619510440862152, "duration": 5.073164939880371, "step": 47096}
{"episode_reward": -2.227786830456185, "episode": 1584.0, "batch_reward": -0.051186581452687584, "critic_loss": 0.5560547610123953, "ae_transition_loss": 1.4445812503496807, "ae_encoder_loss": 0.6119494438171387, "actor_loss": -0.7574823300043741, "actor_target_entropy": -2.0, "actor_entropy": 1.2069352865219116, "alpha_loss": 0.004909949687620004, "alpha_value": 0.003613091759413647, "duration": 6.368180274963379, "step": 47125}
{"episode_reward": -5.267363595083915, "episode": 1585.0, "duration": 0.2392418384552002, "step": 47126}
{"episode_reward": -0.3319228190102109, "episode": 1586.0, "duration": 0.22376489639282227, "step": 47127}
{"episode_reward": -0.36293214559555054, "episode": 1587.0, "batch_reward": -0.03153427131474018, "critic_loss": 0.6605321963628134, "ae_transition_loss": 1.510947585105896, "ae_encoder_loss": 0.8948137362798055, "actor_loss": -0.7987798055013021, "actor_target_entropy": -2.0, "actor_entropy": 1.6887503067652385, "alpha_loss": 0.005794236281265815, "alpha_value": 0.003605519831419976, "duration": 6.236233234405518, "step": 47157}
{"episode_reward": -12.026034332735406, "episode": 1588.0, "batch_reward": -0.07162421196699142, "critic_loss": 0.5107306838035583, "ae_transition_loss": 1.6020328402519226, "ae_encoder_loss": 0.9295892715454102, "actor_loss": -0.4772958308458328, "actor_target_entropy": -2.0, "actor_entropy": 2.420660376548767, "alpha_loss": 0.0054750165436416864, "alpha_value": 0.0035990739525571898, "duration": 4.719547986984253, "step": 47179}
{"episode_reward": -7.486099196240158, "episode": 1589.0, "batch_reward": -0.008792758919298649, "critic_loss": 0.742705762386322, "ae_transition_loss": 1.2343743443489075, "ae_encoder_loss": 1.0741999745368958, "actor_loss": -0.7628275752067566, "actor_target_entropy": -2.0, "actor_entropy": 2.125051975250244, "alpha_loss": 0.004467040533199906, "alpha_value": 0.0035938293523752997, "duration": 3.3465538024902344, "step": 47194}
{"episode_reward": -5.818081130503554, "episode": 1590.0, "duration": 0.24501299858093262, "step": 47195}
{"episode_reward": -0.4093952148006561, "episode": 1591.0, "batch_reward": -0.06337165439294444, "critic_loss": 0.6796723736657037, "ae_transition_loss": 1.0245343181822035, "ae_encoder_loss": 0.694846941365136, "actor_loss": -0.5827026466528574, "actor_target_entropy": -2.0, "actor_entropy": 1.220316105418735, "alpha_loss": 0.0029826774003191125, "alpha_value": 0.003581049574237604, "duration": 111.67669701576233, "step": 47282}
{"episode_reward": -40.33147588114193, "episode": 1592.0, "batch_reward": 0.03252711519598961, "critic_loss": 0.5688947439193726, "ae_transition_loss": 0.9118963479995728, "ae_encoder_loss": 1.1355900764465332, "actor_loss": -0.9448180198669434, "actor_target_entropy": -2.0, "actor_entropy": 1.3161306381225586, "alpha_loss": 0.00429964205250144, "alpha_value": 0.0035710180242213493, "duration": 3.231069564819336, "step": 47298}
{"episode_reward": -5.471490366995667, "episode": 1593.0, "batch_reward": -0.05634117983281613, "critic_loss": 0.9085384488105774, "ae_transition_loss": 1.1979789018630982, "ae_encoder_loss": 1.0916883826255799, "actor_loss": -0.3359021544456482, "actor_target_entropy": -2.0, "actor_entropy": 1.354347252845764, "alpha_loss": 0.004824542347341776, "alpha_value": 0.003565082741840726, "duration": 9.39565396308899, "step": 47341}
{"episode_reward": -11.067751486546312, "episode": 1594.0, "batch_reward": -0.05984059628099203, "critic_loss": 0.9990063607692719, "ae_transition_loss": 1.3087117969989777, "ae_encoder_loss": 1.089253917336464, "actor_loss": -0.4410674571990967, "actor_target_entropy": -2.0, "actor_entropy": 1.4970492124557495, "alpha_loss": 0.005274648079648614, "alpha_value": 0.0035555636035460875, "duration": 10.003873109817505, "step": 47390}
{"episode_reward": -10.832055489580503, "episode": 1595.0, "batch_reward": -0.04644994158297777, "critic_loss": 0.89400914311409, "ae_transition_loss": 1.2085341314474742, "ae_encoder_loss": 0.8885852495829264, "actor_loss": -0.8986909588177999, "actor_target_entropy": -2.0, "actor_entropy": 1.7636763056119282, "alpha_loss": 0.0049014649509141845, "alpha_value": 0.003544334724710113, "duration": 11.92772126197815, "step": 47449}
{"episode_reward": -7.646054317072159, "episode": 1596.0, "batch_reward": -0.0473502054810524, "critic_loss": 0.6818891167640686, "ae_transition_loss": 1.2986841201782227, "ae_encoder_loss": 0.9372324645519257, "actor_loss": -0.46263809502124786, "actor_target_entropy": -2.0, "actor_entropy": 1.7931231260299683, "alpha_loss": 0.0049328990280628204, "alpha_value": 0.003535194269630696, "duration": 3.995753526687622, "step": 47468}
{"episode_reward": -6.781390485814975, "episode": 1597.0, "batch_reward": -0.004831938073039055, "critic_loss": 0.5758036971092224, "ae_transition_loss": 1.2606768012046814, "ae_encoder_loss": 0.8197648525238037, "actor_loss": -0.8709215223789215, "actor_target_entropy": -2.0, "actor_entropy": 1.7193817496299744, "alpha_loss": 0.0048065034206956625, "alpha_value": 0.00353052416214566, "duration": 3.9558162689208984, "step": 47487}
{"episode_reward": -7.563921494080027, "episode": 1598.0, "batch_reward": -0.04230605810880661, "critic_loss": 0.5733548402786255, "ae_transition_loss": 1.4690903425216675, "ae_encoder_loss": 1.0987113118171692, "actor_loss": -0.5868871510028839, "actor_target_entropy": -2.0, "actor_entropy": 1.6834859251976013, "alpha_loss": 0.004331013187766075, "alpha_value": 0.0035258738929577066, "duration": 4.731852293014526, "step": 47510}
{"episode_reward": -7.976136557034062, "episode": 1599.0, "batch_reward": -0.05415104600884344, "critic_loss": 0.7853701619998269, "ae_transition_loss": 1.2368948537370432, "ae_encoder_loss": 0.8258443941240725, "actor_loss": -0.6189928611983424, "actor_target_entropy": -2.0, "actor_entropy": 1.7995707159457, "alpha_loss": 0.001309018931351602, "alpha_value": 0.003507737971127168, "duration": 45.20496988296509, "step": 47734}
{"episode_reward": -168.83904141462182, "episode": 1600.0, "batch_reward": -0.08522243164479733, "critic_loss": 0.7827671051025391, "ae_transition_loss": 1.4196160793304444, "ae_encoder_loss": 1.3410866260528564, "actor_loss": -0.43874924778938296, "actor_target_entropy": -2.0, "actor_entropy": 1.8325562000274658, "alpha_loss": 0.00410121213644743, "alpha_value": 0.003494768073058351, "duration": 11.238728761672974, "step": 47790}
{"episode_reward": -20.64923598554772, "episode": 1601.0, "batch_reward": -0.03639877215027809, "critic_loss": 0.9595963756243387, "ae_transition_loss": 1.4708778063456218, "ae_encoder_loss": 1.1502745350201924, "actor_loss": -0.5654408435026804, "actor_target_entropy": -2.0, "actor_entropy": 1.6073005199432373, "alpha_loss": 0.003976673275853197, "alpha_value": 0.0034890949336370465, "duration": 25.583686113357544, "step": 47816}
{"episode_reward": -8.71605247971001, "episode": 1602.0, "batch_reward": -0.03467278927564621, "critic_loss": 0.73863152662913, "ae_transition_loss": 1.2950501441955566, "ae_encoder_loss": 1.0501622160275776, "actor_loss": -0.337858647108078, "actor_target_entropy": -2.0, "actor_entropy": 1.5668328205744426, "alpha_loss": 0.004611876637985309, "alpha_value": 0.003484244204158235, "duration": 6.12784481048584, "step": 47845}
{"episode_reward": -10.611431034846639, "episode": 1603.0, "batch_reward": 0.01212648581713438, "critic_loss": 0.6116909682750702, "ae_transition_loss": 1.2053293585777283, "ae_encoder_loss": 0.9286774396896362, "actor_loss": -1.164150595664978, "actor_target_entropy": -2.0, "actor_entropy": 1.4919390082359314, "alpha_loss": 0.0027427998138591647, "alpha_value": 0.0034798372529443178, "duration": 4.259981155395508, "step": 47866}
{"episode_reward": -9.292449997051495, "episode": 1604.0, "duration": 0.24353432655334473, "step": 47867}
{"episode_reward": -0.0938704358731205, "episode": 1605.0, "duration": 0.23161721229553223, "step": 47868}
{"episode_reward": -0.4802190780143524, "episode": 1606.0, "duration": 0.2243807315826416, "step": 47869}
{"episode_reward": -0.47655948996543884, "episode": 1607.0, "batch_reward": -0.06667949445545673, "critic_loss": 0.6054889410734177, "ae_transition_loss": 1.4012760519981384, "ae_encoder_loss": 0.9400746673345566, "actor_loss": -0.5867599882185459, "actor_target_entropy": -2.0, "actor_entropy": 1.6793147325515747, "alpha_loss": 0.0035301907337270677, "alpha_value": 0.0034746584778416983, "duration": 7.111434698104858, "step": 47903}
{"episode_reward": -20.18144465602837, "episode": 1608.0, "batch_reward": -0.07767431065440178, "critic_loss": 0.7179453372955322, "ae_transition_loss": 1.2760396003723145, "ae_encoder_loss": 0.7731178104877472, "actor_loss": -0.5708390772342682, "actor_target_entropy": -2.0, "actor_entropy": 2.0308425426483154, "alpha_loss": 0.0027304908726364374, "alpha_value": 0.0034695994351005535, "duration": 5.427896499633789, "step": 47930}
{"episode_reward": -14.07781291112833, "episode": 1609.0, "batch_reward": 0.012529903091490269, "critic_loss": 0.708195686340332, "ae_transition_loss": 1.146475002169609, "ae_encoder_loss": 0.7665694802999496, "actor_loss": -0.931567519903183, "actor_target_entropy": -2.0, "actor_entropy": 1.98111093044281, "alpha_loss": 0.0013841326290275902, "alpha_value": 0.003464849526102951, "duration": 7.559793472290039, "step": 47966}
{"episode_reward": -22.000863361549435, "episode": 1610.0, "batch_reward": -0.043020522221922874, "critic_loss": 0.6110972464084625, "ae_transition_loss": 1.2387118339538574, "ae_encoder_loss": 1.1530969738960266, "actor_loss": -0.614847332239151, "actor_target_entropy": -2.0, "actor_entropy": 1.5567572712898254, "alpha_loss": 0.00017978767573367804, "alpha_value": 0.0034607319193463936, "duration": 3.717582941055298, "step": 47982}
{"episode_reward": -9.840586501841065, "episode": 1611.0, "batch_reward": 0.013372217305004597, "critic_loss": 0.4199827313423157, "ae_transition_loss": 1.1649150848388672, "ae_encoder_loss": 1.1731839179992676, "actor_loss": -0.9478514194488525, "actor_target_entropy": -2.0, "actor_entropy": 1.5105006694793701, "alpha_loss": -0.0015448859194293618, "alpha_value": 0.0034590931327786265, "duration": 83.70226693153381, "step": 47999}
{"episode_reward": -9.208220940117744, "episode": 1612.0, "batch_reward": -0.03879588842391968, "critic_loss": 0.8401103019714355, "ae_transition_loss": 1.2578200101852417, "ae_encoder_loss": 0.9303543567657471, "actor_loss": -0.5079049468040466, "actor_target_entropy": -2.0, "actor_entropy": 1.6768858432769775, "alpha_loss": 0.0008293219143524766, "alpha_value": 0.0034578185633562823, "duration": 4.1036107540130615, "step": 48018}
{"episode_reward": -12.790598849429324, "episode": 1613.0, "batch_reward": -0.0401451401412487, "critic_loss": 0.4099898040294647, "ae_transition_loss": 0.9386440217494965, "ae_encoder_loss": 0.7387176156044006, "actor_loss": -0.5581484287977219, "actor_target_entropy": -2.0, "actor_entropy": 1.9608009457588196, "alpha_loss": 0.0036822305992245674, "alpha_value": 0.0034562258278824044, "duration": 3.0714900493621826, "step": 48031}
{"episode_reward": -4.231799859094136, "episode": 1614.0, "batch_reward": -0.062111735343933105, "critic_loss": 0.7874883860349655, "ae_transition_loss": 1.0858503480752308, "ae_encoder_loss": 0.67377337316672, "actor_loss": -0.4549415210882823, "actor_target_entropy": -2.0, "actor_entropy": 2.0105966130892434, "alpha_loss": 0.0064079964843889075, "alpha_value": 0.0034513011669429043, "duration": 13.30387544631958, "step": 48094}
{"episode_reward": -20.625703534664847, "episode": 1615.0, "batch_reward": -0.04409047029912472, "critic_loss": 0.9159119427204132, "ae_transition_loss": 1.202263206243515, "ae_encoder_loss": 0.605955645442009, "actor_loss": -0.41280248016119003, "actor_target_entropy": -2.0, "actor_entropy": 1.6879743933677673, "alpha_loss": 0.005892985383979976, "alpha_value": 0.0034420419882998194, "duration": 8.13560962677002, "step": 48131}
{"episode_reward": -7.5335104388846545, "episode": 1616.0, "batch_reward": -0.043021202087402344, "critic_loss": 0.5309494137763977, "ae_transition_loss": 1.1616674661636353, "ae_encoder_loss": 0.6343917548656464, "actor_loss": -0.7464551627635956, "actor_target_entropy": -2.0, "actor_entropy": 1.618713140487671, "alpha_loss": 0.005462887696921825, "alpha_value": 0.0034353404817298204, "duration": 4.475051403045654, "step": 48153}
{"episode_reward": -3.7970271142057053, "episode": 1617.0, "batch_reward": -0.08609496057033539, "critic_loss": 0.5031822323799133, "ae_transition_loss": 1.1799678206443787, "ae_encoder_loss": 0.6814944893121719, "actor_loss": -0.6379092335700989, "actor_target_entropy": -2.0, "actor_entropy": 1.6486284732818604, "alpha_loss": 0.0048351832665503025, "alpha_value": 0.0034306113538375904, "duration": 4.877014636993408, "step": 48177}
{"episode_reward": -5.937588069251129, "episode": 1618.0, "duration": 0.23145079612731934, "step": 48178}
{"episode_reward": -0.2006939510307917, "episode": 1619.0, "batch_reward": -0.08086235634982586, "critic_loss": 1.1539083123207092, "ae_transition_loss": 1.4140634536743164, "ae_encoder_loss": 0.8585436642169952, "actor_loss": -0.6881145238876343, "actor_target_entropy": -2.0, "actor_entropy": 1.6178632378578186, "alpha_loss": 0.004266740288585424, "alpha_value": 0.0034259022477380807, "duration": 4.348077297210693, "step": 48199}
{"episode_reward": -4.465657844260516, "episode": 1620.0, "batch_reward": -0.0517078364888827, "critic_loss": 0.7843013803164164, "ae_transition_loss": 1.0547766486803691, "ae_encoder_loss": 0.6514292359352112, "actor_loss": -0.5476679503917694, "actor_target_entropy": -2.0, "actor_entropy": 1.6518385410308838, "alpha_loss": 0.004750868616004785, "alpha_value": 0.0034201729218894792, "duration": 5.056806325912476, "step": 48222}
{"episode_reward": -7.363289807870497, "episode": 1621.0, "batch_reward": -0.02833018498495221, "critic_loss": 0.6158975958824158, "ae_transition_loss": 1.217723786830902, "ae_encoder_loss": 0.7435147762298584, "actor_loss": -0.5494435727596283, "actor_target_entropy": -2.0, "actor_entropy": 1.6786605715751648, "alpha_loss": 0.005589160835370421, "alpha_value": 0.0034144422396877156, "duration": 47.19872784614563, "step": 48246}
{"episode_reward": -6.822452846196919, "episode": 1622.0, "duration": 0.22780895233154297, "step": 48247}
{"episode_reward": -0.4224168360233307, "episode": 1623.0, "batch_reward": -0.04807203263044357, "critic_loss": 0.7648386657238007, "ae_transition_loss": 1.2147098183631897, "ae_encoder_loss": 0.8514220416545868, "actor_loss": -0.6024574637413025, "actor_target_entropy": -2.0, "actor_entropy": 1.6841651797294617, "alpha_loss": 0.0037151642609387636, "alpha_value": 0.0034097586924114456, "duration": 3.654742956161499, "step": 48265}
{"episode_reward": -4.451657140349776, "episode": 1624.0, "duration": 0.8964872360229492, "step": 48268}
{"episode_reward": -1.3626554556262676, "episode": 1625.0, "batch_reward": -0.0655564134940505, "critic_loss": 0.5423677861690521, "ae_transition_loss": 1.0581213235855103, "ae_encoder_loss": 0.8493967205286026, "actor_loss": -0.5183785874396563, "actor_target_entropy": -2.0, "actor_entropy": 1.7189750671386719, "alpha_loss": 0.004258551693055779, "alpha_value": 0.0034030334733099873, "duration": 7.0030341148376465, "step": 48302}
{"episode_reward": -13.939750159011833, "episode": 1626.0, "duration": 0.22224879264831543, "step": 48303}
{"episode_reward": -0.11999289369338884, "episode": 1627.0, "batch_reward": -0.06790836434811354, "critic_loss": 0.5020464211702347, "ae_transition_loss": 1.3022623658180237, "ae_encoder_loss": 0.5795469582080841, "actor_loss": -0.6289924085140228, "actor_target_entropy": -2.0, "actor_entropy": 1.7765825986862183, "alpha_loss": 0.0042844710405915976, "alpha_value": 0.0033964753336489656, "duration": 4.67061448097229, "step": 48325}
{"episode_reward": -9.87870586308091, "episode": 1628.0, "duration": 0.24358177185058594, "step": 48326}
{"episode_reward": -1.0371597835615156, "episode": 1629.0, "duration": 0.22409510612487793, "step": 48327}
{"episode_reward": -0.7875071135155365, "episode": 1630.0, "batch_reward": -0.053191546350717545, "critic_loss": 0.6282509466012319, "ae_transition_loss": 1.3345845143000286, "ae_encoder_loss": 0.8491019805272421, "actor_loss": -0.6323559383551279, "actor_target_entropy": -2.0, "actor_entropy": 1.6471198002497356, "alpha_loss": 0.0016798981232568622, "alpha_value": 0.0033912439340632247, "duration": 5.513233184814453, "step": 48353}
{"episode_reward": -8.71332187588744, "episode": 1631.0, "batch_reward": -0.07031117379665375, "critic_loss": 0.7690908014774323, "ae_transition_loss": 1.1412957310676575, "ae_encoder_loss": 0.7425536811351776, "actor_loss": -0.45205608010292053, "actor_target_entropy": -2.0, "actor_entropy": 1.6427696347236633, "alpha_loss": 0.001194104115711525, "alpha_value": 0.0033866312759175104, "duration": 50.08669400215149, "step": 48373}
{"episode_reward": -10.546568185541485, "episode": 1632.0, "batch_reward": -0.08518792688846588, "critic_loss": 0.6798069775104523, "ae_transition_loss": 1.2890573740005493, "ae_encoder_loss": 0.8591670989990234, "actor_loss": -0.778785765171051, "actor_target_entropy": -2.0, "actor_entropy": 1.7250813841819763, "alpha_loss": 0.0016450670664198697, "alpha_value": 0.0033834630985515738, "duration": 4.157094478607178, "step": 48392}
{"episode_reward": -9.306911441412224, "episode": 1633.0, "batch_reward": -0.0491131276357919, "critic_loss": 0.3893749713897705, "ae_transition_loss": 1.3159718215465546, "ae_encoder_loss": 0.9008982181549072, "actor_loss": -0.6314930766820908, "actor_target_entropy": -2.0, "actor_entropy": 2.004861831665039, "alpha_loss": 0.00263862224528566, "alpha_value": 0.0033791814110378246, "duration": 9.405049562454224, "step": 48439}
{"episode_reward": -31.849561460601915, "episode": 1634.0, "batch_reward": -0.08282570727169514, "critic_loss": 0.8120442926883698, "ae_transition_loss": 1.1398853063583374, "ae_encoder_loss": 0.7221079468727112, "actor_loss": -0.42182670533657074, "actor_target_entropy": -2.0, "actor_entropy": 2.1111828088760376, "alpha_loss": 0.002329370705410838, "alpha_value": 0.0033750327261144243, "duration": 3.1421570777893066, "step": 48454}
{"episode_reward": -9.46291615819639, "episode": 1635.0, "batch_reward": -0.004597509279847145, "critic_loss": 0.718273401260376, "ae_transition_loss": 1.1530017852783203, "ae_encoder_loss": 0.8991079330444336, "actor_loss": -0.7300161123275757, "actor_target_entropy": -2.0, "actor_entropy": 1.9095648527145386, "alpha_loss": 0.0017174468375742435, "alpha_value": 0.0033730352430477602, "duration": 2.144376754760742, "step": 48463}
{"episode_reward": -3.418586750865096, "episode": 1636.0, "batch_reward": -0.14118359982967377, "critic_loss": 0.41352516412734985, "ae_transition_loss": 1.2527936697006226, "ae_encoder_loss": 1.0035282373428345, "actor_loss": -0.5184493064880371, "actor_target_entropy": -2.0, "actor_entropy": 1.855139136314392, "alpha_loss": 0.002579230349510908, "alpha_value": 0.0033717700799794437, "duration": 3.1418192386627197, "step": 48479}
{"episode_reward": -7.267710123381158, "episode": 1637.0, "batch_reward": -0.033936405554413795, "critic_loss": 0.5126164108514786, "ae_transition_loss": 1.23747980594635, "ae_encoder_loss": 0.4973791241645813, "actor_loss": -0.6537267565727234, "actor_target_entropy": -2.0, "actor_entropy": 1.5438914895057678, "alpha_loss": 0.0009668001730460674, "alpha_value": 0.0033699273592525674, "duration": 3.788071393966675, "step": 48497}
{"episode_reward": -8.97757240074009, "episode": 1638.0, "duration": 0.22757577896118164, "step": 48498}
{"episode_reward": -0.5591632866431682, "episode": 1639.0, "batch_reward": -0.060609253481603585, "critic_loss": 0.5841362315874833, "ae_transition_loss": 1.2353033606822674, "ae_encoder_loss": 0.7626844827945416, "actor_loss": -0.5652212466184909, "actor_target_entropy": -2.0, "actor_entropy": 1.649772020486685, "alpha_loss": 0.000407222015872741, "alpha_value": 0.003363608154383633, "duration": 25.170804500579834, "step": 48622}
{"episode_reward": -110.21887346882302, "episode": 1640.0, "duration": 0.25914716720581055, "step": 48623}
{"episode_reward": -0.27180821100644936, "episode": 1641.0, "duration": 105.10951113700867, "step": 48624}
{"episode_reward": -0.17243405734889705, "episode": 1642.0, "batch_reward": -0.03684011225899061, "critic_loss": 0.8725757797559103, "ae_transition_loss": 1.341420571009318, "ae_encoder_loss": 0.7271768848101298, "actor_loss": -0.7924948136011759, "actor_target_entropy": -2.0, "actor_entropy": 2.018725554148356, "alpha_loss": 0.0010892434996397544, "alpha_value": 0.003359424412000614, "duration": 6.8158369064331055, "step": 48656}
{"episode_reward": -20.053800827337923, "episode": 1643.0, "duration": 0.23561716079711914, "step": 48657}
{"episode_reward": -0.29468238801578744, "episode": 1644.0, "batch_reward": -0.08557565013567607, "critic_loss": 0.8844094077746073, "ae_transition_loss": 1.3543775081634521, "ae_encoder_loss": 0.865842362244924, "actor_loss": -0.503631462653478, "actor_target_entropy": -2.0, "actor_entropy": 1.7893717288970947, "alpha_loss": 0.0020247307450821004, "alpha_value": 0.0033578782462085877, "duration": 5.480268239974976, "step": 48681}
{"episode_reward": -10.556250770646244, "episode": 1645.0, "batch_reward": -0.06521607981994748, "critic_loss": 0.7423725724220276, "ae_transition_loss": 1.4405429661273956, "ae_encoder_loss": 0.9323493093252182, "actor_loss": -0.4047813415527344, "actor_target_entropy": -2.0, "actor_entropy": 1.5340718626976013, "alpha_loss": 0.0018704593239817768, "alpha_value": 0.003355732916807919, "duration": 9.459570169448853, "step": 48727}
{"episode_reward": -30.332096252511434, "episode": 1646.0, "batch_reward": -0.04584249667823315, "critic_loss": 0.9606643915176392, "ae_transition_loss": 1.2928627729415894, "ae_encoder_loss": 0.8476617534955343, "actor_loss": -0.6007113854090372, "actor_target_entropy": -2.0, "actor_entropy": 1.610088626543681, "alpha_loss": 0.0037990201575060687, "alpha_value": 0.003353140553048467, "duration": 5.286422252655029, "step": 48751}
{"episode_reward": -16.30048747563529, "episode": 1647.0, "batch_reward": -0.11064361035823822, "critic_loss": 0.6264290809631348, "ae_transition_loss": 1.3528832793235779, "ae_encoder_loss": 0.9231048226356506, "actor_loss": -0.4057656228542328, "actor_target_entropy": -2.0, "actor_entropy": 1.645642876625061, "alpha_loss": 0.003683517687022686, "alpha_value": 0.0033506365568292855, "duration": 5.845076560974121, "step": 48779}
{"episode_reward": -17.59695999544375, "episode": 1648.0, "batch_reward": -0.06408222464637624, "critic_loss": 0.6237946980529361, "ae_transition_loss": 1.3065905835893419, "ae_encoder_loss": 0.7953961458471086, "actor_loss": -0.4584227932824029, "actor_target_entropy": -2.0, "actor_entropy": 1.6563826269573636, "alpha_loss": 0.00222055819499979, "alpha_value": 0.003343996876982521, "duration": 17.661314249038696, "step": 48862}
{"episode_reward": -49.83116050202731, "episode": 1649.0, "batch_reward": -0.11127948760986328, "critic_loss": 0.8500638604164124, "ae_transition_loss": 1.3358123302459717, "ae_encoder_loss": 0.7562752366065979, "actor_loss": -0.6696159839630127, "actor_target_entropy": -2.0, "actor_entropy": 1.8460040092468262, "alpha_loss": 0.0018891403451561928, "alpha_value": 0.003338260966271818, "duration": 3.5104360580444336, "step": 48879}
{"episode_reward": -6.950770749163237, "episode": 1650.0, "duration": 0.24767327308654785, "step": 48880}
{"episode_reward": -0.39043535073523344, "episode": 1651.0, "batch_reward": -0.0778923430480063, "critic_loss": 0.4276116266846657, "ae_transition_loss": 1.4914508163928986, "ae_encoder_loss": 0.6079340279102325, "actor_loss": -0.6486341655254364, "actor_target_entropy": -2.0, "actor_entropy": 1.993404895067215, "alpha_loss": 0.0021752938846475445, "alpha_value": 0.0033357449793373103, "duration": 48.19041562080383, "step": 48913}
{"episode_reward": -10.848698456474967, "episode": 1652.0, "batch_reward": -0.054863519966602325, "critic_loss": 0.2961634695529938, "ae_transition_loss": 1.362612247467041, "ae_encoder_loss": 0.9075933694839478, "actor_loss": -0.4577754735946655, "actor_target_entropy": -2.0, "actor_entropy": 2.019273042678833, "alpha_loss": 0.0030274458695203066, "alpha_value": 0.003333214546330572, "duration": 2.366560459136963, "step": 48923}
{"episode_reward": -5.175806264300362, "episode": 1653.0, "batch_reward": -0.10199442505836487, "critic_loss": 1.0923465490341187, "ae_transition_loss": 1.002598762512207, "ae_encoder_loss": 1.3521349430084229, "actor_loss": -0.7617141604423523, "actor_target_entropy": -2.0, "actor_entropy": 1.9361644983291626, "alpha_loss": 0.0021157395094633102, "alpha_value": 0.003332097853415552, "duration": 3.322441339492798, "step": 48939}
{"episode_reward": -5.291295953912003, "episode": 1654.0, "batch_reward": -0.08194024364153545, "critic_loss": 0.5356690684954325, "ae_transition_loss": 1.2157168984413147, "ae_encoder_loss": 1.058959722518921, "actor_loss": -0.2892262041568756, "actor_target_entropy": -2.0, "actor_entropy": 1.8076407512029011, "alpha_loss": 0.003230314274939398, "alpha_value": 0.0033297535377590955, "duration": 5.3774402141571045, "step": 48964}
{"episode_reward": -8.530867850142926, "episode": 1655.0, "batch_reward": -0.07523935474455357, "critic_loss": 0.46559979021549225, "ae_transition_loss": 1.2149006724357605, "ae_encoder_loss": 0.8261494040489197, "actor_loss": -0.6959105134010315, "actor_target_entropy": -2.0, "actor_entropy": 1.5465810298919678, "alpha_loss": 0.003351254272274673, "alpha_value": 0.003326640178841176, "duration": 4.586145639419556, "step": 48985}
{"episode_reward": -6.607351915140255, "episode": 1656.0, "batch_reward": 0.03132319264113903, "critic_loss": 0.79622882604599, "ae_transition_loss": 1.3279316425323486, "ae_encoder_loss": 0.8283361792564392, "actor_loss": -1.0483088493347168, "actor_target_entropy": -2.0, "actor_entropy": 1.3658431768417358, "alpha_loss": 0.0004443279030965641, "alpha_value": 0.0033240948581208128, "duration": 4.48777961730957, "step": 49007}
{"episode_reward": -11.842949718607219, "episode": 1657.0, "batch_reward": -0.0021559055894613266, "critic_loss": 0.392227903008461, "ae_transition_loss": 1.2050950527191162, "ae_encoder_loss": 0.6826774179935455, "actor_loss": -0.8501465618610382, "actor_target_entropy": -2.0, "actor_entropy": 1.3403475880622864, "alpha_loss": 0.0003160442865919322, "alpha_value": 0.0033218818550791243, "duration": 3.446686029434204, "step": 49023}
{"episode_reward": -5.855160479067042, "episode": 1658.0, "batch_reward": -0.07625569713612397, "critic_loss": 0.4298594295978546, "ae_transition_loss": 1.1893831888834636, "ae_encoder_loss": 0.9371323188145956, "actor_loss": -0.534174770116806, "actor_target_entropy": -2.0, "actor_entropy": 1.577831228574117, "alpha_loss": -0.0001614218344911933, "alpha_value": 0.0033196917262128065, "duration": 7.0770769119262695, "step": 49058}
{"episode_reward": -19.74539077948519, "episode": 1659.0, "batch_reward": -0.0967174619436264, "critic_loss": 0.48719334602355957, "ae_transition_loss": 0.8088750839233398, "ae_encoder_loss": 1.1524428129196167, "actor_loss": -0.8417801856994629, "actor_target_entropy": -2.0, "actor_entropy": 1.8113855123519897, "alpha_loss": 0.000464483950054273, "alpha_value": 0.003318327403409176, "duration": 1.9280219078063965, "step": 49067}
{"episode_reward": -1.900345035358772, "episode": 1660.0, "batch_reward": -0.10356111327807109, "critic_loss": 0.8284626454114914, "ae_transition_loss": 1.3762488166491191, "ae_encoder_loss": 0.8017867008845011, "actor_loss": -0.1517449834694465, "actor_target_entropy": -2.0, "actor_entropy": 2.002342939376831, "alpha_loss": 0.0012477458658395335, "alpha_value": 0.0033164438729497013, "duration": 12.119797706604004, "step": 49127}
{"episode_reward": -35.97539093308379, "episode": 1661.0, "batch_reward": -0.013901793708403906, "critic_loss": 0.6191045045852661, "ae_transition_loss": 1.4063671827316284, "ae_encoder_loss": 1.4281740585962932, "actor_loss": -0.6743956208229065, "actor_target_entropy": -2.0, "actor_entropy": 1.6157310406366985, "alpha_loss": 0.0005287826061248779, "alpha_value": 0.0033137674650856193, "duration": 90.19139575958252, "step": 49160}
{"episode_reward": -20.20294873052115, "episode": 1662.0, "batch_reward": -0.017292445525527, "critic_loss": 1.0418174266815186, "ae_transition_loss": 1.3397729396820068, "ae_encoder_loss": 1.8256078958511353, "actor_loss": -0.5292240381240845, "actor_target_entropy": -2.0, "actor_entropy": 1.471653699874878, "alpha_loss": 0.0018836951348930597, "alpha_value": 0.0033125899584621954, "duration": 2.083831548690796, "step": 49170}
{"episode_reward": -4.996179145727826, "episode": 1663.0, "batch_reward": -0.08362405002117157, "critic_loss": 1.2200884819030762, "ae_transition_loss": 2.099501132965088, "ae_encoder_loss": 1.0235480070114136, "actor_loss": -0.47436559200286865, "actor_target_entropy": -2.0, "actor_entropy": 1.4108673334121704, "alpha_loss": 0.0007223074790090322, "alpha_value": 0.003312026633130947, "duration": 1.163722038269043, "step": 49175}
{"episode_reward": -1.8655933706161936, "episode": 1664.0, "batch_reward": -0.0766211138772113, "critic_loss": 0.9215717996869769, "ae_transition_loss": 1.650810377938407, "ae_encoder_loss": 1.213233768939972, "actor_loss": -0.5838481443268912, "actor_target_entropy": -2.0, "actor_entropy": 1.6668094055993217, "alpha_loss": 0.0018397370669325547, "alpha_value": 0.0033099230190905557, "duration": 14.775912761688232, "step": 49249}
{"episode_reward": -54.9477805162752, "episode": 1665.0, "batch_reward": -0.03849606898923715, "critic_loss": 0.7267058293024699, "ae_transition_loss": 1.3933806419372559, "ae_encoder_loss": 0.9559893806775411, "actor_loss": -0.7260632316271464, "actor_target_entropy": -2.0, "actor_entropy": 1.836620569229126, "alpha_loss": 0.002811026138563951, "alpha_value": 0.003306460726109312, "duration": 5.783667325973511, "step": 49277}
{"episode_reward": -9.776291743244723, "episode": 1666.0, "duration": 0.23173809051513672, "step": 49278}
{"episode_reward": -2.858036094610289, "episode": 1667.0, "batch_reward": -0.0818227706477046, "critic_loss": 0.8550472855567932, "ae_transition_loss": 1.482185274362564, "ae_encoder_loss": 0.6932036578655243, "actor_loss": -0.736135259270668, "actor_target_entropy": -2.0, "actor_entropy": 1.5208525955677032, "alpha_loss": 0.0013690998275706079, "alpha_value": 0.0033032747434556297, "duration": 7.2825026512146, "step": 49314}
{"episode_reward": -19.343571612474772, "episode": 1668.0, "batch_reward": -0.039350034669041634, "critic_loss": 0.589855432510376, "ae_transition_loss": 1.081181287765503, "ae_encoder_loss": 0.6851471960544586, "actor_loss": -0.4341457337141037, "actor_target_entropy": -2.0, "actor_entropy": 1.4191064834594727, "alpha_loss": 0.0025945903034880757, "alpha_value": 0.003300619057577614, "duration": 4.957209348678589, "step": 49337}
{"episode_reward": -9.309343002669426, "episode": 1669.0, "batch_reward": -0.07328616455197334, "critic_loss": 0.8075589239597321, "ae_transition_loss": 1.3760448098182678, "ae_encoder_loss": 1.080028772354126, "actor_loss": -0.5553300976753235, "actor_target_entropy": -2.0, "actor_entropy": 1.3441885709762573, "alpha_loss": 0.002845145994797349, "alpha_value": 0.0032987588534461078, "duration": 3.3528225421905518, "step": 49352}
{"episode_reward": -5.559329862090504, "episode": 1670.0, "batch_reward": -0.031910053143898644, "critic_loss": 0.7931201855341593, "ae_transition_loss": 1.2199734846750896, "ae_encoder_loss": 0.8364552656809489, "actor_loss": -0.6446395913759867, "actor_target_entropy": -2.0, "actor_entropy": 1.4289013544718425, "alpha_loss": 0.004607437799374263, "alpha_value": 0.003296053950710138, "duration": 6.730897903442383, "step": 49385}
{"episode_reward": -14.760397432774651, "episode": 1671.0, "batch_reward": -0.06230350024998188, "critic_loss": 0.6979029774665833, "ae_transition_loss": 1.2874557375907898, "ae_encoder_loss": 0.9229927361011505, "actor_loss": -0.6032989248633385, "actor_target_entropy": -2.0, "actor_entropy": 1.4502189755439758, "alpha_loss": 0.0045030469773337245, "alpha_value": 0.0032912532972654185, "duration": 63.13884210586548, "step": 49423}
{"episode_reward": -11.880179808097513, "episode": 1672.0, "batch_reward": -0.06021182984113693, "critic_loss": 0.7200590223073959, "ae_transition_loss": 1.2068015038967133, "ae_encoder_loss": 0.8824117332696915, "actor_loss": -0.6476244926452637, "actor_target_entropy": -2.0, "actor_entropy": 1.4401800036430359, "alpha_loss": 0.004007065377663821, "alpha_value": 0.0032847076790716266, "duration": 8.408495664596558, "step": 49463}
{"episode_reward": -14.540958458259901, "episode": 1673.0, "batch_reward": -0.1609240472316742, "critic_loss": 0.5392390489578247, "ae_transition_loss": 1.3066717386245728, "ae_encoder_loss": 0.939534604549408, "actor_loss": -0.4830416440963745, "actor_target_entropy": -2.0, "actor_entropy": 1.343966007232666, "alpha_loss": 0.004125978797674179, "alpha_value": 0.003280339922490098, "duration": 2.36850905418396, "step": 49474}
{"episode_reward": -4.683459689801118, "episode": 1674.0, "batch_reward": -0.062235595658421516, "critic_loss": 0.788986474275589, "ae_transition_loss": 1.2412928342819214, "ae_encoder_loss": 0.9739455282688141, "actor_loss": -0.4608949273824692, "actor_target_entropy": -2.0, "actor_entropy": 1.3513599038124084, "alpha_loss": 0.0035513158654794097, "alpha_value": 0.003277712547187817, "duration": 4.715198993682861, "step": 49496}
{"episode_reward": -5.580093218345809, "episode": 1675.0, "batch_reward": -0.0742220040410757, "critic_loss": 0.5724083185195923, "ae_transition_loss": 1.4582388997077942, "ae_encoder_loss": 1.3210396766662598, "actor_loss": -0.6412701904773712, "actor_target_entropy": -2.0, "actor_entropy": 1.2342194318771362, "alpha_loss": 0.0028797402046620846, "alpha_value": 0.003274230822285129, "duration": 4.363869667053223, "step": 49517}
{"episode_reward": -5.021338131966706, "episode": 1676.0, "batch_reward": -0.0802916157990694, "critic_loss": 0.6809986531734467, "ae_transition_loss": 1.7004892826080322, "ae_encoder_loss": 1.3225269317626953, "actor_loss": -0.6027557849884033, "actor_target_entropy": -2.0, "actor_entropy": 1.3085868954658508, "alpha_loss": 0.0017449104343540967, "alpha_value": 0.0032708895484300686, "duration": 3.711669683456421, "step": 49535}
{"episode_reward": -6.366627799982929, "episode": 1677.0, "batch_reward": -0.023633516393601894, "critic_loss": 0.5802080035209656, "ae_transition_loss": 1.2135419249534607, "ae_encoder_loss": 0.9304936528205872, "actor_loss": -0.6660394966602325, "actor_target_entropy": -2.0, "actor_entropy": 1.2784610986709595, "alpha_loss": 0.0020051216706633568, "alpha_value": 0.0032678254827799, "duration": 4.227581739425659, "step": 49555}
{"episode_reward": -5.79746209666814, "episode": 1678.0, "batch_reward": -0.06682366132736206, "critic_loss": 0.7677834630012512, "ae_transition_loss": 1.324817955493927, "ae_encoder_loss": 0.9688715636730194, "actor_loss": -0.4099307060241699, "actor_target_entropy": -2.0, "actor_entropy": 1.3168371319770813, "alpha_loss": 0.0030689561390317976, "alpha_value": 0.0032649070169547376, "duration": 4.627812623977661, "step": 49577}
{"episode_reward": -8.402750005860986, "episode": 1679.0, "batch_reward": -0.1076150294393301, "critic_loss": 0.6424038112163544, "ae_transition_loss": 1.3628182411193848, "ae_encoder_loss": 0.8084192276000977, "actor_loss": -0.3915628045797348, "actor_target_entropy": -2.0, "actor_entropy": 1.1315346956253052, "alpha_loss": 0.0009240409126505256, "alpha_value": 0.0032620510455280867, "duration": 3.6701037883758545, "step": 49595}
{"episode_reward": -2.83435350187065, "episode": 1680.0, "batch_reward": -0.0664132758975029, "critic_loss": 0.7462463080883026, "ae_transition_loss": 1.247651219367981, "ae_encoder_loss": 0.9487582743167877, "actor_loss": -0.3824928253889084, "actor_target_entropy": -2.0, "actor_entropy": 1.2394860982894897, "alpha_loss": -0.0013698390102945268, "alpha_value": 0.0032595860288807893, "duration": 4.961443901062012, "step": 49619}
{"episode_reward": -6.3405469111227495, "episode": 1681.0, "batch_reward": -0.07473630830645561, "critic_loss": 0.6537519097328186, "ae_transition_loss": 1.5453171730041504, "ae_encoder_loss": 1.1767745912075043, "actor_loss": -0.5318515598773956, "actor_target_entropy": -2.0, "actor_entropy": 1.3593068718910217, "alpha_loss": -0.0030932968948036432, "alpha_value": 0.0032578204372495753, "duration": 36.10149073600769, "step": 49636}
{"episode_reward": -5.374615851642143, "episode": 1682.0, "duration": 0.2779967784881592, "step": 49637}
{"episode_reward": -0.8260025921238107, "episode": 1683.0, "batch_reward": -0.01391188707202673, "critic_loss": 0.4430639445781708, "ae_transition_loss": 1.4187548160552979, "ae_encoder_loss": 1.2273838520050049, "actor_loss": -0.49885237216949463, "actor_target_entropy": -2.0, "actor_entropy": 1.319277286529541, "alpha_loss": -0.0008782526128925383, "alpha_value": 0.003257059330513383, "duration": 2.812070608139038, "step": 49650}
{"episode_reward": -6.205073669204743, "episode": 1684.0, "batch_reward": -0.06420090794563293, "critic_loss": 0.8510301113128662, "ae_transition_loss": 1.318980097770691, "ae_encoder_loss": 1.0273730754852295, "actor_loss": -0.23464465141296387, "actor_target_entropy": -2.0, "actor_entropy": 1.3200936317443848, "alpha_loss": -0.0012214048765599728, "alpha_value": 0.003256720002756317, "duration": 2.1716034412384033, "step": 49660}
{"episode_reward": -3.0236997593825046, "episode": 1685.0, "batch_reward": -0.052176112309098244, "critic_loss": 0.7093989849090576, "ae_transition_loss": 1.3739947875340779, "ae_encoder_loss": 1.5103938380877178, "actor_loss": -0.5602641006310781, "actor_target_entropy": -2.0, "actor_entropy": 1.6698416868845622, "alpha_loss": -0.000755187434454759, "alpha_value": 0.0032563773348529817, "duration": 5.995910167694092, "step": 49688}
{"episode_reward": -14.793361152162488, "episode": 1686.0, "batch_reward": -0.03946925327181816, "critic_loss": 0.9587085247039795, "ae_transition_loss": 1.4434760808944702, "ae_encoder_loss": 0.9365975856781006, "actor_loss": -0.2678607106208801, "actor_target_entropy": -2.0, "actor_entropy": 1.88871431350708, "alpha_loss": 0.001658863853663206, "alpha_value": 0.0032562032834071754, "duration": 2.679905891418457, "step": 49700}
{"episode_reward": -5.088634978956518, "episode": 1687.0, "batch_reward": -0.07133496552705765, "critic_loss": 0.6035009622573853, "ae_transition_loss": 1.5226378043492634, "ae_encoder_loss": 1.506808082262675, "actor_loss": -0.43319905797640484, "actor_target_entropy": -2.0, "actor_entropy": 1.6589853763580322, "alpha_loss": 0.0029742176023622355, "alpha_value": 0.003255717227910139, "duration": 5.179980039596558, "step": 49723}
{"episode_reward": -3.4940086922438187, "episode": 1688.0, "batch_reward": -0.04652021763225397, "critic_loss": 0.5482629140218099, "ae_transition_loss": 1.4683340390523274, "ae_encoder_loss": 1.1052569945653279, "actor_loss": -0.7136728465557098, "actor_target_entropy": -2.0, "actor_entropy": 1.1221434672673543, "alpha_loss": 0.002668198198080063, "alpha_value": 0.003254191116992995, "duration": 7.225475072860718, "step": 49757}
{"episode_reward": -6.5380012303961506, "episode": 1689.0, "batch_reward": -0.04143858700990677, "critic_loss": 1.1837739944458008, "ae_transition_loss": 1.4727059602737427, "ae_encoder_loss": 1.8464760780334473, "actor_loss": -1.0213069915771484, "actor_target_entropy": -2.0, "actor_entropy": 0.918867290019989, "alpha_loss": 0.002797949593514204, "alpha_value": 0.0032527970070255195, "duration": 1.9740045070648193, "step": 49766}
{"episode_reward": -3.41465037774438, "episode": 1690.0, "batch_reward": -0.043300659861415625, "critic_loss": 0.6380922496318817, "ae_transition_loss": 1.51938596367836, "ae_encoder_loss": 1.2723495662212372, "actor_loss": -0.8101054728031158, "actor_target_entropy": -2.0, "actor_entropy": 1.1847731173038483, "alpha_loss": 0.00288633955642581, "alpha_value": 0.0032506745989535164, "duration": 7.890223026275635, "step": 49802}
{"episode_reward": -10.589613559991792, "episode": 1691.0, "batch_reward": -0.042449694126844406, "critic_loss": 0.7319493144750595, "ae_transition_loss": 1.431890845298767, "ae_encoder_loss": 1.4969732165336609, "actor_loss": -0.6460613310337067, "actor_target_entropy": -2.0, "actor_entropy": 1.4032350778579712, "alpha_loss": 0.0028144530951976776, "alpha_value": 0.0032477467633320527, "duration": 39.225379943847656, "step": 49827}
{"episode_reward": -8.611135015283432, "episode": 1692.0, "duration": 0.23781991004943848, "step": 49828}
{"episode_reward": -0.8593808229442369, "episode": 1693.0, "duration": 0.2254946231842041, "step": 49829}
{"episode_reward": -0.12042874384191557, "episode": 1694.0, "duration": 0.22376465797424316, "step": 49830}
{"episode_reward": -0.14627104997634888, "episode": 1695.0, "batch_reward": -0.12315129488706589, "critic_loss": 0.5832400321960449, "ae_transition_loss": 1.2843270301818848, "ae_encoder_loss": 1.030484676361084, "actor_loss": -0.6705461740493774, "actor_target_entropy": -2.0, "actor_entropy": 1.3700621128082275, "alpha_loss": 0.004278522916138172, "alpha_value": 0.0032461298125997405, "duration": 0.5279262065887451, "step": 49831}
{"episode_reward": -0.494108691208599, "episode": 1696.0, "batch_reward": -0.07572779556115468, "critic_loss": 0.49786559740702313, "ae_transition_loss": 1.498835285504659, "ae_encoder_loss": 1.1073868076006572, "actor_loss": -0.5039797425270081, "actor_target_entropy": -2.0, "actor_entropy": 1.5237355629603069, "alpha_loss": 0.0032878381510575614, "alpha_value": 0.0032436625270474404, "duration": 6.075950622558594, "step": 49861}
{"episode_reward": -4.642215683576937, "episode": 1697.0, "batch_reward": -0.06739373505115509, "critic_loss": 0.6497294902801514, "ae_transition_loss": 1.2405288219451904, "ae_encoder_loss": 0.8513356447219849, "actor_loss": -0.2645617723464966, "actor_target_entropy": -2.0, "actor_entropy": 1.5707517862319946, "alpha_loss": 0.0018492731032893062, "alpha_value": 0.0032410797405422343, "duration": 2.3991177082061768, "step": 49872}
{"episode_reward": -1.4270741889644374, "episode": 1698.0, "batch_reward": -0.006582396104931831, "critic_loss": 0.6629263758659363, "ae_transition_loss": 1.3281993865966797, "ae_encoder_loss": 1.5681474208831787, "actor_loss": -0.7582671940326691, "actor_target_entropy": -2.0, "actor_entropy": 1.5635389685630798, "alpha_loss": 0.0023070399183779955, "alpha_value": 0.0032392122193596437, "duration": 4.728334426879883, "step": 49896}
{"episode_reward": -7.301985223596147, "episode": 1699.0, "batch_reward": -0.09590753633528948, "critic_loss": 0.9251074939966202, "ae_transition_loss": 1.4672603607177734, "ae_encoder_loss": 1.3160147070884705, "actor_loss": -0.4488810747861862, "actor_target_entropy": -2.0, "actor_entropy": 1.459102988243103, "alpha_loss": 4.294543759897351e-05, "alpha_value": 0.00323569735540073, "duration": 8.087661743164062, "step": 49934}
{"episode_reward": -13.938611666876332, "episode": 1700.0, "batch_reward": -0.028959685936570168, "critic_loss": 0.6804084777832031, "ae_transition_loss": 2.15261173248291, "ae_encoder_loss": 1.2768163681030273, "actor_loss": -0.6170660257339478, "actor_target_entropy": -2.0, "actor_entropy": 1.4392809867858887, "alpha_loss": -0.001418144442141056, "alpha_value": 0.0032333569705533137, "duration": 2.883868932723999, "step": 49947}
{"episode_reward": -6.992763172749111, "episode": 1701.0, "batch_reward": -0.07691875770688057, "critic_loss": 0.61591557264328, "ae_transition_loss": 1.7134127616882324, "ae_encoder_loss": 1.2015215158462524, "actor_loss": -0.49191596508026125, "actor_target_entropy": -2.0, "actor_entropy": 1.5639472961425782, "alpha_loss": -3.4507224336266516e-05, "alpha_value": 0.0032317664438162885, "duration": 51.48406958580017, "step": 49996}
{"episode_reward": -31.449382385911548, "episode": 1702.0, "batch_reward": -0.0496810848514239, "critic_loss": 0.6820600926876068, "ae_transition_loss": 1.5591985781987507, "ae_encoder_loss": 1.13127205769221, "actor_loss": -0.6130694150924683, "actor_target_entropy": -2.0, "actor_entropy": 1.582133372624715, "alpha_loss": 0.0018731788732111454, "alpha_value": 0.0032301155970973685, "duration": 9.900804996490479, "step": 50023}
{"episode_reward": -5.6511523982205665, "episode": 1703.0, "duration": 0.19967412948608398, "step": 50024}
{"episode_reward": -0.8802869636878284, "episode": 1704.0, "duration": 0.23447370529174805, "step": 50025}
{"episode_reward": -0.4173245896721155, "episode": 1705.0, "duration": 0.23598456382751465, "step": 50026}
{"episode_reward": -1.0819708788991527, "episode": 1706.0, "batch_reward": -0.06639451440423727, "critic_loss": 1.0269300788640976, "ae_transition_loss": 1.424812376499176, "ae_encoder_loss": 1.06135194003582, "actor_loss": -0.4324983209371567, "actor_target_entropy": -2.0, "actor_entropy": 1.3235262632369995, "alpha_loss": 0.0034703750861808658, "alpha_value": 0.0032280715832533674, "duration": 7.426169395446777, "step": 50062}
{"episode_reward": -13.198964187626341, "episode": 1707.0, "batch_reward": -0.05430353060364723, "critic_loss": 0.9391218274831772, "ae_transition_loss": 1.5561345517635345, "ae_encoder_loss": 1.0436062961816788, "actor_loss": -0.43655573949217796, "actor_target_entropy": -2.0, "actor_entropy": 1.2616385221481323, "alpha_loss": 0.004202810290735215, "alpha_value": 0.003224336051072561, "duration": 8.09740424156189, "step": 50102}
{"episode_reward": -6.085276859359959, "episode": 1708.0, "batch_reward": -0.04646352678537369, "critic_loss": 0.6904541949431101, "ae_transition_loss": 1.4198193947474163, "ae_encoder_loss": 1.018224040667216, "actor_loss": -0.5597419142723083, "actor_target_entropy": -2.0, "actor_entropy": 1.1789100567499797, "alpha_loss": 0.004777687136083841, "alpha_value": 0.003219799696144887, "duration": 7.544122219085693, "step": 50139}
{"episode_reward": -3.305907660578832, "episode": 1709.0, "duration": 0.23964166641235352, "step": 50140}
{"episode_reward": 0.016101140503520073, "episode": 1710.0, "batch_reward": -0.10007709544152021, "critic_loss": 0.8687688112258911, "ae_transition_loss": 1.4801202416419983, "ae_encoder_loss": 0.995614543557167, "actor_loss": -0.25757987424731255, "actor_target_entropy": -2.0, "actor_entropy": 1.0217703580856323, "alpha_loss": 0.004972979659214616, "alpha_value": 0.0032139726682071414, "duration": 7.883784294128418, "step": 50180}
{"episode_reward": -4.60148666894699, "episode": 1711.0, "batch_reward": -0.07186445593833923, "critic_loss": 0.6490206023057302, "ae_transition_loss": 1.5114007393519084, "ae_encoder_loss": 1.0583866437276204, "actor_loss": -0.2284066155552864, "actor_target_entropy": -2.0, "actor_entropy": 1.0247365633646648, "alpha_loss": 0.004205146028349797, "alpha_value": 0.003207384653376394, "duration": 63.281917095184326, "step": 50205}
{"episode_reward": -4.012492247055103, "episode": 1712.0, "batch_reward": -0.09584445754686992, "critic_loss": 0.7625189820925394, "ae_transition_loss": 1.4396604696909587, "ae_encoder_loss": 0.915495753288269, "actor_loss": -0.6950652201970419, "actor_target_entropy": -2.0, "actor_entropy": 1.3175790309906006, "alpha_loss": 0.003170610095063845, "alpha_value": 0.0032016357995673216, "duration": 5.813064336776733, "step": 50231}
{"episode_reward": -3.6601825493813864, "episode": 1713.0, "batch_reward": -0.09221900347620249, "critic_loss": 0.7032784968614578, "ae_transition_loss": 1.5096400380134583, "ae_encoder_loss": 1.1958806216716766, "actor_loss": -0.1416184213012457, "actor_target_entropy": -2.0, "actor_entropy": 1.121085986495018, "alpha_loss": 0.002869173855287954, "alpha_value": 0.0031952865864051335, "duration": 8.644978523254395, "step": 50275}
{"episode_reward": -6.622641522273482, "episode": 1714.0, "batch_reward": -0.05745076760649681, "critic_loss": 0.953190803527832, "ae_transition_loss": 1.3860072493553162, "ae_encoder_loss": 1.236096978187561, "actor_loss": -0.1809268854558468, "actor_target_entropy": -2.0, "actor_entropy": 1.0984548330307007, "alpha_loss": 0.002473546308465302, "alpha_value": 0.003190194388569329, "duration": 4.831347703933716, "step": 50298}
{"episode_reward": -1.8739290615588606, "episode": 1715.0, "batch_reward": -0.08329975853363673, "critic_loss": 0.5801246662934622, "ae_transition_loss": 1.7121143738428752, "ae_encoder_loss": 1.0039181510607402, "actor_loss": -0.4129796201984088, "actor_target_entropy": -2.0, "actor_entropy": 1.33445938428243, "alpha_loss": 0.002390398488690456, "alpha_value": 0.003186257925776879, "duration": 5.3073341846466064, "step": 50321}
{"episode_reward": -2.312332576297747, "episode": 1716.0, "duration": 0.19544553756713867, "step": 50322}
{"episode_reward": -0.2467145132058986, "episode": 1717.0, "batch_reward": -0.10651055350899696, "critic_loss": 0.6045472323894501, "ae_transition_loss": 1.4552825689315796, "ae_encoder_loss": 0.9777646064758301, "actor_loss": -0.3217264711856842, "actor_target_entropy": -2.0, "actor_entropy": 1.4922847747802734, "alpha_loss": 0.002154820947907865, "alpha_value": 0.0031825238642770913, "duration": 5.224541664123535, "step": 50346}
{"episode_reward": -1.9370374566894109, "episode": 1718.0, "batch_reward": -0.07345011457800865, "critic_loss": 0.866851419210434, "ae_transition_loss": 1.408586323261261, "ae_encoder_loss": 1.0422698855400085, "actor_loss": -0.3396444618701935, "actor_target_entropy": -2.0, "actor_entropy": 1.4665512442588806, "alpha_loss": 0.001961121684871614, "alpha_value": 0.00317968370237232, "duration": 4.484347105026245, "step": 50367}
{"episode_reward": -6.383923626921818, "episode": 1719.0, "batch_reward": -0.05730215087532997, "critic_loss": 1.0378987789154053, "ae_transition_loss": 1.4630426168441772, "ae_encoder_loss": 1.0914104878902435, "actor_loss": -0.4555600881576538, "actor_target_entropy": -2.0, "actor_entropy": 1.400688886642456, "alpha_loss": 0.0012185215600766242, "alpha_value": 0.0031770216424825337, "duration": 4.319045305252075, "step": 50388}
{"episode_reward": -4.1020476157848265, "episode": 1720.0, "duration": 0.2518422603607178, "step": 50389}
{"episode_reward": -0.4639194905757904, "episode": 1721.0, "batch_reward": -0.04759843647480011, "critic_loss": 0.6895498633384705, "ae_transition_loss": 1.3652722239494324, "ae_encoder_loss": 0.7659299075603485, "actor_loss": -0.3941160514950752, "actor_target_entropy": -2.0, "actor_entropy": 1.4159859418869019, "alpha_loss": 0.0017583814915269613, "alpha_value": 0.0031746122013693503, "duration": 48.764195680618286, "step": 50410}
{"episode_reward": -6.723934134973019, "episode": 1722.0, "batch_reward": -0.06516327429562807, "critic_loss": 0.8253844618797302, "ae_transition_loss": 1.2385137319564818, "ae_encoder_loss": 0.7224497675895691, "actor_loss": -0.458404541015625, "actor_target_entropy": -2.0, "actor_entropy": 1.380708932876587, "alpha_loss": 0.0020490193739533423, "alpha_value": 0.0031706989097771885, "duration": 8.817080020904541, "step": 50452}
{"episode_reward": -17.988238423119522, "episode": 1723.0, "batch_reward": -0.060638987769683204, "critic_loss": 0.5756508012612661, "ae_transition_loss": 1.0749635299046834, "ae_encoder_loss": 0.7819852828979492, "actor_loss": -0.3735589186350505, "actor_target_entropy": -2.0, "actor_entropy": 1.3912322918574016, "alpha_loss": 0.0036207419664909444, "alpha_value": 0.003166310171651045, "duration": 6.361867427825928, "step": 50481}
{"episode_reward": -5.370864952749291, "episode": 1724.0, "batch_reward": -0.02454158787926038, "critic_loss": 0.6870156526565552, "ae_transition_loss": 1.4565568367640178, "ae_encoder_loss": 0.6615297993024191, "actor_loss": -0.41439223662018776, "actor_target_entropy": -2.0, "actor_entropy": 1.3745893239974976, "alpha_loss": 0.004939268187930186, "alpha_value": 0.0031624767107758032, "duration": 7.604228734970093, "step": 50518}
{"episode_reward": -5.457568684555655, "episode": 1725.0, "batch_reward": -0.07566790282726288, "critic_loss": 0.6649765074253082, "ae_transition_loss": 1.5469289422035217, "ae_encoder_loss": 1.2750362753868103, "actor_loss": -0.36160557717084885, "actor_target_entropy": -2.0, "actor_entropy": 1.4174671173095703, "alpha_loss": 0.004944411339238286, "alpha_value": 0.003158608634305877, "duration": 4.071784019470215, "step": 50537}
{"episode_reward": -9.112170472031421, "episode": 1726.0, "duration": 0.23165488243103027, "step": 50538}
{"episode_reward": -0.8125479817390442, "episode": 1727.0, "batch_reward": -0.0679532065987587, "critic_loss": 0.8525806665420532, "ae_transition_loss": 1.3207087516784668, "ae_encoder_loss": 1.1554576009511948, "actor_loss": -0.6471166759729385, "actor_target_entropy": -2.0, "actor_entropy": 1.2773007452487946, "alpha_loss": 0.003231499809771776, "alpha_value": 0.0031533320997505533, "duration": 8.127909660339355, "step": 50576}
{"episode_reward": -13.12270965866088, "episode": 1728.0, "batch_reward": -0.05685609206557274, "critic_loss": 0.7049997001886368, "ae_transition_loss": 1.4871382117271423, "ae_encoder_loss": 1.512961894273758, "actor_loss": -0.3891574889421463, "actor_target_entropy": -2.0, "actor_entropy": 1.3875324428081512, "alpha_loss": 0.0010705460590543225, "alpha_value": 0.003146741852153583, "duration": 8.331927061080933, "step": 50616}
{"episode_reward": -13.929681908815336, "episode": 1729.0, "batch_reward": -0.09470374882221222, "critic_loss": 0.6010295748710632, "ae_transition_loss": 1.3590328693389893, "ae_encoder_loss": 1.7729647159576416, "actor_loss": -0.5303223729133606, "actor_target_entropy": -2.0, "actor_entropy": 1.3857563734054565, "alpha_loss": -0.00010214987560175359, "alpha_value": 0.0031433176578626984, "duration": 2.179459810256958, "step": 50626}
{"episode_reward": -5.8386258966778115, "episode": 1730.0, "batch_reward": -0.10245023667812347, "critic_loss": 0.46456238627433777, "ae_transition_loss": 1.1591988801956177, "ae_encoder_loss": 1.0169981718063354, "actor_loss": -0.1637323796749115, "actor_target_entropy": -2.0, "actor_entropy": 1.3514761924743652, "alpha_loss": 0.0017931126058101654, "alpha_value": 0.003142179851728138, "duration": 2.815988063812256, "step": 50639}
{"episode_reward": -7.595030799095533, "episode": 1731.0, "batch_reward": -0.13499677926301956, "critic_loss": 0.4912760555744171, "ae_transition_loss": 1.408586323261261, "ae_encoder_loss": 1.133130431175232, "actor_loss": -0.2046041004359722, "actor_target_entropy": -2.0, "actor_entropy": 1.5217540860176086, "alpha_loss": 0.00037651457387255505, "alpha_value": 0.003140549835453716, "duration": 102.74774599075317, "step": 50655}
{"episode_reward": -10.607632563258358, "episode": 1732.0, "batch_reward": -0.08259309753775597, "critic_loss": 0.6214190721511841, "ae_transition_loss": 1.5836638689041138, "ae_encoder_loss": 1.7256645202636718, "actor_loss": -0.3456444352865219, "actor_target_entropy": -2.0, "actor_entropy": 1.2645952105522156, "alpha_loss": 0.002542307460680604, "alpha_value": 0.003137140002108013, "duration": 9.8437659740448, "step": 50704}
{"episode_reward": -37.25314521659008, "episode": 1733.0, "batch_reward": -0.10192101448774338, "critic_loss": 1.0912806987762451, "ae_transition_loss": 1.1325669288635254, "ae_encoder_loss": 1.3721102476119995, "actor_loss": -0.5952903032302856, "actor_target_entropy": -2.0, "actor_entropy": 0.9912096261978149, "alpha_loss": 0.002322989050298929, "alpha_value": 0.003134081281809154, "duration": 1.8456077575683594, "step": 50711}
{"episode_reward": -2.011316281885394, "episode": 1734.0, "batch_reward": -0.04577087859312693, "critic_loss": 0.6686115662256876, "ae_transition_loss": 1.3057623306910198, "ae_encoder_loss": 1.9055077234903972, "actor_loss": -0.5324293176333109, "actor_target_entropy": -2.0, "actor_entropy": 1.0187991261482239, "alpha_loss": 0.0021486798068508506, "alpha_value": 0.0031319172220210557, "duration": 7.025886535644531, "step": 50746}
{"episode_reward": -3.042484671175988, "episode": 1735.0, "duration": 0.2723250389099121, "step": 50747}
{"episode_reward": -0.5353216528892517, "episode": 1736.0, "batch_reward": -0.06955699188013871, "critic_loss": 0.49141592780749005, "ae_transition_loss": 1.5061379671096802, "ae_encoder_loss": 1.4763304789861043, "actor_loss": -0.45425628622372943, "actor_target_entropy": -2.0, "actor_entropy": 1.2434707880020142, "alpha_loss": 0.00286535134849449, "alpha_value": 0.0031286785269618103, "duration": 5.729336500167847, "step": 50775}
{"episode_reward": -4.271700704482906, "episode": 1737.0, "batch_reward": -0.08852451294660568, "critic_loss": 0.789010614156723, "ae_transition_loss": 1.4332930445671082, "ae_encoder_loss": 1.4254956245422363, "actor_loss": -0.2501801699399948, "actor_target_entropy": -2.0, "actor_entropy": 1.4304139018058777, "alpha_loss": 0.002551416167989373, "alpha_value": 0.003125819520812827, "duration": 4.905746698379517, "step": 50800}
{"episode_reward": -5.7100203315033955, "episode": 1738.0, "batch_reward": -0.05664705112576485, "critic_loss": 0.3320598006248474, "ae_transition_loss": 1.7129225730895996, "ae_encoder_loss": 2.029421329498291, "actor_loss": -0.40158259868621826, "actor_target_entropy": -2.0, "actor_entropy": 1.4067679643630981, "alpha_loss": 0.0031383871100842953, "alpha_value": 0.003124035756452284, "duration": 0.9761562347412109, "step": 50803}
{"episode_reward": -1.9427073656341558, "episode": 1739.0, "batch_reward": -0.08128836005926132, "critic_loss": 0.5789036452770233, "ae_transition_loss": 1.3885248005390167, "ae_encoder_loss": 1.568743258714676, "actor_loss": -0.40072251111268997, "actor_target_entropy": -2.0, "actor_entropy": 1.2263875901699066, "alpha_loss": 0.0019165482954122126, "alpha_value": 0.003121034259520425, "duration": 7.894399166107178, "step": 50841}
{"episode_reward": -6.2617128173905865, "episode": 1740.0, "batch_reward": -0.05662685198088487, "critic_loss": 0.5013196766376495, "ae_transition_loss": 1.5148773988087971, "ae_encoder_loss": 1.3949732780456543, "actor_loss": -0.5029287909468015, "actor_target_entropy": -2.0, "actor_entropy": 1.0519648591677349, "alpha_loss": 0.001629035493048529, "alpha_value": 0.0031155316853151496, "duration": 13.50092339515686, "step": 50908}
{"episode_reward": -15.972080882019034, "episode": 1741.0, "batch_reward": -0.06331176161766053, "critic_loss": 0.4510653614997864, "ae_transition_loss": 1.5558224678039552, "ae_encoder_loss": 1.6193655252456665, "actor_loss": -0.304250992834568, "actor_target_entropy": -2.0, "actor_entropy": 0.5804158031940461, "alpha_loss": 0.002293716708663851, "alpha_value": 0.0031101113532682567, "duration": 69.27579021453857, "step": 50957}
{"episode_reward": -0.6700079660352374, "episode": 1742.0, "batch_reward": -0.06341696220139663, "critic_loss": 0.8891473114490509, "ae_transition_loss": 1.3841892679532368, "ae_encoder_loss": 1.3810662428538005, "actor_loss": -0.4877277339498202, "actor_target_entropy": -2.0, "actor_entropy": 1.3365429143110912, "alpha_loss": 0.0029975559640054903, "alpha_value": 0.0031041852133182144, "duration": 11.170879364013672, "step": 51012}
{"episode_reward": -8.154517361017634, "episode": 1743.0, "batch_reward": -0.04676898894831538, "critic_loss": 0.7827195078134537, "ae_transition_loss": 1.472548931837082, "ae_encoder_loss": 1.5335107147693634, "actor_loss": -0.601616807281971, "actor_target_entropy": -2.0, "actor_entropy": 1.2729792594909668, "alpha_loss": 0.0017922261904459447, "alpha_value": 0.0030981611620462487, "duration": 8.063350677490234, "step": 51051}
{"episode_reward": -6.8974767410446285, "episode": 1744.0, "batch_reward": -0.10706262290477753, "critic_loss": 1.0968035658200581, "ae_transition_loss": 1.7572304010391235, "ae_encoder_loss": 1.6575936873753865, "actor_loss": -0.18210681776205698, "actor_target_entropy": -2.0, "actor_entropy": 1.4746034145355225, "alpha_loss": 0.001287172296239684, "alpha_value": 0.0030943001050200126, "duration": 6.581277370452881, "step": 51085}
{"episode_reward": -7.055625269783505, "episode": 1745.0, "batch_reward": -0.05864371545612812, "critic_loss": 0.8933045119047165, "ae_transition_loss": 1.6208451390266418, "ae_encoder_loss": 1.397596001625061, "actor_loss": -0.44248732924461365, "actor_target_entropy": -2.0, "actor_entropy": 1.2163502871990204, "alpha_loss": 0.0009098902119148988, "alpha_value": 0.0030909019077002093, "duration": 8.303757905960083, "step": 51127}
{"episode_reward": -15.857777515429834, "episode": 1746.0, "batch_reward": -0.14814633131027222, "critic_loss": 1.3413329124450684, "ae_transition_loss": 1.4188828468322754, "ae_encoder_loss": 1.9137401580810547, "actor_loss": -0.16450423002243042, "actor_target_entropy": -2.0, "actor_entropy": 1.2333087921142578, "alpha_loss": 0.002115032635629177, "alpha_value": 0.00308876273932536, "duration": 1.2846894264221191, "step": 51131}
{"episode_reward": -0.875126469437724, "episode": 1747.0, "batch_reward": -0.09533051587641239, "critic_loss": 0.6111747920513153, "ae_transition_loss": 1.4965211153030396, "ae_encoder_loss": 1.581870675086975, "actor_loss": -0.3379019498825073, "actor_target_entropy": -2.0, "actor_entropy": 1.3580649495124817, "alpha_loss": 0.0015989582461770624, "alpha_value": 0.0030875400074489813, "duration": 4.74681282043457, "step": 51155}
{"episode_reward": -6.7184366048148565, "episode": 1748.0, "batch_reward": -0.06671554701668876, "critic_loss": 0.783540849174772, "ae_transition_loss": 1.5187686000551497, "ae_encoder_loss": 1.5898480330194746, "actor_loss": -0.3848792335816792, "actor_target_entropy": -2.0, "actor_entropy": 1.4596275431769234, "alpha_loss": 0.002522300762523498, "alpha_value": 0.00308350335383943, "duration": 14.512054920196533, "step": 51227}
{"episode_reward": -22.454216918178876, "episode": 1749.0, "batch_reward": -0.09263994917273521, "critic_loss": 0.9676477015018463, "ae_transition_loss": 1.576849341392517, "ae_encoder_loss": 1.3694305419921875, "actor_loss": -0.2431069314479828, "actor_target_entropy": -2.0, "actor_entropy": 1.1540828943252563, "alpha_loss": 0.0020604070741683245, "alpha_value": 0.0030789240951488023, "duration": 3.0912046432495117, "step": 51241}
{"episode_reward": -4.298691077045846, "episode": 1750.0, "batch_reward": -0.07224389724433422, "critic_loss": 1.089359611272812, "ae_transition_loss": 1.6128711700439453, "ae_encoder_loss": 1.7581692934036255, "actor_loss": -0.5207813233137131, "actor_target_entropy": -2.0, "actor_entropy": 1.316871166229248, "alpha_loss": 0.000471281266072765, "alpha_value": 0.0030760407523222144, "duration": 9.260097980499268, "step": 51288}
{"episode_reward": -16.760324938371504, "episode": 1751.0, "duration": 37.70515418052673, "step": 51289}
{"episode_reward": -0.13188153620192733, "episode": 1752.0, "batch_reward": -0.09539172612130642, "critic_loss": 1.1929266154766083, "ae_transition_loss": 1.744813859462738, "ae_encoder_loss": 1.7250896990299225, "actor_loss": -0.32275987416505814, "actor_target_entropy": -2.0, "actor_entropy": 1.6943961083889008, "alpha_loss": 0.002577498615210061, "alpha_value": 0.003072902329080998, "duration": 7.95867133140564, "step": 51328}
{"episode_reward": -9.35431473031338, "episode": 1753.0, "batch_reward": -0.06926804035902023, "critic_loss": 1.2340226513998849, "ae_transition_loss": 1.6672042778560094, "ae_encoder_loss": 1.4486137798854284, "actor_loss": -0.39084481980119434, "actor_target_entropy": -2.0, "actor_entropy": 1.4834970576422555, "alpha_loss": 0.0012143992519538318, "alpha_value": 0.0030678004642382753, "duration": 13.550994873046875, "step": 51392}
{"episode_reward": -20.482922271443254, "episode": 1754.0, "batch_reward": -0.05476871319115162, "critic_loss": 1.1813284158706665, "ae_transition_loss": 1.8671147525310516, "ae_encoder_loss": 1.4526107609272003, "actor_loss": -0.5326093286275864, "actor_target_entropy": -2.0, "actor_entropy": 1.542155683040619, "alpha_loss": -0.002762487914878875, "alpha_value": 0.0030636756196656444, "duration": 9.308670282363892, "step": 51437}
{"episode_reward": -21.091444091932793, "episode": 1755.0, "batch_reward": -0.059169089421629906, "critic_loss": 0.8203173756599427, "ae_transition_loss": 1.6903172254562377, "ae_encoder_loss": 1.4157106161117554, "actor_loss": -0.3009932920336723, "actor_target_entropy": -2.0, "actor_entropy": 1.7237465620040893, "alpha_loss": 0.003218619339168072, "alpha_value": 0.003062861610956016, "duration": 10.68755054473877, "step": 51489}
{"episode_reward": -29.856558984375102, "episode": 1756.0, "batch_reward": -0.11215355743964513, "critic_loss": 0.6550816893577576, "ae_transition_loss": 1.8430037101109822, "ae_encoder_loss": 1.327789306640625, "actor_loss": -0.13393792510032654, "actor_target_entropy": -2.0, "actor_entropy": 1.444763461748759, "alpha_loss": 0.0031291451305150986, "alpha_value": 0.0030605602139853524, "duration": 4.956405878067017, "step": 51511}
{"episode_reward": -3.88311985877619, "episode": 1757.0, "batch_reward": -0.05790495499968529, "critic_loss": 0.9433643817901611, "ae_transition_loss": 1.6505906581878662, "ae_encoder_loss": 1.0859811902046204, "actor_loss": -0.5669276267290115, "actor_target_entropy": -2.0, "actor_entropy": 1.1977453231811523, "alpha_loss": 0.001727247581584379, "alpha_value": 0.0030583438837682325, "duration": 4.577730894088745, "step": 51532}
{"episode_reward": -5.862705915074226, "episode": 1758.0, "batch_reward": -0.09461331367492676, "critic_loss": 1.224500298500061, "ae_transition_loss": 1.6234277486801147, "ae_encoder_loss": 1.4295295476913452, "actor_loss": -0.6555363535881042, "actor_target_entropy": -2.0, "actor_entropy": 1.1201368570327759, "alpha_loss": 0.002129515865817666, "alpha_value": 0.0030569886682821723, "duration": 3.5892317295074463, "step": 51550}
{"episode_reward": -3.7673570883758045, "episode": 1759.0, "batch_reward": -0.09814730818782534, "critic_loss": 1.1502338818141393, "ae_transition_loss": 1.5163463183811732, "ae_encoder_loss": 1.384945205279759, "actor_loss": -0.5153201520442963, "actor_target_entropy": -2.0, "actor_entropy": 1.1315592527389526, "alpha_loss": 0.0010195025076557482, "alpha_value": 0.00305374051747991, "duration": 13.302712202072144, "step": 51612}
{"episode_reward": -4.803849782955554, "episode": 1760.0, "batch_reward": -0.11536823585629463, "critic_loss": 0.884579986333847, "ae_transition_loss": 1.603126883506775, "ae_encoder_loss": 1.568406879901886, "actor_loss": -0.1694456785917282, "actor_target_entropy": -2.0, "actor_entropy": 1.3627492189407349, "alpha_loss": 0.0016121995286084712, "alpha_value": 0.003050405106934383, "duration": 5.628968954086304, "step": 51639}
{"episode_reward": -4.510469280241478, "episode": 1761.0, "batch_reward": -0.07113757977883021, "critic_loss": 1.170822560787201, "ae_transition_loss": 1.6316670576731365, "ae_encoder_loss": 1.2877941926320393, "actor_loss": -0.20171654472748438, "actor_target_entropy": -2.0, "actor_entropy": 1.1757574876149495, "alpha_loss": 0.0016101640261088808, "alpha_value": 0.0030485560921907086, "duration": 44.81574535369873, "step": 51661}
{"episode_reward": -6.105257163351689, "episode": 1762.0, "duration": 0.19480419158935547, "step": 51662}
{"episode_reward": -0.6243716973308772, "episode": 1763.0, "duration": 0.7686400413513184, "step": 51665}
{"episode_reward": -0.7899751185137742, "episode": 1764.0, "batch_reward": 0.007469508796930313, "critic_loss": 1.408956527709961, "ae_transition_loss": 1.4919986724853516, "ae_encoder_loss": 1.0230897665023804, "actor_loss": -0.29077205061912537, "actor_target_entropy": -2.0, "actor_entropy": 1.092118263244629, "alpha_loss": 0.0007227945607155561, "alpha_value": 0.0030470527328820196, "duration": 2.5199649333953857, "step": 51677}
{"episode_reward": -4.683814903910582, "episode": 1765.0, "batch_reward": -0.03762025572359562, "critic_loss": 0.9466741482416788, "ae_transition_loss": 1.6092416842778523, "ae_encoder_loss": 1.2898800770441692, "actor_loss": -0.4452421963214874, "actor_target_entropy": -2.0, "actor_entropy": 1.1240963141123455, "alpha_loss": -0.00011513511223408084, "alpha_value": 0.003045705208309981, "duration": 5.7585694789886475, "step": 51704}
{"episode_reward": -11.122354713136724, "episode": 1766.0, "duration": 0.2991616725921631, "step": 51705}
{"episode_reward": -0.009011311636580976, "episode": 1767.0, "batch_reward": -0.06455973287423451, "critic_loss": 0.669274648030599, "ae_transition_loss": 1.573320706685384, "ae_encoder_loss": 1.2738674680391948, "actor_loss": -0.5401867429415385, "actor_target_entropy": -2.0, "actor_entropy": 1.3637645641962688, "alpha_loss": -0.0017450488327691953, "alpha_value": 0.003044271534041186, "duration": 6.0172789096832275, "step": 51732}
{"episode_reward": -11.122837623892881, "episode": 1768.0, "batch_reward": -0.09955866262316704, "critic_loss": 1.1374287605285645, "ae_transition_loss": 1.379859447479248, "ae_encoder_loss": 1.2628260254859924, "actor_loss": -0.3306511789560318, "actor_target_entropy": -2.0, "actor_entropy": 1.649583101272583, "alpha_loss": -0.002168054925277829, "alpha_value": 0.0030438694306659238, "duration": 4.8522655963897705, "step": 51756}
{"episode_reward": -8.625820963913363, "episode": 1769.0, "batch_reward": -0.026560240425169468, "critic_loss": 0.9826598018407822, "ae_transition_loss": 1.4896533787250519, "ae_encoder_loss": 1.519013985991478, "actor_loss": -0.6803852617740631, "actor_target_entropy": -2.0, "actor_entropy": 1.7388174831867218, "alpha_loss": 9.68486929195933e-05, "alpha_value": 0.003044248043304238, "duration": 7.830930471420288, "step": 51793}
{"episode_reward": -20.609424025191238, "episode": 1770.0, "batch_reward": -0.06622570846229792, "critic_loss": 0.7137309014797211, "ae_transition_loss": 1.35775488615036, "ae_encoder_loss": 1.2029375433921814, "actor_loss": -0.5214375630021095, "actor_target_entropy": -2.0, "actor_entropy": 1.6508013010025024, "alpha_loss": 0.0019000255269929767, "alpha_value": 0.003044349125094413, "duration": 9.484575986862183, "step": 51839}
{"episode_reward": -18.693410838499293, "episode": 1771.0, "batch_reward": -0.08393003791570663, "critic_loss": 0.8811594943205515, "ae_transition_loss": 1.5272064010302226, "ae_encoder_loss": 1.3439703782399495, "actor_loss": -0.4058568899830182, "actor_target_entropy": -2.0, "actor_entropy": 1.574837863445282, "alpha_loss": 0.0020989576975504556, "alpha_value": 0.003042544873925555, "duration": 63.11992287635803, "step": 51895}
{"episode_reward": -24.599317086294835, "episode": 1772.0, "batch_reward": -0.05563345272094011, "critic_loss": 0.8075659920771917, "ae_transition_loss": 1.7018831372261047, "ae_encoder_loss": 1.2099022070566814, "actor_loss": -0.4493609468142192, "actor_target_entropy": -2.0, "actor_entropy": 2.0525078773498535, "alpha_loss": 0.0021341596924078963, "alpha_value": 0.0030385457682576117, "duration": 11.90388011932373, "step": 51954}
{"episode_reward": -16.214819335252145, "episode": 1773.0, "batch_reward": -0.07597724641008037, "critic_loss": 0.7503923092569623, "ae_transition_loss": 1.4347873074667794, "ae_encoder_loss": 0.9509912048067365, "actor_loss": -0.3616995822106089, "actor_target_entropy": -2.0, "actor_entropy": 1.5018492255892073, "alpha_loss": 0.003036668025223272, "alpha_value": 0.003032824360523871, "duration": 13.75195598602295, "step": 52023}
{"episode_reward": -18.292722719641027, "episode": 1774.0, "batch_reward": -0.062436314831886976, "critic_loss": 0.6394090141568866, "ae_transition_loss": 1.4227177245276315, "ae_encoder_loss": 0.9822837880679539, "actor_loss": -0.5522069505282811, "actor_target_entropy": -2.0, "actor_entropy": 1.0879931705338615, "alpha_loss": 0.002429652277247182, "alpha_value": 0.003024789521022226, "duration": 14.831474304199219, "step": 52096}
{"episode_reward": -17.092957851989077, "episode": 1775.0, "batch_reward": -0.0797081281031881, "critic_loss": 0.8679283772196088, "ae_transition_loss": 1.6923157487596785, "ae_encoder_loss": 1.0752197248595101, "actor_loss": -0.46842027668442043, "actor_target_entropy": -2.0, "actor_entropy": 1.4954063381467546, "alpha_loss": 0.0026392902114561628, "alpha_value": 0.0030160186655592315, "duration": 13.951740741729736, "step": 52166}
{"episode_reward": -12.542276307970313, "episode": 1776.0, "batch_reward": -0.0657239630818367, "critic_loss": 0.701901987195015, "ae_transition_loss": 1.5919110774993896, "ae_encoder_loss": 1.2554233372211456, "actor_loss": -0.36330753564834595, "actor_target_entropy": -2.0, "actor_entropy": 1.8715616762638092, "alpha_loss": 0.0024079472350422293, "alpha_value": 0.0030088949224512025, "duration": 7.791473627090454, "step": 52203}
{"episode_reward": -10.713198640000206, "episode": 1777.0, "batch_reward": -0.09377195779234171, "critic_loss": 1.014623910188675, "ae_transition_loss": 1.6551097631454468, "ae_encoder_loss": 1.244486153125763, "actor_loss": -0.40976104512810707, "actor_target_entropy": -2.0, "actor_entropy": 1.6419406533241272, "alpha_loss": 0.002514774852897972, "alpha_value": 0.0030039229589759074, "duration": 9.520288705825806, "step": 52250}
{"episode_reward": -8.60834624189848, "episode": 1778.0, "batch_reward": -0.06530727446079254, "critic_loss": 0.7461033165454865, "ae_transition_loss": 1.5518564581871033, "ae_encoder_loss": 1.1068888008594513, "actor_loss": -0.49784862995147705, "actor_target_entropy": -2.0, "actor_entropy": 1.2584811449050903, "alpha_loss": 0.00203983869869262, "alpha_value": 0.003000255139759586, "duration": 3.112224578857422, "step": 52264}
{"episode_reward": -3.9027377308378406, "episode": 1779.0, "duration": 0.9548842906951904, "step": 52268}
{"episode_reward": -1.4666150751197822, "episode": 1780.0, "batch_reward": -0.06120879761874676, "critic_loss": 0.7289841671784719, "ae_transition_loss": 1.5599632263183594, "ae_encoder_loss": 1.2496525645256042, "actor_loss": -0.5774992927908897, "actor_target_entropy": -2.0, "actor_entropy": 1.3572351733843486, "alpha_loss": 0.0011470844425881903, "alpha_value": 0.002995654524248497, "duration": 11.44422197341919, "step": 52325}
{"episode_reward": -22.73824580674877, "episode": 1781.0, "batch_reward": -0.09573426780601342, "critic_loss": 1.0555319786071777, "ae_transition_loss": 1.5374895334243774, "ae_encoder_loss": 1.1983808875083923, "actor_loss": -0.2151367850601673, "actor_target_entropy": -2.0, "actor_entropy": 1.3175365924835205, "alpha_loss": -0.00023431958591875932, "alpha_value": 0.002990368300181757, "duration": 89.9739043712616, "step": 52381}
{"episode_reward": -25.652196618941836, "episode": 1782.0, "batch_reward": -0.047886062413454056, "critic_loss": 0.5306697487831116, "ae_transition_loss": 1.5857839584350586, "ae_encoder_loss": 0.8306991457939148, "actor_loss": -0.21317555010318756, "actor_target_entropy": -2.0, "actor_entropy": 1.357020378112793, "alpha_loss": -0.0025965797249227762, "alpha_value": 0.0029885215073474827, "duration": 3.669978618621826, "step": 52398}
{"episode_reward": -10.535179740364066, "episode": 1783.0, "batch_reward": -0.048536673188209534, "critic_loss": 0.5610989034175873, "ae_transition_loss": 1.4407042662302654, "ae_encoder_loss": 1.2730486790339153, "actor_loss": -0.5942203998565674, "actor_target_entropy": -2.0, "actor_entropy": 1.5179961919784546, "alpha_loss": -0.001482845361654957, "alpha_value": 0.0029882011220682975, "duration": 5.803722143173218, "step": 52425}
{"episode_reward": -14.870695894267152, "episode": 1784.0, "batch_reward": -0.08318716074739184, "critic_loss": 0.8231151870318821, "ae_transition_loss": 1.5637992450169154, "ae_encoder_loss": 1.0504834481648035, "actor_loss": -0.4503175531114851, "actor_target_entropy": -2.0, "actor_entropy": 1.8914590052195959, "alpha_loss": -0.0007849848272079336, "alpha_value": 0.002988630519938034, "duration": 14.707701921463013, "step": 52496}
{"episode_reward": -44.31859445098215, "episode": 1785.0, "batch_reward": -0.025957148522138596, "critic_loss": 0.6141516864299774, "ae_transition_loss": 1.5303407311439514, "ae_encoder_loss": 0.9815642237663269, "actor_loss": -0.7538513243198395, "actor_target_entropy": -2.0, "actor_entropy": 1.8356836438179016, "alpha_loss": -0.0009082109318114817, "alpha_value": 0.002989544009373897, "duration": 4.26772928237915, "step": 52517}
{"episode_reward": -11.167972577640843, "episode": 1786.0, "batch_reward": -0.1082298755645752, "critic_loss": 1.573348879814148, "ae_transition_loss": 1.5086373090744019, "ae_encoder_loss": 0.820624053478241, "actor_loss": -0.5484192371368408, "actor_target_entropy": -2.0, "actor_entropy": 1.625597596168518, "alpha_loss": 3.819812263827771e-05, "alpha_value": 0.002989929149380644, "duration": 1.9596002101898193, "step": 52526}
{"episode_reward": -5.268069517543131, "episode": 1787.0, "batch_reward": -0.08557221045096715, "critic_loss": 0.845850259065628, "ae_transition_loss": 1.5739585757255554, "ae_encoder_loss": 1.3190905253092449, "actor_loss": -0.4366713414589564, "actor_target_entropy": -2.0, "actor_entropy": 1.5367063681284587, "alpha_loss": 0.0002806677366606891, "alpha_value": 0.0029905906421261656, "duration": 12.655984163284302, "step": 52587}
{"episode_reward": -34.267191571059385, "episode": 1788.0, "batch_reward": -0.10447254776954651, "critic_loss": 0.30627554655075073, "ae_transition_loss": 1.2471171617507935, "ae_encoder_loss": 1.0152978897094727, "actor_loss": -0.3454766273498535, "actor_target_entropy": -2.0, "actor_entropy": 1.320006251335144, "alpha_loss": 0.0019789698999375105, "alpha_value": 0.0029909865021699278, "duration": 1.2348911762237549, "step": 52591}
{"episode_reward": -1.095285982122714, "episode": 1789.0, "batch_reward": -0.09437441329161327, "critic_loss": 0.7582244078318278, "ae_transition_loss": 1.4790454705556233, "ae_encoder_loss": 1.1904283165931702, "actor_loss": -0.37368735174338025, "actor_target_entropy": -2.0, "actor_entropy": 1.4828626314798992, "alpha_loss": 0.00082100932195317, "alpha_value": 0.0029905676570030505, "duration": 13.028956890106201, "step": 52655}
{"episode_reward": -37.180310060938844, "episode": 1790.0, "batch_reward": -0.09868057568868001, "critic_loss": 0.9062635898590088, "ae_transition_loss": 1.4696264266967773, "ae_encoder_loss": 1.0880773464838664, "actor_loss": -0.35846060514450073, "actor_target_entropy": -2.0, "actor_entropy": 1.419577956199646, "alpha_loss": -0.00011032008721182744, "alpha_value": 0.002989666220966606, "duration": 7.39989972114563, "step": 52689}
{"episode_reward": -16.344174042743344, "episode": 1791.0, "batch_reward": -0.1195921078324318, "critic_loss": 0.9368454416592916, "ae_transition_loss": 1.8067689736684163, "ae_encoder_loss": 1.0573087731997173, "actor_loss": -0.19123464822769165, "actor_target_entropy": -2.0, "actor_entropy": 1.2011614640553792, "alpha_loss": -2.211680597004791e-05, "alpha_value": 0.002989190978710201, "duration": 90.9712884426117, "step": 52717}
{"episode_reward": -15.137334594326312, "episode": 1792.0, "batch_reward": -0.08318331651389599, "critic_loss": 0.8318224847316742, "ae_transition_loss": 1.5454077124595642, "ae_encoder_loss": 1.3652224441369374, "actor_loss": -0.4536842852830887, "actor_target_entropy": -2.0, "actor_entropy": 1.2036641240119934, "alpha_loss": -0.000506612098736999, "alpha_value": 0.002988832433385092, "duration": 11.21670937538147, "step": 52772}
{"episode_reward": -31.99085393575681, "episode": 1793.0, "batch_reward": -0.07115938692974548, "critic_loss": 0.9356479297081629, "ae_transition_loss": 1.7520039081573486, "ae_encoder_loss": 1.3676918546358745, "actor_loss": -0.4164852499961853, "actor_target_entropy": -2.0, "actor_entropy": 1.3026421864827473, "alpha_loss": -0.00034463130577933043, "alpha_value": 0.002989168250880079, "duration": 12.71561312675476, "step": 52834}
{"episode_reward": -35.35645010699342, "episode": 1794.0, "batch_reward": -0.07282160914369992, "critic_loss": 0.7535861645426069, "ae_transition_loss": 1.7462242330823625, "ae_encoder_loss": 1.3787048884800501, "actor_loss": -0.40112614950963427, "actor_target_entropy": -2.0, "actor_entropy": 1.7358091729027885, "alpha_loss": 0.0006175994016562722, "alpha_value": 0.0029898664917458718, "duration": 15.60283899307251, "step": 52909}
{"episode_reward": -40.20198308296079, "episode": 1795.0, "batch_reward": -0.12472198605537414, "critic_loss": 0.7666769981384277, "ae_transition_loss": 1.5566289186477662, "ae_encoder_loss": 1.3199392795562743, "actor_loss": -0.10645397007465363, "actor_target_entropy": -2.0, "actor_entropy": 0.9755598425865173, "alpha_loss": 0.00011424727563280612, "alpha_value": 0.00298945293457271, "duration": 10.147756338119507, "step": 52960}
{"episode_reward": -25.220035260416655, "episode": 1796.0, "batch_reward": -0.09383684024214745, "critic_loss": 0.8379902958869934, "ae_transition_loss": 1.504212498664856, "ae_encoder_loss": 1.5406395673751831, "actor_loss": -0.26340646743774415, "actor_target_entropy": -2.0, "actor_entropy": 1.0281314969062805, "alpha_loss": 0.0011556208948604763, "alpha_value": 0.0029887072193956823, "duration": 10.416797161102295, "step": 53010}
{"episode_reward": -21.265962377131107, "episode": 1797.0, "batch_reward": -0.11387062321106593, "critic_loss": 0.8504098057746887, "ae_transition_loss": 1.5972439050674438, "ae_encoder_loss": 1.4657363494237263, "actor_loss": -0.439447025458018, "actor_target_entropy": -2.0, "actor_entropy": 1.2240543762842815, "alpha_loss": 0.0012173984432592988, "alpha_value": 0.00298753733106279, "duration": 5.898824214935303, "step": 53039}
{"episode_reward": -4.5739007988031855, "episode": 1798.0, "batch_reward": -0.1112348772585392, "critic_loss": 0.9360855370759964, "ae_transition_loss": 1.5625163912773132, "ae_encoder_loss": 1.4596192240715027, "actor_loss": -0.21017071977257729, "actor_target_entropy": -2.0, "actor_entropy": 1.3270570039749146, "alpha_loss": 0.00041917181806638837, "alpha_value": 0.002986190041935885, "duration": 7.2406535148620605, "step": 53073}
{"episode_reward": -7.7189028197959795, "episode": 1799.0, "batch_reward": -0.08777382224798203, "critic_loss": 1.013538420200348, "ae_transition_loss": 1.3938331007957458, "ae_encoder_loss": 2.124837636947632, "actor_loss": -0.3921583592891693, "actor_target_entropy": -2.0, "actor_entropy": 1.5921518802642822, "alpha_loss": 0.0011636215349426493, "alpha_value": 0.002985134096575059, "duration": 5.134958267211914, "step": 53098}
{"episode_reward": -10.326908549933956, "episode": 1800.0, "batch_reward": -0.07724679820239544, "critic_loss": 0.7231344729661942, "ae_transition_loss": 1.41201913356781, "ae_encoder_loss": 1.7422285974025726, "actor_loss": -0.320944182574749, "actor_target_entropy": -2.0, "actor_entropy": 1.4751241207122803, "alpha_loss": -0.00032246347836917266, "alpha_value": 0.002984042128028458, "duration": 7.582242250442505, "step": 53134}
{"episode_reward": -9.99917116751973, "episode": 1801.0, "duration": 54.35728478431702, "step": 53135}
{"episode_reward": 0.27355319519780275, "episode": 1802.0, "batch_reward": -0.1122226615746816, "critic_loss": 1.033965011437734, "ae_transition_loss": 1.9287906487782795, "ae_encoder_loss": 1.7818979819615681, "actor_loss": -0.40246910353501636, "actor_target_entropy": -2.0, "actor_entropy": 1.378136436144511, "alpha_loss": -0.00019432731399623057, "alpha_value": 0.0029832797756787852, "duration": 6.591789484024048, "step": 53167}
{"episode_reward": -13.876750522508296, "episode": 1803.0, "duration": 0.25971317291259766, "step": 53168}
{"episode_reward": -1.0197036782114985, "episode": 1804.0, "batch_reward": -0.11283846696217854, "critic_loss": 1.0508219798405964, "ae_transition_loss": 1.3859745661417644, "ae_encoder_loss": 1.598819375038147, "actor_loss": -0.1288385589917501, "actor_target_entropy": -2.0, "actor_entropy": 1.625922958056132, "alpha_loss": 0.0014266350966257353, "alpha_value": 0.0029829185473270793, "duration": 5.094866514205933, "step": 53192}
{"episode_reward": -8.575339059796859, "episode": 1805.0, "batch_reward": 0.02987397089600563, "critic_loss": 1.2093076705932617, "ae_transition_loss": 1.4817744493484497, "ae_encoder_loss": 2.293095588684082, "actor_loss": -0.7420327663421631, "actor_target_entropy": -2.0, "actor_entropy": 1.7237082719802856, "alpha_loss": 0.0009962980402633548, "alpha_value": 0.002982455974347183, "duration": 3.645582437515259, "step": 53210}
{"episode_reward": -6.663440636154654, "episode": 1806.0, "batch_reward": -0.08928658130268256, "critic_loss": 1.5826373895009358, "ae_transition_loss": 1.7046232620875041, "ae_encoder_loss": 1.4872868061065674, "actor_loss": -0.4616939226786296, "actor_target_entropy": -2.0, "actor_entropy": 1.5928923686345418, "alpha_loss": 0.0020545575534924865, "alpha_value": 0.0029817499797840405, "duration": 4.9234020709991455, "step": 53232}
{"episode_reward": -10.589077322794878, "episode": 1807.0, "batch_reward": -0.050671614706516266, "critic_loss": 1.029580533504486, "ae_transition_loss": 1.5588505268096924, "ae_encoder_loss": 2.2393908500671387, "actor_loss": -0.44821420311927795, "actor_target_entropy": -2.0, "actor_entropy": 1.3309330940246582, "alpha_loss": 0.001975748687982559, "alpha_value": 0.0029805220035632406, "duration": 4.383786201477051, "step": 53254}
{"episode_reward": -5.299906894047579, "episode": 1808.0, "batch_reward": -0.0967913269996643, "critic_loss": 0.9352282881736755, "ae_transition_loss": 1.4773589372634888, "ae_encoder_loss": 1.4624361991882324, "actor_loss": -0.03940284624695778, "actor_target_entropy": -2.0, "actor_entropy": 1.2867157459259033, "alpha_loss": 0.0029136352241039276, "alpha_value": 0.002979607574442454, "duration": 2.667424201965332, "step": 53267}
{"episode_reward": -5.866162462013614, "episode": 1809.0, "batch_reward": -0.057704491540789604, "critic_loss": 1.030607908964157, "ae_transition_loss": 1.5351843237876892, "ae_encoder_loss": 1.6098251044750214, "actor_loss": -0.651813417673111, "actor_target_entropy": -2.0, "actor_entropy": 1.4358628690242767, "alpha_loss": 0.001604448894795496, "alpha_value": 0.002977707580445378, "duration": 7.299777507781982, "step": 53302}
{"episode_reward": -15.050501490271866, "episode": 1810.0, "batch_reward": -0.08131609112024307, "critic_loss": 1.0067520936330159, "ae_transition_loss": 1.7295314073562622, "ae_encoder_loss": 1.5551653305689495, "actor_loss": -0.27964378396670025, "actor_target_entropy": -2.0, "actor_entropy": 1.4646963278452556, "alpha_loss": 0.0005614033580059186, "alpha_value": 0.0029750824181105882, "duration": 7.41585898399353, "step": 53338}
{"episode_reward": -8.595927193722622, "episode": 1811.0, "duration": 27.559495449066162, "step": 53339}
{"episode_reward": -0.3617247148099272, "episode": 1812.0, "batch_reward": -0.06753973476588726, "critic_loss": 1.2105088531970978, "ae_transition_loss": 1.9155825972557068, "ae_encoder_loss": 1.3299660682678223, "actor_loss": -0.21812831610441208, "actor_target_entropy": -2.0, "actor_entropy": 1.5580272674560547, "alpha_loss": 0.00034718625829555094, "alpha_value": 0.00297346729805114, "duration": 4.140064716339111, "step": 53359}
{"episode_reward": -11.735954147733834, "episode": 1813.0, "batch_reward": -0.1287725567817688, "critic_loss": 0.9117989242076874, "ae_transition_loss": 1.6966469585895538, "ae_encoder_loss": 1.6679149866104126, "actor_loss": -0.19863736629486084, "actor_target_entropy": -2.0, "actor_entropy": 1.8282735347747803, "alpha_loss": 0.0010217377712251619, "alpha_value": 0.0029719657812472696, "duration": 7.332158803939819, "step": 53394}
{"episode_reward": -15.937608281353645, "episode": 1814.0, "duration": 0.23955392837524414, "step": 53395}
{"episode_reward": -0.13272297382354736, "episode": 1815.0, "batch_reward": -0.04255134090781212, "critic_loss": 0.8075901508331299, "ae_transition_loss": 1.6269342422485351, "ae_encoder_loss": 1.755167055130005, "actor_loss": -0.2133772775530815, "actor_target_entropy": -2.0, "actor_entropy": 1.3736879110336304, "alpha_loss": 0.0023510558065027, "alpha_value": 0.0029694026217105597, "duration": 10.215717792510986, "step": 53444}
{"episode_reward": -25.176739396303073, "episode": 1816.0, "batch_reward": -0.07760022766888142, "critic_loss": 0.8061507741610209, "ae_transition_loss": 1.797196090221405, "ae_encoder_loss": 1.305090030034383, "actor_loss": -0.5969014763832092, "actor_target_entropy": -2.0, "actor_entropy": 1.1797971526781719, "alpha_loss": 0.004406358115375042, "alpha_value": 0.0029643135027495834, "duration": 12.423514604568481, "step": 53505}
{"episode_reward": -19.374078019512215, "episode": 1817.0, "batch_reward": -0.0705778107047081, "critic_loss": 0.9104148149490356, "ae_transition_loss": 1.6646851539611816, "ae_encoder_loss": 1.2440890669822693, "actor_loss": -0.45206871032714846, "actor_target_entropy": -2.0, "actor_entropy": 1.2275867223739625, "alpha_loss": 0.004205707786604762, "alpha_value": 0.002956250794591691, "duration": 10.114745855331421, "step": 53554}
{"episode_reward": -26.195845237402256, "episode": 1818.0, "duration": 1.405250072479248, "step": 53560}
{"episode_reward": -2.2527890849574987, "episode": 1819.0, "batch_reward": -0.047928945471843086, "critic_loss": 0.9876912633577982, "ae_transition_loss": 1.6014195680618286, "ae_encoder_loss": 1.5001869201660156, "actor_loss": -0.3845020333925883, "actor_target_entropy": -2.0, "actor_entropy": 1.3444957335789998, "alpha_loss": 0.003138309810310602, "alpha_value": 0.0029491709982770995, "duration": 4.9842798709869385, "step": 53583}
{"episode_reward": -5.926549365002312, "episode": 1820.0, "duration": 0.20307302474975586, "step": 53584}
{"episode_reward": -0.12477519480163683, "episode": 1821.0, "batch_reward": -0.08708037436008453, "critic_loss": 0.8507294654846191, "ae_transition_loss": 1.640663743019104, "ae_encoder_loss": 1.4823871850967407, "actor_loss": -0.14620113372802734, "actor_target_entropy": -2.0, "actor_entropy": 1.3619840145111084, "alpha_loss": 0.0023670298978686333, "alpha_value": 0.0029456081728832795, "duration": 36.756340742111206, "step": 53600}
{"episode_reward": -0.17334484450879115, "episode": 1822.0, "batch_reward": -0.08601205516606569, "critic_loss": 0.9746561795473099, "ae_transition_loss": 1.6281051933765411, "ae_encoder_loss": 1.367412120103836, "actor_loss": -0.06059665326029062, "actor_target_entropy": -2.0, "actor_entropy": 1.3214618265628815, "alpha_loss": 0.001975471357582137, "alpha_value": 0.0029415321821968745, "duration": 7.983415365219116, "step": 53637}
{"episode_reward": -16.550696923941437, "episode": 1823.0, "batch_reward": -0.07140990967551868, "critic_loss": 1.1944905519485474, "ae_transition_loss": 1.6746596097946167, "ae_encoder_loss": 1.2114781141281128, "actor_loss": -0.5319194694360098, "actor_target_entropy": -2.0, "actor_entropy": 1.309947411219279, "alpha_loss": 0.0006839301543853556, "alpha_value": 0.0029364012330974788, "duration": 6.189066410064697, "step": 53666}
{"episode_reward": -6.518673909309982, "episode": 1824.0, "batch_reward": -0.1433771662414074, "critic_loss": 1.216185450553894, "ae_transition_loss": 1.4256536960601807, "ae_encoder_loss": 1.164597749710083, "actor_loss": -0.5221788212656975, "actor_target_entropy": -2.0, "actor_entropy": 1.3373467326164246, "alpha_loss": 0.000665127852698788, "alpha_value": 0.0029333962521942572, "duration": 4.134356498718262, "step": 53685}
{"episode_reward": -5.136354856457439, "episode": 1825.0, "batch_reward": -0.11392940580844879, "critic_loss": 1.1375067035357158, "ae_transition_loss": 1.596111536026001, "ae_encoder_loss": 1.1928589344024658, "actor_loss": -0.06559100250403087, "actor_target_entropy": -2.0, "actor_entropy": 1.237862269083659, "alpha_loss": 0.0007185423746705055, "alpha_value": 0.002930832025952164, "duration": 6.787895202636719, "step": 53718}
{"episode_reward": -13.064258264039553, "episode": 1826.0, "batch_reward": -0.07858775556087494, "critic_loss": 1.2343738079071045, "ae_transition_loss": 1.5584675669670105, "ae_encoder_loss": 1.309198796749115, "actor_loss": -0.39247994124889374, "actor_target_entropy": -2.0, "actor_entropy": 1.288501501083374, "alpha_loss": 0.0013339194119907916, "alpha_value": 0.0029285980195870942, "duration": 4.127696990966797, "step": 53737}
{"episode_reward": -4.142964745459648, "episode": 1827.0, "batch_reward": -0.08389566202337544, "critic_loss": 0.8455321590105692, "ae_transition_loss": 1.6984527309735615, "ae_encoder_loss": 1.335066060225169, "actor_loss": -0.10123312473297119, "actor_target_entropy": -2.0, "actor_entropy": 1.5869869788487752, "alpha_loss": 0.001741359456597517, "alpha_value": 0.002925314767202152, "duration": 13.240240812301636, "step": 53800}
{"episode_reward": -36.419192783929205, "episode": 1828.0, "batch_reward": -0.12518827617168427, "critic_loss": 1.0076208114624023, "ae_transition_loss": 1.6387030482292175, "ae_encoder_loss": 1.2484507262706757, "actor_loss": -0.28478441946208477, "actor_target_entropy": -2.0, "actor_entropy": 1.3471927642822266, "alpha_loss": 0.0020046787976752967, "alpha_value": 0.002919315769967215, "duration": 16.197513580322266, "step": 53874}
{"episode_reward": -36.91068892530258, "episode": 1829.0, "batch_reward": -0.0683334618806839, "critic_loss": 0.66913241147995, "ae_transition_loss": 1.4533527493476868, "ae_encoder_loss": 0.9367892146110535, "actor_loss": -0.41858766973018646, "actor_target_entropy": -2.0, "actor_entropy": 1.6632429957389832, "alpha_loss": 0.0020063373958691955, "alpha_value": 0.0029146891557133223, "duration": 3.8820807933807373, "step": 53891}
{"episode_reward": -5.538257992559531, "episode": 1830.0, "duration": 1.3382058143615723, "step": 53898}
{"episode_reward": -2.541432704233987, "episode": 1831.0, "duration": 41.271522521972656, "step": 53899}
{"episode_reward": -0.47865718603134155, "episode": 1832.0, "batch_reward": -0.05192580446600914, "critic_loss": 0.8314677476882935, "ae_transition_loss": 1.536773681640625, "ae_encoder_loss": 1.0160426795482635, "actor_loss": -0.05833098292350769, "actor_target_entropy": -2.0, "actor_entropy": 1.5645464062690735, "alpha_loss": 0.0025092186988331378, "alpha_value": 0.0029126500203034873, "duration": 3.3638627529144287, "step": 53915}
{"episode_reward": -6.2023679749872915, "episode": 1833.0, "duration": 0.22745084762573242, "step": 53916}
{"episode_reward": -0.16756823658943176, "episode": 1834.0, "batch_reward": -0.13124383240938187, "critic_loss": 0.6912007331848145, "ae_transition_loss": 1.5364959239959717, "ae_encoder_loss": 0.7425562739372253, "actor_loss": -0.005106896162033081, "actor_target_entropy": -2.0, "actor_entropy": 1.4642523527145386, "alpha_loss": 0.002051893447060138, "alpha_value": 0.0029105361048994837, "duration": 4.892345666885376, "step": 53940}
{"episode_reward": -9.735737785329773, "episode": 1835.0, "batch_reward": -0.05046289227902889, "critic_loss": 0.6263742744922638, "ae_transition_loss": 1.845077633857727, "ae_encoder_loss": 0.8562442660331726, "actor_loss": -0.37080349028110504, "actor_target_entropy": -2.0, "actor_entropy": 1.673757255077362, "alpha_loss": 0.0027277549961581826, "alpha_value": 0.002908371388541966, "duration": 3.167668342590332, "step": 53955}
{"episode_reward": -4.874282581053476, "episode": 1836.0, "batch_reward": -0.0958852544426918, "critic_loss": 0.7792443037033081, "ae_transition_loss": 1.6529210209846497, "ae_encoder_loss": 0.8150857985019684, "actor_loss": -0.16929985582828522, "actor_target_entropy": -2.0, "actor_entropy": 1.9271799325942993, "alpha_loss": 0.0022639274829998612, "alpha_value": 0.002906098123144984, "duration": 4.86353874206543, "step": 53979}
{"episode_reward": -7.913336895277684, "episode": 1837.0, "duration": 0.2317955493927002, "step": 53980}
{"episode_reward": -0.28399392891655895, "episode": 1838.0, "batch_reward": -0.07007640103499095, "critic_loss": 1.2408426403999329, "ae_transition_loss": 1.576208511988322, "ae_encoder_loss": 0.8562764724095663, "actor_loss": -0.33720949788888294, "actor_target_entropy": -2.0, "actor_entropy": 2.227285941441854, "alpha_loss": 0.005211206929137309, "alpha_value": 0.0029030424549836135, "duration": 4.740380525588989, "step": 54001}
{"episode_reward": -5.438057175896394, "episode": 1839.0, "batch_reward": -0.05308498442173004, "critic_loss": 0.627300500869751, "ae_transition_loss": 1.6554838418960571, "ae_encoder_loss": 0.9292365908622742, "actor_loss": -0.13107210397720337, "actor_target_entropy": -2.0, "actor_entropy": 1.8273259401321411, "alpha_loss": 0.0045968410558998585, "alpha_value": 0.0029000738587674647, "duration": 2.605132818222046, "step": 54013}
{"episode_reward": -2.6383775224008135, "episode": 1840.0, "batch_reward": -0.1224681877841552, "critic_loss": 0.8246621489524841, "ae_transition_loss": 1.5020761092503865, "ae_encoder_loss": 0.8492581049601237, "actor_loss": -0.15082341680924097, "actor_target_entropy": -2.0, "actor_entropy": 1.367914358774821, "alpha_loss": 0.005473743192851543, "alpha_value": 0.0028965853178177224, "duration": 6.086097478866577, "step": 54041}
{"episode_reward": -5.735776622160851, "episode": 1841.0, "batch_reward": -0.0561034243243436, "critic_loss": 0.8533980250358582, "ae_transition_loss": 1.7769293983777363, "ae_encoder_loss": 0.8901726752519608, "actor_loss": -0.1728138110289971, "actor_target_entropy": -2.0, "actor_entropy": -0.16939036113520464, "alpha_loss": 0.003303437464637682, "alpha_value": 0.002881742448572281, "duration": 53.903621435165405, "step": 54165}
{"episode_reward": -3.588001209656894, "episode": 1842.0, "batch_reward": -0.03888582872847716, "critic_loss": 0.6081500252087911, "ae_transition_loss": 1.60763418674469, "ae_encoder_loss": 1.0561251441637676, "actor_loss": -0.22172683477401733, "actor_target_entropy": -2.0, "actor_entropy": 0.6504201690355936, "alpha_loss": 0.004577136753747861, "alpha_value": 0.002868003399419505, "duration": 7.14773416519165, "step": 54200}
{"episode_reward": -0.35705075524356467, "episode": 1843.0, "batch_reward": -0.10164080560207367, "critic_loss": 0.7006294012069703, "ae_transition_loss": 1.484645128250122, "ae_encoder_loss": 0.7997197508811951, "actor_loss": -0.05087875723838806, "actor_target_entropy": -2.0, "actor_entropy": 0.6890977561473847, "alpha_loss": 0.0051145550794899465, "alpha_value": 0.00286016672960793, "duration": 10.05985951423645, "step": 54249}
{"episode_reward": -7.328572774404079, "episode": 1844.0, "duration": 0.22743535041809082, "step": 54250}
{"episode_reward": 0.5116990605767192, "episode": 1845.0, "batch_reward": -0.09035130739212036, "critic_loss": 0.6740783631801606, "ae_transition_loss": 1.2795198440551758, "ae_encoder_loss": 0.789637565612793, "actor_loss": 0.06718073636293412, "actor_target_entropy": -2.0, "actor_entropy": -0.5230258107185364, "alpha_loss": 0.002035842998884618, "alpha_value": 0.002849660798659627, "duration": 8.767848253250122, "step": 54293}
{"episode_reward": 0.2976641072246339, "episode": 1846.0, "duration": 0.22066044807434082, "step": 54294}
{"episode_reward": -0.409833740465402, "episode": 1847.0, "batch_reward": -0.07203205178181331, "critic_loss": 0.6405424475669861, "ae_transition_loss": 1.2005532781283061, "ae_encoder_loss": 0.9351333379745483, "actor_loss": -0.04101227720578512, "actor_target_entropy": -2.0, "actor_entropy": -0.005113253990809123, "alpha_loss": 0.002463793304438392, "alpha_value": 0.0028424459622519173, "duration": 7.223314046859741, "step": 54329}
{"episode_reward": 1.9967153121990757, "episode": 1848.0, "duration": 0.22773241996765137, "step": 54330}
{"episode_reward": -0.06390906850475331, "episode": 1849.0, "batch_reward": -0.09762493055313826, "critic_loss": 0.672298975288868, "ae_transition_loss": 1.727804720401764, "ae_encoder_loss": 0.7923673391342163, "actor_loss": 0.09599984064698219, "actor_target_entropy": -2.0, "actor_entropy": 0.1952319610863924, "alpha_loss": 0.0030957087292335927, "alpha_value": 0.0028367863435966104, "duration": 8.255774021148682, "step": 54370}
{"episode_reward": 3.328259161552162, "episode": 1850.0, "batch_reward": -0.1151556670665741, "critic_loss": 0.8736359079678854, "ae_transition_loss": 1.450065016746521, "ae_encoder_loss": 0.9133430123329163, "actor_loss": -0.2771163880825043, "actor_target_entropy": -2.0, "actor_entropy": 0.0573183943827947, "alpha_loss": 0.0027294488002856574, "alpha_value": 0.002831184206103661, "duration": 4.879992961883545, "step": 54393}
{"episode_reward": -0.33468278711091315, "episode": 1851.0, "duration": 44.49978852272034, "step": 54394}
{"episode_reward": -0.9936753270404972, "episode": 1852.0, "batch_reward": -0.08497598270575206, "critic_loss": 1.0013423760732014, "ae_transition_loss": 1.5995207627614338, "ae_encoder_loss": 0.9095300038655599, "actor_loss": -0.11192390074332555, "actor_target_entropy": -2.0, "actor_entropy": -0.023003657658894856, "alpha_loss": 0.0030966156627982855, "alpha_value": 0.002826505126924027, "duration": 5.948638200759888, "step": 54422}
{"episode_reward": 3.89314353526186, "episode": 1853.0, "batch_reward": -0.025897365994751453, "critic_loss": 0.5529065728187561, "ae_transition_loss": 1.4490334391593933, "ae_encoder_loss": 0.7858549952507019, "actor_loss": -0.08849453181028366, "actor_target_entropy": -2.0, "actor_entropy": 0.0681089498102665, "alpha_loss": 0.0027802304830402136, "alpha_value": 0.0028225960254612305, "duration": 4.340678930282593, "step": 54444}
{"episode_reward": 0.6439849860610436, "episode": 1854.0, "batch_reward": -0.07374261785298586, "critic_loss": 0.579065352678299, "ae_transition_loss": 1.5323308408260345, "ae_encoder_loss": 0.9042588174343109, "actor_loss": -0.15347426664084196, "actor_target_entropy": -2.0, "actor_entropy": 0.19625628739595413, "alpha_loss": 0.0031911945552565157, "alpha_value": 0.0028179329461927786, "duration": 8.076742887496948, "step": 54482}
{"episode_reward": 4.551085033949684, "episode": 1855.0, "batch_reward": -0.07867810688912868, "critic_loss": 0.6518624169485909, "ae_transition_loss": 1.5757140261786324, "ae_encoder_loss": 0.9096740058490208, "actor_loss": -0.044303477076547484, "actor_target_entropy": -2.0, "actor_entropy": 0.5909946433135441, "alpha_loss": 0.0034900899045169353, "alpha_value": 0.002803178767957774, "duration": 29.51716709136963, "step": 54625}
{"episode_reward": 21.71180238078303, "episode": 1856.0, "batch_reward": -0.0974107326939702, "critic_loss": 1.0214918375015258, "ae_transition_loss": 1.5348099231719972, "ae_encoder_loss": 0.6941595435142517, "actor_loss": -0.09123562797904014, "actor_target_entropy": -2.0, "actor_entropy": 0.844638729095459, "alpha_loss": 0.004171417932957411, "alpha_value": 0.002786715716648602, "duration": 10.20023488998413, "step": 54673}
{"episode_reward": 1.6952625729359971, "episode": 1857.0, "batch_reward": -0.09733764082193375, "critic_loss": 1.0925869941711426, "ae_transition_loss": 2.351511299610138, "ae_encoder_loss": 0.8232286274433136, "actor_loss": -0.08123363927006721, "actor_target_entropy": -2.0, "actor_entropy": 0.8006256222724915, "alpha_loss": 0.004494864260777831, "alpha_value": 0.0027801974843281187, "duration": 4.050980567932129, "step": 54691}
{"episode_reward": -2.3336463310587687, "episode": 1858.0, "batch_reward": -0.12001701879004638, "critic_loss": 0.863760381937027, "ae_transition_loss": 1.5704134305318196, "ae_encoder_loss": 0.8934969206651052, "actor_loss": 0.06409824794779222, "actor_target_entropy": -2.0, "actor_entropy": -0.04975009088714918, "alpha_loss": 0.003017788752913475, "alpha_value": 0.0027724004048771717, "duration": 13.179373264312744, "step": 54753}
{"episode_reward": -1.878706627336149, "episode": 1859.0, "batch_reward": -0.05600215122103691, "critic_loss": 1.1517914533615112, "ae_transition_loss": 1.4654568433761597, "ae_encoder_loss": 0.7017558217048645, "actor_loss": -0.1800391674041748, "actor_target_entropy": -2.0, "actor_entropy": -0.03948533535003662, "alpha_loss": 0.001973198726773262, "alpha_value": 0.0027659557022745736, "duration": 3.4127063751220703, "step": 54770}
{"episode_reward": -2.929467927424353, "episode": 1860.0, "batch_reward": -0.09448839724063873, "critic_loss": 1.0427906513214111, "ae_transition_loss": 1.4166289567947388, "ae_encoder_loss": 0.590343713760376, "actor_loss": -0.2596740126609802, "actor_target_entropy": -2.0, "actor_entropy": -0.2318955361843109, "alpha_loss": 0.0018714792095124722, "alpha_value": 0.00276428148174393, "duration": 2.0157368183135986, "step": 54779}
{"episode_reward": -3.495534215278518, "episode": 1861.0, "batch_reward": -0.08720036099354427, "critic_loss": 0.734877347946167, "ae_transition_loss": 1.3688373963038127, "ae_encoder_loss": 0.6938155293464661, "actor_loss": 0.028577061990896862, "actor_target_entropy": -2.0, "actor_entropy": -0.660143514474233, "alpha_loss": 0.002260364747295777, "alpha_value": 0.0027611041466004313, "duration": 50.84960103034973, "step": 54803}
{"episode_reward": -3.9153156149650283, "episode": 1862.0, "batch_reward": -0.08205316159874201, "critic_loss": 0.8271404385566712, "ae_transition_loss": 1.1887086033821106, "ae_encoder_loss": 0.7215909957885742, "actor_loss": 0.007923265546560287, "actor_target_entropy": -2.0, "actor_entropy": -0.1706787534058094, "alpha_loss": 0.002968649729155004, "alpha_value": 0.0027517608257035466, "duration": 21.537784576416016, "step": 54910}
{"episode_reward": -12.163435190724257, "episode": 1863.0, "batch_reward": -0.08685473538935184, "critic_loss": 0.6317750364542007, "ae_transition_loss": 1.3137620687484741, "ae_encoder_loss": 0.8257534205913544, "actor_loss": -0.028549807146191597, "actor_target_entropy": -2.0, "actor_entropy": 0.13696137629449368, "alpha_loss": 0.0031809989595785737, "alpha_value": 0.002741260693744195, "duration": 7.103986740112305, "step": 54944}
{"episode_reward": 1.945584024490197, "episode": 1864.0, "batch_reward": -0.04679826802263657, "critic_loss": 0.489791880051295, "ae_transition_loss": 1.2482206424077351, "ae_encoder_loss": 0.9352659980456034, "actor_loss": -0.258684977889061, "actor_target_entropy": -2.0, "actor_entropy": 0.281378909945488, "alpha_loss": 0.002906230976805091, "alpha_value": 0.002735726594584717, "duration": 7.379717826843262, "step": 54980}
{"episode_reward": 1.0379835577156156, "episode": 1865.0, "batch_reward": -0.10136128067970276, "critic_loss": 0.6198316812515259, "ae_transition_loss": 1.5010441064834594, "ae_encoder_loss": 1.0123695135116577, "actor_loss": 0.1987987905740738, "actor_target_entropy": -2.0, "actor_entropy": 0.491817319393158, "alpha_loss": 0.002765974495559931, "alpha_value": 0.0027296566792750095, "duration": 8.994138479232788, "step": 55024}
{"episode_reward": 3.2466408993454134, "episode": 1866.0, "batch_reward": -0.05655797105282545, "critic_loss": 0.5464221239089966, "ae_transition_loss": 1.4379339814186096, "ae_encoder_loss": 0.8077590018510818, "actor_loss": 0.14321430586278439, "actor_target_entropy": -2.0, "actor_entropy": 0.23447484336793423, "alpha_loss": 0.00266181118786335, "alpha_value": 0.0027230016325699253, "duration": 8.81718111038208, "step": 55069}
{"episode_reward": 4.346961251544713, "episode": 1867.0, "batch_reward": -0.09831582357486089, "critic_loss": 0.7105747818946838, "ae_transition_loss": 1.514570140838623, "ae_encoder_loss": 0.7892949302991231, "actor_loss": 0.010556092113256454, "actor_target_entropy": -2.0, "actor_entropy": 0.23469856828451158, "alpha_loss": 0.0029035082397361597, "alpha_value": 0.0027093212703665484, "duration": 28.525949954986572, "step": 55212}
{"episode_reward": -24.097985672432394, "episode": 1868.0, "batch_reward": -0.024637959897518158, "critic_loss": 0.7565034627914429, "ae_transition_loss": 1.243293285369873, "ae_encoder_loss": 0.4784441590309143, "actor_loss": 0.27218395471572876, "actor_target_entropy": -2.0, "actor_entropy": 0.7367109656333923, "alpha_loss": 0.003495539538562298, "alpha_value": 0.0026977739474578102, "duration": 3.4058632850646973, "step": 55229}
{"episode_reward": -3.068811472559231, "episode": 1869.0, "batch_reward": -0.04167414146165053, "critic_loss": 0.7428034146626791, "ae_transition_loss": 1.4194236993789673, "ae_encoder_loss": 0.5861972769101461, "actor_loss": -0.23124921321868896, "actor_target_entropy": -2.0, "actor_entropy": 0.7188820242881775, "alpha_loss": 0.0041207911757131415, "alpha_value": 0.0026946646757965522, "duration": 5.109430551528931, "step": 55254}
{"episode_reward": 1.2213510277333568, "episode": 1870.0, "batch_reward": -0.09274046814867429, "critic_loss": 0.6594942339829036, "ae_transition_loss": 1.264505956854139, "ae_encoder_loss": 0.5945927202701569, "actor_loss": 0.07697850146463939, "actor_target_entropy": -2.0, "actor_entropy": 0.43545724557978766, "alpha_loss": 0.003678619296156934, "alpha_value": 0.0026860887159155683, "duration": 14.818161487579346, "step": 55328}
{"episode_reward": -9.798941939716977, "episode": 1871.0, "batch_reward": -0.05881513406833013, "critic_loss": 0.5557272732257843, "ae_transition_loss": 1.3316417237122853, "ae_encoder_loss": 0.7387046217918396, "actor_loss": -0.003914737453063329, "actor_target_entropy": -2.0, "actor_entropy": 0.03391875078280767, "alpha_loss": 0.003161610608610014, "alpha_value": 0.0026747956227713243, "duration": 81.68492841720581, "step": 55388}
{"episode_reward": -0.3322850208661591, "episode": 1872.0, "batch_reward": -0.1128425473968188, "critic_loss": 0.7994217028220495, "ae_transition_loss": 1.693818708260854, "ae_encoder_loss": 1.2099254926045735, "actor_loss": 0.1576563355823358, "actor_target_entropy": -2.0, "actor_entropy": 0.5378673821687698, "alpha_loss": 0.0037301523067678013, "alpha_value": 0.00266469839697076, "duration": 11.49583888053894, "step": 55446}
{"episode_reward": -0.3749765474099171, "episode": 1873.0, "batch_reward": -0.09411827381700277, "critic_loss": 1.4127200096845627, "ae_transition_loss": 1.3196646869182587, "ae_encoder_loss": 0.4980202317237854, "actor_loss": 0.16016297787427902, "actor_target_entropy": -2.0, "actor_entropy": 0.700420930981636, "alpha_loss": 0.004194264591205865, "alpha_value": 0.0026557958831880443, "duration": 9.085145473480225, "step": 55490}
{"episode_reward": 0.5899110318688752, "episode": 1874.0, "batch_reward": -0.18034712970256805, "critic_loss": 1.5244203805923462, "ae_transition_loss": 1.2035719156265259, "ae_encoder_loss": 0.42301055788993835, "actor_loss": 0.3035080134868622, "actor_target_entropy": -2.0, "actor_entropy": 0.8784782886505127, "alpha_loss": 0.0044487519189715385, "alpha_value": 0.0026511122725313948, "duration": 0.6292140483856201, "step": 55491}
{"episode_reward": -0.6823973647018466, "episode": 1875.0, "batch_reward": -0.1306583769619465, "critic_loss": 1.1972988843917847, "ae_transition_loss": 1.1134329438209534, "ae_encoder_loss": 0.5533160120248795, "actor_loss": 0.38845154643058777, "actor_target_entropy": -2.0, "actor_entropy": 0.9278871715068817, "alpha_loss": 0.004445703700184822, "alpha_value": 0.0026482166412492465, "duration": 4.811841726303101, "step": 55516}
{"episode_reward": -1.009407617064379, "episode": 1876.0, "batch_reward": -0.09021403416991233, "critic_loss": 0.903765058517456, "ae_transition_loss": 0.7796490490436554, "ae_encoder_loss": 0.6038439989089965, "actor_loss": 0.3486019790172577, "actor_target_entropy": -2.0, "actor_entropy": 0.5638672530651092, "alpha_loss": 0.00360707207582891, "alpha_value": 0.0026413524303667254, "duration": 9.423571825027466, "step": 55561}
{"episode_reward": -0.7476921750865004, "episode": 1877.0, "batch_reward": -0.05185614340007305, "critic_loss": 0.7662852704524994, "ae_transition_loss": 0.7185786366462708, "ae_encoder_loss": 0.515888974070549, "actor_loss": 0.16305658966302872, "actor_target_entropy": -2.0, "actor_entropy": 0.12313948944211006, "alpha_loss": 0.0031226588180288672, "alpha_value": 0.0026346430602297837, "duration": 4.370922803878784, "step": 55582}
{"episode_reward": 0.11493950517528043, "episode": 1878.0, "batch_reward": -0.07413984866191943, "critic_loss": 0.9647395809491476, "ae_transition_loss": 1.504384974638621, "ae_encoder_loss": 0.8011021415392557, "actor_loss": 0.14967594544092813, "actor_target_entropy": -2.0, "actor_entropy": -0.015061636765797934, "alpha_loss": 0.0027322338428348303, "alpha_value": 0.002630102277148184, "duration": 7.2249181270599365, "step": 55619}
{"episode_reward": 0.3727982779669981, "episode": 1879.0, "batch_reward": -0.05987978435587138, "critic_loss": 0.6399803459644318, "ae_transition_loss": 1.123992308974266, "ae_encoder_loss": 0.9442788884043694, "actor_loss": 0.1413866952061653, "actor_target_entropy": -2.0, "actor_entropy": 0.09886739309877157, "alpha_loss": 0.0028146037948317826, "alpha_value": 0.0026208613682199297, "duration": 15.473530769348145, "step": 55693}
{"episode_reward": -6.416456488974568, "episode": 1880.0, "batch_reward": -0.0864149771630764, "critic_loss": 0.446955543756485, "ae_transition_loss": 1.2840766906738281, "ae_encoder_loss": 0.9638243794441224, "actor_loss": 0.1689312629401684, "actor_target_entropy": -2.0, "actor_entropy": 0.2136136770248413, "alpha_loss": 0.0027601524721831082, "alpha_value": 0.002610719021447797, "duration": 10.20207142829895, "step": 55742}
{"episode_reward": 4.7578532880961015, "episode": 1881.0, "batch_reward": -0.07109715122108658, "critic_loss": 0.5399013931552569, "ae_transition_loss": 1.3417785863081615, "ae_encoder_loss": 0.922474334637324, "actor_loss": 0.09604278672486544, "actor_target_entropy": -2.0, "actor_entropy": -0.0037992987781763077, "alpha_loss": 0.002797898603603244, "alpha_value": 0.0025984843201619368, "duration": 145.20456528663635, "step": 55866}
{"episode_reward": -2.655754859859286, "episode": 1882.0, "batch_reward": -0.10490583442151546, "critic_loss": 0.4720464736223221, "ae_transition_loss": 1.2734299182891846, "ae_encoder_loss": 0.9032389163970947, "actor_loss": 0.22186208553612233, "actor_target_entropy": -2.0, "actor_entropy": -0.19332271367311477, "alpha_loss": 0.001958075270522386, "alpha_value": 0.0025833946596626484, "duration": 20.673439979553223, "step": 55962}
{"episode_reward": -0.09911811148743621, "episode": 1883.0, "batch_reward": -0.10463393479585648, "critic_loss": 0.5218583941459656, "ae_transition_loss": 1.3667284846305847, "ae_encoder_loss": 0.7901769081751505, "actor_loss": 0.3132721781730652, "actor_target_entropy": -2.0, "actor_entropy": 0.24412895242373148, "alpha_loss": 0.0014624618149052064, "alpha_value": 0.002575726721203115, "duration": 7.7416722774505615, "step": 56000}
{"episode_reward": -1.1131554613511458, "episode": 1884.0, "batch_reward": -0.07989519741386175, "critic_loss": 0.7150895893573761, "ae_transition_loss": 1.4328437447547913, "ae_encoder_loss": 0.6549486219882965, "actor_loss": 0.08420340189089377, "actor_target_entropy": -2.0, "actor_entropy": 0.20873184377948442, "alpha_loss": 0.001297848706599325, "alpha_value": 0.002571348921407792, "duration": 11.827420473098755, "step": 56056}
{"episode_reward": 3.2238400976878863, "episode": 1885.0, "batch_reward": -0.0849130917340517, "critic_loss": 0.5991270393133163, "ae_transition_loss": 1.2212327420711517, "ae_encoder_loss": 0.6126252263784409, "actor_loss": -0.012848004698753357, "actor_target_entropy": -2.0, "actor_entropy": -0.37248722463846207, "alpha_loss": 0.0013330167275853455, "alpha_value": 0.002567069863388101, "duration": 8.208098411560059, "step": 56095}
{"episode_reward": 1.0705355591509316, "episode": 1886.0, "batch_reward": -0.09116884209215641, "critic_loss": 0.5616638392210007, "ae_transition_loss": 1.2969621539115905, "ae_encoder_loss": 0.6629326045513153, "actor_loss": 0.34132982809096574, "actor_target_entropy": -2.0, "actor_entropy": -0.7394005477428436, "alpha_loss": 0.0015304898377507925, "alpha_value": 0.002561703733197096, "duration": 19.974979639053345, "step": 56192}
{"episode_reward": -0.26994849751458366, "episode": 1887.0, "batch_reward": -0.079880241304636, "critic_loss": 0.5121083736419678, "ae_transition_loss": 1.4491830110549926, "ae_encoder_loss": 0.6661714434623718, "actor_loss": 0.10676877796649933, "actor_target_entropy": -2.0, "actor_entropy": -0.7378124237060547, "alpha_loss": 0.0013530514203011989, "alpha_value": 0.0025560331575003948, "duration": 11.064616203308105, "step": 56246}
{"episode_reward": 0.5707414973246697, "episode": 1888.0, "batch_reward": -0.029288334771990776, "critic_loss": 0.45167410373687744, "ae_transition_loss": 1.033756971359253, "ae_encoder_loss": 0.7343970537185669, "actor_loss": -0.02608056366443634, "actor_target_entropy": -2.0, "actor_entropy": -0.356235533952713, "alpha_loss": 0.0020481832907535136, "alpha_value": 0.002553470986815183, "duration": 5.027615308761597, "step": 56270}
{"episode_reward": -1.7606943127551475, "episode": 1889.0, "batch_reward": -0.09391660690307617, "critic_loss": 0.6290594100952148, "ae_transition_loss": 1.05088312625885, "ae_encoder_loss": 0.5746082186698913, "actor_loss": -0.016925081983208655, "actor_target_entropy": -2.0, "actor_entropy": -0.17942769974470138, "alpha_loss": 0.0027503326069563626, "alpha_value": 0.002550467531922939, "duration": 9.587703227996826, "step": 56317}
{"episode_reward": -1.0137822019301193, "episode": 1890.0, "batch_reward": -0.07586413982789963, "critic_loss": 0.5778807103633881, "ae_transition_loss": 0.6670846790075302, "ae_encoder_loss": 0.38606425002217293, "actor_loss": 0.24060546327382326, "actor_target_entropy": -2.0, "actor_entropy": -0.47336871922016144, "alpha_loss": 0.0010795074049383402, "alpha_value": 0.0025443034079843923, "duration": 16.7438907623291, "step": 56398}
{"episode_reward": 14.235783530477864, "episode": 1891.0, "batch_reward": -0.07806475437246263, "critic_loss": 0.58128222823143, "ae_transition_loss": 0.6942920200526714, "ae_encoder_loss": 0.48540525138378143, "actor_loss": 0.16381922736763954, "actor_target_entropy": -2.0, "actor_entropy": -0.48118438199162483, "alpha_loss": 0.0006045799073035596, "alpha_value": 0.0025384357703982646, "duration": 126.5877194404602, "step": 56480}
{"episode_reward": 32.58422957748311, "episode": 1892.0, "batch_reward": -0.11984462849795818, "critic_loss": 0.36534491181373596, "ae_transition_loss": 0.7236568629741669, "ae_encoder_loss": 0.7862999141216278, "actor_loss": 0.3277650997042656, "actor_target_entropy": -2.0, "actor_entropy": -0.45231565833091736, "alpha_loss": 0.00018038129928754643, "alpha_value": 0.002535786685289221, "duration": 4.116084098815918, "step": 56500}
{"episode_reward": 1.3341511981947998, "episode": 1893.0, "batch_reward": -0.054444678127765656, "critic_loss": 1.131385788321495, "ae_transition_loss": 0.77303746342659, "ae_encoder_loss": 0.7276515662670135, "actor_loss": 0.31518321111798286, "actor_target_entropy": -2.0, "actor_entropy": -0.612602025270462, "alpha_loss": 0.00034597617559484206, "alpha_value": 0.002534959590832416, "duration": 3.39963698387146, "step": 56516}
{"episode_reward": 0.8399777087889562, "episode": 1894.0, "batch_reward": -0.09593484923243523, "critic_loss": 0.5733156402905782, "ae_transition_loss": 1.1172552903493245, "ae_encoder_loss": 0.5894808669885, "actor_loss": 0.13635927935441336, "actor_target_entropy": -2.0, "actor_entropy": -0.69951464732488, "alpha_loss": 0.0009699990526617815, "alpha_value": 0.002534038665378201, "duration": 5.701656103134155, "step": 56544}
{"episode_reward": 2.109841570235887, "episode": 1895.0, "batch_reward": -0.04878545179963112, "critic_loss": 0.6121798455715179, "ae_transition_loss": 1.0193234235048294, "ae_encoder_loss": 0.794003039598465, "actor_loss": 0.0747170178219676, "actor_target_entropy": -2.0, "actor_entropy": -0.6191418617963791, "alpha_loss": 0.0010974857141263783, "alpha_value": 0.0025326475637772266, "duration": 7.94657564163208, "step": 56582}
{"episode_reward": 4.307656992688255, "episode": 1896.0, "batch_reward": -0.0621965155005455, "critic_loss": 0.5391702651977539, "ae_transition_loss": 1.152014970779419, "ae_encoder_loss": 0.7589867115020752, "actor_loss": 0.14210409671068192, "actor_target_entropy": -2.0, "actor_entropy": -0.3513570576906204, "alpha_loss": 0.0018849180196411908, "alpha_value": 0.0025313010081864425, "duration": 4.535170793533325, "step": 56605}
{"episode_reward": -1.5139265245598579, "episode": 1897.0, "duration": 0.22730612754821777, "step": 56606}
{"episode_reward": -0.19128385186195374, "episode": 1898.0, "batch_reward": -0.0018294486217200756, "critic_loss": 0.5132119655609131, "ae_transition_loss": 1.3620028495788574, "ae_encoder_loss": 0.7795245051383972, "actor_loss": 0.1439807452261448, "actor_target_entropy": -2.0, "actor_entropy": -0.1198444738984108, "alpha_loss": 0.0017754393047653139, "alpha_value": 0.002530214282752811, "duration": 4.756094217300415, "step": 56628}
{"episode_reward": -3.611520294843038, "episode": 1899.0, "batch_reward": -0.08111758654316266, "critic_loss": 0.42180919647216797, "ae_transition_loss": 1.2677717208862305, "ae_encoder_loss": 0.6159821351369222, "actor_loss": 0.22006738185882568, "actor_target_entropy": -2.0, "actor_entropy": 0.2861642042795817, "alpha_loss": 0.0019936630269512534, "alpha_value": 0.002528620506378214, "duration": 6.711966037750244, "step": 56660}
{"episode_reward": -0.3326199733731765, "episode": 1900.0, "batch_reward": -0.0647274062037468, "critic_loss": 0.7292334318161011, "ae_transition_loss": 1.2749387502670289, "ae_encoder_loss": 0.7419597506523132, "actor_loss": 0.09510201886296273, "actor_target_entropy": -2.0, "actor_entropy": 0.12182002514600754, "alpha_loss": 0.001637921086512506, "alpha_value": 0.002525639755054431, "duration": 10.032071828842163, "step": 56709}
{"episode_reward": 2.801605474827477, "episode": 1901.0, "batch_reward": -0.057351103673378624, "critic_loss": 0.6043396393458048, "ae_transition_loss": 1.1741582949956257, "ae_encoder_loss": 0.8224317828814188, "actor_loss": 0.1694713607430458, "actor_target_entropy": -2.0, "actor_entropy": -0.3453274667263031, "alpha_loss": 0.0006172453383139024, "alpha_value": 0.0025226051131232853, "duration": 80.71544742584229, "step": 56739}
{"episode_reward": 3.2358064499652235, "episode": 1902.0, "batch_reward": -0.012122106272727251, "critic_loss": 0.5699817389249802, "ae_transition_loss": 1.0903881192207336, "ae_encoder_loss": 0.7996114790439606, "actor_loss": 0.2356455847620964, "actor_target_entropy": -2.0, "actor_entropy": -0.3839704245328903, "alpha_loss": 0.0007535610056947917, "alpha_value": 0.0025209837344423187, "duration": 4.047813892364502, "step": 56758}
{"episode_reward": 0.49858165147763667, "episode": 1903.0, "batch_reward": -0.056379060726612806, "critic_loss": 0.677399180829525, "ae_transition_loss": 1.1191212683916092, "ae_encoder_loss": 0.47131016105413437, "actor_loss": 0.06465847790241241, "actor_target_entropy": -2.0, "actor_entropy": -0.22215619310736656, "alpha_loss": 0.0010191122419200838, "alpha_value": 0.0025192779792005543, "duration": 8.275965690612793, "step": 56798}
{"episode_reward": 7.732367611519652, "episode": 1904.0, "batch_reward": -0.03351134077335397, "critic_loss": 0.5161234686772028, "ae_transition_loss": 0.9223998884359995, "ae_encoder_loss": 0.3936151663462321, "actor_loss": 0.07875563949346542, "actor_target_entropy": -2.0, "actor_entropy": -0.13175771137078604, "alpha_loss": 0.0009060614199067155, "alpha_value": 0.0025165075018575302, "duration": 11.10370683670044, "step": 56853}
{"episode_reward": 13.093288962516148, "episode": 1905.0, "batch_reward": -0.07830474774042766, "critic_loss": 0.5693337718645731, "ae_transition_loss": 0.8534857034683228, "ae_encoder_loss": 0.4652153054873149, "actor_loss": 0.24610142409801483, "actor_target_entropy": -2.0, "actor_entropy": -0.20105834801991782, "alpha_loss": 0.000426710748191302, "alpha_value": 0.002514186573302824, "duration": 7.459977626800537, "step": 56890}
{"episode_reward": 5.400123498503776, "episode": 1906.0, "batch_reward": -0.06755630671977997, "critic_loss": 0.5355945378541946, "ae_transition_loss": 0.8865111470222473, "ae_encoder_loss": 0.44553565979003906, "actor_loss": 0.26266802102327347, "actor_target_entropy": -2.0, "actor_entropy": -0.5571767687797546, "alpha_loss": 0.00021557432046392933, "alpha_value": 0.0025131208084207607, "duration": 2.9701013565063477, "step": 56904}
{"episode_reward": -1.259166601225405, "episode": 1907.0, "batch_reward": -0.1286480501294136, "critic_loss": 0.5943763852119446, "ae_transition_loss": 1.361899197101593, "ae_encoder_loss": 0.5311885327100754, "actor_loss": 0.6276701837778091, "actor_target_entropy": -2.0, "actor_entropy": -0.6579712629318237, "alpha_loss": -0.00011866961722262204, "alpha_value": 0.0025123980096920474, "duration": 3.9818460941314697, "step": 56921}
{"episode_reward": -0.8424868642756246, "episode": 1908.0, "batch_reward": -0.09811114147305489, "critic_loss": 0.6066587150096894, "ae_transition_loss": 0.9785748302936554, "ae_encoder_loss": 0.49970732927322387, "actor_loss": 0.22781564369797708, "actor_target_entropy": -2.0, "actor_entropy": -0.8008755505084991, "alpha_loss": -2.4103486794047057e-06, "alpha_value": 0.0025110155790618455, "duration": 20.98532795906067, "step": 57026}
{"episode_reward": 31.234019506459294, "episode": 1909.0, "batch_reward": -0.09627568380286296, "critic_loss": 0.5986930429935455, "ae_transition_loss": 1.0447512368361156, "ae_encoder_loss": 0.46356886128584546, "actor_loss": 0.199711283047994, "actor_target_entropy": -2.0, "actor_entropy": -0.6785735289255778, "alpha_loss": -0.00018395750885247253, "alpha_value": 0.00251007368678432, "duration": 12.729611873626709, "step": 57090}
{"episode_reward": 17.30614060258277, "episode": 1910.0, "batch_reward": -0.062147291377186775, "critic_loss": 0.6323668956756592, "ae_transition_loss": 0.8779323399066925, "ae_encoder_loss": 0.5867189466953278, "actor_loss": 0.1619640477001667, "actor_target_entropy": -2.0, "actor_entropy": -0.548634946346283, "alpha_loss": 0.00012281885574338958, "alpha_value": 0.0025099467852396397, "duration": 3.927663803100586, "step": 57109}
{"episode_reward": -1.3966701707768547, "episode": 1911.0, "batch_reward": -0.09107641130685806, "critic_loss": 0.8363259434700012, "ae_transition_loss": 0.9436289966106415, "ae_encoder_loss": 0.43732932209968567, "actor_loss": 0.3834870010614395, "actor_target_entropy": -2.0, "actor_entropy": -0.47764816880226135, "alpha_loss": -0.00045720458729192615, "alpha_value": 0.0025099417814362216, "duration": 74.53591108322144, "step": 57128}
{"episode_reward": -0.35340756117898275, "episode": 1912.0, "batch_reward": -0.09628954343497753, "critic_loss": 0.7794671058654785, "ae_transition_loss": 0.7014335840940475, "ae_encoder_loss": 0.3938462436199188, "actor_loss": 0.13014960382133722, "actor_target_entropy": -2.0, "actor_entropy": -0.3863672465085983, "alpha_loss": 1.1649219231912866e-05, "alpha_value": 0.002510035330627121, "duration": 7.060121774673462, "step": 57164}
{"episode_reward": 6.446791641326567, "episode": 1913.0, "batch_reward": -0.09217485661307971, "critic_loss": 0.7859021623929342, "ae_transition_loss": 0.7510019143422445, "ae_encoder_loss": 0.361054668823878, "actor_loss": 0.623512883981069, "actor_target_entropy": -2.0, "actor_entropy": -0.3049114445845286, "alpha_loss": 8.070956876811881e-05, "alpha_value": 0.002510105358998352, "duration": 6.919743299484253, "step": 57198}
{"episode_reward": 3.1089196659125435, "episode": 1914.0, "batch_reward": -0.04288373018304507, "critic_loss": 0.4941454380750656, "ae_transition_loss": 0.837002823750178, "ae_encoder_loss": 0.37917547424634296, "actor_loss": 0.09797134002049764, "actor_target_entropy": -2.0, "actor_entropy": -0.278833935658137, "alpha_loss": 0.0002501554299669806, "alpha_value": 0.0025100449662571168, "duration": 12.159437656402588, "step": 57256}
{"episode_reward": 12.012602961547826, "episode": 1915.0, "batch_reward": -0.06463842342297237, "critic_loss": 0.5336131850878397, "ae_transition_loss": 0.7318851153055826, "ae_encoder_loss": 0.38993756969769794, "actor_loss": 0.115082452694575, "actor_target_entropy": -2.0, "actor_entropy": -0.26708365480105084, "alpha_loss": 0.00029963152095054585, "alpha_value": 0.0025097993096634135, "duration": 6.171966552734375, "step": 57285}
{"episode_reward": -2.096891263566616, "episode": 1916.0, "batch_reward": -0.10508786638577779, "critic_loss": 0.6925080815951029, "ae_transition_loss": 0.8456366260846456, "ae_encoder_loss": 0.4032102127869924, "actor_loss": 0.16420589635769525, "actor_target_entropy": -2.0, "actor_entropy": -0.3149070342381795, "alpha_loss": 0.00031912415094363195, "alpha_value": 0.0025095129764371392, "duration": 5.67338490486145, "step": 57311}
{"episode_reward": 4.787705232005754, "episode": 1917.0, "batch_reward": -0.08763532284647227, "critic_loss": 0.5808279752731323, "ae_transition_loss": 0.9224560678005218, "ae_encoder_loss": 0.34567852318286896, "actor_loss": 0.2427121490240097, "actor_target_entropy": -2.0, "actor_entropy": -0.25136304646730423, "alpha_loss": 7.00465781847015e-05, "alpha_value": 0.002508976356947008, "duration": 20.217183351516724, "step": 57412}
{"episode_reward": 53.51187442499885, "episode": 1918.0, "batch_reward": -0.06307129375636578, "critic_loss": 0.3192237466573715, "ae_transition_loss": 0.7012754678726196, "ae_encoder_loss": 0.29177887737751007, "actor_loss": 0.0458686500787735, "actor_target_entropy": -2.0, "actor_entropy": -0.1640683114528656, "alpha_loss": -7.927228580228984e-05, "alpha_value": 0.002508620508152537, "duration": 4.410661220550537, "step": 57432}
{"episode_reward": 0.7994088508308181, "episode": 1919.0, "batch_reward": -0.04570231058945259, "critic_loss": 0.5194609264532725, "ae_transition_loss": 0.8849555253982544, "ae_encoder_loss": 0.30830516417821247, "actor_loss": 0.0011994751791159313, "actor_target_entropy": -2.0, "actor_entropy": -0.15817500154177347, "alpha_loss": 0.00046247315428142127, "alpha_value": 0.0025084581203836417, "duration": 6.777859210968018, "step": 57465}
{"episode_reward": 6.016147338544644, "episode": 1920.0, "batch_reward": -0.029413544572889805, "critic_loss": 0.9590540528297424, "ae_transition_loss": 0.8058928847312927, "ae_encoder_loss": 0.35876038670539856, "actor_loss": 0.06391342356801033, "actor_target_entropy": -2.0, "actor_entropy": -0.15156684070825577, "alpha_loss": 0.0003332976302772295, "alpha_value": 0.0025082055829117496, "duration": 4.479776859283447, "step": 57486}
{"episode_reward": -0.47622517894277216, "episode": 1921.0, "batch_reward": -0.07119066640734673, "critic_loss": 0.5302138030529022, "ae_transition_loss": 0.8398530185222626, "ae_encoder_loss": 0.3932107388973236, "actor_loss": 0.20473963022232056, "actor_target_entropy": -2.0, "actor_entropy": -0.20761527866125107, "alpha_loss": 0.00022958722547627985, "alpha_value": 0.002507988859222365, "duration": 87.94783854484558, "step": 57501}
{"episode_reward": -0.48113089361850125, "episode": 1922.0, "duration": 0.23391366004943848, "step": 57502}
{"episode_reward": -0.7853048237741469, "episode": 1923.0, "batch_reward": -0.08199701268625047, "critic_loss": 0.5472833237477711, "ae_transition_loss": 1.0465423933097295, "ae_encoder_loss": 0.3477310155119215, "actor_loss": 0.14713686864290917, "actor_target_entropy": -2.0, "actor_entropy": -0.5882303885051182, "alpha_loss": 1.7607281604016733e-05, "alpha_value": 0.0025071613704342826, "duration": 30.321619987487793, "step": 57650}
{"episode_reward": 44.53018687533884, "episode": 1924.0, "batch_reward": -0.09824189047018687, "critic_loss": 0.591783795091841, "ae_transition_loss": 1.0074458983209398, "ae_encoder_loss": 0.3462378912501865, "actor_loss": 0.17710048705339432, "actor_target_entropy": -2.0, "actor_entropy": -0.8510894245571561, "alpha_loss": -0.00019434279561715407, "alpha_value": 0.002506798221435035, "duration": 18.659752130508423, "step": 57740}
{"episode_reward": 35.77582868168329, "episode": 1925.0, "batch_reward": -0.07722407393157482, "critic_loss": 0.3481216073036194, "ae_transition_loss": 1.0099742889404297, "ae_encoder_loss": 0.4731321752071381, "actor_loss": 0.258948826789856, "actor_target_entropy": -2.0, "actor_entropy": -0.8720193862915039, "alpha_loss": -0.00022299697011476382, "alpha_value": 0.0025071860747081344, "duration": 8.83958649635315, "step": 57781}
{"episode_reward": 3.3075441517565762, "episode": 1926.0, "batch_reward": -0.06808397825807333, "critic_loss": 0.3593797907233238, "ae_transition_loss": 0.9989257156848907, "ae_encoder_loss": 0.4061797186732292, "actor_loss": 0.2468521324917674, "actor_target_entropy": -2.0, "actor_entropy": -0.8468130528926849, "alpha_loss": -0.00016569271974731237, "alpha_value": 0.0025075994649334053, "duration": 9.080575466156006, "step": 57825}
{"episode_reward": 8.864529243005832, "episode": 1927.0, "batch_reward": -0.08329320357491572, "critic_loss": 0.5707097500562668, "ae_transition_loss": 1.1407931943734486, "ae_encoder_loss": 0.3363334387540817, "actor_loss": 0.10016140341758728, "actor_target_entropy": -2.0, "actor_entropy": -0.7230662306149801, "alpha_loss": -9.330798638984561e-05, "alpha_value": 0.002508050861322182, "duration": 13.17730712890625, "step": 57887}
{"episode_reward": 4.87143148034521, "episode": 1928.0, "batch_reward": -0.15040792524814606, "critic_loss": 0.6102774143218994, "ae_transition_loss": 1.392462134361267, "ae_encoder_loss": 0.40098151564598083, "actor_loss": 0.028949648141860962, "actor_target_entropy": -2.0, "actor_entropy": -0.6870129108428955, "alpha_loss": 0.0002191164530813694, "alpha_value": 0.002508311514068807, "duration": 1.9138727188110352, "step": 57896}
{"episode_reward": -1.1651403088406322, "episode": 1929.0, "batch_reward": -0.09628316760063171, "critic_loss": 0.7986528873443604, "ae_transition_loss": 1.7664669752120972, "ae_encoder_loss": 0.3966873586177826, "actor_loss": 0.027324959635734558, "actor_target_entropy": -2.0, "actor_entropy": -0.5991549491882324, "alpha_loss": -0.0008086641901172698, "alpha_value": 0.002508353169055593, "duration": 1.8997220993041992, "step": 57905}
{"episode_reward": -1.2027810408160295, "episode": 1930.0, "batch_reward": -0.0715051641066869, "critic_loss": 0.39790087938308716, "ae_transition_loss": 1.1773628393809001, "ae_encoder_loss": 0.3922949731349945, "actor_loss": 0.12363540629545848, "actor_target_entropy": -2.0, "actor_entropy": -0.42603544394175213, "alpha_loss": -0.0007347859791480005, "alpha_value": 0.00250856413080236, "duration": 6.807638883590698, "step": 57938}
{"episode_reward": 4.211455791857927, "episode": 1931.0, "batch_reward": -0.019846751044193905, "critic_loss": 0.7228989700476328, "ae_transition_loss": 1.167555570602417, "ae_encoder_loss": 0.36413328846295673, "actor_loss": -0.013304543991883596, "actor_target_entropy": -2.0, "actor_entropy": -0.31203792492548627, "alpha_loss": 0.0003872691498448451, "alpha_value": 0.002509015570789117, "duration": 48.778111934661865, "step": 57963}
{"episode_reward": 0.4823734775252356, "episode": 1932.0, "duration": 0.18958353996276855, "step": 57964}
{"episode_reward": -0.4375079274177551, "episode": 1933.0, "batch_reward": -0.09544968232512474, "critic_loss": 0.7334672709306082, "ae_transition_loss": 1.1729042132695515, "ae_encoder_loss": 0.41410302619139355, "actor_loss": 0.20883588741223016, "actor_target_entropy": -2.0, "actor_entropy": -0.3626931260029475, "alpha_loss": 0.0004715388373976263, "alpha_value": 0.002509187138866777, "duration": 12.891929864883423, "step": 58027}
{"episode_reward": 10.450699761659216, "episode": 1934.0, "batch_reward": -0.093774590951701, "critic_loss": 0.5051827430725098, "ae_transition_loss": 1.1528885861237843, "ae_encoder_loss": 0.43849989771842957, "actor_loss": 0.2713852847615878, "actor_target_entropy": -2.0, "actor_entropy": -0.6278608441352844, "alpha_loss": 0.0006151351941904674, "alpha_value": 0.002508623953002943, "duration": 12.051526308059692, "step": 58087}
{"episode_reward": 9.319379298703954, "episode": 1935.0, "batch_reward": -0.07414839193224906, "critic_loss": 0.41690443754196166, "ae_transition_loss": 1.2736531972885132, "ae_encoder_loss": 0.39991862177848814, "actor_loss": 0.07700305469334126, "actor_target_entropy": -2.0, "actor_entropy": -0.8367255210876465, "alpha_loss": 0.0004107526125153527, "alpha_value": 0.0025075904623143444, "duration": 10.007992506027222, "step": 58136}
{"episode_reward": 5.401387480289344, "episode": 1936.0, "batch_reward": -0.061418160982429984, "critic_loss": 0.463888880610466, "ae_transition_loss": 1.188959503173828, "ae_encoder_loss": 0.41159502863883973, "actor_loss": 0.0570853017270565, "actor_target_entropy": -2.0, "actor_entropy": -0.7847802996635437, "alpha_loss": 0.00030711296130903065, "alpha_value": 0.0025065770006270365, "duration": 9.671748161315918, "step": 58184}
{"episode_reward": 7.494043088935453, "episode": 1937.0, "batch_reward": -0.08056649664307342, "critic_loss": 0.6614421062609729, "ae_transition_loss": 1.2368807091432459, "ae_encoder_loss": 0.4216143383699305, "actor_loss": 0.22526227989617517, "actor_target_entropy": -2.0, "actor_entropy": -0.662627893335679, "alpha_loss": 0.00019873971841126846, "alpha_value": 0.0025049279735782225, "duration": 34.264002084732056, "step": 58355}
{"episode_reward": 11.571893049472289, "episode": 1938.0, "batch_reward": -0.08352419865938525, "critic_loss": 0.5501346066594124, "ae_transition_loss": 1.3234209020932515, "ae_encoder_loss": 0.4018961265683174, "actor_loss": 0.17046196603526673, "actor_target_entropy": -2.0, "actor_entropy": -0.4620249383151531, "alpha_loss": 0.000521748952451162, "alpha_value": 0.002503054326161139, "duration": 24.81220841407776, "step": 58480}
{"episode_reward": 18.71821482002608, "episode": 1939.0, "batch_reward": -0.05210403104623159, "critic_loss": 0.57341068983078, "ae_transition_loss": 1.086371660232544, "ae_encoder_loss": 0.4222179154555003, "actor_loss": 0.03069072961807251, "actor_target_entropy": -2.0, "actor_entropy": -0.5053708354632059, "alpha_loss": 0.0014760201253617804, "alpha_value": 0.002501413110599463, "duration": 5.87526535987854, "step": 58509}
{"episode_reward": 0.44094056180835445, "episode": 1940.0, "batch_reward": -0.06204046122729778, "critic_loss": 0.36544571816921234, "ae_transition_loss": 1.2216923236846924, "ae_encoder_loss": 0.46151117980480194, "actor_loss": -0.01640530303120613, "actor_target_entropy": -2.0, "actor_entropy": -0.48901036381721497, "alpha_loss": 0.0011211317032575607, "alpha_value": 0.002500371113626392, "duration": 2.9835808277130127, "step": 58522}
{"episode_reward": -1.1628605537662193, "episode": 1941.0, "batch_reward": -0.07010198757052422, "critic_loss": 0.5084048509597778, "ae_transition_loss": 1.1493670344352722, "ae_encoder_loss": 0.5066055059432983, "actor_loss": 0.027834929525852203, "actor_target_entropy": -2.0, "actor_entropy": -0.5591266751289368, "alpha_loss": 0.0010850709513761103, "alpha_value": 0.00249943628920785, "duration": 101.45641827583313, "step": 58542}
{"episode_reward": -1.596012932162899, "episode": 1942.0, "batch_reward": -0.06285096285864711, "critic_loss": 0.26177140325307846, "ae_transition_loss": 0.9701858162879944, "ae_encoder_loss": 0.47192928194999695, "actor_loss": 0.22924258559942245, "actor_target_entropy": -2.0, "actor_entropy": -0.9047761410474777, "alpha_loss": -2.721543569350615e-05, "alpha_value": 0.0024980390953753275, "duration": 9.239216804504395, "step": 58588}
{"episode_reward": 2.124019426492368, "episode": 1943.0, "duration": 0.23978590965270996, "step": 58589}
{"episode_reward": -0.17153076061744946, "episode": 1944.0, "batch_reward": -0.08857609704136848, "critic_loss": 0.3468177169561386, "ae_transition_loss": 1.1107106059789658, "ae_encoder_loss": 0.4602893218398094, "actor_loss": 0.11843664571642876, "actor_target_entropy": -2.0, "actor_entropy": -0.7402694672346115, "alpha_loss": -0.0003090586542384699, "alpha_value": 0.002496779770176114, "duration": 6.951465368270874, "step": 58621}
{"episode_reward": 1.7791568174186418, "episode": 1945.0, "duration": 0.2435300350189209, "step": 58622}
{"episode_reward": 0.05028016702256033, "episode": 1946.0, "batch_reward": -0.0698151933029294, "critic_loss": 0.42893999069929123, "ae_transition_loss": 1.0945825278759003, "ae_encoder_loss": 0.5348121002316475, "actor_loss": 0.15574045851826668, "actor_target_entropy": -2.0, "actor_entropy": -0.6840135455131531, "alpha_loss": 5.840568337589502e-05, "alpha_value": 0.002496102540080249, "duration": 9.72044849395752, "step": 58669}
{"episode_reward": 7.565814101411159, "episode": 1947.0, "batch_reward": -0.09592512995004654, "critic_loss": 0.9127406676610311, "ae_transition_loss": 1.1752142906188965, "ae_encoder_loss": 0.5463066299756368, "actor_loss": 0.29681869596242905, "actor_target_entropy": -2.0, "actor_entropy": -0.7240545550982157, "alpha_loss": -0.0005136042988548676, "alpha_value": 0.0024957136521510134, "duration": 6.475919008255005, "step": 58700}
{"episode_reward": 1.7367095103153338, "episode": 1948.0, "batch_reward": -0.0681988799571991, "critic_loss": 0.7323833787441254, "ae_transition_loss": 1.2990376782417297, "ae_encoder_loss": 0.48443808674812316, "actor_loss": 0.10781275361776352, "actor_target_entropy": -2.0, "actor_entropy": -0.6869606423377991, "alpha_loss": -0.00020175771845970303, "alpha_value": 0.002496963308235047, "duration": 52.61579394340515, "step": 58949}
{"episode_reward": -11.38072931141701, "episode": 1949.0, "batch_reward": -0.08496179827488959, "critic_loss": 1.0170671790838242, "ae_transition_loss": 1.2396255731582642, "ae_encoder_loss": 0.5640824139118195, "actor_loss": 0.05709621775895357, "actor_target_entropy": -2.0, "actor_entropy": -0.4773354306817055, "alpha_loss": 0.0005272065463941544, "alpha_value": 0.002498158628996306, "duration": 8.463833808898926, "step": 58988}
{"episode_reward": 4.970188992204841, "episode": 1950.0, "batch_reward": -0.09251736700534821, "critic_loss": 0.9133705496788025, "ae_transition_loss": 1.327134907245636, "ae_encoder_loss": 0.6673652172088623, "actor_loss": 0.29763817191123965, "actor_target_entropy": -2.0, "actor_entropy": -0.6407235145568848, "alpha_loss": 4.5606319326907395e-05, "alpha_value": 0.002497854919420204, "duration": 10.719573736190796, "step": 59040}
{"episode_reward": 14.16459010551642, "episode": 1951.0, "batch_reward": -0.05184138419904879, "critic_loss": 0.7148455423968179, "ae_transition_loss": 1.489210741860526, "ae_encoder_loss": 0.5824166791779655, "actor_loss": -0.03742324986628124, "actor_target_entropy": -2.0, "actor_entropy": -0.8950267519269671, "alpha_loss": 2.198005053547344e-05, "alpha_value": 0.002497487595484166, "duration": 77.07171106338501, "step": 59107}
{"episode_reward": 19.45522390577961, "episode": 1952.0, "batch_reward": -0.07371203601360321, "critic_loss": 0.5173863843083382, "ae_transition_loss": 1.374019593000412, "ae_encoder_loss": 0.5057632178068161, "actor_loss": 0.145151455886662, "actor_target_entropy": -2.0, "actor_entropy": -0.9148597121238708, "alpha_loss": 7.290454595931806e-05, "alpha_value": 0.002497322174965024, "duration": 8.111841678619385, "step": 59147}
{"episode_reward": 7.426121332777243, "episode": 1953.0, "batch_reward": -0.09895732626318932, "critic_loss": 0.4958992749452591, "ae_transition_loss": 1.3326934576034546, "ae_encoder_loss": 0.44883275032043457, "actor_loss": 0.44585050642490387, "actor_target_entropy": -2.0, "actor_entropy": -0.8649681806564331, "alpha_loss": 5.322587821865454e-05, "alpha_value": 0.0024972531774341646, "duration": 3.8500266075134277, "step": 59165}
{"episode_reward": -0.44001928515149336, "episode": 1954.0, "batch_reward": -0.050488533452153206, "critic_loss": 0.40986962616443634, "ae_transition_loss": 1.373995582262675, "ae_encoder_loss": 0.496947040160497, "actor_loss": 0.1096013467758894, "actor_target_entropy": -2.0, "actor_entropy": -0.6920575002829233, "alpha_loss": 0.00013886297771629566, "alpha_value": 0.002497133392148918, "duration": 11.730531215667725, "step": 59223}
{"episode_reward": 28.618274806848852, "episode": 1955.0, "batch_reward": -0.05581417183081309, "critic_loss": 0.36317602793375653, "ae_transition_loss": 1.1903123060862224, "ae_encoder_loss": 0.4694892068703969, "actor_loss": 0.203510249654452, "actor_target_entropy": -2.0, "actor_entropy": -0.4820236365000407, "alpha_loss": 0.000562570011728288, "alpha_value": 0.0024969096834216212, "duration": 6.173613786697388, "step": 59251}
{"episode_reward": 0.46121525278333986, "episode": 1956.0, "duration": 0.18748831748962402, "step": 59252}
{"episode_reward": 0.538888162281314, "episode": 1957.0, "batch_reward": -0.05249319256593784, "critic_loss": 0.5186069971985288, "ae_transition_loss": 1.500993741883172, "ae_encoder_loss": 0.4838023881117503, "actor_loss": 0.1075673976706134, "actor_target_entropy": -2.0, "actor_entropy": -0.47511715359157985, "alpha_loss": 0.0007310577554259604, "alpha_value": 0.002495600673786486, "duration": 19.169348001480103, "step": 59346}
{"episode_reward": 32.69372953936393, "episode": 1958.0, "batch_reward": -0.09503205865621567, "critic_loss": 0.6902714967727661, "ae_transition_loss": 1.3746167023976643, "ae_encoder_loss": 0.5136474370956421, "actor_loss": 0.3726537028948466, "actor_target_entropy": -2.0, "actor_entropy": -0.7019866307576498, "alpha_loss": 0.00028729521242591244, "alpha_value": 0.00249387804720314, "duration": 6.819753646850586, "step": 59380}
{"episode_reward": 6.622194463881911, "episode": 1959.0, "batch_reward": -0.02038949417571227, "critic_loss": 0.7449679672718048, "ae_transition_loss": 1.3804430564244587, "ae_encoder_loss": 0.5710494617621104, "actor_loss": 0.01569065699974696, "actor_target_entropy": -2.0, "actor_entropy": -0.7267032066980997, "alpha_loss": 3.821680002147332e-05, "alpha_value": 0.0024931497823519433, "duration": 5.803821802139282, "step": 59408}
{"episode_reward": 1.8380382928874466, "episode": 1960.0, "duration": 0.2356421947479248, "step": 59409}
{"episode_reward": -0.16352793001526011, "episode": 1961.0, "batch_reward": -0.022142411209642887, "critic_loss": 0.5015020370483398, "ae_transition_loss": 1.4122272431850433, "ae_encoder_loss": 1.3739393651485443, "actor_loss": 0.2694988362491131, "actor_target_entropy": -2.0, "actor_entropy": -0.7255418300628662, "alpha_loss": 0.00021573329286184162, "alpha_value": 0.0024925285355627187, "duration": 58.00253343582153, "step": 59443}
{"episode_reward": 8.146317157589136, "episode": 1962.0, "batch_reward": -0.03752129524946213, "critic_loss": 0.6751481294631958, "ae_transition_loss": 1.8345767259597778, "ae_encoder_loss": 1.5332895070314407, "actor_loss": 0.10922243818640709, "actor_target_entropy": -2.0, "actor_entropy": -0.7525872737169266, "alpha_loss": -7.064589590299875e-05, "alpha_value": 0.0024919496168399036, "duration": 8.286614179611206, "step": 59481}
{"episode_reward": 9.481913264520404, "episode": 1963.0, "batch_reward": -0.08652072176337242, "critic_loss": 0.9631777167320251, "ae_transition_loss": 1.6464489936828612, "ae_encoder_loss": 1.4669508695602418, "actor_loss": 0.2252091199159622, "actor_target_entropy": -2.0, "actor_entropy": -0.7090202331542969, "alpha_loss": -0.0001863366283942014, "alpha_value": 0.0024915377319563534, "duration": 10.448964834213257, "step": 59532}
{"episode_reward": 12.464124743393006, "episode": 1964.0, "batch_reward": -0.11253380961716175, "critic_loss": 0.6671639233827591, "ae_transition_loss": 1.5016865134239197, "ae_encoder_loss": 0.9939001053571701, "actor_loss": 0.3811361938714981, "actor_target_entropy": -2.0, "actor_entropy": -0.6248384863138199, "alpha_loss": -0.0003966273143305443, "alpha_value": 0.0024914498623229303, "duration": 8.42224907875061, "step": 59573}
{"episode_reward": 13.347815794109, "episode": 1965.0, "duration": 0.18825912475585938, "step": 59574}
{"episode_reward": 0.5252192276093627, "episode": 1966.0, "batch_reward": -0.04446014203131199, "critic_loss": 0.6192882444177356, "ae_transition_loss": 1.5978027752467565, "ae_encoder_loss": 1.1792715276990617, "actor_loss": 0.2691534794867039, "actor_target_entropy": -2.0, "actor_entropy": -0.6144403730119977, "alpha_loss": -0.0008759747392364911, "alpha_value": 0.0024920273821600696, "duration": 14.994517803192139, "step": 59646}
{"episode_reward": 36.603948344660616, "episode": 1967.0, "batch_reward": -0.049175651371479036, "critic_loss": 0.7228546619415284, "ae_transition_loss": 1.6487457752227783, "ae_encoder_loss": 1.3812233448028564, "actor_loss": 0.28809812664985657, "actor_target_entropy": -2.0, "actor_entropy": -0.6002416729927063, "alpha_loss": -0.0007838011370040476, "alpha_value": 0.002493682953326675, "duration": 10.87551498413086, "step": 59698}
{"episode_reward": 19.780417422644565, "episode": 1968.0, "batch_reward": -0.053885325168569885, "critic_loss": 0.7810758054256439, "ae_transition_loss": 1.5421513716379802, "ae_encoder_loss": 0.7687689065933228, "actor_loss": 0.17348755399386087, "actor_target_entropy": -2.0, "actor_entropy": -0.621557354927063, "alpha_loss": -0.0006827217293903232, "alpha_value": 0.002495128362168244, "duration": 5.9038779735565186, "step": 59726}
{"episode_reward": 2.3592887375051586, "episode": 1969.0, "batch_reward": -0.022657615691423418, "critic_loss": 0.5818107962608338, "ae_transition_loss": 1.368679165840149, "ae_encoder_loss": 0.545994758605957, "actor_loss": -0.04211187139153481, "actor_target_entropy": -2.0, "actor_entropy": -0.6529932141304016, "alpha_loss": -0.0007536702876677736, "alpha_value": 0.0024966280423655424, "duration": 10.84543752670288, "step": 59777}
{"episode_reward": 0.5083625027898367, "episode": 1970.0, "batch_reward": -0.10459198895841837, "critic_loss": 0.5532301440834999, "ae_transition_loss": 1.226454645395279, "ae_encoder_loss": 0.5536758080124855, "actor_loss": 0.31469258666038513, "actor_target_entropy": -2.0, "actor_entropy": -0.7057462483644485, "alpha_loss": -0.0006170166998344939, "alpha_value": 0.0024983693587982423, "duration": 7.473897218704224, "step": 59813}
{"episode_reward": 6.232565489176859, "episode": 1971.0, "duration": 71.31242656707764, "step": 59814}
{"episode_reward": -0.11719778550302784, "episode": 1972.0, "batch_reward": -0.08606172539293766, "critic_loss": 0.4047189176082611, "ae_transition_loss": 1.0871402144432067, "ae_encoder_loss": 0.7230799317359924, "actor_loss": 0.3115634933114052, "actor_target_entropy": -2.0, "actor_entropy": -0.746690821647644, "alpha_loss": -0.0005352719803340733, "alpha_value": 0.0025000616756136263, "duration": 10.99558687210083, "step": 59867}
{"episode_reward": 21.908118080357337, "episode": 1973.0, "batch_reward": -0.07165529648773372, "critic_loss": 0.7550049126148224, "ae_transition_loss": 1.567715436220169, "ae_encoder_loss": 0.4483611434698105, "actor_loss": 0.09915755316615105, "actor_target_entropy": -2.0, "actor_entropy": -0.6483374685049057, "alpha_loss": -0.0007241924649861176, "alpha_value": 0.002501713185467146, "duration": 9.20799207687378, "step": 59910}
{"episode_reward": 12.55964816881748, "episode": 1974.0, "batch_reward": -0.0664761879791816, "critic_loss": 0.4294324070215225, "ae_transition_loss": 1.2561603784561157, "ae_encoder_loss": 0.5742368151744207, "actor_loss": 0.06342968220512073, "actor_target_entropy": -2.0, "actor_entropy": -0.8743436137835184, "alpha_loss": -0.0007322917226701975, "alpha_value": 0.0025036252647353285, "duration": 12.064839601516724, "step": 59969}
{"episode_reward": 9.672244408483008, "episode": 1975.0, "batch_reward": -0.04306725660959879, "critic_loss": 0.5317176034053167, "ae_transition_loss": 1.2250604232152302, "ae_encoder_loss": 0.5261226693789164, "actor_loss": 0.03179009320835272, "actor_target_entropy": -2.0, "actor_entropy": -1.133899172147115, "alpha_loss": -0.0008540190635054993, "alpha_value": 0.0025059657158333633, "duration": 14.618682384490967, "step": 60021}
{"episode_reward": 15.715707990206749, "episode": 1976.0, "batch_reward": -0.04849930811259481, "critic_loss": 0.6700729578733444, "ae_transition_loss": 1.0974449051751032, "ae_encoder_loss": 0.32953827414247727, "actor_loss": 0.10582592421107823, "actor_target_entropy": -2.0, "actor_entropy": -1.1511494716008503, "alpha_loss": -0.0008512367559079495, "alpha_value": 0.0025094070448063496, "duration": 18.21582531929016, "step": 60111}
{"episode_reward": 37.09810819963367, "episode": 1977.0, "batch_reward": -0.05867348850837776, "critic_loss": 0.4358104467391968, "ae_transition_loss": 0.7406384732042041, "ae_encoder_loss": 0.237345067518098, "actor_loss": 0.17933408543467522, "actor_target_entropy": -2.0, "actor_entropy": -1.0067002943583898, "alpha_loss": -0.0011031966340462013, "alpha_value": 0.002513449670569582, "duration": 14.975504398345947, "step": 60185}
{"episode_reward": 19.53427495775966, "episode": 1978.0, "batch_reward": -0.05851052328944206, "critic_loss": 0.5979090829690298, "ae_transition_loss": 0.7402537763118744, "ae_encoder_loss": 0.32145220537980396, "actor_loss": 0.1015503058830897, "actor_target_entropy": -2.0, "actor_entropy": -0.9696326851844788, "alpha_loss": -0.0009859579149633646, "alpha_value": 0.0025163232399030336, "duration": 6.555689811706543, "step": 60217}
{"episode_reward": 7.104168340203282, "episode": 1979.0, "batch_reward": -0.09968014558156331, "critic_loss": 0.7194061179955801, "ae_transition_loss": 0.9768945773442587, "ae_encoder_loss": 0.46738765637079877, "actor_loss": 0.2314333419005076, "actor_target_entropy": -2.0, "actor_entropy": -0.9926697810490926, "alpha_loss": -0.0012427671269203226, "alpha_value": 0.002518105817566426, "duration": 6.085110187530518, "step": 60246}
{"episode_reward": 0.2338597909558953, "episode": 1980.0, "batch_reward": -0.07959508057683706, "critic_loss": 0.6650824993848801, "ae_transition_loss": 0.8035869747400284, "ae_encoder_loss": 0.49611353874206543, "actor_loss": 0.30954261496663094, "actor_target_entropy": -2.0, "actor_entropy": -1.0708305537700653, "alpha_loss": -0.0013859990212949924, "alpha_value": 0.0025202349844727196, "duration": 7.5579142570495605, "step": 60281}
{"episode_reward": 8.212830659377213, "episode": 1981.0, "batch_reward": -0.08645579272082873, "critic_loss": 0.43976321816444397, "ae_transition_loss": 0.985202431678772, "ae_encoder_loss": 0.5967788738863808, "actor_loss": 0.1635791308113507, "actor_target_entropy": -2.0, "actor_entropy": -1.0442856550216675, "alpha_loss": -0.0015986125384058272, "alpha_value": 0.002524214984690246, "duration": 90.24535489082336, "step": 60353}
{"episode_reward": 16.569351601162282, "episode": 1982.0, "batch_reward": -0.08527933973819017, "critic_loss": 0.5134136080741882, "ae_transition_loss": 1.3548233032226562, "ae_encoder_loss": 0.6412305951118469, "actor_loss": 0.20366007164120675, "actor_target_entropy": -2.0, "actor_entropy": -0.8649410367012024, "alpha_loss": -0.0010550982929999008, "alpha_value": 0.002531121380749607, "duration": 20.601532220840454, "step": 60453}
{"episode_reward": 69.8835663721141, "episode": 1983.0, "batch_reward": -0.025524379685521126, "critic_loss": 0.461778424680233, "ae_transition_loss": 1.3266062140464783, "ae_encoder_loss": 0.5713958963751793, "actor_loss": -0.07427723053842783, "actor_target_entropy": -2.0, "actor_entropy": -0.6194785311818123, "alpha_loss": -0.00037466328649315983, "alpha_value": 0.002536219170381441, "duration": 9.529226064682007, "step": 60499}
{"episode_reward": 4.303288845836669, "episode": 1984.0, "batch_reward": -0.05947490781545639, "critic_loss": 0.5157695412635803, "ae_transition_loss": 1.5086394548416138, "ae_encoder_loss": 0.5675581097602844, "actor_loss": -0.15084339678287506, "actor_target_entropy": -2.0, "actor_entropy": -0.6679007411003113, "alpha_loss": 8.449141751043499e-05, "alpha_value": 0.0025378759287898777, "duration": 3.383683681488037, "step": 60515}
{"episode_reward": 0.21067827692980584, "episode": 1985.0, "batch_reward": -0.05990166822448373, "critic_loss": 0.5303064584732056, "ae_transition_loss": 1.2964423894882202, "ae_encoder_loss": 0.495106041431427, "actor_loss": 0.08125144429504871, "actor_target_entropy": -2.0, "actor_entropy": -0.8969139009714127, "alpha_loss": -0.0010770495136966929, "alpha_value": 0.002539107880263002, "duration": 8.60386872291565, "step": 60557}
{"episode_reward": 9.879134017896742, "episode": 1986.0, "batch_reward": -0.08282889372536115, "critic_loss": 0.6104978237833295, "ae_transition_loss": 1.3486237525939941, "ae_encoder_loss": 0.43668897237096516, "actor_loss": 0.2932860404253006, "actor_target_entropy": -2.0, "actor_entropy": -1.0368278452328272, "alpha_loss": -0.001235201015203659, "alpha_value": 0.00254192563570065, "duration": 14.311883926391602, "step": 60629}
{"episode_reward": 27.489040411302582, "episode": 1987.0, "batch_reward": -0.023152034729719162, "critic_loss": 0.5793597251176834, "ae_transition_loss": 1.4720532298088074, "ae_encoder_loss": 0.47002269327640533, "actor_loss": -0.04735236614942551, "actor_target_entropy": -2.0, "actor_entropy": -1.2299426198005676, "alpha_loss": -0.0003953856212319806, "alpha_value": 0.0025446300126732465, "duration": 3.9996774196624756, "step": 60649}
{"episode_reward": -0.14889708964492737, "episode": 1988.0, "batch_reward": -0.05792253417894244, "critic_loss": 0.3779551461338997, "ae_transition_loss": 1.4726738333702087, "ae_encoder_loss": 0.4415721595287323, "actor_loss": 0.28869365341961384, "actor_target_entropy": -2.0, "actor_entropy": -1.1611374616622925, "alpha_loss": -0.001045494936988689, "alpha_value": 0.0025463969816889227, "duration": 7.599928617477417, "step": 60686}
{"episode_reward": 10.515104600854961, "episode": 1989.0, "batch_reward": -0.0648774717003107, "critic_loss": 0.7791318774223328, "ae_transition_loss": 1.377735185623169, "ae_encoder_loss": 0.46041676998138426, "actor_loss": 0.10439294129610062, "actor_target_entropy": -2.0, "actor_entropy": -1.0331167936325074, "alpha_loss": -0.0012796702678315342, "alpha_value": 0.002549139365155638, "duration": 9.424414157867432, "step": 60733}
{"episode_reward": 13.848727807440717, "episode": 1990.0, "batch_reward": -0.08529683388769627, "critic_loss": 0.5723696053028107, "ae_transition_loss": 1.3270609378814697, "ae_encoder_loss": 0.4834181070327759, "actor_loss": 0.09795334190130234, "actor_target_entropy": -2.0, "actor_entropy": -0.8803712129592896, "alpha_loss": -0.0008323833462782204, "alpha_value": 0.0025514030085473077, "duration": 5.395135879516602, "step": 60760}
{"episode_reward": 1.0371618989776292, "episode": 1991.0, "batch_reward": -0.0744260773062706, "critic_loss": 0.4856606900691986, "ae_transition_loss": 1.4369877576828003, "ae_encoder_loss": 0.5605225563049316, "actor_loss": 0.2569727972149849, "actor_target_entropy": -2.0, "actor_entropy": -0.7582624077796936, "alpha_loss": -0.0009093983797356486, "alpha_value": 0.002553649992716141, "duration": 78.48950219154358, "step": 60801}
{"episode_reward": 8.425543724110593, "episode": 1992.0, "batch_reward": -0.02785841701552272, "critic_loss": 0.624275840818882, "ae_transition_loss": 1.3314371407032013, "ae_encoder_loss": 0.6130444556474686, "actor_loss": -0.10753321461379528, "actor_target_entropy": -2.0, "actor_entropy": -0.7792979329824448, "alpha_loss": -0.0008068290335359052, "alpha_value": 0.002556445945863069, "duration": 9.325988531112671, "step": 60848}
{"episode_reward": 10.438557842685551, "episode": 1993.0, "batch_reward": -0.07259583845734596, "critic_loss": 0.47950613498687744, "ae_transition_loss": 1.3408838510513306, "ae_encoder_loss": 0.5832974016666412, "actor_loss": 0.19091052561998367, "actor_target_entropy": -2.0, "actor_entropy": -0.7836336493492126, "alpha_loss": -0.0009250924631487578, "alpha_value": 0.0025581906352894392, "duration": 4.447881698608398, "step": 60869}
{"episode_reward": -1.6175554351891748, "episode": 1994.0, "batch_reward": -0.06704506301321089, "critic_loss": 0.540528766810894, "ae_transition_loss": 1.4195636361837387, "ae_encoder_loss": 0.5678561329841614, "actor_loss": 0.10030126757919788, "actor_target_entropy": -2.0, "actor_entropy": -0.6368930526077747, "alpha_loss": -4.374229592940537e-05, "alpha_value": 0.002560656249260485, "duration": 16.740063190460205, "step": 60949}
{"episode_reward": 23.02888306471631, "episode": 1995.0, "batch_reward": -0.02514227417608102, "critic_loss": 0.5003572404384613, "ae_transition_loss": 1.8005334933598836, "ae_encoder_loss": 0.5957054694493612, "actor_loss": 0.03633310024936994, "actor_target_entropy": -2.0, "actor_entropy": -0.7902279694875082, "alpha_loss": -0.00036252484035988647, "alpha_value": 0.0025624183729871784, "duration": 5.449373722076416, "step": 60973}
{"episode_reward": -2.1063867900942137, "episode": 1996.0, "batch_reward": -0.019817772631843884, "critic_loss": 0.5461387038230896, "ae_transition_loss": 1.5277991096178691, "ae_encoder_loss": 0.7005293269952139, "actor_loss": 0.04783758024374644, "actor_target_entropy": -2.0, "actor_entropy": -0.8676211337248484, "alpha_loss": -0.00044444207499812666, "alpha_value": 0.002563492939048623, "duration": 13.817874193191528, "step": 61040}
{"episode_reward": 5.64486597920026, "episode": 1997.0, "batch_reward": -0.07313523031771182, "critic_loss": 0.33681501150131227, "ae_transition_loss": 1.5730409145355224, "ae_encoder_loss": 0.7769845962524414, "actor_loss": 0.06540429480373859, "actor_target_entropy": -2.0, "actor_entropy": -0.8747296094894409, "alpha_loss": -0.000610338436672464, "alpha_value": 0.0025648784146269483, "duration": 10.411880731582642, "step": 61090}
{"episode_reward": 12.749890440782016, "episode": 1998.0, "batch_reward": -0.045616026036441326, "critic_loss": 0.5589548051357269, "ae_transition_loss": 1.5229249000549316, "ae_encoder_loss": 0.5495380461215973, "actor_loss": -0.14234299212694168, "actor_target_entropy": -2.0, "actor_entropy": -0.8459655046463013, "alpha_loss": -0.0003553898277459666, "alpha_value": 0.002565922562769305, "duration": 4.239802360534668, "step": 61110}
{"episode_reward": 0.6715236208392883, "episode": 1999.0, "batch_reward": -0.05173087430497011, "critic_loss": 0.30902449289957684, "ae_transition_loss": 1.4455078442891438, "ae_encoder_loss": 0.4845696985721588, "actor_loss": -0.03903957083821297, "actor_target_entropy": -2.0, "actor_entropy": -0.791784922281901, "alpha_loss": -0.000670073456907024, "alpha_value": 0.0025667349174975907, "duration": 5.819710731506348, "step": 61138}
{"episode_reward": 5.548394748476916, "episode": 2000.0, "batch_reward": -0.05717016446093718, "critic_loss": 0.6535565257072449, "ae_transition_loss": 1.5011579990386963, "ae_encoder_loss": 0.5486735502878824, "actor_loss": 0.026263621946175892, "actor_target_entropy": -2.0, "actor_entropy": -0.7460461656252543, "alpha_loss": 4.087861452717334e-05, "alpha_value": 0.002567708316275019, "duration": 5.2668139934539795, "step": 61162}
{"episode_reward": 0.35811867601244457, "episode": 2001.0, "batch_reward": -0.005818156525492668, "critic_loss": 0.8091397285461426, "ae_transition_loss": 1.5191667079925537, "ae_encoder_loss": 0.7414892911911011, "actor_loss": -0.04980447143316269, "actor_target_entropy": -2.0, "actor_entropy": -0.7363849878311157, "alpha_loss": -0.001085911993868649, "alpha_value": 0.002568370061860676, "duration": 37.84885263442993, "step": 61188}
{"episode_reward": 2.168333258041714, "episode": 2002.0, "batch_reward": -0.08600011374801397, "critic_loss": 0.28006210923194885, "ae_transition_loss": 1.3577581942081451, "ae_encoder_loss": 0.6935473382472992, "actor_loss": 0.13813674449920654, "actor_target_entropy": -2.0, "actor_entropy": -0.7039363384246826, "alpha_loss": -0.0009978908201446757, "alpha_value": 0.002569456171225667, "duration": 8.120655536651611, "step": 61227}
{"episode_reward": 4.327781394169615, "episode": 2003.0, "batch_reward": -0.050955455750226974, "critic_loss": 0.38382811347643536, "ae_transition_loss": 1.2648623784383137, "ae_encoder_loss": 0.49228206276893616, "actor_loss": 0.211575115720431, "actor_target_entropy": -2.0, "actor_entropy": -0.6712870200475057, "alpha_loss": -0.0004999181449723741, "alpha_value": 0.0025709479258083853, "duration": 5.239201068878174, "step": 61252}
{"episode_reward": 2.0989316896136163, "episode": 2004.0, "batch_reward": -0.0804917138069868, "critic_loss": 0.5245266199111939, "ae_transition_loss": 1.869767427444458, "ae_encoder_loss": 0.6814267635345459, "actor_loss": 0.14871324896812438, "actor_target_entropy": -2.0, "actor_entropy": -0.7575840473175048, "alpha_loss": -0.0006590022589080035, "alpha_value": 0.002572579469575118, "duration": 11.411423683166504, "step": 61309}
{"episode_reward": 30.263294235314053, "episode": 2005.0, "batch_reward": -0.03368608959551368, "critic_loss": 0.7271998694964817, "ae_transition_loss": 1.8379142114094325, "ae_encoder_loss": 0.9048441478184291, "actor_loss": 0.14879761529820307, "actor_target_entropy": -2.0, "actor_entropy": -0.9641337990760803, "alpha_loss": -0.000772186617333708, "alpha_value": 0.002575149595645997, "duration": 14.167789220809937, "step": 61379}
{"episode_reward": 12.752540703551988, "episode": 2006.0, "batch_reward": -0.08134112347449575, "critic_loss": 0.536645552941731, "ae_transition_loss": 1.6607353687286377, "ae_encoder_loss": 1.1670160719326563, "actor_loss": 0.015248843069587435, "actor_target_entropy": -2.0, "actor_entropy": -0.9461155363491603, "alpha_loss": -0.0003807744693144092, "alpha_value": 0.0025781757954242016, "duration": 14.22775936126709, "step": 61449}
{"episode_reward": 19.08923987207823, "episode": 2007.0, "batch_reward": -0.001466359943151474, "critic_loss": 0.5941194494565328, "ae_transition_loss": 1.7295690377553303, "ae_encoder_loss": 1.194262186686198, "actor_loss": -0.3105618357658386, "actor_target_entropy": -2.0, "actor_entropy": -0.9507890542348226, "alpha_loss": -0.0008764029868567983, "alpha_value": 0.0025800578406512654, "duration": 4.7548887729644775, "step": 61471}
{"episode_reward": -0.3039748426403194, "episode": 2008.0, "batch_reward": -0.045570451145370804, "critic_loss": 1.2422916094462078, "ae_transition_loss": 1.751853346824646, "ae_encoder_loss": 0.7636158466339111, "actor_loss": -0.002615754803021749, "actor_target_entropy": -2.0, "actor_entropy": -0.9192796349525452, "alpha_loss": -0.000657165321172215, "alpha_value": 0.00258119302066526, "duration": 6.407140493392944, "step": 61502}
{"episode_reward": 7.268414712859364, "episode": 2009.0, "batch_reward": -0.047811989672482014, "critic_loss": 0.8013280431429545, "ae_transition_loss": 1.6654231746991475, "ae_encoder_loss": 0.7034703443447748, "actor_loss": -0.05330576002597809, "actor_target_entropy": -2.0, "actor_entropy": -0.8351939221223196, "alpha_loss": -0.0006885197071824223, "alpha_value": 0.0025830188552673715, "duration": 13.181389331817627, "step": 61569}
{"episode_reward": 23.435204497903822, "episode": 2010.0, "batch_reward": -0.026855156756937504, "critic_loss": 0.5197436362504959, "ae_transition_loss": 1.4413826763629913, "ae_encoder_loss": 0.6985627710819244, "actor_loss": -0.09664987958967686, "actor_target_entropy": -2.0, "actor_entropy": -0.7041007578372955, "alpha_loss": -0.0015455120301339775, "alpha_value": 0.002585402052057207, "duration": 7.235917806625366, "step": 61604}
{"episode_reward": 8.305553979668359, "episode": 2011.0, "batch_reward": -0.05698418105021119, "critic_loss": 0.45605238030354184, "ae_transition_loss": 1.4590573112169902, "ae_encoder_loss": 0.6298136164744695, "actor_loss": 0.04562210167447726, "actor_target_entropy": -2.0, "actor_entropy": -1.0249459048112233, "alpha_loss": -0.0008818254063953646, "alpha_value": 0.002588436778132296, "duration": 126.10790038108826, "step": 61665}
{"episode_reward": 20.96888276091929, "episode": 2012.0, "batch_reward": -0.14252294600009918, "critic_loss": 0.8421170711517334, "ae_transition_loss": 1.4143264293670654, "ae_encoder_loss": 0.7031667232513428, "actor_loss": 0.05653495341539383, "actor_target_entropy": -2.0, "actor_entropy": -1.427497386932373, "alpha_loss": -0.00046457783901132643, "alpha_value": 0.0025905882403804642, "duration": 2.379699230194092, "step": 61676}
{"episode_reward": -0.40114576362207877, "episode": 2013.0, "batch_reward": -0.10624712457259496, "critic_loss": 0.5076597432295481, "ae_transition_loss": 1.2425564924875896, "ae_encoder_loss": 0.6144668261210123, "actor_loss": 0.18652507166067758, "actor_target_entropy": -2.0, "actor_entropy": -1.419000228246053, "alpha_loss": -0.0013410297882122297, "alpha_value": 0.002591753482671965, "duration": 5.7657246589660645, "step": 61703}
{"episode_reward": 2.163077431398274, "episode": 2014.0, "batch_reward": -0.03209315799176693, "critic_loss": 0.5429516732692719, "ae_transition_loss": 1.1509140133857727, "ae_encoder_loss": 0.539783850312233, "actor_loss": 0.0527755506336689, "actor_target_entropy": -2.0, "actor_entropy": -0.9944486021995544, "alpha_loss": -0.0016364473558496684, "alpha_value": 0.002593324603780974, "duration": 5.334028720855713, "step": 61727}
{"episode_reward": -3.9103210790741993, "episode": 2015.0, "batch_reward": -0.06627830862998962, "critic_loss": 0.4612358585000038, "ae_transition_loss": 1.3649421632289886, "ae_encoder_loss": 0.5746811106801033, "actor_loss": 0.14881241600960493, "actor_target_entropy": -2.0, "actor_entropy": -1.248219609260559, "alpha_loss": -0.0034556937171146274, "alpha_value": 0.0025957112129892674, "duration": 8.859594345092773, "step": 61770}
{"episode_reward": 7.735744410313981, "episode": 2016.0, "batch_reward": -0.08963250741362572, "critic_loss": 0.3712059333920479, "ae_transition_loss": 1.1968799829483032, "ae_encoder_loss": 0.5575399696826935, "actor_loss": 0.33167409896850586, "actor_target_entropy": -2.0, "actor_entropy": -2.004882574081421, "alpha_loss": -0.006599791347980499, "alpha_value": 0.002599264749365905, "duration": 4.271768093109131, "step": 61790}
{"episode_reward": -0.04455873360765217, "episode": 2017.0, "batch_reward": -0.09134561941027641, "critic_loss": 1.20643749833107, "ae_transition_loss": 1.4086961150169373, "ae_encoder_loss": 0.5433820486068726, "actor_loss": -0.05364493280649185, "actor_target_entropy": -2.0, "actor_entropy": -1.9906251430511475, "alpha_loss": -0.0046303533017635345, "alpha_value": 0.0026029511110238425, "duration": 3.920086145401001, "step": 61809}
{"episode_reward": 0.871230208238408, "episode": 2018.0, "batch_reward": -0.07405595108866692, "critic_loss": 0.3685432970523834, "ae_transition_loss": 1.4211992919445038, "ae_encoder_loss": 0.5814158096909523, "actor_loss": -0.08682411815971136, "actor_target_entropy": -2.0, "actor_entropy": -1.5082920491695404, "alpha_loss": -0.0034471259568817914, "alpha_value": 0.0026091828943736544, "duration": 7.330698728561401, "step": 61842}
{"episode_reward": 5.209146221443258, "episode": 2019.0, "duration": 1.100569248199463, "step": 61847}
{"episode_reward": -1.5277383280768477, "episode": 2020.0, "batch_reward": -0.07738386653363705, "critic_loss": 0.558394081890583, "ae_transition_loss": 1.6624785959720612, "ae_encoder_loss": 0.6183372586965561, "actor_loss": 0.109628323931247, "actor_target_entropy": -2.0, "actor_entropy": -1.3150201439857483, "alpha_loss": -0.0025001774774864316, "alpha_value": 0.00261773557256807, "duration": 8.351911067962646, "step": 61887}
{"episode_reward": 0.7038415874180702, "episode": 2021.0, "duration": 74.49973177909851, "step": 61888}
{"episode_reward": -0.6457556713614545, "episode": 2022.0, "batch_reward": 0.011646687053143978, "critic_loss": 0.23439335823059082, "ae_transition_loss": 1.1549142599105835, "ae_encoder_loss": 0.3963623046875, "actor_loss": -0.16103991866111755, "actor_target_entropy": -2.0, "actor_entropy": -1.0801693201065063, "alpha_loss": -0.0015121552860364318, "alpha_value": 0.0026228292696696283, "duration": 2.399869441986084, "step": 61900}
{"episode_reward": -2.015467438958085, "episode": 2023.0, "batch_reward": -0.07909846678376198, "critic_loss": 0.33212292194366455, "ae_transition_loss": 1.355989694595337, "ae_encoder_loss": 0.5046635568141937, "actor_loss": 0.009027652442455292, "actor_target_entropy": -2.0, "actor_entropy": -1.2021681070327759, "alpha_loss": -0.0014498303062282503, "alpha_value": 0.002625643317979031, "duration": 2.7241570949554443, "step": 61911}
{"episode_reward": -2.2194770981768954, "episode": 2024.0, "duration": 0.18279123306274414, "step": 61912}
{"episode_reward": -0.24652472138404846, "episode": 2025.0, "batch_reward": -0.060414190590381625, "critic_loss": 0.4976566582918167, "ae_transition_loss": 1.3845638632774353, "ae_encoder_loss": 0.8232104182243347, "actor_loss": 0.02164482995867729, "actor_target_entropy": -2.0, "actor_entropy": -1.4920768737792969, "alpha_loss": -0.0027347018010914327, "alpha_value": 0.0026361809771984534, "duration": 21.68878746032715, "step": 62019}
{"episode_reward": -1.305314958112468, "episode": 2026.0, "batch_reward": -0.07430187488595645, "critic_loss": 0.5656305352846781, "ae_transition_loss": 1.4148438771565754, "ae_encoder_loss": 0.9756085475285848, "actor_loss": 0.22799346844355264, "actor_target_entropy": -2.0, "actor_entropy": -1.6215944687525432, "alpha_loss": -0.003447021668155988, "alpha_value": 0.0026476989682985203, "duration": 5.311419486999512, "step": 62045}
{"episode_reward": 3.365527081712232, "episode": 2027.0, "batch_reward": -0.04331300035119057, "critic_loss": 0.4789109230041504, "ae_transition_loss": 1.5234610239664714, "ae_encoder_loss": 0.7364358107248942, "actor_loss": 0.022981842358907063, "actor_target_entropy": -2.0, "actor_entropy": -1.1760941743850708, "alpha_loss": -0.0015438737464137375, "alpha_value": 0.002653414703053584, "duration": 6.0575947761535645, "step": 62075}
{"episode_reward": 4.885240357817847, "episode": 2028.0, "batch_reward": -0.06160254621257385, "critic_loss": 0.5614625513553619, "ae_transition_loss": 1.6940733989079793, "ae_encoder_loss": 0.7749408086140951, "actor_loss": -0.005930017679929733, "actor_target_entropy": -2.0, "actor_entropy": -0.8986466825008392, "alpha_loss": -0.001403079484589398, "alpha_value": 0.0026609080535736243, "duration": 11.93799901008606, "step": 62136}
{"episode_reward": 14.49378720205238, "episode": 2029.0, "batch_reward": 0.0010602481197565794, "critic_loss": 0.4075286388397217, "ae_transition_loss": 1.4535718262195587, "ae_encoder_loss": 0.7555563449859619, "actor_loss": -0.18363701179623604, "actor_target_entropy": -2.0, "actor_entropy": -0.7902868092060089, "alpha_loss": -0.000949604480410926, "alpha_value": 0.002667900164413044, "duration": 7.984878301620483, "step": 62174}
{"episode_reward": 1.9036161128581124, "episode": 2030.0, "batch_reward": -0.07868528366088867, "critic_loss": 0.9031167725721995, "ae_transition_loss": 1.4320519367853801, "ae_encoder_loss": 0.784162183602651, "actor_loss": -0.023770198225975037, "actor_target_entropy": -2.0, "actor_entropy": -0.7441765268643697, "alpha_loss": -0.0005363402597140521, "alpha_value": 0.0026718338153214976, "duration": 6.386868953704834, "step": 62205}
{"episode_reward": 3.4925154122210493, "episode": 2031.0, "batch_reward": -0.06426429003477097, "critic_loss": 0.6381120185057322, "ae_transition_loss": 1.4121369520823162, "ae_encoder_loss": 0.7487331430117289, "actor_loss": -0.05505834023157755, "actor_target_entropy": -2.0, "actor_entropy": -0.8838951190312704, "alpha_loss": -0.0006161433993838727, "alpha_value": 0.002674600767561739, "duration": 58.2469961643219, "step": 62232}
{"episode_reward": 1.7546512696468008, "episode": 2032.0, "batch_reward": -0.08953797817230225, "critic_loss": 0.6610677242279053, "ae_transition_loss": 1.5269602537155151, "ae_encoder_loss": 0.7863084077835083, "actor_loss": 0.08659584447741508, "actor_target_entropy": -2.0, "actor_entropy": -0.9429225921630859, "alpha_loss": -0.001890882442239672, "alpha_value": 0.0026766567953139227, "duration": 5.592386245727539, "step": 62258}
{"episode_reward": 4.661152077259189, "episode": 2033.0, "batch_reward": -0.05932726773122946, "critic_loss": 0.42363837361335754, "ae_transition_loss": 1.5934355854988098, "ae_encoder_loss": 0.7232833107312521, "actor_loss": -0.19379485895236334, "actor_target_entropy": -2.0, "actor_entropy": -0.8311359882354736, "alpha_loss": -0.0012590416008606553, "alpha_value": 0.0026803159547133704, "duration": 11.25038194656372, "step": 62311}
{"episode_reward": 32.15407513670164, "episode": 2034.0, "batch_reward": -0.02348034270107746, "critic_loss": 0.47332385182380676, "ae_transition_loss": 1.4817344546318054, "ae_encoder_loss": 0.6464384198188782, "actor_loss": -0.042061030864715576, "actor_target_entropy": -2.0, "actor_entropy": -0.7813252806663513, "alpha_loss": -0.0012054390972480178, "alpha_value": 0.002683937428154237, "duration": 5.850062847137451, "step": 62340}
{"episode_reward": 7.57493001150114, "episode": 2035.0, "batch_reward": -0.049959526707728706, "critic_loss": 0.6178302814563116, "ae_transition_loss": 1.3541557987531025, "ae_encoder_loss": 0.4418039470911026, "actor_loss": -0.04618843179196119, "actor_target_entropy": -2.0, "actor_entropy": -0.8603717982769012, "alpha_loss": -0.0013923663063906133, "alpha_value": 0.0026874207511664873, "duration": 11.339210271835327, "step": 62395}
{"episode_reward": 18.021928522761563, "episode": 2036.0, "batch_reward": -0.1437029093503952, "critic_loss": 0.468705952167511, "ae_transition_loss": 1.5377990007400513, "ae_encoder_loss": 0.387960284948349, "actor_loss": 0.049921803176403046, "actor_target_entropy": -2.0, "actor_entropy": -0.9331843852996826, "alpha_loss": -0.0007613982306793332, "alpha_value": 0.002690580804577792, "duration": 2.5036144256591797, "step": 62406}
{"episode_reward": -1.4348042387219164, "episode": 2037.0, "duration": 0.22376251220703125, "step": 62407}
{"episode_reward": -0.7879755683747565, "episode": 2038.0, "batch_reward": -0.03537867031991482, "critic_loss": 0.4374220371246338, "ae_transition_loss": 1.3687564373016357, "ae_encoder_loss": 0.4347492218017578, "actor_loss": -0.2957050919532776, "actor_target_entropy": -2.0, "actor_entropy": -1.000795829296112, "alpha_loss": -0.0010779378819279373, "alpha_value": 0.0026931646050648112, "duration": 10.45982575416565, "step": 62459}
{"episode_reward": 13.361597538996254, "episode": 2039.0, "batch_reward": -0.08532219628492992, "critic_loss": 0.4688240687052409, "ae_transition_loss": 1.2922289371490479, "ae_encoder_loss": 0.4438619017601013, "actor_loss": -0.08312827348709106, "actor_target_entropy": -2.0, "actor_entropy": -0.9093568722407023, "alpha_loss": -0.0013040583580732346, "alpha_value": 0.0026965001188031363, "duration": 5.759828329086304, "step": 62487}
{"episode_reward": 2.7313652017295285, "episode": 2040.0, "batch_reward": -0.055557031836360696, "critic_loss": 0.4982652612030506, "ae_transition_loss": 1.4944993197917937, "ae_encoder_loss": 0.513120673596859, "actor_loss": -0.10406719837337733, "actor_target_entropy": -2.0, "actor_entropy": -1.4806931018829346, "alpha_loss": -0.002838133933255449, "alpha_value": 0.002710591716204991, "duration": 39.10370206832886, "step": 62684}
{"episode_reward": 46.01439709832601, "episode": 2041.0, "batch_reward": -0.062055555482705436, "critic_loss": 0.39996107419331867, "ae_transition_loss": 1.5290275812149048, "ae_encoder_loss": 0.6117763519287109, "actor_loss": -0.16771587481101355, "actor_target_entropy": -2.0, "actor_entropy": -1.5764158169428508, "alpha_loss": -0.0024527897282193103, "alpha_value": 0.0027308201764302954, "duration": 69.92781209945679, "step": 62717}
{"episode_reward": 6.3460914783652385, "episode": 2042.0, "batch_reward": -0.062432385981082916, "critic_loss": 0.3480452299118042, "ae_transition_loss": 1.4758673310279846, "ae_encoder_loss": 0.6533800959587097, "actor_loss": 0.005048587918281555, "actor_target_entropy": -2.0, "actor_entropy": -1.488584816455841, "alpha_loss": -0.0020016487687826157, "alpha_value": 0.002735526809917445, "duration": 4.607734680175781, "step": 62739}
{"episode_reward": 1.775712840018107, "episode": 2043.0, "batch_reward": -0.0876275284215808, "critic_loss": 0.2924355924129486, "ae_transition_loss": 1.4692311048507691, "ae_encoder_loss": 0.5587888598442078, "actor_loss": -0.09466706514358521, "actor_target_entropy": -2.0, "actor_entropy": -1.494049310684204, "alpha_loss": -0.0029001195449382066, "alpha_value": 0.0027419451157199718, "duration": 9.463571071624756, "step": 62784}
{"episode_reward": 10.230026410152183, "episode": 2044.0, "batch_reward": -0.030388502404093742, "critic_loss": 1.069050908088684, "ae_transition_loss": 1.354034423828125, "ae_encoder_loss": 0.5715637803077698, "actor_loss": -0.22481805086135864, "actor_target_entropy": -2.0, "actor_entropy": -1.5169870853424072, "alpha_loss": -0.0030562872998416424, "alpha_value": 0.002747587636425534, "duration": 3.252007246017456, "step": 62799}
{"episode_reward": -0.2827769324022551, "episode": 2045.0, "batch_reward": -0.06047677745421728, "critic_loss": 0.531168262163798, "ae_transition_loss": 1.6527402599652607, "ae_encoder_loss": 0.6381917099157969, "actor_loss": -0.1864416922132174, "actor_target_entropy": -2.0, "actor_entropy": -1.468118151028951, "alpha_loss": -0.0029142454344158373, "alpha_value": 0.0027545053378990308, "duration": 11.627914905548096, "step": 62857}
{"episode_reward": 17.366046069557193, "episode": 2046.0, "batch_reward": -0.08041475464900334, "critic_loss": 0.25222847362359363, "ae_transition_loss": 1.7956307729085286, "ae_encoder_loss": 0.8477339347203573, "actor_loss": -0.22539810836315155, "actor_target_entropy": -2.0, "actor_entropy": -1.4857139190038045, "alpha_loss": -0.003192175024499496, "alpha_value": 0.002763633388460591, "duration": 5.341827154159546, "step": 62882}
{"episode_reward": 2.8790413757583098, "episode": 2047.0, "batch_reward": -0.06629187520593405, "critic_loss": 0.9533072263002396, "ae_transition_loss": 1.6060738861560822, "ae_encoder_loss": 0.8069088757038116, "actor_loss": 0.027156081050634384, "actor_target_entropy": -2.0, "actor_entropy": -1.4701944291591644, "alpha_loss": -0.003780662838835269, "alpha_value": 0.002771226573629357, "duration": 8.289175271987915, "step": 62923}
{"episode_reward": 9.435259154272607, "episode": 2048.0, "batch_reward": -0.047175055369734764, "critic_loss": 0.4302266538143158, "ae_transition_loss": 1.598983108997345, "ae_encoder_loss": 0.5034198388457298, "actor_loss": -0.26753616984933615, "actor_target_entropy": -2.0, "actor_entropy": -1.3753515779972076, "alpha_loss": -0.0025637217913754284, "alpha_value": 0.00278037000569838, "duration": 8.788248538970947, "step": 62966}
{"episode_reward": 10.113344416929882, "episode": 2049.0, "batch_reward": -0.05426626140251756, "critic_loss": 0.6123353280127048, "ae_transition_loss": 1.4646058827638626, "ae_encoder_loss": 0.4950147047638893, "actor_loss": -0.15918579883873463, "actor_target_entropy": -2.0, "actor_entropy": -1.374909147620201, "alpha_loss": -0.002169717277865857, "alpha_value": 0.0027929102353430406, "duration": 17.803876399993896, "step": 63050}
{"episode_reward": 5.769027317478958, "episode": 2050.0, "batch_reward": -0.06669963151216507, "critic_loss": 0.3907474676767985, "ae_transition_loss": 1.269177516301473, "ae_encoder_loss": 0.5613611340522766, "actor_loss": -0.018485768387715023, "actor_target_entropy": -2.0, "actor_entropy": -1.43750794728597, "alpha_loss": -0.0025792778081571064, "alpha_value": 0.0028033112814869754, "duration": 4.972864389419556, "step": 63071}
{"episode_reward": 1.9755063038592335, "episode": 2051.0, "duration": 62.81831383705139, "step": 63076}
{"episode_reward": -0.914984237101119, "episode": 2052.0, "batch_reward": -0.01960396282374859, "critic_loss": 0.47250014543533325, "ae_transition_loss": 1.4009711265563964, "ae_encoder_loss": 0.6178170442581177, "actor_loss": -0.18421488553285598, "actor_target_entropy": -2.0, "actor_entropy": -1.4474743366241456, "alpha_loss": -0.0022691147634759544, "alpha_value": 0.0028107420936016965, "duration": 9.768775701522827, "step": 63124}
{"episode_reward": 11.81883498731698, "episode": 2053.0, "batch_reward": 0.000808641624947389, "critic_loss": 0.546414519349734, "ae_transition_loss": 1.2605498631795247, "ae_encoder_loss": 0.5612991650899252, "actor_loss": -0.3510577082633972, "actor_target_entropy": -2.0, "actor_entropy": -1.4479695161183674, "alpha_loss": -0.0027289167822649083, "alpha_value": 0.0028207720350180844, "duration": 12.152795553207397, "step": 63181}
{"episode_reward": 7.209289885622492, "episode": 2054.0, "duration": 1.6262145042419434, "step": 63190}
{"episode_reward": -1.795811046082377, "episode": 2055.0, "batch_reward": -0.022819495449463528, "critic_loss": 0.7043054103851318, "ae_transition_loss": 1.395228664080302, "ae_encoder_loss": 0.5878853599230448, "actor_loss": -0.22580275932947794, "actor_target_entropy": -2.0, "actor_entropy": -1.3846052885055542, "alpha_loss": -0.0027245362289249897, "alpha_value": 0.0028292919542066744, "duration": 4.699810028076172, "step": 63212}
{"episode_reward": -0.05578025181969212, "episode": 2056.0, "batch_reward": -0.060126220186551414, "critic_loss": 0.6902977625528971, "ae_transition_loss": 1.5907444953918457, "ae_encoder_loss": 0.5690745015939077, "actor_loss": -0.18846997618675232, "actor_target_entropy": -2.0, "actor_entropy": -1.3497086763381958, "alpha_loss": -0.002954965534930428, "alpha_value": 0.002835231015290426, "duration": 7.823960065841675, "step": 63250}
{"episode_reward": 12.824388758388883, "episode": 2057.0, "batch_reward": -0.05595197668299079, "critic_loss": 0.6348424926400185, "ae_transition_loss": 1.3800885677337646, "ae_encoder_loss": 0.7020861953496933, "actor_loss": -0.29156656935811043, "actor_target_entropy": -2.0, "actor_entropy": -1.361226111650467, "alpha_loss": -0.002640618069563061, "alpha_value": 0.0028422858704308146, "duration": 7.9398193359375, "step": 63289}
{"episode_reward": 11.195762804739445, "episode": 2058.0, "duration": 0.22358083724975586, "step": 63290}
{"episode_reward": -0.2141937319442883, "episode": 2059.0, "batch_reward": -0.03521871007978916, "critic_loss": 0.5623695403337479, "ae_transition_loss": 1.4972932934761047, "ae_encoder_loss": 0.8816212937235832, "actor_loss": -0.07784515619277954, "actor_target_entropy": -2.0, "actor_entropy": -1.287354215979576, "alpha_loss": -0.0023185688332887366, "alpha_value": 0.00285426731449131, "duration": 15.219846248626709, "step": 63365}
{"episode_reward": 27.498271067427762, "episode": 2060.0, "batch_reward": -0.06111983768641949, "critic_loss": 0.6171428710222244, "ae_transition_loss": 1.4600148598353069, "ae_encoder_loss": 0.7736057837804159, "actor_loss": -0.22881469130516052, "actor_target_entropy": -2.0, "actor_entropy": -1.2384424606959026, "alpha_loss": -0.0021718323696404696, "alpha_value": 0.002864727449507106, "duration": 5.7684783935546875, "step": 63393}
{"episode_reward": 3.354356876913503, "episode": 2061.0, "batch_reward": -0.06238725408911705, "critic_loss": 0.4981200198332469, "ae_transition_loss": 1.7331195672353108, "ae_encoder_loss": 0.8638642827669779, "actor_loss": -0.08182586232821147, "actor_target_entropy": -2.0, "actor_entropy": -1.2221884330113728, "alpha_loss": -0.0019751729366059103, "alpha_value": 0.0028702044839701295, "duration": 72.99923610687256, "step": 63427}
{"episode_reward": 4.43167855460512, "episode": 2062.0, "batch_reward": -0.033834490459412336, "critic_loss": 0.5292985215783119, "ae_transition_loss": 1.4759049713611603, "ae_encoder_loss": 1.2120087444782257, "actor_loss": -0.1665351651608944, "actor_target_entropy": -2.0, "actor_entropy": -1.1575393676757812, "alpha_loss": -0.0016947172989603132, "alpha_value": 0.0028762404407737174, "duration": 7.053755760192871, "step": 63461}
{"episode_reward": 8.955174311657073, "episode": 2063.0, "duration": 0.2014005184173584, "step": 63462}
{"episode_reward": -0.47202471986092437, "episode": 2064.0, "batch_reward": -0.052004036804040275, "critic_loss": 0.8958655993143717, "ae_transition_loss": 1.6516225735346477, "ae_encoder_loss": 1.1029608249664307, "actor_loss": -0.15937858323256174, "actor_target_entropy": -2.0, "actor_entropy": -1.1210989554723103, "alpha_loss": -0.0018491140411545832, "alpha_value": 0.002881846255911072, "duration": 6.11441969871521, "step": 63492}
{"episode_reward": 1.8199994832304558, "episode": 2065.0, "batch_reward": -0.07668776189287503, "critic_loss": 0.8537528912226359, "ae_transition_loss": 1.5172901550928752, "ae_encoder_loss": 0.7379539608955383, "actor_loss": -0.21777701377868652, "actor_target_entropy": -2.0, "actor_entropy": -1.1160724957784016, "alpha_loss": -0.0012748416047543287, "alpha_value": 0.0028864408383530563, "duration": 5.9941725730896, "step": 63521}
{"episode_reward": 2.3775136193818307, "episode": 2066.0, "batch_reward": -0.047187965363264084, "critic_loss": 0.695978045463562, "ae_transition_loss": 1.4640514850616455, "ae_encoder_loss": 0.5631311535835266, "actor_loss": -0.061920613050460815, "actor_target_entropy": -2.0, "actor_entropy": -1.081343173980713, "alpha_loss": -0.001490656053647399, "alpha_value": 0.0028892865765503214, "duration": 3.663111448287964, "step": 63540}
{"episode_reward": -1.104217706272919, "episode": 2067.0, "batch_reward": -0.03641975919405619, "critic_loss": 0.7490736842155457, "ae_transition_loss": 1.4303922653198242, "ae_encoder_loss": 0.5328410963217417, "actor_loss": -0.299535408616066, "actor_target_entropy": -2.0, "actor_entropy": -1.1322592894236247, "alpha_loss": -0.0017985687979186575, "alpha_value": 0.002892046513859855, "duration": 4.724389314651489, "step": 63562}
{"episode_reward": 0.12162108285484408, "episode": 2068.0, "batch_reward": -0.05183876492083073, "critic_loss": 0.43050917983055115, "ae_transition_loss": 1.3842103481292725, "ae_encoder_loss": 0.678367555141449, "actor_loss": -0.1095479242503643, "actor_target_entropy": -2.0, "actor_entropy": -1.1495665311813354, "alpha_loss": -0.001829646120313555, "alpha_value": 0.0028954919846925563, "duration": 4.751189470291138, "step": 63586}
{"episode_reward": 5.486853292854089, "episode": 2069.0, "batch_reward": -0.044307587357858814, "critic_loss": 0.40022359291712445, "ae_transition_loss": 1.2956129709879558, "ae_encoder_loss": 0.6235992709795634, "actor_loss": -0.2268110712369283, "actor_target_entropy": -2.0, "actor_entropy": -1.17757644255956, "alpha_loss": -0.0014654365174161892, "alpha_value": 0.0029009566651248347, "duration": 12.848016738891602, "step": 63650}
{"episode_reward": 3.007280841481399, "episode": 2070.0, "batch_reward": -0.025897199288010597, "critic_loss": 0.41216131051381427, "ae_transition_loss": 1.1962312658627827, "ae_encoder_loss": 0.6004581848780314, "actor_loss": -0.056449697663386665, "actor_target_entropy": -2.0, "actor_entropy": -1.2101726531982422, "alpha_loss": -0.001476297543073694, "alpha_value": 0.0029068056513282775, "duration": 5.375633239746094, "step": 63676}
{"episode_reward": 3.002639338701969, "episode": 2071.0, "batch_reward": -0.047084069810807705, "critic_loss": 0.4092343896627426, "ae_transition_loss": 1.4146376848220825, "ae_encoder_loss": 0.5553694069385529, "actor_loss": -0.1813440565019846, "actor_target_entropy": -2.0, "actor_entropy": -1.256986826658249, "alpha_loss": -0.001606499485205859, "alpha_value": 0.002911118945121898, "duration": 59.73744821548462, "step": 63719}
{"episode_reward": 6.636017029728568, "episode": 2072.0, "batch_reward": -0.04303664776186148, "critic_loss": 0.4467525879542033, "ae_transition_loss": 1.6482105652491252, "ae_encoder_loss": 0.6382605036099752, "actor_loss": -0.15677749613920847, "actor_target_entropy": -2.0, "actor_entropy": -1.1988548040390015, "alpha_loss": -0.0014730847518270214, "alpha_value": 0.0029154798130949576, "duration": 5.579497814178467, "step": 63746}
{"episode_reward": 2.6250380515958636, "episode": 2073.0, "duration": 0.2984614372253418, "step": 63747}
{"episode_reward": -1.0906112868944429, "episode": 2074.0, "duration": 0.2317790985107422, "step": 63748}
{"episode_reward": -0.9759961444076436, "episode": 2075.0, "batch_reward": -0.037831678188272884, "critic_loss": 0.46530082396098543, "ae_transition_loss": 1.49642733165196, "ae_encoder_loss": 0.7381608230727059, "actor_loss": -0.23318286027227128, "actor_target_entropy": -2.0, "actor_entropy": -1.1324140174048287, "alpha_loss": -0.0011470630166253873, "alpha_value": 0.002921568294632675, "duration": 14.270917177200317, "step": 63818}
{"episode_reward": 15.394194970532666, "episode": 2076.0, "batch_reward": -0.005370866817732652, "critic_loss": 0.33128556112448376, "ae_transition_loss": 1.4955095847447712, "ae_encoder_loss": 0.70561816294988, "actor_loss": -0.4716460307439168, "actor_target_entropy": -2.0, "actor_entropy": -1.100329319636027, "alpha_loss": -0.000995927626111855, "alpha_value": 0.002927078600376005, "duration": 5.820943355560303, "step": 63845}
{"episode_reward": 2.847834788573937, "episode": 2077.0, "batch_reward": -0.05896563269197941, "critic_loss": 0.6415376365184784, "ae_transition_loss": 1.3853722512722015, "ae_encoder_loss": 0.6199447959661484, "actor_loss": -0.19120042026042938, "actor_target_entropy": -2.0, "actor_entropy": -0.9904537945985794, "alpha_loss": -0.0010553324682405218, "alpha_value": 0.0029305782682686014, "duration": 9.331594944000244, "step": 63890}
{"episode_reward": 6.390195006236186, "episode": 2078.0, "batch_reward": -0.016301061337192852, "critic_loss": 0.4170779585838318, "ae_transition_loss": 1.3443292776743572, "ae_encoder_loss": 0.7266631325085958, "actor_loss": -0.27813656628131866, "actor_target_entropy": -2.0, "actor_entropy": -1.0590686798095703, "alpha_loss": -0.0013375064978996913, "alpha_value": 0.002933878765023032, "duration": 5.323844909667969, "step": 63915}
{"episode_reward": 3.7923705935455483, "episode": 2079.0, "batch_reward": -0.016980712302029133, "critic_loss": 0.9580401182174683, "ae_transition_loss": 1.439858078956604, "ae_encoder_loss": 0.7097691098848978, "actor_loss": -0.1972879966100057, "actor_target_entropy": -2.0, "actor_entropy": -0.9579286575317383, "alpha_loss": -0.0013364927920823295, "alpha_value": 0.002936750757439982, "duration": 7.023943185806274, "step": 63950}
{"episode_reward": 2.8162970415228745, "episode": 2080.0, "batch_reward": -0.04119053855538368, "critic_loss": 0.8683666288852692, "ae_transition_loss": 1.4662526845932007, "ae_encoder_loss": 0.6413328945636749, "actor_loss": -0.10026635974645615, "actor_target_entropy": -2.0, "actor_entropy": -1.0320355892181396, "alpha_loss": -0.0017893649055622518, "alpha_value": 0.0029392597185037193, "duration": 4.059633493423462, "step": 63970}
{"episode_reward": -0.9211152697009178, "episode": 2081.0, "batch_reward": -0.10635710755983989, "critic_loss": 0.7771116097768148, "ae_transition_loss": 1.365142782529195, "ae_encoder_loss": 0.713259200255076, "actor_loss": 0.01978713522354762, "actor_target_entropy": -2.0, "actor_entropy": -0.9403563737869263, "alpha_loss": -0.0019936825071151056, "alpha_value": 0.0029420277970167393, "duration": 103.99176907539368, "step": 63995}
{"episode_reward": 2.39216600706854, "episode": 2082.0, "duration": 0.22758126258850098, "step": 63996}
{"episode_reward": -2.206788289276319, "episode": 2083.0, "duration": 0.2320876121520996, "step": 63997}
{"episode_reward": -0.4426860090934416, "episode": 2084.0, "batch_reward": -0.0283674622575442, "critic_loss": 0.5887637039025625, "ae_transition_loss": 1.477075219154358, "ae_encoder_loss": 0.6248966058095297, "actor_loss": -0.20398498078187308, "actor_target_entropy": -2.0, "actor_entropy": -1.0962388118108113, "alpha_loss": -0.0017764886530737083, "alpha_value": 0.002945651428619516, "duration": 5.935876369476318, "step": 64027}
{"episode_reward": 4.749900780751148, "episode": 2085.0, "batch_reward": -0.06872444599866867, "critic_loss": 0.33579570800065994, "ae_transition_loss": 1.2995307743549347, "ae_encoder_loss": 0.6262151449918747, "actor_loss": -0.22453119605779648, "actor_target_entropy": -2.0, "actor_entropy": -1.0387743413448334, "alpha_loss": -0.0019487153622321784, "alpha_value": 0.0029501935216966167, "duration": 7.629260778427124, "step": 64065}
{"episode_reward": 4.251748127677252, "episode": 2086.0, "duration": 0.23392939567565918, "step": 64066}
{"episode_reward": -0.4385552188671812, "episode": 2087.0, "duration": 0.22806143760681152, "step": 64067}
{"episode_reward": -3.805931393215358, "episode": 2088.0, "batch_reward": -0.08340673707425594, "critic_loss": 0.746436357498169, "ae_transition_loss": 1.4088930785655975, "ae_encoder_loss": 1.1209748536348343, "actor_loss": -0.3784734159708023, "actor_target_entropy": -2.0, "actor_entropy": -1.1449034512043, "alpha_loss": -0.00205597176682204, "alpha_value": 0.002955759800477035, "duration": 8.123817205429077, "step": 64108}
{"episode_reward": 6.683586432968454, "episode": 2089.0, "batch_reward": -0.022617265582084656, "critic_loss": 0.5788564383983612, "ae_transition_loss": 1.577475945154826, "ae_encoder_loss": 1.1462502876917522, "actor_loss": -0.2886710117260615, "actor_target_entropy": -2.0, "actor_entropy": -1.1383380095163982, "alpha_loss": -0.0023726027769347033, "alpha_value": 0.0029609336150069596, "duration": 5.867817401885986, "step": 64136}
{"episode_reward": 2.388396398581907, "episode": 2090.0, "duration": 0.23987650871276855, "step": 64137}
{"episode_reward": -0.966501280418739, "episode": 2091.0, "batch_reward": -0.024635587818920612, "critic_loss": 0.5150855183601379, "ae_transition_loss": 1.601694405078888, "ae_encoder_loss": 0.7505802810192108, "actor_loss": -0.16400916688144207, "actor_target_entropy": -2.0, "actor_entropy": -1.150359869003296, "alpha_loss": -0.002034718170762062, "alpha_value": 0.002964877418716693, "duration": 101.69582033157349, "step": 64156}
{"episode_reward": -0.5813367661782396, "episode": 2092.0, "batch_reward": -0.02142871543765068, "critic_loss": 1.0353367726008098, "ae_transition_loss": 1.5107121864954631, "ae_encoder_loss": 0.7131960193316141, "actor_loss": 0.05883735169967016, "actor_target_entropy": -2.0, "actor_entropy": -1.069867730140686, "alpha_loss": -0.0016808070552845795, "alpha_value": 0.002968867127332598, "duration": 6.491894006729126, "step": 64188}
{"episode_reward": 3.756688448757607, "episode": 2093.0, "batch_reward": -0.10575277358293533, "critic_loss": 0.8430480659008026, "ae_transition_loss": 1.5823333263397217, "ae_encoder_loss": 0.8830395340919495, "actor_loss": 0.09120723232626915, "actor_target_entropy": -2.0, "actor_entropy": -1.00699782371521, "alpha_loss": -0.0022209598682820797, "alpha_value": 0.0029727986812551426, "duration": 3.8036439418792725, "step": 64206}
{"episode_reward": 0.5985359818811655, "episode": 2094.0, "duration": 0.22369599342346191, "step": 64207}
{"episode_reward": 0.04205358796761066, "episode": 2095.0, "batch_reward": -0.02820629719644785, "critic_loss": 0.7198441624641418, "ae_transition_loss": 1.7544732093811035, "ae_encoder_loss": 0.8036777377128601, "actor_loss": -0.12931793928146362, "actor_target_entropy": -2.0, "actor_entropy": -1.1289374232292175, "alpha_loss": -0.0011867769062519073, "alpha_value": 0.002975949625924513, "duration": 4.732197999954224, "step": 64230}
{"episode_reward": 0.7517440666596682, "episode": 2096.0, "batch_reward": -0.06664645423491795, "critic_loss": 1.0420138835906982, "ae_transition_loss": 1.6025511423746746, "ae_encoder_loss": 1.119729479153951, "actor_loss": -0.24926044046878815, "actor_target_entropy": -2.0, "actor_entropy": -1.063614825407664, "alpha_loss": -0.0018978527126212914, "alpha_value": 0.0029796935772373797, "duration": 4.865225076675415, "step": 64253}
{"episode_reward": 3.3202050327391004, "episode": 2097.0, "batch_reward": -0.05170851138730844, "critic_loss": 0.8477389315764109, "ae_transition_loss": 1.6443395217259724, "ae_encoder_loss": 0.5466667612393697, "actor_loss": -0.47797146439552307, "actor_target_entropy": -2.0, "actor_entropy": -1.1749402085940044, "alpha_loss": -0.0020086488220840693, "alpha_value": 0.0029865058479039922, "duration": 12.822097063064575, "step": 64316}
{"episode_reward": 18.09389913637245, "episode": 2098.0, "batch_reward": -0.04960407875478268, "critic_loss": 0.63884170850118, "ae_transition_loss": 1.5270161628723145, "ae_encoder_loss": 0.415518452723821, "actor_loss": -0.43343939383824664, "actor_target_entropy": -2.0, "actor_entropy": -1.2313164472579956, "alpha_loss": -0.00242853001691401, "alpha_value": 0.002993586568502324, "duration": 5.423711061477661, "step": 64341}
{"episode_reward": 2.098063966910302, "episode": 2099.0, "batch_reward": -0.045818314577142395, "critic_loss": 0.5763033131758372, "ae_transition_loss": 1.481635332107544, "ae_encoder_loss": 0.705134982864062, "actor_loss": -0.2717290247480075, "actor_target_entropy": -2.0, "actor_entropy": -1.249087929725647, "alpha_loss": -0.0021236528215619424, "alpha_value": 0.003001296953098994, "duration": 11.983558893203735, "step": 64401}
{"episode_reward": 15.11822788315038, "episode": 2100.0, "batch_reward": -0.046886714485784374, "critic_loss": 0.713611235221227, "ae_transition_loss": 1.6284433007240295, "ae_encoder_loss": 0.8546783824761709, "actor_loss": -0.01721738527218501, "actor_target_entropy": -2.0, "actor_entropy": -1.214435875415802, "alpha_loss": -0.0024591219844296575, "alpha_value": 0.0030117492918945734, "duration": 13.144157886505127, "step": 64467}
{"episode_reward": 30.50298957788277, "episode": 2101.0, "batch_reward": -0.042213586292096546, "critic_loss": 0.8159904522555215, "ae_transition_loss": 1.626413038798741, "ae_encoder_loss": 0.652819744178227, "actor_loss": -0.21546404649104392, "actor_target_entropy": -2.0, "actor_entropy": -1.1811761345182146, "alpha_loss": -0.002313226893810289, "alpha_value": 0.0030238704345110427, "duration": 82.42775821685791, "step": 64534}
{"episode_reward": 42.933134951560525, "episode": 2102.0, "batch_reward": -0.08314171309272449, "critic_loss": 0.7944169541200002, "ae_transition_loss": 1.529717246691386, "ae_encoder_loss": 0.5978927214940389, "actor_loss": -0.2832638422648112, "actor_target_entropy": -2.0, "actor_entropy": -1.0948150952657063, "alpha_loss": -0.0027069183997809887, "alpha_value": 0.0030335338898725274, "duration": 5.979764223098755, "step": 64561}
{"episode_reward": 1.7282663819464927, "episode": 2103.0, "batch_reward": -0.02462525766653319, "critic_loss": 0.65364142258962, "ae_transition_loss": 1.4559888293345769, "ae_encoder_loss": 0.4883245825767517, "actor_loss": -0.3787361178547144, "actor_target_entropy": -2.0, "actor_entropy": -1.201899451514085, "alpha_loss": -0.0022346533975602747, "alpha_value": 0.0030614956896776167, "duration": 51.608073472976685, "step": 64810}
{"episode_reward": -4.183192919926664, "episode": 2104.0, "batch_reward": -0.03297110199928284, "critic_loss": 0.6492210328578949, "ae_transition_loss": 1.7230938911437987, "ae_encoder_loss": 0.5879564046859741, "actor_loss": -0.41578064262866976, "actor_target_entropy": -2.0, "actor_entropy": -1.2807114124298096, "alpha_loss": -0.002159753302112222, "alpha_value": 0.0030894264929557983, "duration": 9.1245436668396, "step": 64851}
{"episode_reward": 11.10403714861145, "episode": 2105.0, "batch_reward": -0.04176465297738711, "critic_loss": 0.6531593352556229, "ae_transition_loss": 1.6299868822097778, "ae_encoder_loss": 1.102435787518819, "actor_loss": -0.2869942883650462, "actor_target_entropy": -2.0, "actor_entropy": -1.2257789373397827, "alpha_loss": -0.0022865881134445467, "alpha_value": 0.0030993233912934496, "duration": 13.129995584487915, "step": 64914}
{"episode_reward": -10.165525481312367, "episode": 2106.0, "batch_reward": -0.024240676313638687, "critic_loss": 0.8910447557767233, "ae_transition_loss": 1.7577248414357503, "ae_encoder_loss": 0.9379449089368185, "actor_loss": -0.022096519668896992, "actor_target_entropy": -2.0, "actor_entropy": -1.0577990810076396, "alpha_loss": -0.002283138611043493, "alpha_value": 0.003107758163248903, "duration": 7.496737480163574, "step": 64949}
{"episode_reward": 2.970484841784392, "episode": 2107.0, "batch_reward": -0.03293529463311037, "critic_loss": 1.4974579016367595, "ae_transition_loss": 1.7321359316507976, "ae_encoder_loss": 0.9814933141072592, "actor_loss": 0.18255087236563364, "actor_target_entropy": -2.0, "actor_entropy": -0.9175978302955627, "alpha_loss": -0.0021782664892574153, "alpha_value": 0.0031135602051411745, "duration": 5.457768201828003, "step": 64974}
{"episode_reward": 1.117153105227728, "episode": 2108.0, "batch_reward": -0.021324770525097847, "critic_loss": 0.7644641101360321, "ae_transition_loss": 1.7221048474311829, "ae_encoder_loss": 1.0520267486572266, "actor_loss": -0.2795434296131134, "actor_target_entropy": -2.0, "actor_entropy": -0.8133186101913452, "alpha_loss": -0.0023335167206823826, "alpha_value": 0.003118419985603884, "duration": 4.689919710159302, "step": 64995}
{"episode_reward": 0.47321046384553556, "episode": 2109.0, "batch_reward": -0.018761375298102696, "critic_loss": 0.530981699625651, "ae_transition_loss": 1.6453053553899128, "ae_encoder_loss": 0.948857307434082, "actor_loss": -0.47210389375686646, "actor_target_entropy": -2.0, "actor_entropy": -0.856147825717926, "alpha_loss": -0.0021816816491385302, "alpha_value": 0.0031232837014966252, "duration": 5.737939834594727, "step": 65021}
{"episode_reward": 4.101043509180489, "episode": 2110.0, "batch_reward": -0.041478592968944995, "critic_loss": 0.7545550359146935, "ae_transition_loss": 1.4266925709588187, "ae_encoder_loss": 0.7505750379392079, "actor_loss": -0.3115212821534702, "actor_target_entropy": -2.0, "actor_entropy": -1.1715322179453713, "alpha_loss": -0.0021486627187446822, "alpha_value": 0.0031401170643104493, "duration": 29.984527826309204, "step": 65164}
{"episode_reward": 32.53918135553306, "episode": 2111.0, "batch_reward": -0.021099593490362167, "critic_loss": 0.9576222896575928, "ae_transition_loss": 1.6476885080337524, "ae_encoder_loss": 0.7361562252044678, "actor_loss": -0.3022068738937378, "actor_target_entropy": -2.0, "actor_entropy": -1.2409887313842773, "alpha_loss": -0.0020088753663003445, "alpha_value": 0.003154662002273181, "duration": 68.9688172340393, "step": 65176}
{"episode_reward": -1.3858911149402222, "episode": 2112.0, "batch_reward": -0.027476978222174302, "critic_loss": 0.77427995630673, "ae_transition_loss": 1.2706669909613473, "ae_encoder_loss": 0.4737523836748941, "actor_loss": -0.2719930644546236, "actor_target_entropy": -2.0, "actor_entropy": -1.152626293046134, "alpha_loss": -0.002072600315191916, "alpha_value": 0.003162137095661433, "duration": 13.99522352218628, "step": 65243}
{"episode_reward": 19.426299058782682, "episode": 2113.0, "batch_reward": -0.02993169240653515, "critic_loss": 0.8755754828453064, "ae_transition_loss": 2.078027606010437, "ae_encoder_loss": 0.4512309283018112, "actor_loss": -0.1778326891362667, "actor_target_entropy": -2.0, "actor_entropy": -1.0093178451061249, "alpha_loss": -0.001615086745005101, "alpha_value": 0.003170549942823342, "duration": 5.316408395767212, "step": 65269}
{"episode_reward": 2.160652202473235, "episode": 2114.0, "batch_reward": -0.05055000865831971, "critic_loss": 0.649288721382618, "ae_transition_loss": 1.6060433089733124, "ae_encoder_loss": 0.7779375873506069, "actor_loss": -0.37944252882152796, "actor_target_entropy": -2.0, "actor_entropy": -1.035051241517067, "alpha_loss": -0.0016582917087362148, "alpha_value": 0.0031794095596594635, "duration": 15.239689350128174, "step": 65345}
{"episode_reward": 55.16039006560673, "episode": 2115.0, "batch_reward": -0.04087878546367089, "critic_loss": 0.6038775146007538, "ae_transition_loss": 1.5530693531036377, "ae_encoder_loss": 0.918480118115743, "actor_loss": -0.42561671634515125, "actor_target_entropy": -2.0, "actor_entropy": -1.0314792394638062, "alpha_loss": -0.0014502260213096936, "alpha_value": 0.003188556480865497, "duration": 6.0921831130981445, "step": 65375}
{"episode_reward": 7.458486672929671, "episode": 2116.0, "duration": 0.24329566955566406, "step": 65376}
{"episode_reward": -0.27113901155201114, "episode": 2117.0, "batch_reward": -0.030661272018083503, "critic_loss": 0.5285533006702151, "ae_transition_loss": 1.4399062565394811, "ae_encoder_loss": 0.4835920993770872, "actor_loss": -0.4080744832754135, "actor_target_entropy": -2.0, "actor_entropy": -1.048523221697126, "alpha_loss": -0.0017386862060188182, "alpha_value": 0.0032018953409305786, "duration": 28.615988731384277, "step": 65518}
{"episode_reward": 48.841740967129404, "episode": 2118.0, "batch_reward": -0.02086062552407384, "critic_loss": 0.5692478284239769, "ae_transition_loss": 1.1374190002679825, "ae_encoder_loss": 0.30287502259016036, "actor_loss": -0.48614907674491403, "actor_target_entropy": -2.0, "actor_entropy": -1.1610723376274108, "alpha_loss": -0.002617596136406064, "alpha_value": 0.003231345038295958, "duration": 39.69588661193848, "step": 65716}
{"episode_reward": 61.90033843665316, "episode": 2119.0, "batch_reward": -0.053254066881808365, "critic_loss": 0.6881663799285889, "ae_transition_loss": 1.2470889741724187, "ae_encoder_loss": 0.49012483250011096, "actor_loss": -0.491609744050286, "actor_target_entropy": -2.0, "actor_entropy": -1.1763266379182988, "alpha_loss": -0.0031982347877188163, "alpha_value": 0.0032676478206548312, "duration": 22.779796361923218, "step": 65829}
{"episode_reward": 35.22606527192039, "episode": 2120.0, "batch_reward": -0.03486313049991926, "critic_loss": 0.5719073712825775, "ae_transition_loss": 1.4886409441630046, "ae_encoder_loss": 0.4043013006448746, "actor_loss": -0.3425840934117635, "actor_target_entropy": -2.0, "actor_entropy": -1.1304231882095337, "alpha_loss": -0.003402976590829591, "alpha_value": 0.003291392362580027, "duration": 11.923840284347534, "step": 65887}
{"episode_reward": 17.928795052209885, "episode": 2121.0, "batch_reward": -0.022678205859847367, "critic_loss": 0.6022883169353008, "ae_transition_loss": 1.1978293061256409, "ae_encoder_loss": 0.4583791568875313, "actor_loss": -0.609869047999382, "actor_target_entropy": -2.0, "actor_entropy": -1.1163541972637177, "alpha_loss": -0.0031118534388951957, "alpha_value": 0.0033064121090086323, "duration": 86.4798014163971, "step": 65925}
{"episode_reward": 8.403002608337221, "episode": 2122.0, "duration": 0.22344350814819336, "step": 65926}
{"episode_reward": -0.7378049492835999, "episode": 2123.0, "batch_reward": -0.05215215515345335, "critic_loss": 0.4571582078933716, "ae_transition_loss": 1.407208514213562, "ae_encoder_loss": 0.5949044227600098, "actor_loss": -0.4889375388622284, "actor_target_entropy": -2.0, "actor_entropy": -1.1719459772109986, "alpha_loss": -0.0028964276891201733, "alpha_value": 0.0033199859224172187, "duration": 11.376013278961182, "step": 65980}
{"episode_reward": 24.48956765833549, "episode": 2124.0, "batch_reward": -0.04994218051433563, "critic_loss": 0.31742312014102936, "ae_transition_loss": 1.56110417842865, "ae_encoder_loss": 0.5831070840358734, "actor_loss": -0.5809603333473206, "actor_target_entropy": -2.0, "actor_entropy": -1.2022245526313782, "alpha_loss": -0.002761274576187134, "alpha_value": 0.0033302867219813445, "duration": 3.856882095336914, "step": 65998}
{"episode_reward": -1.470808130914448, "episode": 2125.0, "duration": 0.23097538948059082, "step": 65999}
{"episode_reward": -0.2961363843886129, "episode": 2126.0, "duration": 0.22748899459838867, "step": 66000}
{"episode_reward": -0.6786822884286556, "episode": 2127.0, "batch_reward": -0.05375463142991066, "critic_loss": 1.4256069660186768, "ae_transition_loss": 1.5149816274642944, "ae_encoder_loss": 0.4578043222427368, "actor_loss": -0.38772767782211304, "actor_target_entropy": -2.0, "actor_entropy": -1.049981713294983, "alpha_loss": -0.0026872551534324884, "alpha_value": 0.003334617117224378, "duration": 0.5388658046722412, "step": 66001}
{"episode_reward": -0.214775752286525, "episode": 2128.0, "batch_reward": -0.038694609621805806, "critic_loss": 0.5409626577581678, "ae_transition_loss": 1.3618760790143694, "ae_encoder_loss": 0.5580915978976658, "actor_loss": -0.5210938921996525, "actor_target_entropy": -2.0, "actor_entropy": -1.1609992980957031, "alpha_loss": -0.002978459798863956, "alpha_value": 0.003346032446142031, "duration": 14.984601736068726, "step": 66076}
{"episode_reward": 39.178424228366424, "episode": 2129.0, "batch_reward": 0.0001506327341000239, "critic_loss": 0.6687061786651611, "ae_transition_loss": 1.3476320902506511, "ae_encoder_loss": 0.5401176313559214, "actor_loss": -0.6052303115526835, "actor_target_entropy": -2.0, "actor_entropy": -1.1826941569646199, "alpha_loss": -0.0033141289992878833, "alpha_value": 0.003360392734527633, "duration": 6.056011915206909, "step": 66105}
{"episode_reward": 6.1757592123907665, "episode": 2130.0, "batch_reward": -0.03767653690143065, "critic_loss": 0.5746715976433321, "ae_transition_loss": 1.4145691286433826, "ae_encoder_loss": 0.6389931630004536, "actor_loss": -0.3814740506085483, "actor_target_entropy": -2.0, "actor_entropy": -1.093857841058211, "alpha_loss": -0.0031285492322323, "alpha_value": 0.003381579355329706, "duration": 23.315631866455078, "step": 66220}
{"episode_reward": 46.08178422407555, "episode": 2131.0, "batch_reward": -0.049424605909734964, "critic_loss": 0.46841371804475784, "ae_transition_loss": 1.821757286787033, "ae_encoder_loss": 0.5795475840568542, "actor_loss": -0.6076866388320923, "actor_target_entropy": -2.0, "actor_entropy": -1.066983386874199, "alpha_loss": -0.0023442075471393764, "alpha_value": 0.003404273341891834, "duration": 62.50403141975403, "step": 66260}
{"episode_reward": 1.4400931205043375, "episode": 2132.0, "batch_reward": -0.09847013279795647, "critic_loss": 0.48546525835990906, "ae_transition_loss": 1.5716063976287842, "ae_encoder_loss": 0.49271929264068604, "actor_loss": -0.2889447249472141, "actor_target_entropy": -2.0, "actor_entropy": -1.004962682723999, "alpha_loss": -0.0017544608563184738, "alpha_value": 0.003412766622452518, "duration": 2.619399309158325, "step": 66271}
{"episode_reward": -1.9257058404628538, "episode": 2133.0, "duration": 0.18058490753173828, "step": 66272}
{"episode_reward": -0.510820684376328, "episode": 2134.0, "batch_reward": -0.040418367832899094, "critic_loss": 0.5323673685391744, "ae_transition_loss": 1.5836950540542603, "ae_encoder_loss": 0.4396970470746358, "actor_loss": -0.5183498859405518, "actor_target_entropy": -2.0, "actor_entropy": -1.0129376848538716, "alpha_loss": -0.002852177945896983, "alpha_value": 0.003419316909775491, "duration": 6.4716551303863525, "step": 66304}
{"episode_reward": 5.935171907127677, "episode": 2135.0, "batch_reward": -0.034145040437579155, "critic_loss": 0.6429461240768433, "ae_transition_loss": 1.7495505809783936, "ae_encoder_loss": 0.6667489409446716, "actor_loss": -0.5326338708400726, "actor_target_entropy": -2.0, "actor_entropy": -0.9950892329216003, "alpha_loss": -0.0021798565867356956, "alpha_value": 0.003425895766501717, "duration": 5.131464004516602, "step": 66330}
{"episode_reward": 6.266942837772217, "episode": 2136.0, "batch_reward": -0.004788059741258621, "critic_loss": 0.5214135050773621, "ae_transition_loss": 1.47135728597641, "ae_encoder_loss": 0.571394145488739, "actor_loss": -0.6002593636512756, "actor_target_entropy": -2.0, "actor_entropy": -1.0249382555484772, "alpha_loss": -0.00351827300619334, "alpha_value": 0.003431064289403496, "duration": 3.17982816696167, "step": 66345}
{"episode_reward": 0.11759447346784672, "episode": 2137.0, "batch_reward": -0.035598354414105415, "critic_loss": 0.7177203496297201, "ae_transition_loss": 1.493979573249817, "ae_encoder_loss": 0.5178132752577463, "actor_loss": -0.380965660015742, "actor_target_entropy": -2.0, "actor_entropy": -1.0519190033276875, "alpha_loss": -0.0030553905138125024, "alpha_value": 0.0034378589627759846, "duration": 6.007340908050537, "step": 66375}
{"episode_reward": 5.151563812581055, "episode": 2138.0, "batch_reward": -0.04093831926584244, "critic_loss": 0.5243316382169724, "ae_transition_loss": 1.4188271284103393, "ae_encoder_loss": 0.5586867928504944, "actor_loss": -0.37644111514091494, "actor_target_entropy": -2.0, "actor_entropy": -1.0099294900894165, "alpha_loss": -0.003017880255356431, "alpha_value": 0.003449146069009954, "duration": 9.998401641845703, "step": 66422}
{"episode_reward": 3.694609374737503, "episode": 2139.0, "batch_reward": 0.014123898930847645, "critic_loss": 0.4349672496318817, "ae_transition_loss": 1.3165976405143738, "ae_encoder_loss": 0.5809749960899353, "actor_loss": -0.5206833779811859, "actor_target_entropy": -2.0, "actor_entropy": -1.022889256477356, "alpha_loss": -0.002356336801312864, "alpha_value": 0.0034592283690646044, "duration": 4.118946552276611, "step": 66441}
{"episode_reward": 2.2960566375486255, "episode": 2140.0, "batch_reward": -0.01770300914843877, "critic_loss": 0.3806283970673879, "ae_transition_loss": 1.284564773241679, "ae_encoder_loss": 0.5483346382776896, "actor_loss": -0.5426884988943735, "actor_target_entropy": -2.0, "actor_entropy": -1.0937548279762268, "alpha_loss": -0.003075903203959266, "alpha_value": 0.0034663190781559516, "duration": 7.0064697265625, "step": 66476}
{"episode_reward": 8.926126283698524, "episode": 2141.0, "batch_reward": -0.02348274697682687, "critic_loss": 0.6540460245949882, "ae_transition_loss": 1.6717521803719657, "ae_encoder_loss": 1.1096400788852148, "actor_loss": -0.4790354637163026, "actor_target_entropy": -2.0, "actor_entropy": -1.1424681757177626, "alpha_loss": -0.003302455081471375, "alpha_value": 0.003491588187280486, "duration": 85.1584038734436, "step": 66611}
{"episode_reward": 74.09621914191345, "episode": 2142.0, "batch_reward": -0.01705598719418049, "critic_loss": 1.0154883941014607, "ae_transition_loss": 1.5726705948511759, "ae_encoder_loss": 1.3570462107658385, "actor_loss": -0.4128446653485298, "actor_target_entropy": -2.0, "actor_entropy": -1.1677866141001383, "alpha_loss": -0.0029487690965955458, "alpha_value": 0.003537960058882519, "duration": 31.223692655563354, "step": 66763}
{"episode_reward": 48.30753355946, "episode": 2143.0, "batch_reward": -0.05010821344330907, "critic_loss": 0.9647914208471775, "ae_transition_loss": 1.7078170850872993, "ae_encoder_loss": 0.852508258074522, "actor_loss": -0.41524628596380353, "actor_target_entropy": -2.0, "actor_entropy": -1.1904493868350983, "alpha_loss": -0.002925626453361474, "alpha_value": 0.0035855631345410237, "duration": 32.57308793067932, "step": 66922}
{"episode_reward": 35.66213746049055, "episode": 2144.0, "batch_reward": -0.04642016999423504, "critic_loss": 0.683253156642119, "ae_transition_loss": 1.6045133074124653, "ae_encoder_loss": 1.1672873298327129, "actor_loss": -0.5287770877281824, "actor_target_entropy": -2.0, "actor_entropy": -1.2284586826960247, "alpha_loss": -0.0033738003500426808, "alpha_value": 0.0036198993379986514, "duration": 13.627789735794067, "step": 66990}
{"episode_reward": 41.191440423758515, "episode": 2145.0, "batch_reward": -0.029619761183857916, "critic_loss": 0.6156881093978882, "ae_transition_loss": 1.5782408237457275, "ae_encoder_loss": 0.7648477196693421, "actor_loss": -0.4350664347410202, "actor_target_entropy": -2.0, "actor_entropy": -1.1792898893356323, "alpha_loss": -0.003109403001144528, "alpha_value": 0.0036385859501462414, "duration": 8.947345733642578, "step": 67032}
{"episode_reward": 9.360286988046079, "episode": 2146.0, "batch_reward": -0.031123658642172813, "critic_loss": 0.6486366152763366, "ae_transition_loss": 1.5753697872161865, "ae_encoder_loss": 0.5526969790458679, "actor_loss": -0.4166966244578362, "actor_target_entropy": -2.0, "actor_entropy": -1.0650419116020202, "alpha_loss": -0.0025357346748933196, "alpha_value": 0.0036626601359412508, "duration": 21.844316482543945, "step": 67138}
{"episode_reward": 56.53245330851429, "episode": 2147.0, "batch_reward": -0.028683156395951908, "critic_loss": 0.8941386143366495, "ae_transition_loss": 1.547264536221822, "ae_encoder_loss": 0.8687343796094259, "actor_loss": -0.6260747429397371, "actor_target_entropy": -2.0, "actor_entropy": -1.0093408359421625, "alpha_loss": -0.0022546856069109505, "alpha_value": 0.003690232134211354, "duration": 17.707188606262207, "step": 67223}
{"episode_reward": 10.675777947601537, "episode": 2148.0, "batch_reward": -0.018864070251584052, "critic_loss": 0.7390982985496521, "ae_transition_loss": 1.4229208946228027, "ae_encoder_loss": 0.6597496747970581, "actor_loss": -0.5718461036682129, "actor_target_entropy": -2.0, "actor_entropy": -1.0178791403770446, "alpha_loss": -0.003126793773844838, "alpha_value": 0.003709335859589124, "duration": 11.620354175567627, "step": 67279}
{"episode_reward": 17.48901406777887, "episode": 2149.0, "batch_reward": -0.0009399820119142532, "critic_loss": 0.8337733447551727, "ae_transition_loss": 1.776412010192871, "ae_encoder_loss": 0.6584866046905518, "actor_loss": -0.5333623737096786, "actor_target_entropy": -2.0, "actor_entropy": -1.0054312646389008, "alpha_loss": -0.0022916332236491144, "alpha_value": 0.003719502023149983, "duration": 4.239943742752075, "step": 67299}
{"episode_reward": 0.5994276742532733, "episode": 2150.0, "batch_reward": -0.028601820447615216, "critic_loss": 0.711937929902758, "ae_transition_loss": 1.5491793496268136, "ae_encoder_loss": 0.7394685660089765, "actor_loss": -0.42828010129077093, "actor_target_entropy": -2.0, "actor_entropy": -0.966333167893546, "alpha_loss": -0.0029810608830302954, "alpha_value": 0.003733015613090882, "duration": 13.354706287384033, "step": 67362}
{"episode_reward": 22.582209589827087, "episode": 2151.0, "duration": 91.35687589645386, "step": 67363}
{"episode_reward": -0.4913292271091946, "episode": 2152.0, "batch_reward": -0.055079800209828784, "critic_loss": 0.8781337312289647, "ae_transition_loss": 1.5377382380621774, "ae_encoder_loss": 1.45511451789311, "actor_loss": -0.37396123153822763, "actor_target_entropy": -2.0, "actor_entropy": -0.9400536588260106, "alpha_loss": -0.002768825939191239, "alpha_value": 0.003754471036796404, "duration": 13.964863061904907, "step": 67432}
{"episode_reward": 27.816383989163718, "episode": 2153.0, "batch_reward": -0.02127905065814654, "critic_loss": 0.8198987245559692, "ae_transition_loss": 1.5543181896209717, "ae_encoder_loss": 1.2273380756378174, "actor_loss": -0.5169295867284139, "actor_target_entropy": -2.0, "actor_entropy": -0.8193227847417196, "alpha_loss": -0.0026302382660408816, "alpha_value": 0.003769885843412519, "duration": 5.993085145950317, "step": 67461}
{"episode_reward": 3.4488113047482307, "episode": 2154.0, "batch_reward": -0.03843659535050392, "critic_loss": 1.0591248124837875, "ae_transition_loss": 2.257939875125885, "ae_encoder_loss": 1.8498670160770416, "actor_loss": -0.42736751213669777, "actor_target_entropy": -2.0, "actor_entropy": -0.8819538354873657, "alpha_loss": -0.0018262578814756125, "alpha_value": 0.003780356607113998, "duration": 9.506378650665283, "step": 67510}
{"episode_reward": 15.048287418341339, "episode": 2155.0, "batch_reward": -0.032540759071707726, "critic_loss": 1.0347452958424885, "ae_transition_loss": 1.91554061571757, "ae_encoder_loss": 1.6693250735600789, "actor_loss": -0.5498873194058737, "actor_target_entropy": -2.0, "actor_entropy": -0.8922170797983805, "alpha_loss": -0.002301857379886011, "alpha_value": 0.0037901501569749586, "duration": 5.11397123336792, "step": 67534}
{"episode_reward": -7.681381776927197, "episode": 2156.0, "batch_reward": -0.03098205228646596, "critic_loss": 0.8828901449839274, "ae_transition_loss": 1.8435993989308674, "ae_encoder_loss": 1.7660503387451172, "actor_loss": -0.6458100080490112, "actor_target_entropy": -2.0, "actor_entropy": -0.8335033853848776, "alpha_loss": -0.00230106587211291, "alpha_value": 0.0037981394631662817, "duration": 6.588712692260742, "step": 67566}
{"episode_reward": 4.588171505614391, "episode": 2157.0, "batch_reward": -0.020952781895175576, "critic_loss": 0.7889153249561787, "ae_transition_loss": 1.904395505785942, "ae_encoder_loss": 1.2965992763638496, "actor_loss": -0.49642697162926197, "actor_target_entropy": -2.0, "actor_entropy": -0.8265388458967209, "alpha_loss": -0.0024817729099595454, "alpha_value": 0.0038130682597256093, "duration": 16.364044666290283, "step": 67647}
{"episode_reward": 32.94081605263498, "episode": 2158.0, "batch_reward": -0.049738859136899315, "critic_loss": 0.5578071276346842, "ae_transition_loss": 1.9573902289072673, "ae_encoder_loss": 1.0771471063296, "actor_loss": -0.4980638523896535, "actor_target_entropy": -2.0, "actor_entropy": -0.8185980916023254, "alpha_loss": -0.0013068852325280507, "alpha_value": 0.003827858436423144, "duration": 6.5074303150177, "step": 67679}
{"episode_reward": 7.012044027549312, "episode": 2159.0, "batch_reward": 0.08096441626548767, "critic_loss": 0.7652910351753235, "ae_transition_loss": 1.8831745386123657, "ae_encoder_loss": 0.9285862445831299, "actor_loss": -0.8659482598304749, "actor_target_entropy": -2.0, "actor_entropy": -0.8449910879135132, "alpha_loss": -0.0028934497386217117, "alpha_value": 0.0038327275273758845, "duration": 1.3078563213348389, "step": 67685}
{"episode_reward": -2.0988083884920425, "episode": 2160.0, "batch_reward": -0.02767268195748329, "critic_loss": 1.0259162187576294, "ae_transition_loss": 1.9245514869689941, "ae_encoder_loss": 0.9285108049710592, "actor_loss": -0.4800059298674266, "actor_target_entropy": -2.0, "actor_entropy": -0.7847505211830139, "alpha_loss": -0.0012091748649254441, "alpha_value": 0.0038373969504789363, "duration": 5.4598305225372314, "step": 67711}
{"episode_reward": 3.7885511208729623, "episode": 2161.0, "batch_reward": 0.016091104596853256, "critic_loss": 0.882166196902593, "ae_transition_loss": 1.8551236391067505, "ae_encoder_loss": 0.7432650129000345, "actor_loss": -0.7253442804018656, "actor_target_entropy": -2.0, "actor_entropy": -0.8484765291213989, "alpha_loss": -0.0024362107117970786, "alpha_value": 0.003844115134696025, "duration": 75.6037826538086, "step": 67749}
{"episode_reward": 4.500494294811865, "episode": 2162.0, "batch_reward": -0.024951956421136855, "critic_loss": 0.6816280603408813, "ae_transition_loss": 1.8356435775756836, "ae_encoder_loss": 0.7410340309143066, "actor_loss": -0.762823736667633, "actor_target_entropy": -2.0, "actor_entropy": -0.810824990272522, "alpha_loss": -0.0017921051243320108, "alpha_value": 0.003853408388905627, "duration": 9.171968698501587, "step": 67795}
{"episode_reward": 13.515096423898989, "episode": 2163.0, "batch_reward": -0.03260872885584831, "critic_loss": 0.9377881586551666, "ae_transition_loss": 1.631584095954895, "ae_encoder_loss": 0.5624165654182434, "actor_loss": -0.6874104857444763, "actor_target_entropy": -2.0, "actor_entropy": -0.7816443324089051, "alpha_loss": -0.0017829505726695062, "alpha_value": 0.0038645578826893567, "duration": 9.80612063407898, "step": 67843}
{"episode_reward": 13.332188112136453, "episode": 2164.0, "batch_reward": -0.020013049244880676, "critic_loss": 0.47905975580215454, "ae_transition_loss": 1.662365436553955, "ae_encoder_loss": 0.5039002895355225, "actor_loss": -0.7766766548156738, "actor_target_entropy": -2.0, "actor_entropy": -0.8300918340682983, "alpha_loss": -0.003043579403311014, "alpha_value": 0.0038710330971892808, "duration": 2.7973098754882812, "step": 67856}
{"episode_reward": -1.8395059399500235, "episode": 2165.0, "batch_reward": 0.042207784950733185, "critic_loss": 0.5391479134559631, "ae_transition_loss": 1.4618832468986511, "ae_encoder_loss": 0.6394421458244324, "actor_loss": -0.840461939573288, "actor_target_entropy": -2.0, "actor_entropy": -0.8152894079685211, "alpha_loss": -0.0030200807377696037, "alpha_value": 0.0038744916445627624, "duration": 4.0039963722229, "step": 67875}
{"episode_reward": 0.6479453526370773, "episode": 2166.0, "batch_reward": -0.03050238313153386, "critic_loss": 0.4577024579048157, "ae_transition_loss": 1.3848003149032593, "ae_encoder_loss": 0.5310399830341339, "actor_loss": -0.8622768223285675, "actor_target_entropy": -2.0, "actor_entropy": -0.8831272721290588, "alpha_loss": -0.0027859299443662167, "alpha_value": 0.0038795050993031474, "duration": 4.995471715927124, "step": 67900}
{"episode_reward": 6.475696741063215, "episode": 2167.0, "batch_reward": 0.0071291085332632065, "critic_loss": 0.8719962537288666, "ae_transition_loss": 1.4985828638076781, "ae_encoder_loss": 0.7402276515960693, "actor_loss": -0.7674947500228881, "actor_target_entropy": -2.0, "actor_entropy": -0.8768444061279297, "alpha_loss": -0.002194254333153367, "alpha_value": 0.0038887337512629704, "duration": 9.368003368377686, "step": 67945}
{"episode_reward": 16.54543335056352, "episode": 2168.0, "batch_reward": -0.07078208844177425, "critic_loss": 0.628337025642395, "ae_transition_loss": 1.8492836654186249, "ae_encoder_loss": 0.8626549988985062, "actor_loss": -0.34293345734477043, "actor_target_entropy": -2.0, "actor_entropy": -0.9374767243862152, "alpha_loss": -0.002927730471128598, "alpha_value": 0.003900760127754168, "duration": 8.754893064498901, "step": 67987}
{"episode_reward": 14.20293568711675, "episode": 2169.0, "batch_reward": -0.04978889280131885, "critic_loss": 0.6086431230817523, "ae_transition_loss": 1.6615000792912074, "ae_encoder_loss": 0.776081668479102, "actor_loss": -0.5543520088706698, "actor_target_entropy": -2.0, "actor_entropy": -0.9609420895576477, "alpha_loss": -0.002555868089465158, "alpha_value": 0.0039164951261293195, "duration": 14.624811172485352, "step": 68056}
{"episode_reward": 21.76274197964327, "episode": 2170.0, "batch_reward": -0.05171910699989114, "critic_loss": 0.7011183713163648, "ae_transition_loss": 1.5785751513072424, "ae_encoder_loss": 0.9108579201357705, "actor_loss": -0.6270090171269008, "actor_target_entropy": -2.0, "actor_entropy": -0.9509707689285278, "alpha_loss": -0.0027127949121807304, "alpha_value": 0.003937440653387653, "duration": 14.428041696548462, "step": 68127}
{"episode_reward": 18.600159656947, "episode": 2171.0, "duration": 45.763312339782715, "step": 68128}
{"episode_reward": -3.5597180429339206, "episode": 2172.0, "batch_reward": -0.02321152723229983, "critic_loss": 0.847800810547436, "ae_transition_loss": 1.8458983757916618, "ae_encoder_loss": 1.4549969294491936, "actor_loss": -0.6592157290262335, "actor_target_entropy": -2.0, "actor_entropy": -0.9145994396770701, "alpha_loss": -0.0023138421409599043, "alpha_value": 0.003972766962068875, "duration": 33.75882935523987, "step": 68291}
{"episode_reward": 42.378441672042754, "episode": 2173.0, "batch_reward": -0.03406631566273669, "critic_loss": 0.7801856795946757, "ae_transition_loss": 1.988230327765147, "ae_encoder_loss": 2.864560047785441, "actor_loss": -0.6526732742786407, "actor_target_entropy": -2.0, "actor_entropy": -0.8007693787415823, "alpha_loss": -0.00169136681749175, "alpha_value": 0.004005558616297402, "duration": 12.471934080123901, "step": 68352}
{"episode_reward": 17.952895633241212, "episode": 2174.0, "batch_reward": -0.029653971393903095, "critic_loss": 0.487752765417099, "ae_transition_loss": 2.1220784187316895, "ae_encoder_loss": 3.845094680786133, "actor_loss": -0.8064129749933878, "actor_target_entropy": -2.0, "actor_entropy": -0.9120844205220541, "alpha_loss": -0.0013698724020893376, "alpha_value": 0.004016912507780409, "duration": 6.235764265060425, "step": 68382}
{"episode_reward": 3.627707123899702, "episode": 2175.0, "batch_reward": -0.014906411059200764, "critic_loss": 0.5919139981269836, "ae_transition_loss": 1.9618374109268188, "ae_encoder_loss": 3.694608449935913, "actor_loss": -0.6401375532150269, "actor_target_entropy": -2.0, "actor_entropy": -0.7730055451393127, "alpha_loss": -0.0021218457259237766, "alpha_value": 0.004021435908188387, "duration": 3.3646044731140137, "step": 68398}
{"episode_reward": 0.377348312312298, "episode": 2176.0, "batch_reward": -0.0029468356321255365, "critic_loss": 0.7576508720715841, "ae_transition_loss": 2.0494295358657837, "ae_encoder_loss": 2.0353513956069946, "actor_loss": -0.8903573155403137, "actor_target_entropy": -2.0, "actor_entropy": -0.9052656888961792, "alpha_loss": -0.002004426826412479, "alpha_value": 0.004025951680316505, "duration": 4.978898048400879, "step": 68421}
{"episode_reward": 4.586226958928444, "episode": 2177.0, "batch_reward": -0.022706810384988785, "critic_loss": 0.7284312844276428, "ae_transition_loss": 1.9872872829437256, "ae_encoder_loss": 1.222111999988556, "actor_loss": -0.8101544380187988, "actor_target_entropy": -2.0, "actor_entropy": -0.9110453426837921, "alpha_loss": -0.0019126883707940578, "alpha_value": 0.004031719708799881, "duration": 5.552742958068848, "step": 68450}
{"episode_reward": 6.465343398108988, "episode": 2178.0, "batch_reward": 0.027431908374031384, "critic_loss": 0.9356141289075216, "ae_transition_loss": 1.9955006837844849, "ae_encoder_loss": 0.9080923199653625, "actor_loss": -0.8222525318463644, "actor_target_entropy": -2.0, "actor_entropy": -0.9472175240516663, "alpha_loss": -0.0017685598771398265, "alpha_value": 0.004037524643320335, "duration": 5.567702054977417, "step": 68477}
{"episode_reward": 4.344929001399403, "episode": 2179.0, "batch_reward": -0.011767460033297539, "critic_loss": 0.6190546452999115, "ae_transition_loss": 1.923173725605011, "ae_encoder_loss": 0.917595624923706, "actor_loss": -1.0299082398414612, "actor_target_entropy": -2.0, "actor_entropy": -0.9534075856208801, "alpha_loss": -0.002425535349175334, "alpha_value": 0.004043269079628341, "duration": 3.177694320678711, "step": 68491}
{"episode_reward": 1.4723529441366119, "episode": 2180.0, "batch_reward": -0.02215631096623838, "critic_loss": 0.9139339327812195, "ae_transition_loss": 2.0129906833171844, "ae_encoder_loss": 0.7112634778022766, "actor_loss": -0.9610389471054077, "actor_target_entropy": -2.0, "actor_entropy": -0.9795055836439133, "alpha_loss": -0.0018830650369636714, "alpha_value": 0.004050398450166341, "duration": 8.159923553466797, "step": 68531}
{"episode_reward": 9.730209737193316, "episode": 2181.0, "batch_reward": -0.026374585181474685, "critic_loss": 0.7477314352989197, "ae_transition_loss": 1.8396114826202392, "ae_encoder_loss": 0.7119306564331055, "actor_loss": -0.7689740180969238, "actor_target_entropy": -2.0, "actor_entropy": -1.0085939168930054, "alpha_loss": -0.0030850930605083706, "alpha_value": 0.00406145461518931, "duration": 62.68753719329834, "step": 68582}
{"episode_reward": 13.602979186234823, "episode": 2182.0, "duration": 0.18651056289672852, "step": 68583}
{"episode_reward": 0.38089639404622605, "episode": 2183.0, "batch_reward": -0.04287481866776943, "critic_loss": 0.7413618862628937, "ae_transition_loss": 1.8044055104255676, "ae_encoder_loss": 0.5658917874097824, "actor_loss": -0.6588605046272278, "actor_target_entropy": -2.0, "actor_entropy": -1.1400905847549438, "alpha_loss": -0.002636061515659094, "alpha_value": 0.004071408603432012, "duration": 4.711377859115601, "step": 68606}
{"episode_reward": 3.0340668233836414, "episode": 2184.0, "batch_reward": -0.05562867969274521, "critic_loss": 1.18043851852417, "ae_transition_loss": 1.7454919815063477, "ae_encoder_loss": 0.5677019357681274, "actor_loss": -0.5142814964056015, "actor_target_entropy": -2.0, "actor_entropy": -1.0856375098228455, "alpha_loss": -0.0035155145451426506, "alpha_value": 0.0040775984090594165, "duration": 3.708380937576294, "step": 68624}
{"episode_reward": -0.5687762050433531, "episode": 2185.0, "duration": 0.2070751190185547, "step": 68625}
{"episode_reward": 0.3765360273032583, "episode": 2186.0, "batch_reward": -0.014218956232070923, "critic_loss": 0.8358882665634155, "ae_transition_loss": 1.6373271544774373, "ae_encoder_loss": 0.4600379367669423, "actor_loss": -0.8428795536359152, "actor_target_entropy": -2.0, "actor_entropy": -1.1995192766189575, "alpha_loss": -0.0036807795986533165, "alpha_value": 0.004085910636158655, "duration": 6.10178017616272, "step": 68654}
{"episode_reward": 5.726261614376724, "episode": 2187.0, "duration": 0.2299337387084961, "step": 68655}
{"episode_reward": -0.2273795808453863, "episode": 2188.0, "duration": 0.8437085151672363, "step": 68658}
{"episode_reward": -1.046309151897802, "episode": 2189.0, "batch_reward": -0.02353968347112338, "critic_loss": 0.495341678460439, "ae_transition_loss": 1.485763390858968, "ae_encoder_loss": 0.5468801160653433, "actor_loss": -0.8317597508430481, "actor_target_entropy": -2.0, "actor_entropy": -1.2548491954803467, "alpha_loss": -0.0039634905600299435, "alpha_value": 0.004096960471264941, "duration": 5.155317544937134, "step": 68683}
{"episode_reward": 3.6098786154626166, "episode": 2190.0, "duration": 0.203139066696167, "step": 68684}
{"episode_reward": 0.08848897274846612, "episode": 2191.0, "batch_reward": -0.062022688682191074, "critic_loss": 0.588982880115509, "ae_transition_loss": 1.724293291568756, "ae_encoder_loss": 0.4978514462709427, "actor_loss": -0.8463249802589417, "actor_target_entropy": -2.0, "actor_entropy": -1.3285382390022278, "alpha_loss": -0.003306307829916477, "alpha_value": 0.004110836948064376, "duration": 82.03697967529297, "step": 68730}
{"episode_reward": 8.243093061180781, "episode": 2192.0, "batch_reward": -0.019275724329054354, "critic_loss": 0.9358351767063141, "ae_transition_loss": 1.4597259998321532, "ae_encoder_loss": 0.5276394605636596, "actor_loss": -0.7115061998367309, "actor_target_entropy": -2.0, "actor_entropy": -1.2562324047088622, "alpha_loss": -0.0032247676514089107, "alpha_value": 0.004128921845386621, "duration": 9.759635925292969, "step": 68778}
{"episode_reward": 14.361880533756333, "episode": 2193.0, "batch_reward": -0.06922619013736646, "critic_loss": 0.9084155956904093, "ae_transition_loss": 1.6966788172721863, "ae_encoder_loss": 0.5834712435801824, "actor_loss": -0.6460308382908503, "actor_target_entropy": -2.0, "actor_entropy": -1.1702501277128856, "alpha_loss": -0.0033852665219455957, "alpha_value": 0.00415114522768096, "duration": 11.49268889427185, "step": 68834}
{"episode_reward": 14.476603390881252, "episode": 2194.0, "batch_reward": -0.012229384233554205, "critic_loss": 0.6441253423690796, "ae_transition_loss": 1.5116657416025798, "ae_encoder_loss": 0.5702828665574392, "actor_loss": -0.9112753868103027, "actor_target_entropy": -2.0, "actor_entropy": -1.066315472126007, "alpha_loss": -0.003764476627111435, "alpha_value": 0.004169721832737008, "duration": 5.95227313041687, "step": 68862}
{"episode_reward": 5.1768358381695965, "episode": 2195.0, "batch_reward": -0.052856920287013054, "critic_loss": 0.7480958700180054, "ae_transition_loss": 1.715513825416565, "ae_encoder_loss": 0.8131618897120158, "actor_loss": -0.8035462896029154, "actor_target_entropy": -2.0, "actor_entropy": -1.2150246302286785, "alpha_loss": -0.004270306322723627, "alpha_value": 0.004182794779549947, "duration": 6.033499717712402, "step": 68891}
{"episode_reward": 5.40936481702483, "episode": 2196.0, "duration": 1.7087652683258057, "step": 68900}
{"episode_reward": -1.8170477407017718, "episode": 2197.0, "batch_reward": -0.07151492685079575, "critic_loss": 0.7214463651180267, "ae_transition_loss": 1.5590668320655823, "ae_encoder_loss": 0.820243239402771, "actor_loss": -0.5124699771404266, "actor_target_entropy": -2.0, "actor_entropy": -1.0069971084594727, "alpha_loss": -0.00313426461070776, "alpha_value": 0.004194122888955056, "duration": 2.8636951446533203, "step": 68912}
{"episode_reward": -0.7908287669235535, "episode": 2198.0, "batch_reward": -0.023817289620637894, "critic_loss": 0.3861589878797531, "ae_transition_loss": 1.462722897529602, "ae_encoder_loss": 0.8420582413673401, "actor_loss": -0.6641855388879776, "actor_target_entropy": -2.0, "actor_entropy": -0.9927433729171753, "alpha_loss": -0.005061134696006775, "alpha_value": 0.004203182731731826, "duration": 4.431916236877441, "step": 68934}
{"episode_reward": 0.6556375002721687, "episode": 2199.0, "duration": 0.22551727294921875, "step": 68935}
{"episode_reward": -0.7979409694671631, "episode": 2200.0, "batch_reward": -0.01081806824853023, "critic_loss": 0.5486541291077932, "ae_transition_loss": 1.4938161373138428, "ae_encoder_loss": 0.6644024054209391, "actor_loss": -0.9562652707099915, "actor_target_entropy": -2.0, "actor_entropy": -1.1675464709599812, "alpha_loss": -0.004091023933142424, "alpha_value": 0.004215196147388976, "duration": 5.642328262329102, "step": 68961}
{"episode_reward": 0.8947378123421232, "episode": 2201.0, "batch_reward": -0.04928744211792946, "critic_loss": 0.9437304139137268, "ae_transition_loss": 2.309694528579712, "ae_encoder_loss": 0.7922687232494354, "actor_loss": -0.630657285451889, "actor_target_entropy": -2.0, "actor_entropy": -1.1231607794761658, "alpha_loss": -0.004040302010253072, "alpha_value": 0.004227511426331727, "duration": 54.41171622276306, "step": 68988}
{"episode_reward": 2.5362961771308874, "episode": 2202.0, "duration": 0.22778058052062988, "step": 68989}
{"episode_reward": 0.05480062970021632, "episode": 2203.0, "batch_reward": -0.0015142833193143208, "critic_loss": 0.47764724493026733, "ae_transition_loss": 1.4871360063552856, "ae_encoder_loss": 0.7694078087806702, "actor_loss": -1.0444699327150981, "actor_target_entropy": -2.0, "actor_entropy": -1.0530527432759602, "alpha_loss": -0.0036694930555919805, "alpha_value": 0.0042400263074066505, "duration": 6.703624963760376, "step": 69020}
{"episode_reward": 3.4208011482703484, "episode": 2204.0, "batch_reward": -0.07687072828412056, "critic_loss": 0.5259118676185608, "ae_transition_loss": 1.5956093072891235, "ae_encoder_loss": 0.8190069397290548, "actor_loss": -0.5665909051895142, "actor_target_entropy": -2.0, "actor_entropy": -0.9490280946095785, "alpha_loss": -0.0039957565410683555, "alpha_value": 0.00425513913765783, "duration": 5.227997064590454, "step": 69043}
{"episode_reward": 3.110590666553343, "episode": 2205.0, "duration": 0.21276521682739258, "step": 69044}
{"episode_reward": -0.7154960632324219, "episode": 2206.0, "batch_reward": -0.0216022334061563, "critic_loss": 0.6552828401327133, "ae_transition_loss": 1.6822680234909058, "ae_encoder_loss": 0.6567588746547699, "actor_loss": -0.6186472475528717, "actor_target_entropy": -2.0, "actor_entropy": -0.9214221835136414, "alpha_loss": -0.002522732422221452, "alpha_value": 0.004267708037601972, "duration": 5.244653701782227, "step": 69067}
{"episode_reward": 3.1458000306325227, "episode": 2207.0, "batch_reward": -0.007844108467300734, "critic_loss": 0.6824626525243124, "ae_transition_loss": 1.6757047176361084, "ae_encoder_loss": 0.7427635391553243, "actor_loss": -0.6757054924964905, "actor_target_entropy": -2.0, "actor_entropy": -0.8408927718798319, "alpha_loss": -0.004029839454839627, "alpha_value": 0.004279478861174263, "duration": 6.0859057903289795, "step": 69096}
{"episode_reward": 3.4830567121273632, "episode": 2208.0, "batch_reward": -0.007786288236578305, "critic_loss": 0.799937923749288, "ae_transition_loss": 1.5799576838811238, "ae_encoder_loss": 0.7314267158508301, "actor_loss": -0.8681275447209676, "actor_target_entropy": -2.0, "actor_entropy": -1.0290889739990234, "alpha_loss": -0.0035793640029927096, "alpha_value": 0.0042937110255022596, "duration": 5.894625425338745, "step": 69123}
{"episode_reward": 2.3893404031569947, "episode": 2209.0, "batch_reward": -0.04168657785547631, "critic_loss": 0.7924398566995349, "ae_transition_loss": 1.7923648868288313, "ae_encoder_loss": 0.793236472776958, "actor_loss": -0.8091065287590027, "actor_target_entropy": -2.0, "actor_entropy": -0.9518471530505589, "alpha_loss": -0.0029306584370455573, "alpha_value": 0.004316774214993509, "duration": 14.951945543289185, "step": 69194}
{"episode_reward": -1.0150206703285864, "episode": 2210.0, "batch_reward": -0.011865641921758652, "critic_loss": 0.3992658853530884, "ae_transition_loss": 1.5511605739593506, "ae_encoder_loss": 0.707509458065033, "actor_loss": -1.034315824508667, "actor_target_entropy": -2.0, "actor_entropy": -0.9126685261726379, "alpha_loss": -0.003899670671671629, "alpha_value": 0.004334386707321027, "duration": 2.3808939456939697, "step": 69204}
{"episode_reward": -0.9447407974206077, "episode": 2211.0, "duration": 63.399566888809204, "step": 69205}
{"episode_reward": -0.9770221814925181, "episode": 2212.0, "batch_reward": -0.025397910053531328, "critic_loss": 0.7968367914358775, "ae_transition_loss": 1.5469687620798747, "ae_encoder_loss": 0.7149813214937846, "actor_loss": -0.8391563951969147, "actor_target_entropy": -2.0, "actor_entropy": -0.9863348325093587, "alpha_loss": -0.002359608622888724, "alpha_value": 0.004368016257112779, "duration": 31.763739585876465, "step": 69360}
{"episode_reward": 42.1783674435704, "episode": 2213.0, "batch_reward": -0.022462736659993727, "critic_loss": 0.7995356321334839, "ae_transition_loss": 1.5496654510498047, "ae_encoder_loss": 0.6941591103871664, "actor_loss": -0.7727575898170471, "actor_target_entropy": -2.0, "actor_entropy": -0.9831200242042542, "alpha_loss": -0.0010164521324137847, "alpha_value": 0.004400202128021325, "duration": 4.782343149185181, "step": 69382}
{"episode_reward": 2.5076288461100225, "episode": 2214.0, "batch_reward": -0.03929281607270241, "critic_loss": 0.7148048082987467, "ae_transition_loss": 1.5344988505045574, "ae_encoder_loss": 0.7064709862073263, "actor_loss": -0.9806731740633646, "actor_target_entropy": -2.0, "actor_entropy": -0.9804544647534689, "alpha_loss": -0.0018495297990739346, "alpha_value": 0.004408110122124435, "duration": 7.581374406814575, "step": 69419}
{"episode_reward": 8.817571489120809, "episode": 2215.0, "batch_reward": 0.029359765350818634, "critic_loss": 0.47194886207580566, "ae_transition_loss": 1.4943001866340637, "ae_encoder_loss": 0.8790318667888641, "actor_loss": -1.2750110626220703, "actor_target_entropy": -2.0, "actor_entropy": -0.9444003999233246, "alpha_loss": -0.0007508479175157845, "alpha_value": 0.0044143984479399975, "duration": 3.067490816116333, "step": 69433}
{"episode_reward": -1.0997895555244364, "episode": 2216.0, "batch_reward": -0.020314013585448265, "critic_loss": 0.4984310567378998, "ae_transition_loss": 1.7650476098060608, "ae_encoder_loss": 0.6371726989746094, "actor_loss": -0.8686534762382507, "actor_target_entropy": -2.0, "actor_entropy": -0.8928971588611603, "alpha_loss": -0.0025679873069748282, "alpha_value": 0.004418995568929787, "duration": 4.511900186538696, "step": 69455}
{"episode_reward": -0.28238038638525903, "episode": 2217.0, "batch_reward": -0.07854755595326424, "critic_loss": 0.7190798223018646, "ae_transition_loss": 1.6636655926704407, "ae_encoder_loss": 0.5354318767786026, "actor_loss": -0.5846200734376907, "actor_target_entropy": -2.0, "actor_entropy": -0.7632274925708771, "alpha_loss": -0.0015606031520292163, "alpha_value": 0.004423907256088635, "duration": 3.5270016193389893, "step": 69471}
{"episode_reward": -1.8378035061271845, "episode": 2218.0, "batch_reward": -0.1208103597164154, "critic_loss": 0.49288442730903625, "ae_transition_loss": 2.2075276374816895, "ae_encoder_loss": 0.6336474418640137, "actor_loss": -0.6660374999046326, "actor_target_entropy": -2.0, "actor_entropy": -0.577003002166748, "alpha_loss": -0.0030154779087752104, "alpha_value": 0.004427572593994077, "duration": 3.0926599502563477, "step": 69487}
{"episode_reward": -2.3011703901442213, "episode": 2219.0, "batch_reward": 0.029517866671085358, "critic_loss": 0.6865241527557373, "ae_transition_loss": 1.820292353630066, "ae_encoder_loss": 0.900418221950531, "actor_loss": -1.2845948934555054, "actor_target_entropy": -2.0, "actor_entropy": -0.48793312907218933, "alpha_loss": -0.0005153432721272111, "alpha_value": 0.0044301636456659955, "duration": 1.3232910633087158, "step": 69492}
{"episode_reward": -1.9546711413294027, "episode": 2220.0, "batch_reward": 0.06545385345816612, "critic_loss": 0.949016198515892, "ae_transition_loss": 1.6510282158851624, "ae_encoder_loss": 0.610643595457077, "actor_loss": -1.3212003111839294, "actor_target_entropy": -2.0, "actor_entropy": -0.6186536848545074, "alpha_loss": -0.0015664493257645518, "alpha_value": 0.004433835059226689, "duration": 3.9689900875091553, "step": 69512}
{"episode_reward": -3.248439805954076, "episode": 2221.0, "batch_reward": -0.04519869387149811, "critic_loss": 1.5566533009211223, "ae_transition_loss": 1.6120134592056274, "ae_encoder_loss": 0.7796200513839722, "actor_loss": -0.4694107671578725, "actor_target_entropy": -2.0, "actor_entropy": -0.941591719786326, "alpha_loss": -0.0015377025119960308, "alpha_value": 0.004439776482801036, "duration": 80.99914860725403, "step": 69548}
{"episode_reward": 5.90258742094461, "episode": 2222.0, "batch_reward": 0.006047275538245837, "critic_loss": 0.9027911076943079, "ae_transition_loss": 1.6522773901621501, "ae_encoder_loss": 0.7681388854980469, "actor_loss": -0.8709694743156433, "actor_target_entropy": -2.0, "actor_entropy": -1.0701300700505574, "alpha_loss": -0.002028058404296947, "alpha_value": 0.004449959011927045, "duration": 10.96639895439148, "step": 69602}
{"episode_reward": 17.276559590735616, "episode": 2223.0, "batch_reward": -0.11198118329048157, "critic_loss": 1.3287169337272644, "ae_transition_loss": 1.908900260925293, "ae_encoder_loss": 1.4343780279159546, "actor_loss": -0.4527759552001953, "actor_target_entropy": -2.0, "actor_entropy": -1.135607898235321, "alpha_loss": -0.002645965665578842, "alpha_value": 0.004459711758438273, "duration": 5.5134193897247314, "step": 69629}
{"episode_reward": 5.998382007244526, "episode": 2224.0, "batch_reward": -0.07011683285236359, "critic_loss": 0.5001275539398193, "ae_transition_loss": 1.5689479112625122, "ae_encoder_loss": 1.3764044046401978, "actor_loss": -0.8848896622657776, "actor_target_entropy": -2.0, "actor_entropy": -1.134162187576294, "alpha_loss": -0.0030972915701568127, "alpha_value": 0.004463741716822898, "duration": 2.0516772270202637, "step": 69639}
{"episode_reward": -1.3735883087360847, "episode": 2225.0, "batch_reward": 0.0029158887142936387, "critic_loss": 0.7696642676989237, "ae_transition_loss": 1.7593834797541301, "ae_encoder_loss": 1.4915755987167358, "actor_loss": -0.8992896477381388, "actor_target_entropy": -2.0, "actor_entropy": -1.071476697921753, "alpha_loss": -0.003194580553099513, "alpha_value": 0.004469689392158302, "duration": 4.954038858413696, "step": 69662}
{"episode_reward": 1.6666483693091036, "episode": 2226.0, "duration": 1.0532596111297607, "step": 69667}
{"episode_reward": -1.1844481742033257, "episode": 2227.0, "batch_reward": -0.017644178587943316, "critic_loss": 1.592673122882843, "ae_transition_loss": 1.7620327472686768, "ae_encoder_loss": 0.8714064061641693, "actor_loss": -0.6888389140367508, "actor_target_entropy": -2.0, "actor_entropy": -1.0363113284111023, "alpha_loss": -0.0024518705322407186, "alpha_value": 0.004477646114340426, "duration": 3.3939504623413086, "step": 69683}
{"episode_reward": -1.1528022488056022, "episode": 2228.0, "batch_reward": -0.036633643632133804, "critic_loss": 1.173174411058426, "ae_transition_loss": 2.0360976258913674, "ae_encoder_loss": 1.2698585391044617, "actor_loss": -0.7629273931185404, "actor_target_entropy": -2.0, "actor_entropy": -0.9642403423786163, "alpha_loss": -0.0018843974685296416, "alpha_value": 0.004490202481775253, "duration": 12.700740098953247, "step": 69746}
{"episode_reward": 13.611782168342515, "episode": 2229.0, "batch_reward": -0.005769897252321243, "critic_loss": 1.170979619026184, "ae_transition_loss": 1.876649022102356, "ae_encoder_loss": 1.6385283470153809, "actor_loss": -0.9432719945907593, "actor_target_entropy": -2.0, "actor_entropy": -0.8975991606712341, "alpha_loss": -0.002657698467373848, "alpha_value": 0.004500711205275429, "duration": 2.9329495429992676, "step": 69760}
{"episode_reward": -0.986260831161769, "episode": 2230.0, "batch_reward": -0.05558277294039726, "critic_loss": 0.9488446513811747, "ae_transition_loss": 1.9710809191068013, "ae_encoder_loss": 2.00605579217275, "actor_loss": -0.6529295245806376, "actor_target_entropy": -2.0, "actor_entropy": -0.8660419483979543, "alpha_loss": -0.0016433697989365708, "alpha_value": 0.0045112747531122765, "duration": 10.489213228225708, "step": 69812}
{"episode_reward": 7.047675593408861, "episode": 2231.0, "batch_reward": -0.009009383386000991, "critic_loss": 1.0174011886119843, "ae_transition_loss": 1.9925569593906403, "ae_encoder_loss": 1.5705892741680145, "actor_loss": -0.7773284614086151, "actor_target_entropy": -2.0, "actor_entropy": -0.7873826324939728, "alpha_loss": -0.0007193965502665378, "alpha_value": 0.004524843603350842, "duration": 48.170429944992065, "step": 69857}
{"episode_reward": 7.950370379015368, "episode": 2232.0, "duration": 0.21938014030456543, "step": 69858}
{"episode_reward": -1.3274407632057372, "episode": 2233.0, "batch_reward": -0.0033018181824849713, "critic_loss": 0.9373632702562544, "ae_transition_loss": 1.7280811601214938, "ae_encoder_loss": 0.6163058231274287, "actor_loss": -1.0113269885381062, "actor_target_entropy": -2.0, "actor_entropy": -0.5943339715401331, "alpha_loss": -0.0018233027917125986, "alpha_value": 0.004549965665388279, "duration": 40.97740054130554, "step": 70032}
{"episode_reward": -3.9654294705496436, "episode": 2234.0, "batch_reward": -0.01965461391955614, "critic_loss": 0.9014299511909485, "ae_transition_loss": 1.5220710039138794, "ae_encoder_loss": 0.7371284365653992, "actor_loss": -0.8832370042800903, "actor_target_entropy": -2.0, "actor_entropy": -0.6809526979923248, "alpha_loss": -0.0024739147629588842, "alpha_value": 0.004573994000352572, "duration": 5.426683187484741, "step": 70058}
{"episode_reward": 2.0935546976177513, "episode": 2235.0, "batch_reward": -0.019689522683620453, "critic_loss": 0.33975788950920105, "ae_transition_loss": 1.4667693376541138, "ae_encoder_loss": 0.5570390820503235, "actor_loss": -1.1379222869873047, "actor_target_entropy": -2.0, "actor_entropy": -0.7512844204902649, "alpha_loss": -0.0016247646417468786, "alpha_value": 0.004578056672847571, "duration": 2.1039137840270996, "step": 70067}
{"episode_reward": -1.6663334676014872, "episode": 2236.0, "batch_reward": -0.10629206523299217, "critic_loss": 0.7451016008853912, "ae_transition_loss": 1.519140601158142, "ae_encoder_loss": 0.557576447725296, "actor_loss": -0.9035999476909637, "actor_target_entropy": -2.0, "actor_entropy": -0.7514613270759583, "alpha_loss": -0.002381516504101455, "alpha_value": 0.004582111447936592, "duration": 4.65552282333374, "step": 70089}
{"episode_reward": -1.5307939799857768, "episode": 2237.0, "duration": 0.2625539302825928, "step": 70090}
{"episode_reward": -0.8953594775566676, "episode": 2238.0, "batch_reward": -0.039691393822431566, "critic_loss": 1.169215875864029, "ae_transition_loss": 1.4885912895202638, "ae_encoder_loss": 0.6156431317329407, "actor_loss": -0.9460746765136718, "actor_target_entropy": -2.0, "actor_entropy": -0.7910665154457093, "alpha_loss": -0.002271424001082778, "alpha_value": 0.0045923626697312115, "duration": 10.989060640335083, "step": 70139}
{"episode_reward": 5.711604231526228, "episode": 2239.0, "batch_reward": -0.034618777355977466, "critic_loss": 1.0512351053101676, "ae_transition_loss": 1.4217734336853027, "ae_encoder_loss": 0.552434082542147, "actor_loss": -0.9217565315110343, "actor_target_entropy": -2.0, "actor_entropy": -0.8630466972078595, "alpha_loss": -0.0022352961490729024, "alpha_value": 0.004610736388755152, "duration": 13.29657506942749, "step": 70202}
{"episode_reward": 10.188987199763156, "episode": 2240.0, "batch_reward": -0.08082206174731255, "critic_loss": 0.829935610294342, "ae_transition_loss": 1.4778311848640442, "ae_encoder_loss": 0.6645036935806274, "actor_loss": -0.6907425969839096, "actor_target_entropy": -2.0, "actor_entropy": -0.8285310566425323, "alpha_loss": -0.001635782653465867, "alpha_value": 0.004624668840904194, "duration": 4.470889329910278, "step": 70223}
{"episode_reward": 0.8659561726493689, "episode": 2241.0, "batch_reward": -0.035972468089312315, "critic_loss": 0.8102929592132568, "ae_transition_loss": 1.4182530045509338, "ae_encoder_loss": 0.7485325783491135, "actor_loss": -0.7626843005418777, "actor_target_entropy": -2.0, "actor_entropy": -0.7542638182640076, "alpha_loss": -0.001029186518280767, "alpha_value": 0.004632768078676374, "duration": 50.31187176704407, "step": 70266}
{"episode_reward": 8.489084949841033, "episode": 2242.0, "batch_reward": -0.03247858149309953, "critic_loss": 0.7862714926401774, "ae_transition_loss": 1.761796514193217, "ae_encoder_loss": 0.9071790476640066, "actor_loss": -0.6677433873216311, "actor_target_entropy": -2.0, "actor_entropy": -0.7663034101327261, "alpha_loss": -0.0006642014971779039, "alpha_value": 0.0046442962757064984, "duration": 11.8958580493927, "step": 70325}
{"episode_reward": 19.98481344130629, "episode": 2243.0, "batch_reward": 0.02741354238241911, "critic_loss": 0.6839006990194321, "ae_transition_loss": 1.5167409777641296, "ae_encoder_loss": 0.6916062086820602, "actor_loss": -1.0467214584350586, "actor_target_entropy": -2.0, "actor_entropy": -0.6392156481742859, "alpha_loss": -0.0006494252302218229, "alpha_value": 0.004653177753090841, "duration": 8.899929285049438, "step": 70368}
{"episode_reward": 14.797691951780193, "episode": 2244.0, "batch_reward": -0.019180235918611288, "critic_loss": 0.766762875020504, "ae_transition_loss": 1.7672696560621262, "ae_encoder_loss": 0.8111493140459061, "actor_loss": -0.8819536566734314, "actor_target_entropy": -2.0, "actor_entropy": -0.6976514309644699, "alpha_loss": -0.00046766620653215796, "alpha_value": 0.00466154935770385, "duration": 15.711737871170044, "step": 70447}
{"episode_reward": 36.463157389213784, "episode": 2245.0, "batch_reward": -0.03361609258822033, "critic_loss": 0.9077185051781791, "ae_transition_loss": 1.9530641862324305, "ae_encoder_loss": 0.8822481802531651, "actor_loss": -0.8503976208823067, "actor_target_entropy": -2.0, "actor_entropy": -0.7520714742796761, "alpha_loss": -0.00029785610136709044, "alpha_value": 0.004669432043139181, "duration": 13.907870054244995, "step": 70515}
{"episode_reward": 25.43912112247463, "episode": 2246.0, "batch_reward": -0.023209605272859334, "critic_loss": 0.8110834240913392, "ae_transition_loss": 1.7937117099761963, "ae_encoder_loss": 0.7523773968219757, "actor_loss": -0.8097209602594375, "actor_target_entropy": -2.0, "actor_entropy": -0.641756820678711, "alpha_loss": 0.0003121467249002308, "alpha_value": 0.004674252741687206, "duration": 20.603474855422974, "step": 70619}
{"episode_reward": 40.70290646447911, "episode": 2247.0, "batch_reward": -0.05738045492519935, "critic_loss": 0.8546755015850067, "ae_transition_loss": 1.7489997744560242, "ae_encoder_loss": 1.0054046511650085, "actor_loss": -0.9733960131804148, "actor_target_entropy": -2.0, "actor_entropy": -0.5749989748001099, "alpha_loss": 0.0005778723279945552, "alpha_value": 0.004673891200800109, "duration": 11.37850022315979, "step": 70673}
{"episode_reward": 21.106764155624177, "episode": 2248.0, "batch_reward": -0.007798377387225628, "critic_loss": 0.7607833474874497, "ae_transition_loss": 1.7594575834274293, "ae_encoder_loss": 0.7048269891738892, "actor_loss": -1.007387206554413, "actor_target_entropy": -2.0, "actor_entropy": -0.5565446305274964, "alpha_loss": -0.00015162306022830307, "alpha_value": 0.004671598116466507, "duration": 50.34905004501343, "step": 70922}
{"episode_reward": -5.349026957582964, "episode": 2249.0, "batch_reward": -0.011550756357610225, "critic_loss": 0.7085110425949097, "ae_transition_loss": 1.7219948530197144, "ae_encoder_loss": 0.8263012528419494, "actor_loss": -0.9935742139816284, "actor_target_entropy": -2.0, "actor_entropy": -0.4206533133983612, "alpha_loss": 0.00032597712124697863, "alpha_value": 0.004674803019817502, "duration": 11.036078691482544, "step": 70976}
{"episode_reward": 15.562876952963077, "episode": 2250.0, "batch_reward": -0.02324492111802101, "critic_loss": 1.0503491844449724, "ae_transition_loss": 2.296814663069589, "ae_encoder_loss": 1.207220801285335, "actor_loss": -0.8721276095935276, "actor_target_entropy": -2.0, "actor_entropy": -0.45533454418182373, "alpha_loss": -0.00021031392056361904, "alpha_value": 0.004673951920124371, "duration": 14.807588577270508, "step": 71047}
{"episode_reward": 20.178835181859448, "episode": 2251.0, "duration": 91.89601445198059, "step": 71048}
{"episode_reward": -0.1998841017484665, "episode": 2252.0, "batch_reward": -0.09391061961650848, "critic_loss": 0.7718075513839722, "ae_transition_loss": 2.1032623648643494, "ae_encoder_loss": 3.894960403442383, "actor_loss": -0.5196676813066006, "actor_target_entropy": -2.0, "actor_entropy": -0.36633583158254623, "alpha_loss": -0.000452668231446296, "alpha_value": 0.004674423087338087, "duration": 8.515788793563843, "step": 71089}
{"episode_reward": 6.63017841360411, "episode": 2253.0, "duration": 0.21978545188903809, "step": 71090}
{"episode_reward": -0.5935192289744801, "episode": 2254.0, "batch_reward": -0.023918949267161742, "critic_loss": 1.9286686437470573, "ae_transition_loss": 2.3006334134510587, "ae_encoder_loss": 4.7020657403128485, "actor_loss": -0.5245109700730869, "actor_target_entropy": -2.0, "actor_entropy": -0.31380695583564894, "alpha_loss": 0.00032180443148328256, "alpha_value": 0.004674109207470935, "duration": 28.211713314056396, "step": 71229}
{"episode_reward": 34.981411443154606, "episode": 2255.0, "batch_reward": -0.026606790721416473, "critic_loss": 3.5684943993886313, "ae_transition_loss": 2.249260743459066, "ae_encoder_loss": 1.4546185731887817, "actor_loss": -0.6381997168064117, "actor_target_entropy": -2.0, "actor_entropy": 0.20114926745494208, "alpha_loss": 0.0008576009810591737, "alpha_value": 0.004672204115198989, "duration": 6.419767141342163, "step": 71259}
{"episode_reward": 3.78278269566711, "episode": 2256.0, "batch_reward": -0.05626395344734192, "critic_loss": 2.1568328738212585, "ae_transition_loss": 2.254151225090027, "ae_encoder_loss": 1.2162404656410217, "actor_loss": -0.8969014585018158, "actor_target_entropy": -2.0, "actor_entropy": 0.20429478585720062, "alpha_loss": 0.0006055278281564824, "alpha_value": 0.0046710825361936156, "duration": 3.799764394760132, "step": 71277}
{"episode_reward": -0.6295056250579851, "episode": 2257.0, "batch_reward": -0.031808731611818075, "critic_loss": 2.012951672077179, "ae_transition_loss": 2.233889639377594, "ae_encoder_loss": 0.8389267176389694, "actor_loss": -0.27277701906859875, "actor_target_entropy": -2.0, "actor_entropy": -0.526889244094491, "alpha_loss": -0.0012305792406550609, "alpha_value": 0.004669516801773851, "duration": 8.767753601074219, "step": 71319}
{"episode_reward": 14.39247980974263, "episode": 2258.0, "duration": 0.227783203125, "step": 71320}
{"episode_reward": -0.41041353254618884, "episode": 2259.0, "batch_reward": -0.00553130405023694, "critic_loss": 1.612016648054123, "ae_transition_loss": 2.21099990606308, "ae_encoder_loss": 0.7839232683181763, "actor_loss": -1.1396402269601822, "actor_target_entropy": -2.0, "actor_entropy": -1.0046851933002472, "alpha_loss": -0.002050222654361278, "alpha_value": 0.00467062984354437, "duration": 7.859960079193115, "step": 71358}
{"episode_reward": 9.925180374117183, "episode": 2260.0, "batch_reward": 0.02674128736058871, "critic_loss": 1.7834053834279378, "ae_transition_loss": 2.1876394748687744, "ae_encoder_loss": 0.6678822835286459, "actor_loss": -0.8474363287289938, "actor_target_entropy": -2.0, "actor_entropy": -1.1173505783081055, "alpha_loss": -0.0030537880957126617, "alpha_value": 0.004674986843077179, "duration": 5.972195625305176, "step": 71386}
{"episode_reward": 3.9125238094716908, "episode": 2261.0, "batch_reward": -0.0131831718608737, "critic_loss": 1.4950062831242878, "ae_transition_loss": 2.1618874867757163, "ae_encoder_loss": 0.5527106920878092, "actor_loss": -0.6232001384099325, "actor_target_entropy": -2.0, "actor_entropy": -1.1628165642420452, "alpha_loss": -0.003368636593222618, "alpha_value": 0.004681383384617981, "duration": 112.09105181694031, "step": 71411}
{"episode_reward": 2.920778218403182, "episode": 2262.0, "batch_reward": -0.044564252719283104, "critic_loss": 1.9501802325248718, "ae_transition_loss": 2.1213839054107666, "ae_encoder_loss": 0.6396905481815338, "actor_loss": -0.3976995646953583, "actor_target_entropy": -2.0, "actor_entropy": -1.1435602903366089, "alpha_loss": -0.003352613653987646, "alpha_value": 0.004688536002341522, "duration": 5.600020885467529, "step": 71439}
{"episode_reward": 7.199160783645547, "episode": 2263.0, "batch_reward": 0.04960976541042328, "critic_loss": 2.0137939453125, "ae_transition_loss": 2.102285385131836, "ae_encoder_loss": 0.7674861550331116, "actor_loss": -0.9807037711143494, "actor_target_entropy": -2.0, "actor_entropy": -1.1071233749389648, "alpha_loss": -0.0020144269801676273, "alpha_value": 0.004693488795980704, "duration": 2.163719654083252, "step": 71449}
{"episode_reward": -2.600156127530448, "episode": 2264.0, "batch_reward": -0.08413180708885193, "critic_loss": 1.379817008972168, "ae_transition_loss": 2.1187894344329834, "ae_encoder_loss": 0.5223891735076904, "actor_loss": -0.5468051433563232, "actor_target_entropy": -2.0, "actor_entropy": -1.121338963508606, "alpha_loss": -0.0034929770044982433, "alpha_value": 0.004696849710847878, "duration": 1.435767650604248, "step": 71455}
{"episode_reward": -3.140652759237639, "episode": 2265.0, "duration": 0.2279224395751953, "step": 71456}
{"episode_reward": 0.18719441471603293, "episode": 2266.0, "batch_reward": 0.014211964793503284, "critic_loss": 1.023165538907051, "ae_transition_loss": 2.0587547421455383, "ae_encoder_loss": 0.6668383032083511, "actor_loss": -1.1370986700057983, "actor_target_entropy": -2.0, "actor_entropy": -1.1229310035705566, "alpha_loss": -0.0030161149916239083, "alpha_value": 0.004705989101832026, "duration": 7.426486968994141, "step": 71491}
{"episode_reward": 3.8997449214060915, "episode": 2267.0, "batch_reward": -0.07344929128885269, "critic_loss": 2.0481154918670654, "ae_transition_loss": 2.1290931701660156, "ae_encoder_loss": 0.7529905438423157, "actor_loss": -1.0527737140655518, "actor_target_entropy": -2.0, "actor_entropy": -1.0253078937530518, "alpha_loss": -0.0031071340199559927, "alpha_value": 0.004715612780736884, "duration": 2.853158950805664, "step": 71505}
{"episode_reward": -2.237961561634803, "episode": 2268.0, "batch_reward": -0.00972619466483593, "critic_loss": 1.2006952464580536, "ae_transition_loss": 2.082188993692398, "ae_encoder_loss": 0.558663621544838, "actor_loss": -1.0224737375974655, "actor_target_entropy": -2.0, "actor_entropy": -0.9858289808034897, "alpha_loss": -0.003138532454613596, "alpha_value": 0.0047256928237397735, "duration": 8.895766019821167, "step": 71549}
{"episode_reward": 12.734050197274719, "episode": 2269.0, "batch_reward": 0.03601662069559097, "critic_loss": 1.4146323204040527, "ae_transition_loss": 1.9515215158462524, "ae_encoder_loss": 0.49503618478775024, "actor_loss": -1.0817592144012451, "actor_target_entropy": -2.0, "actor_entropy": -0.9138088226318359, "alpha_loss": -0.004102404695004225, "alpha_value": 0.0047361439126018725, "duration": 1.5039112567901611, "step": 71556}
{"episode_reward": -2.677537335263556, "episode": 2270.0, "batch_reward": 0.052390738079945244, "critic_loss": 0.9923876523971558, "ae_transition_loss": 1.964259664217631, "ae_encoder_loss": 0.6672624945640564, "actor_loss": -1.2103152871131897, "actor_target_entropy": -2.0, "actor_entropy": -0.8047308921813965, "alpha_loss": -0.003943682958682378, "alpha_value": 0.004745460981762689, "duration": 5.313876152038574, "step": 71581}
{"episode_reward": 2.5131893759806507, "episode": 2271.0, "batch_reward": -0.00953337550163269, "critic_loss": 0.5734595060348511, "ae_transition_loss": 1.9201886653900146, "ae_encoder_loss": 0.49885886907577515, "actor_loss": -0.9279029965400696, "actor_target_entropy": -2.0, "actor_entropy": -0.6769404411315918, "alpha_loss": -0.0045108129270374775, "alpha_value": 0.004757842983357357, "duration": 53.74959182739258, "step": 71607}
{"episode_reward": 4.692424258594099, "episode": 2272.0, "batch_reward": -0.0018704179674386978, "critic_loss": 0.864537239074707, "ae_transition_loss": 1.925346314907074, "ae_encoder_loss": 0.6614082157611847, "actor_loss": -1.063505381345749, "actor_target_entropy": -2.0, "actor_entropy": -0.5900448560714722, "alpha_loss": -0.0021102086175233126, "alpha_value": 0.004768315328348684, "duration": 4.283730983734131, "step": 71628}
{"episode_reward": 1.7599391333127534, "episode": 2273.0, "batch_reward": 0.048071036115288734, "critic_loss": 0.8882991671562195, "ae_transition_loss": 1.9028027057647705, "ae_encoder_loss": 0.6065258085727692, "actor_loss": -0.9644767045974731, "actor_target_entropy": -2.0, "actor_entropy": -0.43482665717601776, "alpha_loss": -0.0008718882600078359, "alpha_value": 0.004778179247596262, "duration": 3.0716073513031006, "step": 71641}
{"episode_reward": -1.899562405002993, "episode": 2274.0, "batch_reward": -0.011103593913668936, "critic_loss": 1.0000866109674627, "ae_transition_loss": 1.7238191962242126, "ae_encoder_loss": 0.7694475108926947, "actor_loss": -0.9454248926856301, "actor_target_entropy": -2.0, "actor_entropy": -0.7094405781139027, "alpha_loss": -0.0015478432628283786, "alpha_value": 0.004822007792154172, "duration": 44.85993933677673, "step": 71865}
{"episode_reward": -4.614792601912792, "episode": 2275.0, "batch_reward": 0.053886666893959045, "critic_loss": 0.799614280462265, "ae_transition_loss": 1.4533430337905884, "ae_encoder_loss": 0.7494593262672424, "actor_loss": -1.015486627817154, "actor_target_entropy": -2.0, "actor_entropy": -0.6532254815101624, "alpha_loss": -0.0015501849120482802, "alpha_value": 0.004857084809437549, "duration": 5.003890037536621, "step": 71890}
{"episode_reward": 2.7804737791712357, "episode": 2276.0, "batch_reward": -0.07848388329148293, "critic_loss": 0.8794862776994705, "ae_transition_loss": 1.471316933631897, "ae_encoder_loss": 0.7544844299554825, "actor_loss": -0.6754867769777775, "actor_target_entropy": -2.0, "actor_entropy": -0.6621847748756409, "alpha_loss": -0.0015686172409914434, "alpha_value": 0.004864148550003927, "duration": 7.327907085418701, "step": 71925}
{"episode_reward": 13.802039410577464, "episode": 2277.0, "batch_reward": -0.014643463492393493, "critic_loss": 0.8135687947273255, "ae_transition_loss": 1.3745438575744628, "ae_encoder_loss": 0.8728120803833008, "actor_loss": -1.0011170268058778, "actor_target_entropy": -2.0, "actor_entropy": -0.659124493598938, "alpha_loss": -0.002025157876778394, "alpha_value": 0.004874937469818999, "duration": 9.651654720306396, "step": 71972}
{"episode_reward": 5.606709028752811, "episode": 2278.0, "batch_reward": -0.035024707205593586, "critic_loss": 1.2032721638679504, "ae_transition_loss": 1.4141064286231995, "ae_encoder_loss": 1.0436988472938538, "actor_loss": -1.0267785638570786, "actor_target_entropy": -2.0, "actor_entropy": -0.6361105740070343, "alpha_loss": -0.0011708811216522008, "alpha_value": 0.004886997659934427, "duration": 8.99571704864502, "step": 72017}
{"episode_reward": 9.452774064019817, "episode": 2279.0, "batch_reward": -0.004956563624242942, "critic_loss": 0.9046581586201986, "ae_transition_loss": 1.2699348131815593, "ae_encoder_loss": 0.9077689448992411, "actor_loss": -0.9672431151072184, "actor_target_entropy": -2.0, "actor_entropy": -0.609401802221934, "alpha_loss": -0.0007724213840750357, "alpha_value": 0.004895840535312433, "duration": 5.99588680267334, "step": 72047}
{"episode_reward": 5.301002486151199, "episode": 2280.0, "batch_reward": -0.03278262913227081, "critic_loss": 1.2939152320226033, "ae_transition_loss": 1.558764378229777, "ae_encoder_loss": 0.8076368172963461, "actor_loss": -1.0266867478688557, "actor_target_entropy": -2.0, "actor_entropy": -0.575355996688207, "alpha_loss": -0.001404911211769407, "alpha_value": 0.004905207306789667, "duration": 11.685823440551758, "step": 72104}
{"episode_reward": 15.168943189314055, "episode": 2281.0, "batch_reward": -0.04328199351827303, "critic_loss": 0.7778813441594442, "ae_transition_loss": 1.332593043645223, "ae_encoder_loss": 0.957020123799642, "actor_loss": -0.8996649384498596, "actor_target_entropy": -2.0, "actor_entropy": -0.5725836356480917, "alpha_loss": -0.000641477876342833, "alpha_value": 0.00491477072796397, "duration": 54.34714698791504, "step": 72131}
{"episode_reward": 1.7306400548863063, "episode": 2282.0, "batch_reward": -0.04086984212820729, "critic_loss": 0.8986454804738363, "ae_transition_loss": 1.4823566675186157, "ae_encoder_loss": 0.9019378821055094, "actor_loss": -0.8327505787213644, "actor_target_entropy": -2.0, "actor_entropy": -0.5944043596585592, "alpha_loss": -0.0008588446653448045, "alpha_value": 0.004920777181420661, "duration": 6.557254076004028, "step": 72162}
{"episode_reward": 1.9812427570925983, "episode": 2283.0, "batch_reward": -0.05176001973450184, "critic_loss": 1.0155252516269684, "ae_transition_loss": 1.634992241859436, "ae_encoder_loss": 0.8359497785568237, "actor_loss": -0.9331668615341187, "actor_target_entropy": -2.0, "actor_entropy": -0.5924696326255798, "alpha_loss": -0.00014293656568042934, "alpha_value": 0.004925197955876121, "duration": 4.426934480667114, "step": 72182}
{"episode_reward": 1.0147913502951957, "episode": 2284.0, "duration": 0.2097928524017334, "step": 72183}
{"episode_reward": -0.306437522042793, "episode": 2285.0, "duration": 0.21984386444091797, "step": 72184}
{"episode_reward": -0.2544131384304682, "episode": 2286.0, "duration": 0.22768926620483398, "step": 72185}
{"episode_reward": -0.011810398689936892, "episode": 2287.0, "batch_reward": -0.008090975061058998, "critic_loss": 0.9690554594993591, "ae_transition_loss": 1.5784554386138916, "ae_encoder_loss": 0.9889838409423828, "actor_loss": -1.073372838497162, "actor_target_entropy": -2.0, "actor_entropy": -0.6750258123874664, "alpha_loss": 8.823230047710239e-05, "alpha_value": 0.0049396071763225, "duration": 52.15577483177185, "step": 72434}
{"episode_reward": 201.74649351058048, "episode": 2288.0, "batch_reward": -0.03739326540380716, "critic_loss": 0.9336300194263458, "ae_transition_loss": 1.5171023607254028, "ae_encoder_loss": 0.7663338631391525, "actor_loss": -1.0451427400112152, "actor_target_entropy": -2.0, "actor_entropy": -0.3450770899653435, "alpha_loss": 0.0033348234137520194, "alpha_value": 0.004942031260015467, "duration": 8.911829710006714, "step": 72479}
{"episode_reward": 4.327888404173918, "episode": 2289.0, "batch_reward": -0.01053505390882492, "critic_loss": 1.0192226767539978, "ae_transition_loss": 1.608328640460968, "ae_encoder_loss": 0.5537846088409424, "actor_loss": -1.2005427479743958, "actor_target_entropy": -2.0, "actor_entropy": -0.22590110450983047, "alpha_loss": 0.0025684559950605035, "alpha_value": 0.004936035602108094, "duration": 4.011819839477539, "step": 72499}
{"episode_reward": -0.7997583345025705, "episode": 2290.0, "batch_reward": 0.014153435826301575, "critic_loss": 1.5168569485346477, "ae_transition_loss": 1.5187724431355794, "ae_encoder_loss": 0.5994953513145447, "actor_loss": -1.3848769664764404, "actor_target_entropy": -2.0, "actor_entropy": 0.1073588381210963, "alpha_loss": 0.0036332872696220875, "alpha_value": 0.004928829868872606, "duration": 4.982024908065796, "step": 72521}
{"episode_reward": -1.3559609881876478, "episode": 2291.0, "duration": 40.49344611167908, "step": 72522}
{"episode_reward": -0.08623581266585645, "episode": 2292.0, "batch_reward": -0.003634197637438774, "critic_loss": 1.00882588326931, "ae_transition_loss": 1.3266068696975708, "ae_encoder_loss": 0.46563785523176193, "actor_loss": -1.1254993975162506, "actor_target_entropy": -2.0, "actor_entropy": -0.14058331958949566, "alpha_loss": 0.0015014237724244595, "alpha_value": 0.004916290785450916, "duration": 9.3038649559021, "step": 72568}
{"episode_reward": -5.493005187990538, "episode": 2293.0, "batch_reward": 0.002091088332235813, "critic_loss": 0.8456864953041077, "ae_transition_loss": 1.3374568223953247, "ae_encoder_loss": 0.5191197246313095, "actor_loss": -0.9510692656040192, "actor_target_entropy": -2.0, "actor_entropy": -0.8981925249099731, "alpha_loss": -0.0016795321134850383, "alpha_value": 0.004906180356712901, "duration": 3.739711046218872, "step": 72586}
{"episode_reward": 0.15642012864323912, "episode": 2294.0, "batch_reward": 0.013470312735686699, "critic_loss": 0.9108358323574066, "ae_transition_loss": 1.2699773907661438, "ae_encoder_loss": 0.7761584719022115, "actor_loss": -1.228258728981018, "actor_target_entropy": -2.0, "actor_entropy": -1.086177110671997, "alpha_loss": -0.002427712723147124, "alpha_value": 0.004901139665560945, "duration": 12.127825498580933, "step": 72646}
{"episode_reward": -31.885533877719304, "episode": 2295.0, "duration": 0.24006175994873047, "step": 72647}
{"episode_reward": -0.5120614938825289, "episode": 2296.0, "batch_reward": -0.02743839714676142, "critic_loss": 0.772302770614624, "ae_transition_loss": 1.5591259479522706, "ae_encoder_loss": 1.3102142930030822, "actor_loss": -0.9261156916618347, "actor_target_entropy": -2.0, "actor_entropy": -0.9668515443801879, "alpha_loss": -0.0023227162077091635, "alpha_value": 0.004904649111655837, "duration": 9.529648542404175, "step": 72695}
{"episode_reward": 5.525877223878839, "episode": 2297.0, "batch_reward": -0.008341414108872413, "critic_loss": 0.9263095736503602, "ae_transition_loss": 1.3930772542953491, "ae_encoder_loss": 0.8241147398948669, "actor_loss": -1.075533103942871, "actor_target_entropy": -2.0, "actor_entropy": -0.8945508241653443, "alpha_loss": -0.0020994392922148108, "alpha_value": 0.004914397130563505, "duration": 10.817766189575195, "step": 72750}
{"episode_reward": 17.434103816004587, "episode": 2298.0, "batch_reward": 0.0297366405526797, "critic_loss": 0.5461061298847198, "ae_transition_loss": 1.453652262687683, "ae_encoder_loss": 0.5586145718892416, "actor_loss": -0.924013614654541, "actor_target_entropy": -2.0, "actor_entropy": -0.8938105702400208, "alpha_loss": -0.002859830856323242, "alpha_value": 0.00492434519921572, "duration": 4.673263072967529, "step": 72771}
{"episode_reward": 1.9242596826296645, "episode": 2299.0, "batch_reward": -0.02496190555393696, "critic_loss": 0.4279151111841202, "ae_transition_loss": 1.2402597665786743, "ae_encoder_loss": 0.551925003528595, "actor_loss": -1.1142211556434631, "actor_target_entropy": -2.0, "actor_entropy": -0.8768424689769745, "alpha_loss": -0.0027073902310803533, "alpha_value": 0.004932221787510292, "duration": 5.010470151901245, "step": 72797}
{"episode_reward": 2.6769568077818935, "episode": 2300.0, "batch_reward": -0.033510566456243396, "critic_loss": 0.7575912401080132, "ae_transition_loss": 1.5911728739738464, "ae_encoder_loss": 0.5635508745908737, "actor_loss": -1.054028570652008, "actor_target_entropy": -2.0, "actor_entropy": -1.0350039899349213, "alpha_loss": -0.0023692445538472384, "alpha_value": 0.004942566751856087, "duration": 8.207749128341675, "step": 72838}
{"episode_reward": 7.960455102052568, "episode": 2301.0, "batch_reward": -0.06264074270923932, "critic_loss": 0.8289685646692911, "ae_transition_loss": 1.5889673630396526, "ae_encoder_loss": 0.7942734360694885, "actor_loss": -0.8328985373179117, "actor_target_entropy": -2.0, "actor_entropy": -1.0418773889541626, "alpha_loss": -0.0025169670892258487, "alpha_value": 0.00495513589689844, "duration": 45.62857508659363, "step": 72861}
{"episode_reward": 2.0750442916295904, "episode": 2302.0, "batch_reward": -0.01635107584297657, "critic_loss": 1.704175591468811, "ae_transition_loss": 1.7551067471504211, "ae_encoder_loss": 0.8937998414039612, "actor_loss": -0.9645475447177887, "actor_target_entropy": -2.0, "actor_entropy": -0.9726031124591827, "alpha_loss": -0.0005989930650684983, "alpha_value": 0.0049643427523868135, "duration": 4.814963102340698, "step": 72885}
{"episode_reward": 2.5554995115705013, "episode": 2303.0, "batch_reward": -0.0010435860604047775, "critic_loss": 1.0986348589261372, "ae_transition_loss": 1.995833436648051, "ae_encoder_loss": 0.5737755397955576, "actor_loss": -1.1181381940841675, "actor_target_entropy": -2.0, "actor_entropy": -1.061439077059428, "alpha_loss": -0.0016529866649458806, "alpha_value": 0.004972495825173898, "duration": 6.347814321517944, "step": 72915}
{"episode_reward": 4.701396249538433, "episode": 2304.0, "batch_reward": 0.10726534575223923, "critic_loss": 0.515151858329773, "ae_transition_loss": 1.5394091606140137, "ae_encoder_loss": 0.634296178817749, "actor_loss": -1.2498228549957275, "actor_target_entropy": -2.0, "actor_entropy": -0.9947500228881836, "alpha_loss": -0.0006463266909122467, "alpha_value": 0.004978819214505204, "duration": 1.84883451461792, "step": 72923}
{"episode_reward": 0.026338502069473607, "episode": 2305.0, "duration": 0.19672513008117676, "step": 72924}
{"episode_reward": -0.269918084064033, "episode": 2306.0, "batch_reward": -0.09102979674935341, "critic_loss": 1.3340813517570496, "ae_transition_loss": 1.5300230383872986, "ae_encoder_loss": 0.9251168966293335, "actor_loss": -0.6524262428283691, "actor_target_entropy": -2.0, "actor_entropy": -0.9594539403915405, "alpha_loss": -0.001278537674807012, "alpha_value": 0.004983195359874139, "duration": 4.905687093734741, "step": 72947}
{"episode_reward": 0.4868102098311068, "episode": 2307.0, "batch_reward": -0.014445737237110734, "critic_loss": 1.0067593604326248, "ae_transition_loss": 1.7190355956554413, "ae_encoder_loss": 0.7853480502963066, "actor_loss": -1.0414793714880943, "actor_target_entropy": -2.0, "actor_entropy": -0.932289257645607, "alpha_loss": -0.0011799290514318272, "alpha_value": 0.004996401663765225, "duration": 16.403995990753174, "step": 73027}
{"episode_reward": 20.346840983965084, "episode": 2308.0, "batch_reward": 0.032052889466285706, "critic_loss": 0.9283394813537598, "ae_transition_loss": 1.5996594429016113, "ae_encoder_loss": 0.5032947659492493, "actor_loss": -0.9306130409240723, "actor_target_entropy": -2.0, "actor_entropy": -0.7078762054443359, "alpha_loss": -0.0016433895798400044, "alpha_value": 0.005007638536952699, "duration": 2.8315720558166504, "step": 73040}
{"episode_reward": -0.35391304924865385, "episode": 2309.0, "batch_reward": -0.021435946226119995, "critic_loss": 0.9268211126327515, "ae_transition_loss": 1.5856958627700806, "ae_encoder_loss": 0.9669508337974548, "actor_loss": -0.8775999347368876, "actor_target_entropy": -2.0, "actor_entropy": -0.7845841844876608, "alpha_loss": -0.0014761767427747448, "alpha_value": 0.005012526952313321, "duration": 5.811824083328247, "step": 73067}
{"episode_reward": 6.176429244791391, "episode": 2310.0, "batch_reward": 0.0072854853545626, "critic_loss": 0.9716042876243591, "ae_transition_loss": 1.5311905940373738, "ae_encoder_loss": 0.8375889460245768, "actor_loss": -1.0937878290812175, "actor_target_entropy": -2.0, "actor_entropy": -0.847189704577128, "alpha_loss": -4.774740470262865e-05, "alpha_value": 0.005019527445815369, "duration": 6.171744346618652, "step": 73097}
{"episode_reward": 8.920652292531496, "episode": 2311.0, "batch_reward": 0.022816443350166082, "critic_loss": 0.7295696139335632, "ae_transition_loss": 1.5216701030731201, "ae_encoder_loss": 0.8678747564554214, "actor_loss": -1.2907811999320984, "actor_target_entropy": -2.0, "actor_entropy": -0.7787091881036758, "alpha_loss": -0.002051139948889613, "alpha_value": 0.0050266153816443445, "duration": 67.45572876930237, "step": 73136}
{"episode_reward": 9.08790780877324, "episode": 2312.0, "batch_reward": -0.003952305763959885, "critic_loss": 0.8023528933525086, "ae_transition_loss": 1.5943149089813233, "ae_encoder_loss": 0.7372961640357971, "actor_loss": -1.0077902555465699, "actor_target_entropy": -2.0, "actor_entropy": -0.7583488583564758, "alpha_loss": -0.0011911469424376263, "alpha_value": 0.005036670722835424, "duration": 9.597905397415161, "step": 73181}
{"episode_reward": 13.318801054848166, "episode": 2313.0, "batch_reward": 0.04237637482583523, "critic_loss": 1.1471787095069885, "ae_transition_loss": 1.4736483097076416, "ae_encoder_loss": 0.6796330809593201, "actor_loss": -1.3644301295280457, "actor_target_entropy": -2.0, "actor_entropy": -0.9234052896499634, "alpha_loss": -0.0007481413485947996, "alpha_value": 0.005044167192401994, "duration": 4.7939064502716064, "step": 73205}
{"episode_reward": -1.3002611630591543, "episode": 2314.0, "batch_reward": -0.031460082779328026, "critic_loss": 0.846572756767273, "ae_transition_loss": 1.7205663522084553, "ae_encoder_loss": 0.7357209920883179, "actor_loss": -1.0214502612749736, "actor_target_entropy": -2.0, "actor_entropy": -0.9846821626027426, "alpha_loss": -0.0020948837821682296, "alpha_value": 0.005049417060796708, "duration": 6.771653652191162, "step": 73238}
{"episode_reward": 6.6715276498288585, "episode": 2315.0, "batch_reward": 0.0007740684474507967, "critic_loss": 0.893378476301829, "ae_transition_loss": 1.7102959553400676, "ae_encoder_loss": 0.6638792802890142, "actor_loss": -1.1565607090791066, "actor_target_entropy": -2.0, "actor_entropy": -0.9799820880095164, "alpha_loss": -0.001884079024118061, "alpha_value": 0.005060941377969651, "duration": 11.83956503868103, "step": 73294}
{"episode_reward": 7.233238882052791, "episode": 2316.0, "batch_reward": -0.09659861028194427, "critic_loss": 0.7812586426734924, "ae_transition_loss": 1.6400999426841736, "ae_encoder_loss": 0.994097501039505, "actor_loss": -1.1264528632164001, "actor_target_entropy": -2.0, "actor_entropy": -0.9414635598659515, "alpha_loss": -0.0023788290563970804, "alpha_value": 0.005072161240623988, "duration": 4.508758544921875, "step": 73315}
{"episode_reward": 0.9351529607056666, "episode": 2317.0, "duration": 0.25084805488586426, "step": 73316}
{"episode_reward": -0.6304550448666322, "episode": 2318.0, "duration": 0.2315828800201416, "step": 73317}
{"episode_reward": -0.19421221315860748, "episode": 2319.0, "duration": 0.23982739448547363, "step": 73318}
{"episode_reward": 0.07511256098947461, "episode": 2320.0, "batch_reward": -0.022469051219522952, "critic_loss": 0.8464641106128693, "ae_transition_loss": 1.6824520540237426, "ae_encoder_loss": 0.6488134181499481, "actor_loss": -1.1054382395744324, "actor_target_entropy": -2.0, "actor_entropy": -0.804094443321228, "alpha_loss": -0.001359508337918669, "alpha_value": 0.0051104280339809675, "duration": 52.08998394012451, "step": 73567}
{"episode_reward": -7.773776481929379, "episode": 2321.0, "batch_reward": -0.023511459430058796, "critic_loss": 0.8157711029052734, "ae_transition_loss": 1.5933947960535686, "ae_encoder_loss": 0.5784415602684021, "actor_loss": -1.2250638405481975, "actor_target_entropy": -2.0, "actor_entropy": -0.7628109057744344, "alpha_loss": -0.0008970241566809515, "alpha_value": 0.005146506247118609, "duration": 116.4476706981659, "step": 73597}
{"episode_reward": 5.465754072436062, "episode": 2322.0, "batch_reward": -0.022943176950017612, "critic_loss": 1.322815736134847, "ae_transition_loss": 1.8629813194274902, "ae_encoder_loss": 0.5453633666038513, "actor_loss": -1.332069754600525, "actor_target_entropy": -2.0, "actor_entropy": -0.7716515064239502, "alpha_loss": -0.00102815645126005, "alpha_value": 0.005153009075284366, "duration": 5.914200067520142, "step": 73625}
{"episode_reward": 4.3053596137457335, "episode": 2323.0, "batch_reward": -0.02421615645289421, "critic_loss": 0.6058101654052734, "ae_transition_loss": 1.4873337745666504, "ae_encoder_loss": 0.6077247262001038, "actor_loss": -0.9327802062034607, "actor_target_entropy": -2.0, "actor_entropy": -0.8727516531944275, "alpha_loss": -0.0015367724699899554, "alpha_value": 0.005157093216343092, "duration": 2.2278614044189453, "step": 73635}
{"episode_reward": -1.5745107062649861, "episode": 2324.0, "batch_reward": -0.010095816291868686, "critic_loss": 0.762874710559845, "ae_transition_loss": 1.4968018452326457, "ae_encoder_loss": 0.5558346688747406, "actor_loss": -1.114905192454656, "actor_target_entropy": -2.0, "actor_entropy": -0.8675696214040121, "alpha_loss": -0.0011170115690523137, "alpha_value": 0.005173514430344803, "duration": 31.887545824050903, "step": 73789}
{"episode_reward": 45.636416996665666, "episode": 2325.0, "batch_reward": -0.032036772929131985, "critic_loss": 0.7753540277481079, "ae_transition_loss": 1.7093200087547302, "ae_encoder_loss": 0.6747503578662872, "actor_loss": -0.9950169324874878, "actor_target_entropy": -2.0, "actor_entropy": -0.9109436869621277, "alpha_loss": -0.0013790626544505358, "alpha_value": 0.005190930952455567, "duration": 4.491898059844971, "step": 73810}
{"episode_reward": 4.405964836623393, "episode": 2326.0, "batch_reward": 0.009959156159311533, "critic_loss": 0.46095460653305054, "ae_transition_loss": 1.7369641065597534, "ae_encoder_loss": 0.5259069800376892, "actor_loss": -1.4908919930458069, "actor_target_entropy": -2.0, "actor_entropy": -1.0126246213912964, "alpha_loss": -0.001693227153737098, "alpha_value": 0.005195167541487701, "duration": 3.311779022216797, "step": 73826}
{"episode_reward": -1.5711683414496393, "episode": 2327.0, "batch_reward": -0.01378773401180903, "critic_loss": 0.9906572500864664, "ae_transition_loss": 1.5386329491933186, "ae_encoder_loss": 0.67247607310613, "actor_loss": -1.062437931696574, "actor_target_entropy": -2.0, "actor_entropy": -0.8431245485941569, "alpha_loss": -3.072414741230508e-05, "alpha_value": 0.005200650244978496, "duration": 5.971949577331543, "step": 73856}
{"episode_reward": 2.467716420583833, "episode": 2328.0, "batch_reward": -0.008224616758525372, "critic_loss": 0.991103857755661, "ae_transition_loss": 1.6110695004463196, "ae_encoder_loss": 0.5888204574584961, "actor_loss": -1.3479998707771301, "actor_target_entropy": -2.0, "actor_entropy": -0.8403019607067108, "alpha_loss": -0.0013376417628023773, "alpha_value": 0.005205085172360298, "duration": 3.9008378982543945, "step": 73875}
{"episode_reward": 0.7534581828405604, "episode": 2329.0, "batch_reward": -0.04860560595989227, "critic_loss": 1.1962647438049316, "ae_transition_loss": 1.829072117805481, "ae_encoder_loss": 0.6419285535812378, "actor_loss": -1.4100052118301392, "actor_target_entropy": -2.0, "actor_entropy": -0.9425653219223022, "alpha_loss": -0.001492472947575152, "alpha_value": 0.005207713880922828, "duration": 2.106180429458618, "step": 73884}
{"episode_reward": -0.5567275267972326, "episode": 2330.0, "batch_reward": -0.07226664572954178, "critic_loss": 0.4786427617073059, "ae_transition_loss": 1.4629806280136108, "ae_encoder_loss": 1.0271905660629272, "actor_loss": -1.1150938272476196, "actor_target_entropy": -2.0, "actor_entropy": -0.8713483810424805, "alpha_loss": -0.0024653186555951834, "alpha_value": 0.005209614131197451, "duration": 1.941192865371704, "step": 73892}
{"episode_reward": -0.8680522714533978, "episode": 2331.0, "batch_reward": -0.044494355363505225, "critic_loss": 0.9547365818704877, "ae_transition_loss": 1.6792477880205428, "ae_encoder_loss": 0.967053404876164, "actor_loss": -0.8251213899680546, "actor_target_entropy": -2.0, "actor_entropy": -0.8675202131271362, "alpha_loss": -0.0009497760038357228, "alpha_value": 0.005217965826551149, "duration": 78.04558444023132, "step": 73965}
{"episode_reward": 18.64607315441026, "episode": 2332.0, "batch_reward": -0.02566115092486143, "critic_loss": 0.7876170873641968, "ae_transition_loss": 1.4497308731079102, "ae_encoder_loss": 0.8243356794118881, "actor_loss": -1.3539516627788544, "actor_target_entropy": -2.0, "actor_entropy": -0.8645554035902023, "alpha_loss": -0.0012575068321893923, "alpha_value": 0.00522870353787209, "duration": 8.056689739227295, "step": 74004}
{"episode_reward": 5.4667273840726995, "episode": 2333.0, "batch_reward": -0.004363315800825755, "critic_loss": 0.7340387602647146, "ae_transition_loss": 1.5540888110796611, "ae_encoder_loss": 0.7388260066509247, "actor_loss": -1.3009478251139324, "actor_target_entropy": -2.0, "actor_entropy": -0.7013018131256104, "alpha_loss": -0.0006260271111386828, "alpha_value": 0.005238709793706761, "duration": 12.09029507637024, "step": 74062}
{"episode_reward": 7.523616212425645, "episode": 2334.0, "batch_reward": -0.0033899195492267608, "critic_loss": 0.7930981636047363, "ae_transition_loss": 1.723351240158081, "ae_encoder_loss": 0.6699602603912354, "actor_loss": -1.418229103088379, "actor_target_entropy": -2.0, "actor_entropy": -0.7335641264915467, "alpha_loss": -0.0001651451224461198, "alpha_value": 0.0052475364609675034, "duration": 10.577996253967285, "step": 74114}
{"episode_reward": 12.004389384126453, "episode": 2335.0, "batch_reward": -0.0022599679262687764, "critic_loss": 0.8064954082171122, "ae_transition_loss": 1.8350485662619274, "ae_encoder_loss": 0.8162481933832169, "actor_loss": -1.310911476612091, "actor_target_entropy": -2.0, "actor_entropy": -0.8045403311649958, "alpha_loss": -0.002029294390619422, "alpha_value": 0.005260977107685391, "duration": 25.135287046432495, "step": 74236}
{"episode_reward": 57.82402341893912, "episode": 2336.0, "batch_reward": 0.0015273460497458775, "critic_loss": 1.0411794135967891, "ae_transition_loss": 1.7370432615280151, "ae_encoder_loss": 0.6990977923075358, "actor_loss": -1.2043971419334412, "actor_target_entropy": -2.0, "actor_entropy": -0.9385908742745718, "alpha_loss": -0.0022866426734253764, "alpha_value": 0.005286041182666158, "duration": 11.613996505737305, "step": 74291}
{"episode_reward": 15.112540881030018, "episode": 2337.0, "batch_reward": -0.0014289192855358123, "critic_loss": 1.6289778709411622, "ae_transition_loss": 1.5725543260574342, "ae_encoder_loss": 1.0062765240669251, "actor_loss": -1.1255430579185486, "actor_target_entropy": -2.0, "actor_entropy": -0.940573513507843, "alpha_loss": -0.0020986182847991587, "alpha_value": 0.005305651599116824, "duration": 12.241594314575195, "step": 74350}
{"episode_reward": 12.04367383721003, "episode": 2338.0, "batch_reward": -0.005988140844485976, "critic_loss": 0.8846547170118852, "ae_transition_loss": 1.7330636978149414, "ae_encoder_loss": 0.6457935625856573, "actor_loss": -1.4298157366839321, "actor_target_entropy": -2.0, "actor_entropy": -0.9206435517831282, "alpha_loss": -0.0016480522185288878, "alpha_value": 0.005336500635347049, "duration": 22.401301383972168, "step": 74453}
{"episode_reward": -0.13554979024408564, "episode": 2339.0, "batch_reward": -0.014719587905953327, "critic_loss": 1.4077700972557068, "ae_transition_loss": 1.8103755116462708, "ae_encoder_loss": 0.7650855878988901, "actor_loss": -1.328762908776601, "actor_target_entropy": -2.0, "actor_entropy": -0.7331750094890594, "alpha_loss": -0.0017935588063361745, "alpha_value": 0.005366415464527299, "duration": 13.491405963897705, "step": 74519}
{"episode_reward": 8.771713029494515, "episode": 2340.0, "batch_reward": -0.03190134962399801, "critic_loss": 1.2372889916102092, "ae_transition_loss": 1.691613793373108, "ae_encoder_loss": 0.8564402063687643, "actor_loss": -1.21932719151179, "actor_target_entropy": -2.0, "actor_entropy": -0.7914900978406271, "alpha_loss": -0.0013563243749861915, "alpha_value": 0.005380980130085265, "duration": 5.98664116859436, "step": 74547}
{"episode_reward": 4.254908435372745, "episode": 2341.0, "batch_reward": -0.006511830259114504, "critic_loss": 1.1390057653188705, "ae_transition_loss": 1.5381936728954315, "ae_encoder_loss": 0.6846660673618317, "actor_loss": -1.421133041381836, "actor_target_entropy": -2.0, "actor_entropy": -0.9050063639879227, "alpha_loss": -0.0015139429888222367, "alpha_value": 0.005391525362971966, "duration": 87.16781711578369, "step": 74590}
{"episode_reward": 6.230281659778651, "episode": 2342.0, "batch_reward": -0.01779921104510625, "critic_loss": 1.2376646995544434, "ae_transition_loss": 1.4150087436040242, "ae_encoder_loss": 0.47289355595906574, "actor_loss": -1.236099402109782, "actor_target_entropy": -2.0, "actor_entropy": -0.871158242225647, "alpha_loss": -0.0006978948270746818, "alpha_value": 0.005401644829136562, "duration": 4.797311305999756, "step": 74612}
{"episode_reward": 2.4025878083656202, "episode": 2343.0, "duration": 0.19320154190063477, "step": 74613}
{"episode_reward": 0.41006052028272166, "episode": 2344.0, "batch_reward": 0.0322430015852054, "critic_loss": 1.2284694910049438, "ae_transition_loss": 1.452751914660136, "ae_encoder_loss": 0.5219054520130157, "actor_loss": -1.198984185854594, "actor_target_entropy": -2.0, "actor_entropy": -1.0736996332804363, "alpha_loss": -0.002357824007049203, "alpha_value": 0.005409691505752062, "duration": 7.117002010345459, "step": 74648}
{"episode_reward": 6.3225906484944785, "episode": 2345.0, "batch_reward": -0.022489977534860373, "critic_loss": 1.2703530192375183, "ae_transition_loss": 1.3450853824615479, "ae_encoder_loss": 0.5209590047597885, "actor_loss": -0.9791176915168762, "actor_target_entropy": -2.0, "actor_entropy": -1.0951670408248901, "alpha_loss": -0.0018090074299834669, "alpha_value": 0.005417281687501055, "duration": 3.551804780960083, "step": 74665}
{"episode_reward": -1.000369020739196, "episode": 2346.0, "batch_reward": 0.056699139066040516, "critic_loss": 0.515810638666153, "ae_transition_loss": 1.3576104640960693, "ae_encoder_loss": 0.38586729764938354, "actor_loss": -1.545527160167694, "actor_target_entropy": -2.0, "actor_entropy": -1.1877434849739075, "alpha_loss": -0.0030097687849774957, "alpha_value": 0.0054238854442024125, "duration": 4.323920965194702, "step": 74686}
{"episode_reward": 1.9962359453960898, "episode": 2347.0, "batch_reward": 0.05129054747521877, "critic_loss": 0.5082840323448181, "ae_transition_loss": 1.6526280045509338, "ae_encoder_loss": 0.348537340760231, "actor_loss": -1.4599016904830933, "actor_target_entropy": -2.0, "actor_entropy": -1.1571155786514282, "alpha_loss": -0.0019616199424490333, "alpha_value": 0.005431308285867209, "duration": 4.719620704650879, "step": 74710}
{"episode_reward": 4.597045821733171, "episode": 2348.0, "batch_reward": 0.0362200066447258, "critic_loss": 1.1145218312740326, "ae_transition_loss": 2.622338145971298, "ae_encoder_loss": 1.0267980471253395, "actor_loss": -1.604908436536789, "actor_target_entropy": -2.0, "actor_entropy": -1.2204249501228333, "alpha_loss": -0.0028727904427796602, "alpha_value": 0.0054429251412537625, "duration": 6.878659009933472, "step": 74744}
{"episode_reward": 1.9078130782870941, "episode": 2349.0, "batch_reward": -0.0019482765346765518, "critic_loss": 0.8749843835830688, "ae_transition_loss": 1.7544927597045898, "ae_encoder_loss": 1.1615512371063232, "actor_loss": -1.4895756244659424, "actor_target_entropy": -2.0, "actor_entropy": -1.1971988677978516, "alpha_loss": -0.0036308288108557463, "alpha_value": 0.005453502418165936, "duration": 2.266446828842163, "step": 74754}
{"episode_reward": -0.10225520009056333, "episode": 2350.0, "batch_reward": -0.09607753157615662, "critic_loss": 0.9149153232574463, "ae_transition_loss": 1.768425464630127, "ae_encoder_loss": 1.8005763292312622, "actor_loss": -0.7625078558921814, "actor_target_entropy": -2.0, "actor_entropy": -1.1844022274017334, "alpha_loss": -0.004196619614958763, "alpha_value": 0.005458127986046549, "duration": 2.502370834350586, "step": 74766}
{"episode_reward": 1.1248190256650037, "episode": 2351.0, "batch_reward": 0.0010392256081104279, "critic_loss": 1.4016417264938354, "ae_transition_loss": 1.767026424407959, "ae_encoder_loss": 3.5512475967407227, "actor_loss": -1.722139596939087, "actor_target_entropy": -2.0, "actor_entropy": -1.2400903701782227, "alpha_loss": -0.003409791737794876, "alpha_value": 0.0054631064568049234, "duration": 41.62773418426514, "step": 74775}
{"episode_reward": -1.934124613067238, "episode": 2352.0, "batch_reward": 0.030904924031347036, "critic_loss": 1.1846067309379578, "ae_transition_loss": 1.9010760188102722, "ae_encoder_loss": 6.994227886199951, "actor_loss": -1.6283501386642456, "actor_target_entropy": -2.0, "actor_entropy": -1.2389090061187744, "alpha_loss": -0.0030985880875959992, "alpha_value": 0.00547084266019658, "duration": 4.843719959259033, "step": 74799}
{"episode_reward": -0.5202060357148371, "episode": 2353.0, "batch_reward": -0.004475647583603859, "critic_loss": 1.8815119504928588, "ae_transition_loss": 2.033367466926575, "ae_encoder_loss": 5.515819549560547, "actor_loss": -1.5656406164169312, "actor_target_entropy": -2.0, "actor_entropy": -1.259883499145508, "alpha_loss": -0.0038352412171661853, "alpha_value": 0.005490413791235008, "duration": 8.810969829559326, "step": 74841}
{"episode_reward": 9.293614376896386, "episode": 2354.0, "batch_reward": -0.024264823645353317, "critic_loss": 1.8403128385543823, "ae_transition_loss": 1.9861679077148438, "ae_encoder_loss": 1.890395164489746, "actor_loss": -1.555827021598816, "actor_target_entropy": -2.0, "actor_entropy": -1.2848734855651855, "alpha_loss": -0.003720395267009735, "alpha_value": 0.005508484202616122, "duration": 2.5980663299560547, "step": 74855}
{"episode_reward": -1.7520894900744184, "episode": 2355.0, "batch_reward": -0.01836431895693143, "critic_loss": 3.253662427266439, "ae_transition_loss": 1.9842500289281209, "ae_encoder_loss": 2.4683430989583335, "actor_loss": -1.391976038614909, "actor_target_entropy": -2.0, "actor_entropy": -1.2602193752924602, "alpha_loss": -0.0030933532398194075, "alpha_value": 0.005521063274909831, "duration": 6.8023388385772705, "step": 74890}
{"episode_reward": 10.547538462558572, "episode": 2356.0, "batch_reward": -0.009791298458973566, "critic_loss": 2.2915369669596353, "ae_transition_loss": 1.9335836172103882, "ae_encoder_loss": 1.3310389916102092, "actor_loss": -1.6893961032231648, "actor_target_entropy": -2.0, "actor_entropy": -1.2024624347686768, "alpha_loss": -0.0038339930276075997, "alpha_value": 0.005539844088569022, "duration": 5.203032970428467, "step": 74915}
{"episode_reward": 0.8677002803638403, "episode": 2357.0, "batch_reward": 0.0055704854894429445, "critic_loss": 2.4776227474212646, "ae_transition_loss": 1.810534507036209, "ae_encoder_loss": 0.9865535944700241, "actor_loss": -1.335670530796051, "actor_target_entropy": -2.0, "actor_entropy": -1.1813997626304626, "alpha_loss": -0.003386822558240965, "alpha_value": 0.005562913312080539, "duration": 8.456645727157593, "step": 74957}
{"episode_reward": 7.174311025561024, "episode": 2358.0, "batch_reward": 0.006726328399963677, "critic_loss": 1.561628594994545, "ae_transition_loss": 1.4975474178791046, "ae_encoder_loss": 0.7268637344241142, "actor_loss": -1.4822579324245453, "actor_target_entropy": -2.0, "actor_entropy": -1.2186073511838913, "alpha_loss": -0.004539055487839505, "alpha_value": 0.005605040300421715, "duration": 15.541923999786377, "step": 75032}
{"episode_reward": 25.43246005615468, "episode": 2359.0, "batch_reward": -0.002703684071699778, "critic_loss": 1.3565435806910198, "ae_transition_loss": 1.1213866074879963, "ae_encoder_loss": 0.6532975832621256, "actor_loss": -1.4845330317815144, "actor_target_entropy": -2.0, "actor_entropy": -1.3000958760579426, "alpha_loss": -0.004724803846329451, "alpha_value": 0.005647464092516328, "duration": 7.313544511795044, "step": 75069}
{"episode_reward": 8.337127019752652, "episode": 2360.0, "batch_reward": 0.006598071505626042, "critic_loss": 2.00116229057312, "ae_transition_loss": 1.063925306002299, "ae_encoder_loss": 0.6657967964808146, "actor_loss": -1.2921562194824219, "actor_target_entropy": -2.0, "actor_entropy": -1.2144193649291992, "alpha_loss": -0.0048351451599349575, "alpha_value": 0.005672370368055492, "duration": 5.547845363616943, "step": 75096}
{"episode_reward": 4.2472818010487075, "episode": 2361.0, "batch_reward": 0.02016245573759079, "critic_loss": 1.1006694436073303, "ae_transition_loss": 0.5912014245986938, "ae_encoder_loss": 0.5736645758152008, "actor_loss": -1.8013052940368652, "actor_target_entropy": -2.0, "actor_entropy": -1.3533657789230347, "alpha_loss": -0.0063594121020287275, "alpha_value": 0.005694100645380551, "duration": 73.26796293258667, "step": 75120}
{"episode_reward": 1.0606708984764193, "episode": 2362.0, "batch_reward": -0.015679527074098587, "critic_loss": 1.4841234683990479, "ae_transition_loss": 0.6908909976482391, "ae_encoder_loss": 0.5732960104942322, "actor_loss": -1.4722644686698914, "actor_target_entropy": -2.0, "actor_entropy": -1.5204076170921326, "alpha_loss": -0.006925611291080713, "alpha_value": 0.00571312446626261, "duration": 3.211638927459717, "step": 75135}
{"episode_reward": 1.6305135750812123, "episode": 2363.0, "batch_reward": 0.008619311265647411, "critic_loss": 1.2309267024199169, "ae_transition_loss": 1.0302619437376659, "ae_encoder_loss": 0.7483651836713155, "actor_loss": -1.5598696668942769, "actor_target_entropy": -2.0, "actor_entropy": -1.6331025958061218, "alpha_loss": -0.006453159187609951, "alpha_value": 0.005755426990072265, "duration": 12.833178520202637, "step": 75196}
{"episode_reward": 37.23825682296369, "episode": 2364.0, "batch_reward": -0.07653584827979405, "critic_loss": 1.0806439518928528, "ae_transition_loss": 1.0982435941696167, "ae_encoder_loss": 1.3777199188868205, "actor_loss": -0.7624244689941406, "actor_target_entropy": -2.0, "actor_entropy": -1.6286542812983196, "alpha_loss": -0.005552563971529405, "alpha_value": 0.005805741187946079, "duration": 6.242514133453369, "step": 75227}
{"episode_reward": 4.373301230650084, "episode": 2365.0, "batch_reward": -0.004112418042495847, "critic_loss": 1.188713550567627, "ae_transition_loss": 0.8599112629890442, "ae_encoder_loss": 1.5589596927165985, "actor_loss": -1.2823422402143478, "actor_target_entropy": -2.0, "actor_entropy": -1.5334101021289825, "alpha_loss": -0.005839043064042926, "alpha_value": 0.005845227216923048, "duration": 8.147956132888794, "step": 75267}
{"episode_reward": 13.524579672845737, "episode": 2366.0, "batch_reward": -0.04733585603535175, "critic_loss": 0.8528855621814728, "ae_transition_loss": 0.9139875531196594, "ae_encoder_loss": 1.2434728384017943, "actor_loss": -1.3550173759460449, "actor_target_entropy": -2.0, "actor_entropy": -1.3472486019134522, "alpha_loss": -0.006400023866444826, "alpha_value": 0.005896868551921637, "duration": 9.943542242050171, "step": 75316}
{"episode_reward": 14.209882251344576, "episode": 2367.0, "batch_reward": -0.025123754516243935, "critic_loss": 0.9595963358879089, "ae_transition_loss": 0.9170499742031097, "ae_encoder_loss": 1.4083960056304932, "actor_loss": -1.4567214250564575, "actor_target_entropy": -2.0, "actor_entropy": -1.2745221853256226, "alpha_loss": -0.007180217653512955, "alpha_value": 0.005938556614712289, "duration": 4.555991888046265, "step": 75338}
{"episode_reward": 1.4048047127070749, "episode": 2368.0, "batch_reward": -0.05294831842184067, "critic_loss": 1.459659069776535, "ae_transition_loss": 1.1036856472492218, "ae_encoder_loss": 1.5193526446819305, "actor_loss": -1.1130563020706177, "actor_target_entropy": -2.0, "actor_entropy": -1.2927273511886597, "alpha_loss": -0.006178989191539586, "alpha_value": 0.005975712983655923, "duration": 7.5822834968566895, "step": 75374}
{"episode_reward": 3.9755108563865726, "episode": 2369.0, "batch_reward": 0.005176965923358996, "critic_loss": 1.415646731853485, "ae_transition_loss": 1.212122807900111, "ae_encoder_loss": 1.735116144021352, "actor_loss": -1.7889192899068196, "actor_target_entropy": -2.0, "actor_entropy": -1.3485009868939717, "alpha_loss": -0.006195243448019028, "alpha_value": 0.006037742327278048, "duration": 12.817139148712158, "step": 75438}
{"episode_reward": 24.100764171802428, "episode": 2370.0, "batch_reward": 0.003494471311569214, "critic_loss": 0.927736222743988, "ae_transition_loss": 1.311268538236618, "ae_encoder_loss": 1.5502133071422577, "actor_loss": -1.4780150651931763, "actor_target_entropy": -2.0, "actor_entropy": -1.3016672134399414, "alpha_loss": -0.005754717509262264, "alpha_value": 0.006099768226412192, "duration": 7.281666040420532, "step": 75473}
{"episode_reward": 5.3667343688687605, "episode": 2371.0, "duration": 54.29408550262451, "step": 75474}
{"episode_reward": 0.3557887864046988, "episode": 2372.0, "batch_reward": -0.035182707011699677, "critic_loss": 1.6260771751403809, "ae_transition_loss": 1.312341570854187, "ae_encoder_loss": 1.3577847480773926, "actor_loss": -1.4138059616088867, "actor_target_entropy": -2.0, "actor_entropy": -1.156166911125183, "alpha_loss": -0.005950646474957466, "alpha_value": 0.00613037690307188, "duration": 3.003493309020996, "step": 75489}
{"episode_reward": -1.6427677985139137, "episode": 2373.0, "batch_reward": -0.0741829810043176, "critic_loss": 0.8315948645273844, "ae_transition_loss": 1.3972316980361938, "ae_encoder_loss": 1.4223746061325073, "actor_loss": -1.0979658762613933, "actor_target_entropy": -2.0, "actor_entropy": -1.1771066983540852, "alpha_loss": -0.004657293825099866, "alpha_value": 0.0061541421694430625, "duration": 5.819870948791504, "step": 75517}
{"episode_reward": 5.690097373392342, "episode": 2374.0, "batch_reward": 0.022889863699674606, "critic_loss": 0.6844064295291901, "ae_transition_loss": 1.5141521096229553, "ae_encoder_loss": 1.0752440094947815, "actor_loss": -1.6017292737960815, "actor_target_entropy": -2.0, "actor_entropy": -1.1136422157287598, "alpha_loss": -0.0032631881767883897, "alpha_value": 0.006182653808119899, "duration": 4.003736972808838, "step": 75537}
{"episode_reward": 1.2291159560137466, "episode": 2375.0, "batch_reward": 0.0065975965311129885, "critic_loss": 1.4665533701578777, "ae_transition_loss": 1.5864835182825725, "ae_encoder_loss": 1.1534306208292644, "actor_loss": -1.950520912806193, "actor_target_entropy": -2.0, "actor_entropy": -1.0217446088790894, "alpha_loss": -0.0036626087967306376, "alpha_value": 0.00620888611164539, "duration": 6.231730222702026, "step": 75568}
{"episode_reward": 3.880481724732883, "episode": 2376.0, "batch_reward": -0.032054771979649864, "critic_loss": 1.2174962361653645, "ae_transition_loss": 1.4009743134180705, "ae_encoder_loss": 0.9884460171063741, "actor_loss": -1.3272358576456706, "actor_target_entropy": -2.0, "actor_entropy": -0.7971930106480917, "alpha_loss": -0.003436451700205604, "alpha_value": 0.006238127290907111, "duration": 5.123487710952759, "step": 75592}
{"episode_reward": -1.384062557556883, "episode": 2377.0, "duration": 0.20884990692138672, "step": 75593}
{"episode_reward": -0.38592860606580365, "episode": 2378.0, "batch_reward": -0.04656173661351204, "critic_loss": 1.3672845959663391, "ae_transition_loss": 1.42294180393219, "ae_encoder_loss": 1.0620343089103699, "actor_loss": -1.2079195082187653, "actor_target_entropy": -2.0, "actor_entropy": -0.7651866674423218, "alpha_loss": -0.0018231880385428667, "alpha_value": 0.006260742052950239, "duration": 5.07128119468689, "step": 75618}
{"episode_reward": 0.585348992710623, "episode": 2379.0, "duration": 0.2236475944519043, "step": 75619}
{"episode_reward": -0.48936901978396585, "episode": 2380.0, "batch_reward": -0.003871756372973323, "critic_loss": 1.3148314952850342, "ae_transition_loss": 1.7931646406650543, "ae_encoder_loss": 1.2146613895893097, "actor_loss": -1.4958886206150055, "actor_target_entropy": -2.0, "actor_entropy": -0.8704724460840225, "alpha_loss": -0.0003691642195917666, "alpha_value": 0.006283389372788094, "duration": 8.09595251083374, "step": 75659}
{"episode_reward": 10.437026491976212, "episode": 2381.0, "batch_reward": -0.03044574474915862, "critic_loss": 1.1744819581508636, "ae_transition_loss": 1.7723867893218994, "ae_encoder_loss": 0.9261257946491241, "actor_loss": -1.1310893893241882, "actor_target_entropy": -2.0, "actor_entropy": -0.8609137237071991, "alpha_loss": -0.0004921018262393773, "alpha_value": 0.0063011311314598506, "duration": 116.46029853820801, "step": 75676}
{"episode_reward": -0.36657624936751887, "episode": 2382.0, "duration": 0.23106050491333008, "step": 75677}
{"episode_reward": -0.016224297109025204, "episode": 2383.0, "duration": 0.21976113319396973, "step": 75678}
{"episode_reward": -0.8875472545623779, "episode": 2384.0, "batch_reward": -0.003960692423528859, "critic_loss": 1.2118979266711645, "ae_transition_loss": 1.5882834110941206, "ae_encoder_loss": 0.7609815725258419, "actor_loss": -1.4933819047042303, "actor_target_entropy": -2.0, "actor_entropy": -0.663086644240788, "alpha_loss": -0.0004656022834491783, "alpha_value": 0.006331659376622674, "duration": 28.43592405319214, "step": 75820}
{"episode_reward": 42.77433045225714, "episode": 2385.0, "batch_reward": 0.022701478873689968, "critic_loss": 1.017627735932668, "ae_transition_loss": 1.3693015575408936, "ae_encoder_loss": 0.7671547333399454, "actor_loss": -1.6549458901087444, "actor_target_entropy": -2.0, "actor_entropy": -0.4823718269666036, "alpha_loss": 0.001449098897865042, "alpha_value": 0.006352207180201352, "duration": 5.47441029548645, "step": 75846}
{"episode_reward": 1.7270849723035653, "episode": 2386.0, "batch_reward": 0.0030762068927288055, "critic_loss": 1.1088404258092244, "ae_transition_loss": 1.643246014912923, "ae_encoder_loss": 0.7895029783248901, "actor_loss": -1.6056462526321411, "actor_target_entropy": -2.0, "actor_entropy": -0.8154592712720236, "alpha_loss": 8.051194405804078e-05, "alpha_value": 0.0063531384776587055, "duration": 6.325230121612549, "step": 75877}
{"episode_reward": -0.07878631721379184, "episode": 2387.0, "batch_reward": -0.011903554387390613, "critic_loss": 1.0502282500267028, "ae_transition_loss": 1.9136978387832642, "ae_encoder_loss": 0.6284753918647766, "actor_loss": -1.5753783464431763, "actor_target_entropy": -2.0, "actor_entropy": -0.967595899105072, "alpha_loss": -0.0006424975174013526, "alpha_value": 0.00635430626350203, "duration": 9.272360801696777, "step": 75922}
{"episode_reward": 7.018328500587409, "episode": 2388.0, "batch_reward": 0.01873900283438464, "critic_loss": 1.3301917910575867, "ae_transition_loss": 1.7609787384668987, "ae_encoder_loss": 0.6076569110155106, "actor_loss": -1.5245547890663147, "actor_target_entropy": -2.0, "actor_entropy": -0.7904293636480967, "alpha_loss": -0.0005010175033627698, "alpha_value": 0.0063580292598624044, "duration": 12.42157793045044, "step": 75982}
{"episode_reward": 0.9361731482006186, "episode": 2389.0, "batch_reward": 0.011429662816226482, "critic_loss": 1.303549587726593, "ae_transition_loss": 1.7471402883529663, "ae_encoder_loss": 0.8304430544376373, "actor_loss": -1.3024021983146667, "actor_target_entropy": -2.0, "actor_entropy": -0.4925650358200073, "alpha_loss": -0.0003171366697642952, "alpha_value": 0.006360865548218366, "duration": 4.9453959465026855, "step": 76006}
{"episode_reward": -7.0134172850882095, "episode": 2390.0, "duration": 0.23172426223754883, "step": 76007}
{"episode_reward": -0.4945567298726498, "episode": 2391.0, "batch_reward": -0.09396608918905258, "critic_loss": 0.9778605103492737, "ae_transition_loss": 1.7617031335830688, "ae_encoder_loss": 0.5446901917457581, "actor_loss": -1.2134432792663574, "actor_target_entropy": -2.0, "actor_entropy": -0.364757776260376, "alpha_loss": 0.00181775470264256, "alpha_value": 0.006361998632559241, "duration": 47.94413495063782, "step": 76017}
{"episode_reward": -1.8622319224939936, "episode": 2392.0, "batch_reward": 0.0008818674832582474, "critic_loss": 0.8480538725852966, "ae_transition_loss": 1.7208871841430664, "ae_encoder_loss": 0.6272022426128387, "actor_loss": -1.4942131638526917, "actor_target_entropy": -2.0, "actor_entropy": -0.3632580041885376, "alpha_loss": 0.0003754757344722748, "alpha_value": 0.006362530797250736, "duration": 4.155540704727173, "step": 76037}
{"episode_reward": -0.8439321611811607, "episode": 2393.0, "batch_reward": -0.009634463116526604, "critic_loss": 1.1536759336789448, "ae_transition_loss": 1.6308732430140178, "ae_encoder_loss": 0.5402238269646963, "actor_loss": -1.550953209400177, "actor_target_entropy": -2.0, "actor_entropy": -0.4125054329633713, "alpha_loss": 0.0013091651198919863, "alpha_value": 0.006362057784495026, "duration": 11.722197532653809, "step": 76093}
{"episode_reward": 7.357773019469619, "episode": 2394.0, "batch_reward": 0.03089396966000398, "critic_loss": 1.2777154445648193, "ae_transition_loss": 1.663521409034729, "ae_encoder_loss": 0.5789064566294352, "actor_loss": -1.688503583272298, "actor_target_entropy": -2.0, "actor_entropy": -0.4818879961967468, "alpha_loss": 0.0017323160621648033, "alpha_value": 0.006357201467285252, "duration": 6.781407833099365, "step": 76125}
{"episode_reward": 0.3004414337983831, "episode": 2395.0, "batch_reward": -0.006001378176733851, "critic_loss": 1.0010117590427399, "ae_transition_loss": 1.360815982023875, "ae_encoder_loss": 0.560263862212499, "actor_loss": -1.6025392909844716, "actor_target_entropy": -2.0, "actor_entropy": -0.7231641213099161, "alpha_loss": 0.0006716268302019065, "alpha_value": 0.006348040678037572, "duration": 12.08647632598877, "step": 76183}
{"episode_reward": 15.199667434044557, "episode": 2396.0, "batch_reward": 0.0025919657200574875, "critic_loss": 0.6255570153395335, "ae_transition_loss": 1.678078333536784, "ae_encoder_loss": 0.5403377612431844, "actor_loss": -1.5081408818562825, "actor_target_entropy": -2.0, "actor_entropy": -0.8455061316490173, "alpha_loss": -0.0004139148610799263, "alpha_value": 0.006340381231114686, "duration": 6.173409461975098, "step": 76211}
{"episode_reward": 2.699958622034883, "episode": 2397.0, "duration": 0.2054429054260254, "step": 76212}
{"episode_reward": -0.5031850857410695, "episode": 2398.0, "batch_reward": 0.05736552178859711, "critic_loss": 0.8512048721313477, "ae_transition_loss": 1.2919626832008362, "ae_encoder_loss": 0.47009649872779846, "actor_loss": -1.4144129157066345, "actor_target_entropy": -2.0, "actor_entropy": -0.6747391223907471, "alpha_loss": 0.0005421896858024411, "alpha_value": 0.00633804713827656, "duration": 4.0726165771484375, "step": 76231}
{"episode_reward": 1.3018488258211558, "episode": 2399.0, "duration": 0.19060420989990234, "step": 76232}
{"episode_reward": -0.08670727163553238, "episode": 2400.0, "batch_reward": 0.028866488486528397, "critic_loss": 0.9461511373519897, "ae_transition_loss": 1.389487624168396, "ae_encoder_loss": 0.6162447333335876, "actor_loss": -1.8898792266845703, "actor_target_entropy": -2.0, "actor_entropy": -0.9342466592788696, "alpha_loss": -0.00197969120927155, "alpha_value": 0.006336620949944439, "duration": 3.450381278991699, "step": 76249}
{"episode_reward": -1.9718577788147507, "episode": 2401.0, "batch_reward": -0.022498960420489312, "critic_loss": 0.9389107584953308, "ae_transition_loss": 1.5838834524154664, "ae_encoder_loss": 0.5688085496425629, "actor_loss": -1.2867592334747315, "actor_target_entropy": -2.0, "actor_entropy": -1.1128818035125732, "alpha_loss": -0.00029764766222797336, "alpha_value": 0.006335304277164032, "duration": 52.75468921661377, "step": 76297}
{"episode_reward": 7.8820088930833325, "episode": 2402.0, "batch_reward": -0.050406329333782196, "critic_loss": 0.956213116645813, "ae_transition_loss": 1.7649095058441162, "ae_encoder_loss": 0.5712560713291168, "actor_loss": -1.4267083406448364, "actor_target_entropy": -2.0, "actor_entropy": -1.0111843943595886, "alpha_loss": -0.00473357317969203, "alpha_value": 0.006334919915611109, "duration": 4.859501600265503, "step": 76320}
{"episode_reward": 2.1167855609649995, "episode": 2403.0, "batch_reward": -0.011952226981520653, "critic_loss": 0.8792816400527954, "ae_transition_loss": 1.676167905330658, "ae_encoder_loss": 0.515922948718071, "actor_loss": -1.6928366422653198, "actor_target_entropy": -2.0, "actor_entropy": -1.057460606098175, "alpha_loss": -0.011033661663532257, "alpha_value": 0.006339170329635373, "duration": 3.1302833557128906, "step": 76333}
{"episode_reward": -2.1593350008850485, "episode": 2404.0, "batch_reward": 0.07216499745845795, "critic_loss": 1.0248496532440186, "ae_transition_loss": 1.5284175872802734, "ae_encoder_loss": 0.5685996413230896, "actor_loss": -2.2846689224243164, "actor_target_entropy": -2.0, "actor_entropy": -1.1773383617401123, "alpha_loss": -0.00384948356077075, "alpha_value": 0.006347087606770744, "duration": 2.3306174278259277, "step": 76343}
{"episode_reward": -0.4939168793148577, "episode": 2405.0, "batch_reward": -0.014499519020318985, "critic_loss": 0.5815668106079102, "ae_transition_loss": 1.8041646480560303, "ae_encoder_loss": 0.6297379732131958, "actor_loss": -2.1812736988067627, "actor_target_entropy": -2.0, "actor_entropy": -1.3965861797332764, "alpha_loss": -0.002843813505023718, "alpha_value": 0.006353295301259993, "duration": 2.9363365173339844, "step": 76357}
{"episode_reward": -0.1413436890983953, "episode": 2406.0, "batch_reward": -0.03599714239438375, "critic_loss": 1.071046233177185, "ae_transition_loss": 1.5702054103215535, "ae_encoder_loss": 0.6123359600702921, "actor_loss": -1.3566653728485107, "actor_target_entropy": -2.0, "actor_entropy": -1.0984354813893635, "alpha_loss": -0.003447983879595995, "alpha_value": 0.006365647574069234, "duration": 6.151268005371094, "step": 76386}
{"episode_reward": 6.382855243264318, "episode": 2407.0, "batch_reward": 0.00318489633500576, "critic_loss": 1.1636493802070618, "ae_transition_loss": 1.6197647094726562, "ae_encoder_loss": 0.702191948890686, "actor_loss": -1.3101109504699706, "actor_target_entropy": -2.0, "actor_entropy": -0.6723075211048126, "alpha_loss": -0.0004157622141065076, "alpha_value": 0.006390308901411168, "duration": 9.910230159759521, "step": 76433}
{"episode_reward": 11.854408265808072, "episode": 2408.0, "batch_reward": -0.009254589676856995, "critic_loss": 1.1709985733032227, "ae_transition_loss": 1.6866919994354248, "ae_encoder_loss": 0.6974244458334786, "actor_loss": -1.6171279634748186, "actor_target_entropy": -2.0, "actor_entropy": -0.7688309465135846, "alpha_loss": -0.0014949057783399309, "alpha_value": 0.0064171705559785824, "duration": 13.802143096923828, "step": 76501}
{"episode_reward": 37.12659217312141, "episode": 2409.0, "batch_reward": -0.027381041552871466, "critic_loss": 1.1492053419351578, "ae_transition_loss": 1.5228080451488495, "ae_encoder_loss": 0.5744818076491356, "actor_loss": -1.6976169049739838, "actor_target_entropy": -2.0, "actor_entropy": -0.8016276955604553, "alpha_loss": -0.0013406207144726068, "alpha_value": 0.0064378707039760095, "duration": 8.109594583511353, "step": 76541}
{"episode_reward": 8.839902261934274, "episode": 2410.0, "duration": 0.18340110778808594, "step": 76542}
{"episode_reward": -7.882819805504662, "episode": 2411.0, "batch_reward": -0.012136995326727629, "critic_loss": 0.6441930830478668, "ae_transition_loss": 1.6569219827651978, "ae_encoder_loss": 0.5903447866439819, "actor_loss": -1.6990225315093994, "actor_target_entropy": -2.0, "actor_entropy": -0.45222437381744385, "alpha_loss": -0.0016411193646490574, "alpha_value": 0.00644799890474319, "duration": 85.26858973503113, "step": 76562}
{"episode_reward": -1.4168251446034215, "episode": 2412.0, "batch_reward": -0.04632824659347534, "critic_loss": 0.5558404922485352, "ae_transition_loss": 1.4535049200057983, "ae_encoder_loss": 0.7914078831672668, "actor_loss": -2.064941167831421, "actor_target_entropy": -2.0, "actor_entropy": -0.603762686252594, "alpha_loss": -0.000467627658508718, "alpha_value": 0.0064529078233481005, "duration": 3.2488508224487305, "step": 76578}
{"episode_reward": -4.470888628933602, "episode": 2413.0, "batch_reward": 0.05655129998922348, "critic_loss": 0.5857606530189514, "ae_transition_loss": 1.5363677740097046, "ae_encoder_loss": 0.6271287202835083, "actor_loss": -1.7818114757537842, "actor_target_entropy": -2.0, "actor_entropy": -1.2403697967529297, "alpha_loss": -0.001839821576140821, "alpha_value": 0.0064559825438995876, "duration": 2.476062774658203, "step": 76590}
{"episode_reward": -3.4488784002914463, "episode": 2414.0, "batch_reward": -0.029566967859864235, "critic_loss": 1.8433725237846375, "ae_transition_loss": 1.5295130411783855, "ae_encoder_loss": 0.8914787371953329, "actor_loss": -1.1753087838490803, "actor_target_entropy": -2.0, "actor_entropy": -1.3092053731282551, "alpha_loss": -0.007373329562445481, "alpha_value": 0.006463292956006138, "duration": 4.558130502700806, "step": 76612}
{"episode_reward": -3.7417649936069353, "episode": 2415.0, "batch_reward": -0.04199868068099022, "critic_loss": 1.0542051792144775, "ae_transition_loss": 1.3260148763656616, "ae_encoder_loss": 0.4717614948749542, "actor_loss": -0.6858735084533691, "actor_target_entropy": -2.0, "actor_entropy": -1.1418254375457764, "alpha_loss": -0.01168588176369667, "alpha_value": 0.006474554470919165, "duration": 2.432387113571167, "step": 76624}
{"episode_reward": -4.941062761931205, "episode": 2416.0, "batch_reward": -0.019505932927131653, "critic_loss": 0.6198010742664337, "ae_transition_loss": 1.3112226724624634, "ae_encoder_loss": 0.6273792237043381, "actor_loss": -1.4412564039230347, "actor_target_entropy": -2.0, "actor_entropy": -1.4267616868019104, "alpha_loss": -0.012195374350994825, "alpha_value": 0.006488217310889565, "duration": 4.1031341552734375, "step": 76644}
{"episode_reward": -0.8222183929170852, "episode": 2417.0, "batch_reward": 0.01760615035891533, "critic_loss": 0.8081039786338806, "ae_transition_loss": 1.4659650325775146, "ae_encoder_loss": 0.5245714634656906, "actor_loss": -1.7596926093101501, "actor_target_entropy": -2.0, "actor_entropy": -1.6852697134017944, "alpha_loss": -0.00664007687009871, "alpha_value": 0.006510935055768805, "duration": 4.189974069595337, "step": 76664}
{"episode_reward": 0.7429852570104191, "episode": 2418.0, "batch_reward": -0.029179584234952927, "critic_loss": 1.1311396956443787, "ae_transition_loss": 1.569211224714915, "ae_encoder_loss": 0.6223221768935522, "actor_loss": -1.638534684975942, "actor_target_entropy": -2.0, "actor_entropy": -1.4717466433842976, "alpha_loss": -0.003064742952119559, "alpha_value": 0.006556984130412984, "duration": 11.902791738510132, "step": 76721}
{"episode_reward": 15.387911317148841, "episode": 2419.0, "batch_reward": -0.03499048249796033, "critic_loss": 0.9765654951334, "ae_transition_loss": 1.5086307227611542, "ae_encoder_loss": 0.5780497491359711, "actor_loss": -1.2540807723999023, "actor_target_entropy": -2.0, "actor_entropy": -1.0676111727952957, "alpha_loss": -0.0018184598156949505, "alpha_value": 0.006605386582662705, "duration": 9.77614974975586, "step": 76769}
{"episode_reward": 8.712613308127088, "episode": 2420.0, "batch_reward": 0.0013112348193923633, "critic_loss": 1.399927814801534, "ae_transition_loss": 1.6014376878738403, "ae_encoder_loss": 0.7953992883364359, "actor_loss": -1.6753216981887817, "actor_target_entropy": -2.0, "actor_entropy": -0.7769441604614258, "alpha_loss": -0.0010579386726021767, "alpha_value": 0.006631856058875281, "duration": 5.315917730331421, "step": 76795}
{"episode_reward": 4.073722557060622, "episode": 2421.0, "batch_reward": 0.031702284002676606, "critic_loss": 1.3531752824783325, "ae_transition_loss": 1.5479576587677002, "ae_encoder_loss": 0.7214440703392029, "actor_loss": -1.6462002992630005, "actor_target_entropy": -2.0, "actor_entropy": -0.5202381014823914, "alpha_loss": 0.0005090499616926536, "alpha_value": 0.006647389844029683, "duration": 45.387948751449585, "step": 76817}
{"episode_reward": 3.050029988157488, "episode": 2422.0, "batch_reward": -0.003503235677878062, "critic_loss": 1.3680298427740734, "ae_transition_loss": 1.6749852101008098, "ae_encoder_loss": 0.7048594852288564, "actor_loss": -1.7483568986256917, "actor_target_entropy": -2.0, "actor_entropy": -0.39873742684721947, "alpha_loss": -0.002277053747093305, "alpha_value": 0.006665509829599847, "duration": 11.931284427642822, "step": 76874}
{"episode_reward": 1.9566017487085232, "episode": 2423.0, "batch_reward": -0.02904804396842207, "critic_loss": 1.2168892196246557, "ae_transition_loss": 1.7756663049970354, "ae_encoder_loss": 0.6518031230994633, "actor_loss": -1.5310800245829992, "actor_target_entropy": -2.0, "actor_entropy": -1.0418490597179957, "alpha_loss": -0.004121244136643197, "alpha_value": 0.00670030684717725, "duration": 15.084219694137573, "step": 76947}
{"episode_reward": 19.445845417717983, "episode": 2424.0, "batch_reward": -0.01863026339560747, "critic_loss": 1.055953860282898, "ae_transition_loss": 1.5959870219230652, "ae_encoder_loss": 0.7325316965579987, "actor_loss": -1.3432233929634094, "actor_target_entropy": -2.0, "actor_entropy": -0.7463977932929993, "alpha_loss": -0.000735610636183992, "alpha_value": 0.006730634440411597, "duration": 4.6075828075408936, "step": 76969}
{"episode_reward": -1.6863372530739718, "episode": 2425.0, "batch_reward": -0.014377237608035406, "critic_loss": 0.6834590633710226, "ae_transition_loss": 1.3868197202682495, "ae_encoder_loss": 0.6165288190046946, "actor_loss": -1.4762102365493774, "actor_target_entropy": -2.0, "actor_entropy": -0.6056601603825887, "alpha_loss": -0.0006771919142920524, "alpha_value": 0.0067450866186895666, "duration": 5.815719366073608, "step": 76997}
{"episode_reward": 4.6724880786210345, "episode": 2426.0, "duration": 0.26375794410705566, "step": 76998}
{"episode_reward": -0.19421810609314874, "episode": 2427.0, "batch_reward": 0.00597304425069264, "critic_loss": 1.0885100364685059, "ae_transition_loss": 1.5433157171521867, "ae_encoder_loss": 0.5998932719230652, "actor_loss": -1.5544051613126482, "actor_target_entropy": -2.0, "actor_entropy": -0.5685259103775024, "alpha_loss": 0.0007656186187107648, "alpha_value": 0.006763927865032551, "duration": 14.224059104919434, "step": 77067}
{"episode_reward": 17.443705594813864, "episode": 2428.0, "batch_reward": 0.005365356492499511, "critic_loss": 0.9780846238136292, "ae_transition_loss": 1.439720352490743, "ae_encoder_loss": 0.5800457795461019, "actor_loss": -1.7563775380452473, "actor_target_entropy": -2.0, "actor_entropy": -0.8686083952585856, "alpha_loss": -0.0016710120641315978, "alpha_value": 0.006773964601292756, "duration": 5.554215431213379, "step": 77093}
{"episode_reward": 4.437781198495191, "episode": 2429.0, "batch_reward": -0.048693567514419556, "critic_loss": 0.7424351722002029, "ae_transition_loss": 1.4081464409828186, "ae_encoder_loss": 0.5148672014474869, "actor_loss": -1.46571946144104, "actor_target_entropy": -2.0, "actor_entropy": -0.8370680212974548, "alpha_loss": -0.0017067291191779077, "alpha_value": 0.00677882059793908, "duration": 5.16527533531189, "step": 77119}
{"episode_reward": 2.594624234411949, "episode": 2430.0, "batch_reward": -0.015613421564921737, "critic_loss": 0.8563890308141708, "ae_transition_loss": 1.5759832561016083, "ae_encoder_loss": 0.5512339249253273, "actor_loss": -1.4076668918132782, "actor_target_entropy": -2.0, "actor_entropy": -0.7940098196268082, "alpha_loss": -0.0034526336821727455, "alpha_value": 0.0067866613621531575, "duration": 7.356070518493652, "step": 77154}
{"episode_reward": -6.572677691396058, "episode": 2431.0, "batch_reward": -0.03955702600069344, "critic_loss": 1.0434244610369205, "ae_transition_loss": 1.6372068226337433, "ae_encoder_loss": 0.6905201897025108, "actor_loss": -1.5455617010593414, "actor_target_entropy": -2.0, "actor_entropy": -0.8761846199631691, "alpha_loss": -0.0026398807240184397, "alpha_value": 0.006814341839554692, "duration": 53.1862895488739, "step": 77232}
{"episode_reward": -20.250001376195996, "episode": 2432.0, "batch_reward": -0.029777926206588746, "critic_loss": 0.9522834658622742, "ae_transition_loss": 1.5597747564315796, "ae_encoder_loss": 0.6998411357402802, "actor_loss": -1.3572060823440553, "actor_target_entropy": -2.0, "actor_entropy": -0.7353484988212585, "alpha_loss": -0.0001491087779868394, "alpha_value": 0.00684625170928643, "duration": 10.441233396530151, "step": 77285}
{"episode_reward": 30.590816403288063, "episode": 2433.0, "batch_reward": -0.005292522162199021, "critic_loss": 1.0754762291908264, "ae_transition_loss": 1.6877662181854247, "ae_encoder_loss": 0.8494474172592164, "actor_loss": -1.5331024408340455, "actor_target_entropy": -2.0, "actor_entropy": -0.7695722460746766, "alpha_loss": -0.00047176285297609863, "alpha_value": 0.006860931420876089, "duration": 9.763688802719116, "step": 77333}
{"episode_reward": 9.346648691269314, "episode": 2434.0, "duration": 0.20737195014953613, "step": 77334}
{"episode_reward": -0.6341533035706151, "episode": 2435.0, "batch_reward": -0.030010701157152653, "critic_loss": 1.4515672326087952, "ae_transition_loss": 1.7917172312736511, "ae_encoder_loss": 0.6953629702329636, "actor_loss": -1.5664505362510681, "actor_target_entropy": -2.0, "actor_entropy": -0.798673003911972, "alpha_loss": -0.0013079392374493182, "alpha_value": 0.006868546349780934, "duration": 4.880273818969727, "step": 77357}
{"episode_reward": 2.5144227625941973, "episode": 2436.0, "batch_reward": -0.007360729492372937, "critic_loss": 1.1818744275305006, "ae_transition_loss": 1.5376946793662176, "ae_encoder_loss": 0.6511146061950259, "actor_loss": -1.6533709234661527, "actor_target_entropy": -2.0, "actor_entropy": -0.9645904766188728, "alpha_loss": -0.0025916528797501493, "alpha_value": 0.006885771596344458, "duration": 17.15479588508606, "step": 77442}
{"episode_reward": 21.829824351342744, "episode": 2437.0, "batch_reward": -0.050000415183603764, "critic_loss": 0.902757078409195, "ae_transition_loss": 1.681598961353302, "ae_encoder_loss": 0.7283767908811569, "actor_loss": -1.414910078048706, "actor_target_entropy": -2.0, "actor_entropy": -1.072376549243927, "alpha_loss": 7.239155820570886e-05, "alpha_value": 0.006911674630300598, "duration": 8.92072057723999, "step": 77486}
{"episode_reward": 5.116363648168523, "episode": 2438.0, "batch_reward": 0.037235407158732414, "critic_loss": 0.7752479016780853, "ae_transition_loss": 1.608502209186554, "ae_encoder_loss": 0.670620858669281, "actor_loss": -1.4040567278862, "actor_target_entropy": -2.0, "actor_entropy": -0.7813057601451874, "alpha_loss": 1.6581587260589004e-05, "alpha_value": 0.006920579865138549, "duration": 3.4030678272247314, "step": 77502}
{"episode_reward": -3.6373278573709094, "episode": 2439.0, "batch_reward": 0.004991514608263969, "critic_loss": 1.6387169361114502, "ae_transition_loss": 1.4522827863693237, "ae_encoder_loss": 0.6874807178974152, "actor_loss": -1.3233962655067444, "actor_target_entropy": -2.0, "actor_entropy": -0.7159928679466248, "alpha_loss": -0.0009531022078590468, "alpha_value": 0.006925131742122318, "duration": 5.004770755767822, "step": 77527}
{"episode_reward": -0.2896940791701147, "episode": 2440.0, "duration": 0.2591691017150879, "step": 77528}
{"episode_reward": -0.6272373141184159, "episode": 2441.0, "batch_reward": 7.726345211267471e-05, "critic_loss": 1.2076611518859863, "ae_transition_loss": 1.7709022760391235, "ae_encoder_loss": 0.7394690811634064, "actor_loss": -1.6993701756000519, "actor_target_entropy": -2.0, "actor_entropy": -0.7766319066286087, "alpha_loss": -0.0026409379788674414, "alpha_value": 0.006932405236087076, "duration": 132.43533849716187, "step": 77562}
{"episode_reward": 5.258559340749669, "episode": 2442.0, "duration": 0.8565797805786133, "step": 77566}
{"episode_reward": -1.5476718815304895, "episode": 2443.0, "batch_reward": -0.018301382660865784, "critic_loss": 1.238180935382843, "ae_transition_loss": 1.666740894317627, "ae_encoder_loss": 0.6502888947725296, "actor_loss": -1.7427427768707275, "actor_target_entropy": -2.0, "actor_entropy": -0.9991973042488098, "alpha_loss": -0.0041148620075546205, "alpha_value": 0.006947029249368849, "duration": 7.639727354049683, "step": 77604}
{"episode_reward": 6.698703588054796, "episode": 2444.0, "duration": 0.19968175888061523, "step": 77605}
{"episode_reward": -0.7795488136492519, "episode": 2445.0, "duration": 0.22431683540344238, "step": 77606}
{"episode_reward": -0.9140308228064731, "episode": 2446.0, "batch_reward": -0.0009665612131357193, "critic_loss": 1.5211358070373535, "ae_transition_loss": 1.9849472999572755, "ae_encoder_loss": 0.8012927889823913, "actor_loss": -1.7169753789901734, "actor_target_entropy": -2.0, "actor_entropy": -0.9429644584655762, "alpha_loss": -0.002901508426293731, "alpha_value": 0.006971234375283975, "duration": 10.967576026916504, "step": 77659}
{"episode_reward": -0.11568008622054682, "episode": 2447.0, "batch_reward": 0.01613537408411503, "critic_loss": 0.9086337089538574, "ae_transition_loss": 1.8287625312805176, "ae_encoder_loss": 0.8528205454349518, "actor_loss": -1.5463823676109314, "actor_target_entropy": -2.0, "actor_entropy": -0.6712421178817749, "alpha_loss": -4.0964107029139996e-05, "alpha_value": 0.006991797859415263, "duration": 2.93566632270813, "step": 77671}
{"episode_reward": -2.995756270254309, "episode": 2448.0, "duration": 0.19978904724121094, "step": 77672}
{"episode_reward": -0.28369653003746964, "episode": 2449.0, "batch_reward": -0.009207667782902718, "critic_loss": 1.509748935699463, "ae_transition_loss": 1.7502493262290955, "ae_encoder_loss": 1.05561763048172, "actor_loss": -1.661378026008606, "actor_target_entropy": -2.0, "actor_entropy": -1.046628177165985, "alpha_loss": -0.0020075395732419565, "alpha_value": 0.00700163931423467, "duration": 4.968249320983887, "step": 77697}
{"episode_reward": -4.061810736336412, "episode": 2450.0, "batch_reward": -0.001631372297803561, "critic_loss": 1.521483063697815, "ae_transition_loss": 1.8064852158228557, "ae_encoder_loss": 1.3201258182525635, "actor_loss": -1.3664326270421345, "actor_target_entropy": -2.0, "actor_entropy": -0.9981503883997599, "alpha_loss": -0.002296529244631529, "alpha_value": 0.007013947972626395, "duration": 5.532191276550293, "step": 77723}
{"episode_reward": 3.373921947035793, "episode": 2451.0, "batch_reward": -0.044782749563455584, "critic_loss": 1.2264134347438813, "ae_transition_loss": 1.7860897302627563, "ae_encoder_loss": 1.3851664543151856, "actor_loss": -1.643030309677124, "actor_target_entropy": -2.0, "actor_entropy": -0.8627570509910584, "alpha_loss": -0.001418261998333037, "alpha_value": 0.007033459377439486, "duration": 59.35725474357605, "step": 77774}
{"episode_reward": 14.173537809158168, "episode": 2452.0, "batch_reward": -0.019604493198650225, "critic_loss": 0.9295301607676915, "ae_transition_loss": 1.6951563188007899, "ae_encoder_loss": 1.039862539087023, "actor_loss": -1.7289079427719116, "actor_target_entropy": -2.0, "actor_entropy": -1.037255312715258, "alpha_loss": -0.0031345709160502467, "alpha_value": 0.007061014798867913, "duration": 14.492815017700195, "step": 77843}
{"episode_reward": 16.794297626863806, "episode": 2453.0, "batch_reward": 0.018976153805851936, "critic_loss": 0.7219732105731964, "ae_transition_loss": 1.9326629042625427, "ae_encoder_loss": 0.8143862783908844, "actor_loss": -1.8757768869400024, "actor_target_entropy": -2.0, "actor_entropy": -1.7602907419204712, "alpha_loss": -0.004859322449192405, "alpha_value": 0.007085589364069367, "duration": 5.132625341415405, "step": 77868}
{"episode_reward": 2.8217869117487973, "episode": 2454.0, "batch_reward": -0.036809998963560374, "critic_loss": 1.006129162652152, "ae_transition_loss": 1.64141959803445, "ae_encoder_loss": 0.8063315408570426, "actor_loss": -1.4098689896719796, "actor_target_entropy": -2.0, "actor_entropy": -1.2357765521321977, "alpha_loss": -0.00491321732157043, "alpha_value": 0.007118708857110469, "duration": 14.67567491531372, "step": 77940}
{"episode_reward": 20.09521989875797, "episode": 2455.0, "batch_reward": -0.053162640891969204, "critic_loss": 1.381818413734436, "ae_transition_loss": 1.915526270866394, "ae_encoder_loss": 0.5615757405757904, "actor_loss": -1.7197844982147217, "actor_target_entropy": -2.0, "actor_entropy": -0.7428687214851379, "alpha_loss": -0.006731923436746001, "alpha_value": 0.007157743572796471, "duration": 2.7375705242156982, "step": 77951}
{"episode_reward": -1.1787669048419223, "episode": 2456.0, "duration": 0.1895132064819336, "step": 77952}
{"episode_reward": -0.6884228077836494, "episode": 2457.0, "duration": 0.21393418312072754, "step": 77953}
{"episode_reward": 0.06663665926414994, "episode": 2458.0, "batch_reward": -0.022917013615369797, "critic_loss": 0.8490204811096191, "ae_transition_loss": 1.827094852924347, "ae_encoder_loss": 0.7264889478683472, "actor_loss": -1.6338927745819092, "actor_target_entropy": -2.0, "actor_entropy": -0.6519050300121307, "alpha_loss": -0.0075980068650096655, "alpha_value": 0.007178880718590953, "duration": 5.0305540561676025, "step": 77976}
{"episode_reward": 2.3841609237670003, "episode": 2459.0, "batch_reward": -0.008418693828086058, "critic_loss": 0.9321177552143732, "ae_transition_loss": 1.511858622233073, "ae_encoder_loss": 0.7168439428011576, "actor_loss": -1.527514656384786, "actor_target_entropy": -2.0, "actor_entropy": -0.8691779871781667, "alpha_loss": -0.002811961002104605, "alpha_value": 0.007224620368906847, "duration": 13.103716850280762, "step": 78039}
{"episode_reward": 16.177174731695406, "episode": 2460.0, "batch_reward": -0.04113957489078695, "critic_loss": 0.8878550258549777, "ae_transition_loss": 1.6877157146280461, "ae_encoder_loss": 0.7222599224610762, "actor_loss": -1.5603866360404275, "actor_target_entropy": -2.0, "actor_entropy": -0.9357819665562023, "alpha_loss": -0.00230004215634174, "alpha_value": 0.007298838959351156, "duration": 23.239590644836426, "step": 78150}
{"episode_reward": 54.099183690619235, "episode": 2461.0, "batch_reward": -0.03254525735974312, "critic_loss": 0.9288371205329895, "ae_transition_loss": 1.515900691350301, "ae_encoder_loss": 0.8981544375419617, "actor_loss": -1.320141116778056, "actor_target_entropy": -2.0, "actor_entropy": -0.9415938456853231, "alpha_loss": -0.002361123687781704, "alpha_value": 0.007357935147061519, "duration": 55.47589373588562, "step": 78208}
{"episode_reward": 9.589210560812328, "episode": 2462.0, "batch_reward": 0.020325048516194027, "critic_loss": 1.2346239189306896, "ae_transition_loss": 1.5263919830322266, "ae_encoder_loss": 0.7245412667592367, "actor_loss": -1.6719029347101848, "actor_target_entropy": -2.0, "actor_entropy": -0.9275157848993937, "alpha_loss": -0.004139017624159654, "alpha_value": 0.007386550331453197, "duration": 5.652654647827148, "step": 78233}
{"episode_reward": 5.55388610620119, "episode": 2463.0, "batch_reward": -0.0350569412112236, "critic_loss": 1.1486591299374898, "ae_transition_loss": 1.3527143001556396, "ae_encoder_loss": 0.5235433479150137, "actor_loss": -1.3197155396143596, "actor_target_entropy": -2.0, "actor_entropy": -0.8436325391133627, "alpha_loss": -0.0048283714180191355, "alpha_value": 0.007408101949913076, "duration": 7.258803606033325, "step": 78269}
{"episode_reward": 11.185672798492725, "episode": 2464.0, "batch_reward": -0.01781555525958538, "critic_loss": 0.9389716506004333, "ae_transition_loss": 1.587249207496643, "ae_encoder_loss": 0.6002986311912537, "actor_loss": -1.8174206495285035, "actor_target_entropy": -2.0, "actor_entropy": -0.9927610635757447, "alpha_loss": -0.0031883873511105777, "alpha_value": 0.007440321277890701, "duration": 10.36781620979309, "step": 78320}
{"episode_reward": 14.79280371126817, "episode": 2465.0, "batch_reward": -0.0691645120580991, "critic_loss": 0.6061115066210429, "ae_transition_loss": 1.8055270115534465, "ae_encoder_loss": 0.5267530481020609, "actor_loss": -1.5247915983200073, "actor_target_entropy": -2.0, "actor_entropy": -1.0521620909372966, "alpha_loss": -0.0013438818277791142, "alpha_value": 0.007472451297029492, "duration": 6.479790925979614, "step": 78350}
{"episode_reward": 4.13841018614783, "episode": 2466.0, "batch_reward": -0.01973603417476018, "critic_loss": 0.8745690186818441, "ae_transition_loss": 1.367649515469869, "ae_encoder_loss": 0.4873174826304118, "actor_loss": -1.5695894161860149, "actor_target_entropy": -2.0, "actor_entropy": -0.8921442627906799, "alpha_loss": -0.004329058962563674, "alpha_value": 0.007494685142276852, "duration": 5.315872430801392, "step": 78377}
{"episode_reward": 1.7304407878285553, "episode": 2467.0, "batch_reward": -0.0524365333840251, "critic_loss": 1.0629216432571411, "ae_transition_loss": 1.4765092134475708, "ae_encoder_loss": 0.5921009182929993, "actor_loss": -1.5008782744407654, "actor_target_entropy": -2.0, "actor_entropy": -1.001896470785141, "alpha_loss": -0.002928019384853542, "alpha_value": 0.007514003858610415, "duration": 3.9198524951934814, "step": 78395}
{"episode_reward": -1.2792955880616808, "episode": 2468.0, "duration": 0.21988320350646973, "step": 78396}
{"episode_reward": -0.42073971034386015, "episode": 2469.0, "batch_reward": 0.009266362835963568, "critic_loss": 0.7107912500699362, "ae_transition_loss": 1.3823843797047932, "ae_encoder_loss": 0.6698765456676483, "actor_loss": -1.638013521830241, "actor_target_entropy": -2.0, "actor_entropy": -1.2047460873921711, "alpha_loss": -0.004508049072076877, "alpha_value": 0.007533421321493944, "duration": 5.486292362213135, "step": 78422}
{"episode_reward": 2.5320569258356875, "episode": 2470.0, "batch_reward": 0.00814512837678194, "critic_loss": 0.9176343083381653, "ae_transition_loss": 1.3603424727916718, "ae_encoder_loss": 0.7017181217670441, "actor_loss": -1.96754589676857, "actor_target_entropy": -2.0, "actor_entropy": -1.341480553150177, "alpha_loss": -0.003962138085626066, "alpha_value": 0.007563007389692388, "duration": 9.573164701461792, "step": 78469}
{"episode_reward": 13.657075394856868, "episode": 2471.0, "batch_reward": 0.016361048445105553, "critic_loss": 1.247435708840688, "ae_transition_loss": 1.3602879047393799, "ae_encoder_loss": 0.5211577812830607, "actor_loss": -1.731259862581889, "actor_target_entropy": -2.0, "actor_entropy": -1.4666282335917156, "alpha_loss": -0.0030924519523978233, "alpha_value": 0.007593783998644934, "duration": 38.79208946228027, "step": 78500}
{"episode_reward": 2.371732012972286, "episode": 2472.0, "batch_reward": -0.04479160439223051, "critic_loss": 1.0042868703603745, "ae_transition_loss": 1.3887524604797363, "ae_encoder_loss": 0.5951630398631096, "actor_loss": -1.3644059896469116, "actor_target_entropy": -2.0, "actor_entropy": -1.4200791716575623, "alpha_loss": -0.0032806950621306896, "alpha_value": 0.007623808671329346, "duration": 6.690892696380615, "step": 78531}
{"episode_reward": 5.98469066063571, "episode": 2473.0, "batch_reward": -0.024489807357129297, "critic_loss": 0.9871527678088138, "ae_transition_loss": 1.4455257779673527, "ae_encoder_loss": 0.6503623708298332, "actor_loss": -1.7193770722339028, "actor_target_entropy": -2.0, "actor_entropy": -1.1439278031650342, "alpha_loss": -0.0035022026001426732, "alpha_value": 0.00771986284902395, "duration": 40.70059633255005, "step": 78730}
{"episode_reward": -12.257621586218129, "episode": 2474.0, "batch_reward": -0.04023200273513794, "critic_loss": 1.0050504088401795, "ae_transition_loss": 1.4395657062530518, "ae_encoder_loss": 0.6625989496707916, "actor_loss": -1.4642309904098512, "actor_target_entropy": -2.0, "actor_entropy": -1.212505078315735, "alpha_loss": -0.005205158423632383, "alpha_value": 0.007821731974274142, "duration": 9.999525785446167, "step": 78780}
{"episode_reward": 14.999099821654665, "episode": 2475.0, "batch_reward": 0.0013727347056070964, "critic_loss": 1.1544299125671387, "ae_transition_loss": 1.5810762643814087, "ae_encoder_loss": 0.6600268681844076, "actor_loss": -1.6424846649169922, "actor_target_entropy": -2.0, "actor_entropy": -1.0837557713190715, "alpha_loss": -0.0036250923294574022, "alpha_value": 0.007863304475836483, "duration": 5.848116874694824, "step": 78807}
{"episode_reward": 0.29718479166203854, "episode": 2476.0, "duration": 0.18761324882507324, "step": 78808}
{"episode_reward": -0.43536748053561825, "episode": 2477.0, "duration": 0.22762179374694824, "step": 78809}
{"episode_reward": -0.6495185200308313, "episode": 2478.0, "batch_reward": 0.0002895188517868519, "critic_loss": 1.3897109031677246, "ae_transition_loss": 1.7875936627388, "ae_encoder_loss": 0.575524315237999, "actor_loss": -1.7444546818733215, "actor_target_entropy": -2.0, "actor_entropy": -1.0156397223472595, "alpha_loss": -0.004203111631795764, "alpha_value": 0.00788889995005161, "duration": 3.575838088989258, "step": 78826}
{"episode_reward": -0.4916224274530729, "episode": 2479.0, "batch_reward": -0.0038134735077619553, "critic_loss": 0.6140078604221344, "ae_transition_loss": 1.4673007130622864, "ae_encoder_loss": 0.6639176607131958, "actor_loss": -1.9199822545051575, "actor_target_entropy": -2.0, "actor_entropy": -1.046236276626587, "alpha_loss": -0.0023412680602632463, "alpha_value": 0.007909301314308056, "duration": 4.64396858215332, "step": 78849}
{"episode_reward": 3.381056366363123, "episode": 2480.0, "duration": 0.22983646392822266, "step": 78850}
{"episode_reward": -0.5327215141508781, "episode": 2481.0, "batch_reward": -0.008884490778048834, "critic_loss": 1.691989819208781, "ae_transition_loss": 1.473193923632304, "ae_encoder_loss": 0.5831946432590485, "actor_loss": -1.6515543858210247, "actor_target_entropy": -2.0, "actor_entropy": -0.9485320448875427, "alpha_loss": -0.004811741566906373, "alpha_value": 0.007933585775528204, "duration": 43.64577102661133, "step": 78873}
{"episode_reward": 2.1858493302861786, "episode": 2482.0, "batch_reward": -0.019245800096541643, "critic_loss": 1.2498937249183655, "ae_transition_loss": 1.562223494052887, "ae_encoder_loss": 0.5011813193559647, "actor_loss": -1.6874850988388062, "actor_target_entropy": -2.0, "actor_entropy": -1.091048240661621, "alpha_loss": -0.005426353309303522, "alpha_value": 0.007958698413149362, "duration": 4.975571393966675, "step": 78897}
{"episode_reward": 1.79622263086185, "episode": 2483.0, "batch_reward": -0.09313394129276276, "critic_loss": 0.5231797099113464, "ae_transition_loss": 1.9222238063812256, "ae_encoder_loss": 0.6606500148773193, "actor_loss": -1.1181190013885498, "actor_target_entropy": -2.0, "actor_entropy": -1.2081165313720703, "alpha_loss": -0.004827095661312342, "alpha_value": 0.00797465808530259, "duration": 1.6900782585144043, "step": 78905}
{"episode_reward": -1.7488261454630376, "episode": 2484.0, "batch_reward": 0.019758036981026333, "critic_loss": 1.1080697973569233, "ae_transition_loss": 1.5826298395792644, "ae_encoder_loss": 0.4501907428105672, "actor_loss": -1.6799216667811077, "actor_target_entropy": -2.0, "actor_entropy": -1.1834956804911296, "alpha_loss": -0.0038357488811016083, "alpha_value": 0.007996390258030605, "duration": 5.735245943069458, "step": 78932}
{"episode_reward": 1.2847584045923053, "episode": 2485.0, "duration": 0.18456315994262695, "step": 78933}
{"episode_reward": 0.3474275917580021, "episode": 2486.0, "batch_reward": 0.008594613367070755, "critic_loss": 1.2116597890853882, "ae_transition_loss": 1.4375079075495403, "ae_encoder_loss": 0.41866226494312286, "actor_loss": -1.6722110708554585, "actor_target_entropy": -2.0, "actor_entropy": -1.2258383631706238, "alpha_loss": -0.0027953192378239087, "alpha_value": 0.008041480511435533, "duration": 13.609491109848022, "step": 79000}
{"episode_reward": 11.761999200820133, "episode": 2487.0, "batch_reward": -0.05016764936347803, "critic_loss": 0.8375201423962911, "ae_transition_loss": 1.3992981910705566, "ae_encoder_loss": 0.46898798147837323, "actor_loss": -1.5350200335184734, "actor_target_entropy": -2.0, "actor_entropy": -1.17192808787028, "alpha_loss": -0.0018149423801029723, "alpha_value": 0.00808238101139138, "duration": 4.8686487674713135, "step": 79023}
{"episode_reward": 2.3607892832217594, "episode": 2488.0, "duration": 0.24059414863586426, "step": 79024}
{"episode_reward": -0.3074270051145188, "episode": 2489.0, "batch_reward": 0.024754051119089127, "critic_loss": 0.5469805300235748, "ae_transition_loss": 1.5248038172721863, "ae_encoder_loss": 0.5122291743755341, "actor_loss": -1.8413147926330566, "actor_target_entropy": -2.0, "actor_entropy": -0.8925333321094513, "alpha_loss": -0.002197608118876815, "alpha_value": 0.008102720193622442, "duration": 5.370168209075928, "step": 79050}
{"episode_reward": 2.9045343867105684, "episode": 2490.0, "batch_reward": -0.028794359415769577, "critic_loss": 1.197811782360077, "ae_transition_loss": 1.273618996143341, "ae_encoder_loss": 0.47087518870830536, "actor_loss": -1.8042290806770325, "actor_target_entropy": -2.0, "actor_entropy": -0.8274775445461273, "alpha_loss": -0.0036426896695047617, "alpha_value": 0.008118160155473737, "duration": 4.0435874462127686, "step": 79069}
{"episode_reward": 0.5790726186846609, "episode": 2491.0, "duration": 35.0399227142334, "step": 79070}
{"episode_reward": -0.6839744448661804, "episode": 2492.0, "batch_reward": -0.020008405670523643, "critic_loss": 1.0369127690792084, "ae_transition_loss": 1.413894772529602, "ae_encoder_loss": 0.40202532708644867, "actor_loss": -1.5428439378738403, "actor_target_entropy": -2.0, "actor_entropy": -0.6152479648590088, "alpha_loss": -0.0037894572596997023, "alpha_value": 0.008134283860543327, "duration": 3.073869466781616, "step": 79084}
{"episode_reward": -1.8357720750195625, "episode": 2493.0, "batch_reward": -0.0037605511024594307, "critic_loss": 1.0965676307678223, "ae_transition_loss": 1.2133350372314453, "ae_encoder_loss": 0.372936874628067, "actor_loss": -1.40820974111557, "actor_target_entropy": -2.0, "actor_entropy": -0.7359171509742737, "alpha_loss": -0.0032743819756433368, "alpha_value": 0.008150664974285628, "duration": 4.020391225814819, "step": 79101}
{"episode_reward": 0.24635802192138856, "episode": 2494.0, "batch_reward": 0.014872622986634573, "critic_loss": 0.832090159257253, "ae_transition_loss": 1.4518735806147258, "ae_encoder_loss": 0.3641894956429799, "actor_loss": -1.7976885636647542, "actor_target_entropy": -2.0, "actor_entropy": -0.914155920346578, "alpha_loss": -0.004314801190048456, "alpha_value": 0.008171418253217008, "duration": 6.523986339569092, "step": 79131}
{"episode_reward": 6.861058773993475, "episode": 2495.0, "batch_reward": -0.009460029006004334, "critic_loss": 0.9058158576488495, "ae_transition_loss": 1.4700440406799316, "ae_encoder_loss": 0.47202959656715393, "actor_loss": -2.031187582015991, "actor_target_entropy": -2.0, "actor_entropy": -0.7426205992698669, "alpha_loss": -0.0036068698740564288, "alpha_value": 0.008207421460965184, "duration": 10.663733005523682, "step": 79182}
{"episode_reward": 11.705582763169986, "episode": 2496.0, "duration": 1.496765375137329, "step": 79189}
{"episode_reward": -1.7715221724004073, "episode": 2497.0, "batch_reward": -0.038259568810462954, "critic_loss": 0.9665061593055725, "ae_transition_loss": 1.4756790399551392, "ae_encoder_loss": 0.5013465464115143, "actor_loss": -1.4907810688018799, "actor_target_entropy": -2.0, "actor_entropy": -0.6820743441581726, "alpha_loss": -0.0028644455131143333, "alpha_value": 0.00825016923035605, "duration": 9.496211290359497, "step": 79234}
{"episode_reward": 6.866584583035127, "episode": 2498.0, "batch_reward": -0.007655075751245022, "critic_loss": 0.9629869163036346, "ae_transition_loss": 1.7421252131462097, "ae_encoder_loss": 0.3848545625805855, "actor_loss": -1.9186665415763855, "actor_target_entropy": -2.0, "actor_entropy": -1.267876297235489, "alpha_loss": -0.003550858818925917, "alpha_value": 0.008288195971713439, "duration": 8.539498090744019, "step": 79275}
{"episode_reward": 14.353192052283903, "episode": 2499.0, "batch_reward": -0.026528477668762207, "critic_loss": 1.128341555595398, "ae_transition_loss": 1.6675631602605183, "ae_encoder_loss": 0.4220663706461589, "actor_loss": -1.4567233324050903, "actor_target_entropy": -2.0, "actor_entropy": -1.3091742197672527, "alpha_loss": -0.002593848699082931, "alpha_value": 0.008319127260143333, "duration": 6.823779344558716, "step": 79307}
{"episode_reward": 3.3093602381898837, "episode": 2500.0, "batch_reward": -0.042563311755657196, "critic_loss": 1.5599257946014404, "ae_transition_loss": 1.835030198097229, "ae_encoder_loss": 0.40720710158348083, "actor_loss": -2.081080913543701, "actor_target_entropy": -2.0, "actor_entropy": -1.4736192226409912, "alpha_loss": -0.0025752331130206585, "alpha_value": 0.008336035442596097, "duration": 1.521430492401123, "step": 79313}
{"episode_reward": -1.617644356004674, "episode": 2501.0, "batch_reward": 0.043374836444854736, "critic_loss": 1.0966418981552124, "ae_transition_loss": 1.6394683122634888, "ae_encoder_loss": 0.5141191482543945, "actor_loss": -1.8179359436035156, "actor_target_entropy": -2.0, "actor_entropy": -1.4364728927612305, "alpha_loss": -0.0034984403755515814, "alpha_value": 0.008344195624499388, "duration": 105.25015211105347, "step": 79327}
{"episode_reward": -1.0083785768857425, "episode": 2502.0, "batch_reward": -0.004742913879454136, "critic_loss": 0.9447412341833115, "ae_transition_loss": 1.6684858202934265, "ae_encoder_loss": 0.4252493232488632, "actor_loss": -1.8155221343040466, "actor_target_entropy": -2.0, "actor_entropy": -1.4446820318698883, "alpha_loss": -0.004805996781215072, "alpha_value": 0.008366004378273444, "duration": 7.695701837539673, "step": 79365}
{"episode_reward": 3.263782433931734, "episode": 2503.0, "batch_reward": -0.008442622298995653, "critic_loss": 1.299863616625468, "ae_transition_loss": 1.6483646233876545, "ae_encoder_loss": 0.4417937497297923, "actor_loss": -1.836001952489217, "actor_target_entropy": -2.0, "actor_entropy": -1.4556738932927449, "alpha_loss": -0.006300140327463548, "alpha_value": 0.008400026513151916, "duration": 6.827974557876587, "step": 79399}
{"episode_reward": 7.887950594318886, "episode": 2504.0, "batch_reward": -0.028749277349561453, "critic_loss": 0.6917735263705254, "ae_transition_loss": 1.5888693034648895, "ae_encoder_loss": 0.5072338581085205, "actor_loss": -1.6025141179561615, "actor_target_entropy": -2.0, "actor_entropy": -1.4455748796463013, "alpha_loss": -0.006221324438229203, "alpha_value": 0.0084405173540839, "duration": 6.867644309997559, "step": 79432}
{"episode_reward": 5.758745998053961, "episode": 2505.0, "duration": 0.2510986328125, "step": 79433}
{"episode_reward": -0.1094011010004905, "episode": 2506.0, "batch_reward": -0.11964445933699608, "critic_loss": 1.0187978744506836, "ae_transition_loss": 1.6088544130325317, "ae_encoder_loss": 0.5712312012910843, "actor_loss": -1.2326769828796387, "actor_target_entropy": -2.0, "actor_entropy": -1.3994957208633423, "alpha_loss": -0.004683348932303488, "alpha_value": 0.008478992628718558, "duration": 4.069674730300903, "step": 79452}
{"episode_reward": 1.071673682901006, "episode": 2507.0, "batch_reward": 0.015188968740403652, "critic_loss": 1.1577536364396412, "ae_transition_loss": 1.5340431928634644, "ae_encoder_loss": 0.6665526479482651, "actor_loss": -1.8801045020421345, "actor_target_entropy": -2.0, "actor_entropy": -1.3994649251302083, "alpha_loss": -0.0059016437735408545, "alpha_value": 0.008531588397502106, "duration": 12.918922662734985, "step": 79517}
{"episode_reward": 17.47293482306196, "episode": 2508.0, "batch_reward": -0.03857893869280815, "critic_loss": 0.5763078033924103, "ae_transition_loss": 2.1074891090393066, "ae_encoder_loss": 0.4132203161716461, "actor_loss": -1.4997795820236206, "actor_target_entropy": -2.0, "actor_entropy": -1.327394425868988, "alpha_loss": -0.005676463712006807, "alpha_value": 0.008587052339334173, "duration": 4.2394819259643555, "step": 79538}
{"episode_reward": 2.1199160448800365, "episode": 2509.0, "batch_reward": -0.012749586068093777, "critic_loss": 0.8155560255050659, "ae_transition_loss": 1.7036619663238526, "ae_encoder_loss": 0.5252464532852172, "actor_loss": -1.8249260663986206, "actor_target_entropy": -2.0, "actor_entropy": -1.2817235469818116, "alpha_loss": -0.00608546631410718, "alpha_value": 0.008638312974361429, "duration": 9.138716220855713, "step": 79583}
{"episode_reward": 14.55584339504148, "episode": 2510.0, "batch_reward": -0.072544414550066, "critic_loss": 0.8262402415275574, "ae_transition_loss": 1.591426968574524, "ae_encoder_loss": 0.7859943807125092, "actor_loss": -1.8525770902633667, "actor_target_entropy": -2.0, "actor_entropy": -1.1387723088264465, "alpha_loss": -0.004443787038326263, "alpha_value": 0.008690413538438486, "duration": 4.960839033126831, "step": 79607}
{"episode_reward": 2.3962505587504532, "episode": 2511.0, "batch_reward": -0.047162103156248726, "critic_loss": 1.1509903868039448, "ae_transition_loss": 1.4423417647679646, "ae_encoder_loss": 0.5846346517403921, "actor_loss": -1.5353603760401409, "actor_target_entropy": -2.0, "actor_entropy": -1.1405998468399048, "alpha_loss": -0.0063224177186687784, "alpha_value": 0.008726923690511505, "duration": 51.89860558509827, "step": 79634}
{"episode_reward": -0.56976591874462, "episode": 2512.0, "batch_reward": -0.05988825795551141, "critic_loss": 1.0003972748915355, "ae_transition_loss": 1.5578388373057048, "ae_encoder_loss": 0.5033886531988779, "actor_loss": -1.4882404804229736, "actor_target_entropy": -2.0, "actor_entropy": -1.336926519870758, "alpha_loss": -0.005394241850202282, "alpha_value": 0.008794947404447539, "duration": 12.108832597732544, "step": 79691}
{"episode_reward": 16.21919792105521, "episode": 2513.0, "batch_reward": -0.001506950706243515, "critic_loss": 0.8251672387123108, "ae_transition_loss": 1.4086532592773438, "ae_encoder_loss": 0.4409332275390625, "actor_loss": -1.8451268672943115, "actor_target_entropy": -2.0, "actor_entropy": -1.2236472368240356, "alpha_loss": -0.00430464930832386, "alpha_value": 0.008854350240769998, "duration": 5.416082382202148, "step": 79719}
{"episode_reward": 5.287306663174208, "episode": 2514.0, "batch_reward": -0.015264740213751793, "critic_loss": 1.4888209998607635, "ae_transition_loss": 1.3879673480987549, "ae_encoder_loss": 0.30997370183467865, "actor_loss": -1.378149688243866, "actor_target_entropy": -2.0, "actor_entropy": -1.1851961612701416, "alpha_loss": -0.0044608761090785265, "alpha_value": 0.008882396215660915, "duration": 3.3519070148468018, "step": 79735}
{"episode_reward": 0.4508324860768319, "episode": 2515.0, "batch_reward": 0.026442751288414, "critic_loss": 0.8792410492897034, "ae_transition_loss": 1.43626469373703, "ae_encoder_loss": 0.29618994891643524, "actor_loss": -1.7794976830482483, "actor_target_entropy": -2.0, "actor_entropy": -1.0919414162635803, "alpha_loss": -0.006875548046082258, "alpha_value": 0.008909962814713197, "duration": 3.821027994155884, "step": 79753}
{"episode_reward": -1.773609267308907, "episode": 2516.0, "batch_reward": -0.11555621027946472, "critic_loss": 3.1391940116882324, "ae_transition_loss": 3.7663536071777344, "ae_encoder_loss": 0.40320780873298645, "actor_loss": -1.3498162031173706, "actor_target_entropy": -2.0, "actor_entropy": -1.039137601852417, "alpha_loss": -0.0032538932282477617, "alpha_value": 0.008931655698514104, "duration": 2.8786611557006836, "step": 79767}
{"episode_reward": -1.5531618773897435, "episode": 2517.0, "duration": 0.2194530963897705, "step": 79768}
{"episode_reward": -0.07606826081055554, "episode": 2518.0, "batch_reward": -0.001235208474099636, "critic_loss": 2.1141424477100372, "ae_transition_loss": 1.5682362914085388, "ae_encoder_loss": 0.3868616819381714, "actor_loss": -1.566165179014206, "actor_target_entropy": -2.0, "actor_entropy": -0.9172606766223907, "alpha_loss": -0.004892435041256249, "alpha_value": 0.00896649924651345, "duration": 7.242841720581055, "step": 79803}
{"episode_reward": -2.081800357439907, "episode": 2519.0, "duration": 0.24579334259033203, "step": 79804}
{"episode_reward": -0.3629725733637741, "episode": 2520.0, "batch_reward": -0.03340447135269642, "critic_loss": 0.9876008629798889, "ae_transition_loss": 1.5267824530601501, "ae_encoder_loss": 0.4215775281190872, "actor_loss": -1.55215722322464, "actor_target_entropy": -2.0, "actor_entropy": -1.1876075863838196, "alpha_loss": -0.0065146139822900295, "alpha_value": 0.009008180288111336, "duration": 3.933023691177368, "step": 79821}
{"episode_reward": -0.7540347494408717, "episode": 2521.0, "batch_reward": 0.01145138405263424, "critic_loss": 2.193758726119995, "ae_transition_loss": 1.3725574016571045, "ae_encoder_loss": 0.5852776765823364, "actor_loss": -1.622404932975769, "actor_target_entropy": -2.0, "actor_entropy": -1.2104523181915283, "alpha_loss": -0.0047155702486634254, "alpha_value": 0.009029639281316422, "duration": 56.31361699104309, "step": 79838}
{"episode_reward": 1.929428876231223, "episode": 2522.0, "batch_reward": -0.029945693910121918, "critic_loss": 1.3335840106010437, "ae_transition_loss": 1.564017117023468, "ae_encoder_loss": 0.49285265803337097, "actor_loss": -1.6418495178222656, "actor_target_entropy": -2.0, "actor_entropy": -1.3352376818656921, "alpha_loss": -0.005737934960052371, "alpha_value": 0.009050819028514798, "duration": 3.598715305328369, "step": 79854}
{"episode_reward": 1.3371053036324212, "episode": 2523.0, "duration": 0.21289968490600586, "step": 79855}
{"episode_reward": -0.028749626744932588, "episode": 2524.0, "batch_reward": -0.004181297495961189, "critic_loss": 0.8979312181472778, "ae_transition_loss": 1.3703629970550537, "ae_encoder_loss": 0.6051380038261414, "actor_loss": -1.7957345843315125, "actor_target_entropy": -2.0, "actor_entropy": -1.4867650270462036, "alpha_loss": -0.0028873246628791094, "alpha_value": 0.009079231768659836, "duration": 4.893925905227661, "step": 79878}
{"episode_reward": 2.3645350710826545, "episode": 2525.0, "batch_reward": -0.017731915693730116, "critic_loss": 0.908742144703865, "ae_transition_loss": 1.384503424167633, "ae_encoder_loss": 0.4017590135335922, "actor_loss": -1.7400692999362946, "actor_target_entropy": -2.0, "actor_entropy": -1.5132958590984344, "alpha_loss": -0.005459508683998138, "alpha_value": 0.009119499580541127, "duration": 7.778337717056274, "step": 79915}
{"episode_reward": 5.688172580376766, "episode": 2526.0, "duration": 0.2529900074005127, "step": 79916}
{"episode_reward": 0.2559884853460699, "episode": 2527.0, "batch_reward": -0.04467609152197838, "critic_loss": 1.1885769367218018, "ae_transition_loss": 1.3272797465324402, "ae_encoder_loss": 0.3267195075750351, "actor_loss": -1.8866959810256958, "actor_target_entropy": -2.0, "actor_entropy": -1.3826950788497925, "alpha_loss": -0.004374334122985601, "alpha_value": 0.009160304425158472, "duration": 3.7888858318328857, "step": 79933}
{"episode_reward": -0.4316162752541408, "episode": 2528.0, "duration": 0.2061901092529297, "step": 79934}
{"episode_reward": -0.2757399978126702, "episode": 2529.0, "batch_reward": -0.0419212244451046, "critic_loss": 1.4793994029362996, "ae_transition_loss": 1.3267393906911213, "ae_encoder_loss": 0.3534814814726512, "actor_loss": -1.5924342075983684, "actor_target_entropy": -2.0, "actor_entropy": -1.2435321807861328, "alpha_loss": -0.004474047105759382, "alpha_value": 0.009193786064995964, "duration": 6.80247688293457, "step": 79968}
{"episode_reward": 5.4679209041940595, "episode": 2530.0, "batch_reward": -0.023550386540591717, "critic_loss": 1.078857660293579, "ae_transition_loss": 1.3368347883224487, "ae_encoder_loss": 0.28860385715961456, "actor_loss": -1.8790226578712463, "actor_target_entropy": -2.0, "actor_entropy": -1.1917598247528076, "alpha_loss": -0.006601389963179827, "alpha_value": 0.009226718645150844, "duration": 4.413025617599487, "step": 79989}
{"episode_reward": 4.655427755656796, "episode": 2531.0, "batch_reward": 0.011725120712071657, "critic_loss": 1.0302447080612183, "ae_transition_loss": 1.135664939880371, "ae_encoder_loss": 0.28964700549840927, "actor_loss": -1.8915562629699707, "actor_target_entropy": -2.0, "actor_entropy": -1.1710274815559387, "alpha_loss": -0.007058224640786648, "alpha_value": 0.009255108111854236, "duration": 49.55072617530823, "step": 80006}
{"episode_reward": -0.9147316268036071, "episode": 2532.0, "batch_reward": 0.002232164144515991, "critic_loss": 1.1476385196050007, "ae_transition_loss": 1.3326873381932576, "ae_encoder_loss": 0.2855769693851471, "actor_loss": -2.0421809355417886, "actor_target_entropy": -2.0, "actor_entropy": -1.063259522120158, "alpha_loss": -0.006745351478457451, "alpha_value": 0.009292261379565037, "duration": 6.360790014266968, "step": 80035}
{"episode_reward": 2.8021396585272025, "episode": 2533.0, "batch_reward": 0.023997468873858452, "critic_loss": 0.9981304109096527, "ae_transition_loss": 0.8952009081840515, "ae_encoder_loss": 0.23849596828222275, "actor_loss": -1.8287928700447083, "actor_target_entropy": -2.0, "actor_entropy": -1.0836151838302612, "alpha_loss": -0.0047155170468613505, "alpha_value": 0.009330695044515221, "duration": 4.886701583862305, "step": 80058}
{"episode_reward": 3.9088141361862005, "episode": 2534.0, "batch_reward": -0.03183042506376902, "critic_loss": 1.5830755631128948, "ae_transition_loss": 1.0880136489868164, "ae_encoder_loss": 0.3522334694862366, "actor_loss": -1.6613884766896565, "actor_target_entropy": -2.0, "actor_entropy": -1.052125056584676, "alpha_loss": -0.006781973876059055, "alpha_value": 0.00936972309240866, "duration": 5.9323320388793945, "step": 80086}
{"episode_reward": 3.273368475945308, "episode": 2535.0, "batch_reward": 0.013049547870953878, "critic_loss": 0.738033245007197, "ae_transition_loss": 1.1236370007197063, "ae_encoder_loss": 0.4417322774728139, "actor_loss": -1.8640968402226765, "actor_target_entropy": -2.0, "actor_entropy": -1.0586146513621013, "alpha_loss": -0.006435551835844914, "alpha_value": 0.009418749051940315, "duration": 6.711340427398682, "step": 80117}
{"episode_reward": 2.7357846572994102, "episode": 2536.0, "batch_reward": -0.03642529789358377, "critic_loss": 1.0774224996566772, "ae_transition_loss": 1.491234302520752, "ae_encoder_loss": 0.4397129356861115, "actor_loss": -1.4748631715774536, "actor_target_entropy": -2.0, "actor_entropy": -0.9054073333740235, "alpha_loss": -0.005171069782227278, "alpha_value": 0.009483774878140118, "duration": 11.023587942123413, "step": 80170}
{"episode_reward": 13.146840679330149, "episode": 2537.0, "batch_reward": -0.021771122701466084, "critic_loss": 1.199750080704689, "ae_transition_loss": 1.326269954442978, "ae_encoder_loss": 0.31324290484189987, "actor_loss": -1.7216143608093262, "actor_target_entropy": -2.0, "actor_entropy": -0.3463227115571499, "alpha_loss": -0.007637358503416181, "alpha_value": 0.009557001646480904, "duration": 7.062971591949463, "step": 80204}
{"episode_reward": 7.483204429234728, "episode": 2538.0, "batch_reward": -0.023163841292262077, "critic_loss": 0.8546835064888001, "ae_transition_loss": 1.3817897319793702, "ae_encoder_loss": 0.3590527594089508, "actor_loss": -1.5164641380310058, "actor_target_entropy": -2.0, "actor_entropy": -1.1159255981445313, "alpha_loss": -0.003240235545672476, "alpha_value": 0.00963233812119344, "duration": 10.045621156692505, "step": 80251}
{"episode_reward": 12.280864212280704, "episode": 2539.0, "batch_reward": -0.11447296291589737, "critic_loss": 1.5133546590805054, "ae_transition_loss": 1.810941219329834, "ae_encoder_loss": 0.3309286832809448, "actor_loss": -1.3625140190124512, "actor_target_entropy": -2.0, "actor_entropy": -1.3253514766693115, "alpha_loss": -0.0043054320849478245, "alpha_value": 0.009676695021533132, "duration": 2.409196615219116, "step": 80261}
{"episode_reward": -0.6496291339621533, "episode": 2540.0, "batch_reward": 0.06159917265176773, "critic_loss": 1.6814956068992615, "ae_transition_loss": 1.6197251677513123, "ae_encoder_loss": 0.3491158187389374, "actor_loss": -1.8075758218765259, "actor_target_entropy": -2.0, "actor_entropy": -1.4129170179367065, "alpha_loss": -0.003454322926700115, "alpha_value": 0.009697108891433362, "duration": 5.113386869430542, "step": 80286}
{"episode_reward": 3.8947958725604166, "episode": 2541.0, "batch_reward": 0.010962089523673058, "critic_loss": 0.7642423113187155, "ae_transition_loss": 1.369480053583781, "ae_encoder_loss": 0.3667266170183818, "actor_loss": -1.8025193611780803, "actor_target_entropy": -2.0, "actor_entropy": -1.428154706954956, "alpha_loss": -0.006113089931507905, "alpha_value": 0.009730245382019333, "duration": 80.94778299331665, "step": 80320}
{"episode_reward": 9.34418218927366, "episode": 2542.0, "batch_reward": 0.03218975911537806, "critic_loss": 1.1914135018984477, "ae_transition_loss": 1.5387665430704753, "ae_encoder_loss": 0.35810620586077374, "actor_loss": -1.8155015309651692, "actor_target_entropy": -2.0, "actor_entropy": -1.3185992240905762, "alpha_loss": -0.005176393470416467, "alpha_value": 0.009772092570397158, "duration": 5.279791593551636, "step": 80346}
{"episode_reward": -0.44375576501783365, "episode": 2543.0, "batch_reward": -0.01760696843266487, "critic_loss": 0.5705931067466736, "ae_transition_loss": 1.537253499031067, "ae_encoder_loss": 0.33590067028999326, "actor_loss": -1.9031152963638305, "actor_target_entropy": -2.0, "actor_entropy": -1.1849063396453858, "alpha_loss": -0.003708284394815564, "alpha_value": 0.009827354052423569, "duration": 10.631836414337158, "step": 80399}
{"episode_reward": 15.547490102633027, "episode": 2544.0, "batch_reward": -0.0011514313519001007, "critic_loss": 0.8194178819656373, "ae_transition_loss": 1.610839319229126, "ae_encoder_loss": 0.3356677770614624, "actor_loss": -1.733241367340088, "actor_target_entropy": -2.0, "actor_entropy": -1.0720267295837402, "alpha_loss": -0.00463603469543159, "alpha_value": 0.009890735873318193, "duration": 9.166291952133179, "step": 80445}
{"episode_reward": 12.16612807406825, "episode": 2545.0, "batch_reward": 0.0007854918949306011, "critic_loss": 0.8860695213079453, "ae_transition_loss": 1.589732974767685, "ae_encoder_loss": 0.34988436847925186, "actor_loss": -1.826269507408142, "actor_target_entropy": -2.0, "actor_entropy": -1.022179439663887, "alpha_loss": -0.0041795309516601264, "alpha_value": 0.009947955277566652, "duration": 8.147724628448486, "step": 80485}
{"episode_reward": 3.999536996165108, "episode": 2546.0, "batch_reward": -0.022091203679641087, "critic_loss": 0.9355944196383158, "ae_transition_loss": 1.4508962233861287, "ae_encoder_loss": 0.34550170103708905, "actor_loss": -1.825197458267212, "actor_target_entropy": -2.0, "actor_entropy": -1.0140287081400554, "alpha_loss": -0.004127525103588899, "alpha_value": 0.009992316075809431, "duration": 6.905250310897827, "step": 80519}
{"episode_reward": 3.6464112682389325, "episode": 2547.0, "batch_reward": 0.009732410311698914, "critic_loss": 1.0418785214424133, "ae_transition_loss": 1.3345365524291992, "ae_encoder_loss": 0.3563084453344345, "actor_loss": -1.7304794788360596, "actor_target_entropy": -2.0, "actor_entropy": -1.03269624710083, "alpha_loss": -0.004969474393874407, "alpha_value": 0.010022820581355986, "duration": 3.2336056232452393, "step": 80534}
{"episode_reward": -1.3352684971407405, "episode": 2548.0, "duration": 0.2137751579284668, "step": 80535}
{"episode_reward": -0.8099704201225778, "episode": 2549.0, "batch_reward": -0.026447771737972896, "critic_loss": 1.2431544661521912, "ae_transition_loss": 1.6951840718587239, "ae_encoder_loss": 0.2922547906637192, "actor_loss": -1.848850131034851, "actor_target_entropy": -2.0, "actor_entropy": -1.0227541128794353, "alpha_loss": -0.005055315404509504, "alpha_value": 0.01005471101988606, "duration": 5.783671855926514, "step": 80563}
{"episode_reward": 3.1124423762029143, "episode": 2550.0, "batch_reward": -0.03126838291063905, "critic_loss": 0.926374614238739, "ae_transition_loss": 1.5528124570846558, "ae_encoder_loss": 0.33035385608673096, "actor_loss": -1.7016518115997314, "actor_target_entropy": -2.0, "actor_entropy": -0.9456917345523834, "alpha_loss": -0.0051755052991211414, "alpha_value": 0.010087979008229263, "duration": 5.216229438781738, "step": 80590}
{"episode_reward": 2.1820280570188193, "episode": 2551.0, "batch_reward": 0.0001433286815881729, "critic_loss": 0.9814236760139465, "ae_transition_loss": 1.5093872547149658, "ae_encoder_loss": 0.2532186955213547, "actor_loss": -1.934552550315857, "actor_target_entropy": -2.0, "actor_entropy": -0.9812457263469696, "alpha_loss": -0.004972517606802285, "alpha_value": 0.010115116668233129, "duration": 67.15183305740356, "step": 80605}
{"episode_reward": -3.5124288157934758, "episode": 2552.0, "batch_reward": -0.05408794619143009, "critic_loss": 1.0226099789142609, "ae_transition_loss": 1.4020795822143555, "ae_encoder_loss": 0.40596727281808853, "actor_loss": -1.5581875443458557, "actor_target_entropy": -2.0, "actor_entropy": -0.8415797352790833, "alpha_loss": -0.0027653252764139324, "alpha_value": 0.01015450329972797, "duration": 8.427794218063354, "step": 80646}
{"episode_reward": 11.228896479845353, "episode": 2553.0, "batch_reward": -0.08165733516216278, "critic_loss": 0.3900928795337677, "ae_transition_loss": 1.23210871219635, "ae_encoder_loss": 0.42865294218063354, "actor_loss": -1.1186137199401855, "actor_target_entropy": -2.0, "actor_entropy": -0.5437655448913574, "alpha_loss": -0.0017747373785823584, "alpha_value": 0.010184859561526496, "duration": 1.4502687454223633, "step": 80651}
{"episode_reward": -1.3381164534460837, "episode": 2554.0, "batch_reward": 0.034522147849202156, "critic_loss": 1.2275813519954681, "ae_transition_loss": 1.3943147659301758, "ae_encoder_loss": 0.3453405350446701, "actor_loss": -1.8640056848526, "actor_target_entropy": -2.0, "actor_entropy": -0.49358753859996796, "alpha_loss": 0.0012316622014623135, "alpha_value": 0.010200543086527477, "duration": 4.830400705337524, "step": 80675}
{"episode_reward": 1.8777892520838906, "episode": 2555.0, "duration": 0.22690820693969727, "step": 80676}
{"episode_reward": 0.3695515512475875, "episode": 2556.0, "batch_reward": -0.0013089425861835479, "critic_loss": 1.3493427157402038, "ae_transition_loss": 1.647344994544983, "ae_encoder_loss": 0.4193033635616302, "actor_loss": -1.9132325172424316, "actor_target_entropy": -2.0, "actor_entropy": -0.9724316596984863, "alpha_loss": -0.003513803146779537, "alpha_value": 0.01023036111660667, "duration": 10.319650411605835, "step": 80726}
{"episode_reward": 13.11770776281582, "episode": 2557.0, "batch_reward": -0.025407524779438972, "critic_loss": 0.9865117073059082, "ae_transition_loss": 1.6125285774469376, "ae_encoder_loss": 0.4103901572525501, "actor_loss": -1.8615417331457138, "actor_target_entropy": -2.0, "actor_entropy": -1.2554038166999817, "alpha_loss": -0.0036898744147038087, "alpha_value": 0.010291957517182692, "duration": 16.208791494369507, "step": 80806}
{"episode_reward": 29.73659845714012, "episode": 2558.0, "batch_reward": -0.04354949357608954, "critic_loss": 1.1660668055216472, "ae_transition_loss": 1.5290983120600383, "ae_encoder_loss": 0.5798031290372213, "actor_loss": -1.6341001987457275, "actor_target_entropy": -2.0, "actor_entropy": -1.1423396269480388, "alpha_loss": -0.003799179297251006, "alpha_value": 0.010348096973970098, "duration": 6.098729372024536, "step": 80835}
{"episode_reward": 5.749097476231032, "episode": 2559.0, "batch_reward": -0.04738567769527435, "critic_loss": 1.331401288509369, "ae_transition_loss": 1.764367699623108, "ae_encoder_loss": 0.7068885564804077, "actor_loss": -1.6436566710472107, "actor_target_entropy": -2.0, "actor_entropy": -1.0964956283569336, "alpha_loss": -0.004209605045616627, "alpha_value": 0.010373684100060815, "duration": 4.744000673294067, "step": 80858}
{"episode_reward": 2.0298854311082497, "episode": 2560.0, "batch_reward": -0.03682376816868782, "critic_loss": 0.7650274336338043, "ae_transition_loss": 1.5711926817893982, "ae_encoder_loss": 0.4902190715074539, "actor_loss": -1.6863129138946533, "actor_target_entropy": -2.0, "actor_entropy": -1.1161524057388306, "alpha_loss": -0.00423647160641849, "alpha_value": 0.01039467539849182, "duration": 3.8934028148651123, "step": 80876}
{"episode_reward": -1.0612299665802594, "episode": 2561.0, "batch_reward": -0.011263138304154078, "critic_loss": 1.6208719809850056, "ae_transition_loss": 1.6914419333140056, "ae_encoder_loss": 0.5114550391832987, "actor_loss": -1.862423340479533, "actor_target_entropy": -2.0, "actor_entropy": -0.9593104124069214, "alpha_loss": -0.0029229321905101338, "alpha_value": 0.010421086957745159, "duration": 61.399595737457275, "step": 80903}
{"episode_reward": 0.9906412667230944, "episode": 2562.0, "batch_reward": 0.027197607792913914, "critic_loss": 1.3660857677459717, "ae_transition_loss": 1.5842904448509216, "ae_encoder_loss": 0.40700820088386536, "actor_loss": -2.1668577790260315, "actor_target_entropy": -2.0, "actor_entropy": -0.87403205037117, "alpha_loss": -0.0021863064757781103, "alpha_value": 0.010446661967265798, "duration": 4.986214637756348, "step": 80928}
{"episode_reward": 3.6697457478518887, "episode": 2563.0, "duration": 0.22785472869873047, "step": 80929}
{"episode_reward": -0.7908423220064922, "episode": 2564.0, "batch_reward": -0.006363771157339215, "critic_loss": 1.3627194315195084, "ae_transition_loss": 1.5062435865402222, "ae_encoder_loss": 0.32763495296239853, "actor_loss": -1.5781261026859283, "actor_target_entropy": -2.0, "actor_entropy": -0.6989022493362427, "alpha_loss": -0.0007729861536063254, "alpha_value": 0.010474986873402209, "duration": 7.068538427352905, "step": 80961}
{"episode_reward": 2.78342043211265, "episode": 2565.0, "batch_reward": -0.031417807564139366, "critic_loss": 1.064246505498886, "ae_transition_loss": 1.4445387125015259, "ae_encoder_loss": 0.3248617947101593, "actor_loss": -1.715527594089508, "actor_target_entropy": -2.0, "actor_entropy": -0.7376817762851715, "alpha_loss": -0.0013284342712722719, "alpha_value": 0.010498068875042031, "duration": 4.2840399742126465, "step": 80982}
{"episode_reward": 1.5042073918122654, "episode": 2566.0, "batch_reward": -0.01903997485836347, "critic_loss": 1.095526655515035, "ae_transition_loss": 1.3356533845265706, "ae_encoder_loss": 0.4733549455801646, "actor_loss": -1.747696876525879, "actor_target_entropy": -2.0, "actor_entropy": -0.7354575196901957, "alpha_loss": -0.0020718369729972133, "alpha_value": 0.010513127265989741, "duration": 6.178397178649902, "step": 81011}
{"episode_reward": 2.697349546584335, "episode": 2567.0, "batch_reward": 0.022246748208999634, "critic_loss": 1.1688530147075653, "ae_transition_loss": 1.4976491928100586, "ae_encoder_loss": 0.32128068804740906, "actor_loss": -1.9457175731658936, "actor_target_entropy": -2.0, "actor_entropy": -0.9134700894355774, "alpha_loss": -0.0030464462470263243, "alpha_value": 0.010528040794838016, "duration": 5.720473527908325, "step": 81040}
{"episode_reward": 2.3169148556767754, "episode": 2568.0, "batch_reward": -0.014682605396956205, "critic_loss": 0.9305662214756012, "ae_transition_loss": 1.4588252305984497, "ae_encoder_loss": 0.32251207530498505, "actor_loss": -1.4807120859622955, "actor_target_entropy": -2.0, "actor_entropy": -0.9652786999940872, "alpha_loss": -0.0035805823281407356, "alpha_value": 0.010550004541577467, "duration": 6.805277347564697, "step": 81072}
{"episode_reward": 4.050896025686071, "episode": 2569.0, "batch_reward": -0.0013583873265555926, "critic_loss": 0.7390969736235482, "ae_transition_loss": 1.3913698877607072, "ae_encoder_loss": 0.40479911650930134, "actor_loss": -1.8367139271327428, "actor_target_entropy": -2.0, "actor_entropy": -0.7853440812655857, "alpha_loss": -0.0052327257581055164, "alpha_value": 0.01059931673339519, "duration": 15.016177654266357, "step": 81144}
{"episode_reward": 20.114818715717877, "episode": 2570.0, "batch_reward": -0.007986164279282093, "critic_loss": 1.1804657340049745, "ae_transition_loss": 1.6481516361236572, "ae_encoder_loss": 0.5081849277019501, "actor_loss": -1.9603408336639405, "actor_target_entropy": -2.0, "actor_entropy": -0.7941596388816834, "alpha_loss": -0.0019729199120774865, "alpha_value": 0.010666828346970473, "duration": 10.961557149887085, "step": 81198}
{"episode_reward": 15.717444124384409, "episode": 2571.0, "batch_reward": 0.02353895492851734, "critic_loss": 0.8944624662399292, "ae_transition_loss": 1.773584771156311, "ae_encoder_loss": 0.5420953512191773, "actor_loss": -2.011742281913757, "actor_target_entropy": -2.0, "actor_entropy": -0.9368791103363037, "alpha_loss": -0.0013291677809320391, "alpha_value": 0.010715547574279876, "duration": 128.39184284210205, "step": 81246}
{"episode_reward": 11.924282621012697, "episode": 2572.0, "batch_reward": -0.03806725370564631, "critic_loss": 1.314191120011466, "ae_transition_loss": 1.72042259148189, "ae_encoder_loss": 0.5196234158107212, "actor_loss": -1.6026092086519514, "actor_target_entropy": -2.0, "actor_entropy": -0.8133906126022339, "alpha_loss": -8.11816259686436e-05, "alpha_value": 0.010756750135414559, "duration": 14.943670749664307, "step": 81319}
{"episode_reward": 36.85047825489906, "episode": 2573.0, "batch_reward": -0.021940952477355797, "critic_loss": 1.2880813578764598, "ae_transition_loss": 1.6759213209152222, "ae_encoder_loss": 0.6855217417081197, "actor_loss": -1.7214841643969219, "actor_target_entropy": -2.0, "actor_entropy": -0.6480868309736252, "alpha_loss": 0.002084413329915454, "alpha_value": 0.010777812535183598, "duration": 12.539970636367798, "step": 81380}
{"episode_reward": 11.317886927003912, "episode": 2574.0, "batch_reward": -0.03773777559399605, "critic_loss": 1.1406011283397675, "ae_transition_loss": 1.6226080656051636, "ae_encoder_loss": 0.37004538128773373, "actor_loss": -1.8938055435816448, "actor_target_entropy": -2.0, "actor_entropy": -0.8418591817220052, "alpha_loss": -0.0010587466628445934, "alpha_value": 0.010773246393623063, "duration": 11.615872144699097, "step": 81437}
{"episode_reward": 17.876972858279053, "episode": 2575.0, "batch_reward": -0.04157806560397148, "critic_loss": 0.9076288044452667, "ae_transition_loss": 1.5555755198001862, "ae_encoder_loss": 0.4244750216603279, "actor_loss": -1.7728846669197083, "actor_target_entropy": -2.0, "actor_entropy": -0.8021338284015656, "alpha_loss": -0.0001935890322783962, "alpha_value": 0.010775841160964686, "duration": 8.519656419754028, "step": 81479}
{"episode_reward": 10.028696343325349, "episode": 2576.0, "batch_reward": -0.008921910465384522, "critic_loss": 1.1193299227290683, "ae_transition_loss": 1.4898841381072998, "ae_encoder_loss": 0.4358588026629554, "actor_loss": -1.8772289090686374, "actor_target_entropy": -2.0, "actor_entropy": -0.9240272972318861, "alpha_loss": -0.001533513817574001, "alpha_value": 0.010786222417396572, "duration": 18.223906993865967, "step": 81568}
{"episode_reward": 38.93010322846752, "episode": 2577.0, "batch_reward": 0.0002699708566069603, "critic_loss": 0.908801817893982, "ae_transition_loss": 1.4382822275161744, "ae_encoder_loss": 0.4419691562652588, "actor_loss": -2.2029531478881834, "actor_target_entropy": -2.0, "actor_entropy": -1.1487262010574342, "alpha_loss": -0.002824633335694671, "alpha_value": 0.010807655070832487, "duration": 10.323669910430908, "step": 81618}
{"episode_reward": 11.343960192927526, "episode": 2578.0, "batch_reward": -0.012847657315433025, "critic_loss": 0.9326603015263876, "ae_transition_loss": 1.393902877966563, "ae_encoder_loss": 0.46603959302107495, "actor_loss": -1.7546795805295308, "actor_target_entropy": -2.0, "actor_entropy": -1.0392627120018005, "alpha_loss": -0.001256120949013469, "alpha_value": 0.010835042916125645, "duration": 11.218628883361816, "step": 81675}
{"episode_reward": 14.331349825422656, "episode": 2579.0, "duration": 0.21673870086669922, "step": 81676}
{"episode_reward": -0.5778844491532728, "episode": 2580.0, "batch_reward": 0.006132030626758933, "critic_loss": 1.647924691438675, "ae_transition_loss": 1.5355242490768433, "ae_encoder_loss": 0.5675145089626312, "actor_loss": -1.9180783033370972, "actor_target_entropy": -2.0, "actor_entropy": -0.8038849979639053, "alpha_loss": -0.0014703800989082083, "alpha_value": 0.010859040750220874, "duration": 7.418118238449097, "step": 81711}
{"episode_reward": 1.2651711334628164, "episode": 2581.0, "batch_reward": -0.028125982359051706, "critic_loss": 1.3652714014053344, "ae_transition_loss": 1.4929768323898316, "ae_encoder_loss": 0.5474673211574554, "actor_loss": -1.763791799545288, "actor_target_entropy": -2.0, "actor_entropy": -0.6466766238212586, "alpha_loss": 0.0026019697543233633, "alpha_value": 0.010876936714559296, "duration": 79.20083665847778, "step": 81763}
{"episode_reward": 11.923883099215976, "episode": 2582.0, "batch_reward": -0.02001910749822855, "critic_loss": 1.2406323552131653, "ae_transition_loss": 1.5482192635536194, "ae_encoder_loss": 0.7289801239967346, "actor_loss": -1.9160497188568115, "actor_target_entropy": -2.0, "actor_entropy": -0.6935490667819977, "alpha_loss": 0.0015977029397618026, "alpha_value": 0.010879240322369536, "duration": 4.721818685531616, "step": 81785}
{"episode_reward": -1.681661911877924, "episode": 2583.0, "batch_reward": -0.026479803025722504, "critic_loss": 1.66207488377889, "ae_transition_loss": 2.405738274256388, "ae_encoder_loss": 0.5231966078281403, "actor_loss": -1.8696444829305012, "actor_target_entropy": -2.0, "actor_entropy": -0.7975183924039205, "alpha_loss": -0.0009402809858632585, "alpha_value": 0.010876567505751002, "duration": 7.138412952423096, "step": 81820}
{"episode_reward": 2.7282604012283382, "episode": 2584.0, "batch_reward": 0.005057990085333586, "critic_loss": 1.9578418731689453, "ae_transition_loss": 1.3933013677597046, "ae_encoder_loss": 0.40158531069755554, "actor_loss": -1.5456465482711792, "actor_target_entropy": -2.0, "actor_entropy": -0.7028992176055908, "alpha_loss": -0.00021461304277181625, "alpha_value": 0.01087573693640276, "duration": 0.5873925685882568, "step": 81821}
{"episode_reward": -0.30771185372995813, "episode": 2585.0, "batch_reward": -0.01720916572958231, "critic_loss": 1.6298647820949554, "ae_transition_loss": 1.6130805909633636, "ae_encoder_loss": 0.4831383302807808, "actor_loss": -1.8887131214141846, "actor_target_entropy": -2.0, "actor_entropy": -0.7504528164863586, "alpha_loss": 1.8381804693490267e-05, "alpha_value": 0.010875812811701944, "duration": 8.848411798477173, "step": 81865}
{"episode_reward": 3.369783022386739, "episode": 2586.0, "batch_reward": -0.00737660750746727, "critic_loss": 1.6889244318008423, "ae_transition_loss": 1.7961585223674774, "ae_encoder_loss": 0.8186794817447662, "actor_loss": -1.8677624464035034, "actor_target_entropy": -2.0, "actor_entropy": -0.7145910263061523, "alpha_loss": 0.00207630087970756, "alpha_value": 0.010873131524128875, "duration": 7.88011360168457, "step": 81902}
{"episode_reward": 3.808072999972894, "episode": 2587.0, "batch_reward": -0.04452797817066312, "critic_loss": 0.9964808821678162, "ae_transition_loss": 1.6704590320587158, "ae_encoder_loss": 0.5514973104000092, "actor_loss": -1.5046443939208984, "actor_target_entropy": -2.0, "actor_entropy": -0.7633910477161407, "alpha_loss": 2.9844173695892096e-05, "alpha_value": 0.010866986153877644, "duration": 4.111534118652344, "step": 81921}
{"episode_reward": -0.03953358323808451, "episode": 2588.0, "duration": 0.18764448165893555, "step": 81922}
{"episode_reward": -0.23175521194934845, "episode": 2589.0, "duration": 0.20555400848388672, "step": 81923}
{"episode_reward": -0.9587964674641862, "episode": 2590.0, "batch_reward": -0.03459865786135197, "critic_loss": 1.089245319366455, "ae_transition_loss": 1.6901404062906902, "ae_encoder_loss": 0.5009015301863352, "actor_loss": -1.7238758007685344, "actor_target_entropy": -2.0, "actor_entropy": -0.7169663906097412, "alpha_loss": -0.00024265327374450862, "alpha_value": 0.010862522587124722, "duration": 6.734020471572876, "step": 81956}
{"episode_reward": 1.4506562587878635, "episode": 2591.0, "batch_reward": -0.04872696784635385, "critic_loss": 1.3803139527638753, "ae_transition_loss": 1.6576428016026814, "ae_encoder_loss": 0.4375779132048289, "actor_loss": -1.7147044738133748, "actor_target_entropy": -2.0, "actor_entropy": -0.6818039615948995, "alpha_loss": 0.0018370002120112379, "alpha_value": 0.010857822520219296, "duration": 50.76392602920532, "step": 81986}
{"episode_reward": 4.311828349889942, "episode": 2592.0, "batch_reward": -0.01712699085474014, "critic_loss": 1.6169260799884797, "ae_transition_loss": 1.664272165298462, "ae_encoder_loss": 0.44091224670410156, "actor_loss": -1.8720188021659852, "actor_target_entropy": -2.0, "actor_entropy": -0.5917186141014099, "alpha_loss": 0.000850324594648555, "alpha_value": 0.010845935503522806, "duration": 19.571736812591553, "step": 82081}
{"episode_reward": 57.78721406673151, "episode": 2593.0, "duration": 0.9237544536590576, "step": 82086}
{"episode_reward": -1.9375784368709827, "episode": 2594.0, "batch_reward": -0.009844857134989329, "critic_loss": 1.2894929988043649, "ae_transition_loss": 1.5215820244380407, "ae_encoder_loss": 0.43923080818993704, "actor_loss": -1.8241267715181624, "actor_target_entropy": -2.0, "actor_entropy": -0.28973437207085745, "alpha_loss": 0.002991442269246493, "alpha_value": 0.010820966108966898, "duration": 13.696915864944458, "step": 82152}
{"episode_reward": 18.912033404702125, "episode": 2595.0, "batch_reward": -0.011842374896837605, "critic_loss": 1.2453949981265597, "ae_transition_loss": 1.4470535516738892, "ae_encoder_loss": 0.42776451177067226, "actor_loss": -1.8372801674736872, "actor_target_entropy": -2.0, "actor_entropy": -0.1421952007545365, "alpha_loss": 0.006025958651055892, "alpha_value": 0.010758130108286626, "duration": 18.42910647392273, "step": 82242}
{"episode_reward": 35.05897150552041, "episode": 2596.0, "batch_reward": 0.044470024605592094, "critic_loss": 1.2188992500305176, "ae_transition_loss": 1.6672472755114238, "ae_encoder_loss": 0.34603065252304077, "actor_loss": -2.198727786540985, "actor_target_entropy": -2.0, "actor_entropy": -0.5605033785104752, "alpha_loss": 0.003642329170058171, "alpha_value": 0.010664790610924055, "duration": 12.161789178848267, "step": 82302}
{"episode_reward": 15.850956467134141, "episode": 2597.0, "batch_reward": -0.006894524364421765, "critic_loss": 1.0819930732250214, "ae_transition_loss": 1.5485520958900452, "ae_encoder_loss": 0.34455426037311554, "actor_loss": -2.2295405864715576, "actor_target_entropy": -2.0, "actor_entropy": -0.8897959192593893, "alpha_loss": -0.00046307616867125034, "alpha_value": 0.010596757048793414, "duration": 13.403341293334961, "step": 82370}
{"episode_reward": 35.91792189646626, "episode": 2598.0, "batch_reward": -0.0065167807042598724, "critic_loss": 2.4627264738082886, "ae_transition_loss": 1.716542899608612, "ae_encoder_loss": 0.3482028543949127, "actor_loss": -1.7505521774291992, "actor_target_entropy": -2.0, "actor_entropy": -0.8493982553482056, "alpha_loss": -6.305676652118564e-05, "alpha_value": 0.010569374873160176, "duration": 3.8120925426483154, "step": 82389}
{"episode_reward": -1.3297212156392153, "episode": 2599.0, "batch_reward": -0.031649732030928135, "critic_loss": 0.9309719900290171, "ae_transition_loss": 1.5012858311335247, "ae_encoder_loss": 0.4388474076986313, "actor_loss": -1.56110875805219, "actor_target_entropy": -2.0, "actor_entropy": -0.7169598837693533, "alpha_loss": 0.0024885632252941528, "alpha_value": 0.010550633267898743, "duration": 11.304613828659058, "step": 82443}
{"episode_reward": 7.501958682934337, "episode": 2600.0, "batch_reward": -0.013704228214919567, "critic_loss": 0.9808245599269867, "ae_transition_loss": 1.5271928906440735, "ae_encoder_loss": 0.6534131169319153, "actor_loss": -1.785694420337677, "actor_target_entropy": -2.0, "actor_entropy": -0.6684507727622986, "alpha_loss": 0.0032259958097711205, "alpha_value": 0.010527302828177312, "duration": 3.9042763710021973, "step": 82461}
{"episode_reward": -2.3146969759753224, "episode": 2601.0, "batch_reward": -0.013600176200270653, "critic_loss": 1.4732998808224995, "ae_transition_loss": 1.7112907369931538, "ae_encoder_loss": 0.4237899035215378, "actor_loss": -1.9777332941691081, "actor_target_entropy": -2.0, "actor_entropy": -0.7226355175177256, "alpha_loss": 0.001774339412804693, "alpha_value": 0.010500398602323173, "duration": 76.20630240440369, "step": 82527}
{"episode_reward": 9.430694725694199, "episode": 2602.0, "batch_reward": -0.02470960491336882, "critic_loss": 1.3304414227604866, "ae_transition_loss": 1.5494664907455444, "ae_encoder_loss": 0.3703329749405384, "actor_loss": -1.8758628219366074, "actor_target_entropy": -2.0, "actor_entropy": -0.60865518450737, "alpha_loss": 0.0028693802742054686, "alpha_value": 0.010456873977329206, "duration": 15.206362009048462, "step": 82602}
{"episode_reward": 31.63616642199144, "episode": 2603.0, "batch_reward": 0.00976947471499443, "critic_loss": 1.6162467002868652, "ae_transition_loss": 1.5870058059692382, "ae_encoder_loss": 0.41226927042007444, "actor_loss": -1.8799687385559083, "actor_target_entropy": -2.0, "actor_entropy": -0.40184433460235597, "alpha_loss": 0.00359763465821743, "alpha_value": 0.010408947576941245, "duration": 10.222663402557373, "step": 82652}
{"episode_reward": 15.401943850805374, "episode": 2604.0, "batch_reward": -0.03410952205636671, "critic_loss": 1.3374033740588598, "ae_transition_loss": 1.7790455307279314, "ae_encoder_loss": 0.4054392235619681, "actor_loss": -1.6380698680877686, "actor_target_entropy": -2.0, "actor_entropy": -0.4678002212728773, "alpha_loss": 0.0032228038014311877, "alpha_value": 0.010354857774511972, "duration": 14.278031587600708, "step": 82723}
{"episode_reward": 23.047242486297996, "episode": 2605.0, "batch_reward": -0.021398645266890524, "critic_loss": 1.03060644865036, "ae_transition_loss": 1.6395042181015014, "ae_encoder_loss": 0.40659297704696656, "actor_loss": -1.948537254333496, "actor_target_entropy": -2.0, "actor_entropy": -0.5485712587833405, "alpha_loss": 0.0024920316645875573, "alpha_value": 0.010301369291261317, "duration": 11.43613862991333, "step": 82779}
{"episode_reward": 23.33024318770511, "episode": 2606.0, "batch_reward": -0.02416491631249135, "critic_loss": 1.2839871753345837, "ae_transition_loss": 1.6162110025232488, "ae_encoder_loss": 0.3664566251364621, "actor_loss": -1.8519406643780796, "actor_target_entropy": -2.0, "actor_entropy": -0.5744406553831968, "alpha_loss": 0.001148232608102262, "alpha_value": 0.01024127762518681, "duration": 21.50777554512024, "step": 82886}
{"episode_reward": 43.500708026406116, "episode": 2607.0, "batch_reward": -0.003668125925792588, "critic_loss": 1.1261846952968173, "ae_transition_loss": 1.544266488817003, "ae_encoder_loss": 0.3588334421316783, "actor_loss": -1.8416182398796082, "actor_target_entropy": -2.0, "actor_entropy": -0.48354437119430965, "alpha_loss": 0.0030461994950504354, "alpha_value": 0.010182513866821263, "duration": 17.55623769760132, "step": 82972}
{"episode_reward": 41.666544577223064, "episode": 2608.0, "batch_reward": -0.011142582073807717, "critic_loss": 1.2085630416870117, "ae_transition_loss": 1.6283902883529664, "ae_encoder_loss": 0.5862340748310089, "actor_loss": -2.1499096870422365, "actor_target_entropy": -2.0, "actor_entropy": -0.5684609770774841, "alpha_loss": 0.0010525515535846353, "alpha_value": 0.010134259524129153, "duration": 12.167409181594849, "step": 83030}
{"episode_reward": 12.62212501318296, "episode": 2609.0, "batch_reward": -0.026819221054514248, "critic_loss": 1.2770589192708333, "ae_transition_loss": 1.7041888236999512, "ae_encoder_loss": 0.822526752948761, "actor_loss": -1.6446033716201782, "actor_target_entropy": -2.0, "actor_entropy": -0.5981485247612, "alpha_loss": 0.00021419556772646806, "alpha_value": 0.01011150294602499, "duration": 5.5838751792907715, "step": 83055}
{"episode_reward": 5.338640832022152, "episode": 2610.0, "batch_reward": -0.017572747718077153, "critic_loss": 1.367849349975586, "ae_transition_loss": 1.8391714990139008, "ae_encoder_loss": 0.6565884947776794, "actor_loss": -1.8484013676643372, "actor_target_entropy": -2.0, "actor_entropy": -0.599043995141983, "alpha_loss": 0.00033194157003890723, "alpha_value": 0.010098228000444683, "duration": 7.831131219863892, "step": 83093}
{"episode_reward": 3.2461177898081046, "episode": 2611.0, "batch_reward": -0.08027550205588341, "critic_loss": 1.0158189237117767, "ae_transition_loss": 1.8618826866149902, "ae_encoder_loss": 1.0656607449054718, "actor_loss": -1.8169230222702026, "actor_target_entropy": -2.0, "actor_entropy": -0.6385948956012726, "alpha_loss": -0.0016088501433841884, "alpha_value": 0.01009007874195025, "duration": 61.53399729728699, "step": 83112}
{"episode_reward": -0.34928716415608346, "episode": 2612.0, "duration": 0.1875748634338379, "step": 83113}
{"episode_reward": 0.00587449312192273, "episode": 2613.0, "batch_reward": 0.006793817815681298, "critic_loss": 1.3624361753463745, "ae_transition_loss": 1.6589247783025105, "ae_encoder_loss": 1.0696032643318176, "actor_loss": -1.9785406986872356, "actor_target_entropy": -2.0, "actor_entropy": -0.654243270556132, "alpha_loss": 0.0003581138832184176, "alpha_value": 0.01008621946403449, "duration": 6.097407817840576, "step": 83143}
{"episode_reward": 1.9687677670550054, "episode": 2614.0, "duration": 0.23314571380615234, "step": 83144}
{"episode_reward": -0.725551511590813, "episode": 2615.0, "batch_reward": -0.012129339897497133, "critic_loss": 1.550115704536438, "ae_transition_loss": 1.616800145669417, "ae_encoder_loss": 0.5232187455350702, "actor_loss": -2.0048898458480835, "actor_target_entropy": -2.0, "actor_entropy": -0.5673723681406542, "alpha_loss": 0.00013957971664653584, "alpha_value": 0.010077598404063677, "duration": 22.735358238220215, "step": 83258}
{"episode_reward": 51.14782454658407, "episode": 2616.0, "batch_reward": -0.02041482608765364, "critic_loss": 1.023494017124176, "ae_transition_loss": 1.3970000267028808, "ae_encoder_loss": 0.5723757565021514, "actor_loss": -1.7474789142608642, "actor_target_entropy": -2.0, "actor_entropy": -0.3529137670993805, "alpha_loss": 0.001936239516362548, "alpha_value": 0.010070252773466149, "duration": 10.231823682785034, "step": 83307}
{"episode_reward": 0.6125687958553666, "episode": 2617.0, "batch_reward": -0.013792980127036572, "critic_loss": 1.2059411025047302, "ae_transition_loss": 1.600604066848755, "ae_encoder_loss": 0.3932812035083771, "actor_loss": -2.0423696136474607, "actor_target_entropy": -2.0, "actor_entropy": -0.7390859448909759, "alpha_loss": 7.047212100587786e-05, "alpha_value": 0.010034426901816051, "duration": 50.091896533966064, "step": 83556}
{"episode_reward": 148.71749904936067, "episode": 2618.0, "batch_reward": 0.07758221092323463, "critic_loss": 0.9424521525700887, "ae_transition_loss": 1.4687329530715942, "ae_encoder_loss": 0.3139285743236542, "actor_loss": -2.316002448399862, "actor_target_entropy": -2.0, "actor_entropy": -0.8701382478078207, "alpha_loss": -0.0019256131102641423, "alpha_value": 0.010027190964508133, "duration": 6.855707883834839, "step": 83590}
{"episode_reward": 2.482635344906893, "episode": 2619.0, "batch_reward": 0.006417748052626848, "critic_loss": 1.3015926778316498, "ae_transition_loss": 1.3994914591312408, "ae_encoder_loss": 0.4585693031549454, "actor_loss": -2.251973509788513, "actor_target_entropy": -2.0, "actor_entropy": -0.8722866326570511, "alpha_loss": -0.0012750864116242155, "alpha_value": 0.010034024706379357, "duration": 7.619988679885864, "step": 83625}
{"episode_reward": 3.9059422272770408, "episode": 2620.0, "batch_reward": -0.026198094245046377, "critic_loss": 0.7883842289447784, "ae_transition_loss": 1.317777931690216, "ae_encoder_loss": 0.8872403800487518, "actor_loss": -2.170803666114807, "actor_target_entropy": -2.0, "actor_entropy": -0.9093250632286072, "alpha_loss": -0.0009728347940836102, "alpha_value": 0.010040776831287405, "duration": 4.111543893814087, "step": 83645}
{"episode_reward": 0.18597695271763312, "episode": 2621.0, "duration": 51.54388761520386, "step": 83646}
{"episode_reward": -0.3266211677039542, "episode": 2622.0, "batch_reward": -0.045881813924227445, "critic_loss": 0.9909886973244804, "ae_transition_loss": 1.465400184903826, "ae_encoder_loss": 0.6874562927654811, "actor_loss": -1.5994141783033098, "actor_target_entropy": -2.0, "actor_entropy": -0.8221059100968497, "alpha_loss": -0.0015369793067553214, "alpha_value": 0.01005573189584105, "duration": 13.288727760314941, "step": 83711}
{"episode_reward": 10.907278281707345, "episode": 2623.0, "batch_reward": 0.03377017378807068, "critic_loss": 0.8657412528991699, "ae_transition_loss": 1.7280442714691162, "ae_encoder_loss": 0.6196758151054382, "actor_loss": -2.0649619102478027, "actor_target_entropy": -2.0, "actor_entropy": -0.8601324558258057, "alpha_loss": 0.0003567114472389221, "alpha_value": 0.010070651198227, "duration": 3.1868374347686768, "step": 83727}
{"episode_reward": 1.1781463135456258, "episode": 2624.0, "batch_reward": -0.020505319349467754, "critic_loss": 1.3017975091934204, "ae_transition_loss": 1.4993346333503723, "ae_encoder_loss": 0.6057433784008026, "actor_loss": -1.9732165336608887, "actor_target_entropy": -2.0, "actor_entropy": -0.8166850805282593, "alpha_loss": -0.00030191155383363366, "alpha_value": 0.010078441920588897, "duration": 8.840624809265137, "step": 83770}
{"episode_reward": 11.15100529977989, "episode": 2625.0, "batch_reward": -0.020524033694528043, "critic_loss": 1.810883641242981, "ae_transition_loss": 1.661330133676529, "ae_encoder_loss": 0.5175832509994507, "actor_loss": -1.74445179104805, "actor_target_entropy": -2.0, "actor_entropy": -0.7888097614049911, "alpha_loss": -0.0005469520983751863, "alpha_value": 0.010088301403564209, "duration": 7.087199926376343, "step": 83803}
{"episode_reward": -1.237543606926862, "episode": 2626.0, "duration": 0.23809337615966797, "step": 83804}
{"episode_reward": -0.5220613479614258, "episode": 2627.0, "batch_reward": 0.004697528978188832, "critic_loss": 1.6771659751733143, "ae_transition_loss": 1.6578871607780457, "ae_encoder_loss": 0.5128260950247446, "actor_loss": -1.9071278969446819, "actor_target_entropy": -2.0, "actor_entropy": -0.6770162880420685, "alpha_loss": 0.00016065673359359303, "alpha_value": 0.010096388008564394, "duration": 12.338550567626953, "step": 83864}
{"episode_reward": 1.0034880626291767, "episode": 2628.0, "batch_reward": 0.0021301460219547153, "critic_loss": 1.2955820560455322, "ae_transition_loss": 1.5023044645786285, "ae_encoder_loss": 0.6208540126681328, "actor_loss": -2.022904872894287, "actor_target_entropy": -2.0, "actor_entropy": -0.7487504631280899, "alpha_loss": -0.0011375369358574972, "alpha_value": 0.010102942104987729, "duration": 8.323259592056274, "step": 83904}
{"episode_reward": 5.981454333545989, "episode": 2629.0, "batch_reward": -0.0034686985115210214, "critic_loss": 1.2420546611150105, "ae_transition_loss": 1.5437018076578777, "ae_encoder_loss": 0.6263445119063059, "actor_loss": -2.378321329752604, "actor_target_entropy": -2.0, "actor_entropy": -0.6532980600992838, "alpha_loss": 0.0008506194960015515, "alpha_value": 0.010109016316769753, "duration": 6.915132761001587, "step": 83938}
{"episode_reward": 1.8557375904747913, "episode": 2630.0, "batch_reward": 0.07752848044037819, "critic_loss": 2.5353954434394836, "ae_transition_loss": 1.6881136298179626, "ae_encoder_loss": 0.6653923392295837, "actor_loss": -2.1047033071517944, "actor_target_entropy": -2.0, "actor_entropy": -0.5102324783802032, "alpha_loss": 0.00347417825832963, "alpha_value": 0.010110657907143526, "duration": 3.349024534225464, "step": 83954}
{"episode_reward": -2.9375191088775003, "episode": 2631.0, "duration": 33.78206515312195, "step": 83955}
{"episode_reward": -0.2921906113624573, "episode": 2632.0, "batch_reward": -0.13816878199577332, "critic_loss": 0.9368592500686646, "ae_transition_loss": 1.5333391427993774, "ae_encoder_loss": 0.5216717720031738, "actor_loss": -0.7080482840538025, "actor_target_entropy": -2.0, "actor_entropy": -0.4748794138431549, "alpha_loss": 0.0036527954507619143, "alpha_value": 0.01010875933168535, "duration": 2.260258674621582, "step": 83966}
{"episode_reward": 0.37384235170132585, "episode": 2633.0, "batch_reward": -0.004334727923075358, "critic_loss": 1.5933175484339397, "ae_transition_loss": 1.4284833272298176, "ae_encoder_loss": 0.6157647768656412, "actor_loss": -1.7095326979955037, "actor_target_entropy": -2.0, "actor_entropy": -0.3590422074000041, "alpha_loss": 0.0037676808424293995, "alpha_value": 0.010102438192852921, "duration": 5.494459867477417, "step": 83991}
{"episode_reward": 0.3382925716073296, "episode": 2634.0, "batch_reward": -0.033662604788939156, "critic_loss": 1.163946012655894, "ae_transition_loss": 1.5160648028055828, "ae_encoder_loss": 0.5548635224501292, "actor_loss": -2.0773919423421225, "actor_target_entropy": -2.0, "actor_entropy": -0.5908953746159872, "alpha_loss": 0.002812256027633945, "alpha_value": 0.010087595116414232, "duration": 6.609079599380493, "step": 84024}
{"episode_reward": 4.21057997766536, "episode": 2635.0, "batch_reward": 0.018321429379284382, "critic_loss": 1.339107185602188, "ae_transition_loss": 1.5532720685005188, "ae_encoder_loss": 0.45467453449964523, "actor_loss": -2.217865467071533, "actor_target_entropy": -2.0, "actor_entropy": -0.7489802092313766, "alpha_loss": 0.0014221190212992951, "alpha_value": 0.0100664358186941, "duration": 7.971562623977661, "step": 84061}
{"episode_reward": 3.6708599459166784, "episode": 2636.0, "batch_reward": 0.007193181796797684, "critic_loss": 1.7227468916348048, "ae_transition_loss": 1.8270336730139596, "ae_encoder_loss": 0.5443205067089626, "actor_loss": -2.2578076464789256, "actor_target_entropy": -2.0, "actor_entropy": -0.7402270776884896, "alpha_loss": 0.0003919675114697644, "alpha_value": 0.010040512350242432, "duration": 15.600238561630249, "step": 84137}
{"episode_reward": 15.796020543215729, "episode": 2637.0, "batch_reward": 0.005251646228134632, "critic_loss": 1.7081921815872192, "ae_transition_loss": 1.7008435726165771, "ae_encoder_loss": 0.5378276586532593, "actor_loss": -2.45872540473938, "actor_target_entropy": -2.0, "actor_entropy": -0.7835837483406067, "alpha_loss": 4.015322192572057e-05, "alpha_value": 0.010021707877142537, "duration": 10.431613445281982, "step": 84187}
{"episode_reward": 8.967361102216374, "episode": 2638.0, "batch_reward": 0.020492903267343838, "critic_loss": 1.1390871206919353, "ae_transition_loss": 1.6530975898106892, "ae_encoder_loss": 0.4425210654735565, "actor_loss": -2.264597733815511, "actor_target_entropy": -2.0, "actor_entropy": -0.7384645144144694, "alpha_loss": -0.0012928050418850034, "alpha_value": 0.010014180457756353, "duration": 5.9776451587677, "step": 84216}
{"episode_reward": 0.47467746271362454, "episode": 2639.0, "batch_reward": 0.008075043559074402, "critic_loss": 1.6017604768276215, "ae_transition_loss": 1.478357970714569, "ae_encoder_loss": 0.5575973391532898, "actor_loss": -1.8142842054367065, "actor_target_entropy": -2.0, "actor_entropy": -0.5898605287075043, "alpha_loss": 0.003080095397308469, "alpha_value": 0.010011661413258884, "duration": 3.5611655712127686, "step": 84232}
{"episode_reward": -0.925920626069154, "episode": 2640.0, "batch_reward": -0.02757743261754513, "critic_loss": 1.936246395111084, "ae_transition_loss": 1.7661545753479004, "ae_encoder_loss": 0.7359572410583496, "actor_loss": -1.5254854917526246, "actor_target_entropy": -2.0, "actor_entropy": -0.7150930404663086, "alpha_loss": -0.0040643704822286965, "alpha_value": 0.010006277154298646, "duration": 11.376485824584961, "step": 84288}
{"episode_reward": 33.69294598659663, "episode": 2641.0, "batch_reward": -0.017216994240880013, "critic_loss": 1.6320120334625243, "ae_transition_loss": 1.7665366291999818, "ae_encoder_loss": 0.7921823918819427, "actor_loss": -2.184035289287567, "actor_target_entropy": -2.0, "actor_entropy": -0.7178828924894333, "alpha_loss": 0.0005960028909612447, "alpha_value": 0.01002755696964166, "duration": 104.04842281341553, "step": 84381}
{"episode_reward": 31.316692277718364, "episode": 2642.0, "batch_reward": 0.011913269758224487, "critic_loss": 0.8409432768821716, "ae_transition_loss": 1.664570689201355, "ae_encoder_loss": 1.0659939050674438, "actor_loss": -2.0234293937683105, "actor_target_entropy": -2.0, "actor_entropy": -0.5732129812240601, "alpha_loss": 0.004026582930237055, "alpha_value": 0.0100367981020951, "duration": 3.3236966133117676, "step": 84398}
{"episode_reward": -0.38864669798883256, "episode": 2643.0, "batch_reward": -0.026865965376297634, "critic_loss": 2.130814035733541, "ae_transition_loss": 1.6903527180353801, "ae_encoder_loss": 0.6697158614794413, "actor_loss": -1.684068997701009, "actor_target_entropy": -2.0, "actor_entropy": -0.33223074674606323, "alpha_loss": 0.005654156285648544, "alpha_value": 0.010032570664735674, "duration": 5.122480630874634, "step": 84422}
{"episode_reward": 2.427517382797173, "episode": 2644.0, "duration": 0.23598933219909668, "step": 84423}
{"episode_reward": -0.8826979113067154, "episode": 2645.0, "duration": 0.20288538932800293, "step": 84424}
{"episode_reward": -0.38187917021952517, "episode": 2646.0, "batch_reward": -0.01074469368904829, "critic_loss": 1.6099740028381349, "ae_transition_loss": 1.7399468898773194, "ae_encoder_loss": 0.888027036190033, "actor_loss": -1.831623339653015, "actor_target_entropy": -2.0, "actor_entropy": -0.32773566246032715, "alpha_loss": 0.0023309965734370055, "alpha_value": 0.010012458055403697, "duration": 10.183251142501831, "step": 84472}
{"episode_reward": 5.635658082964518, "episode": 2647.0, "batch_reward": 0.0284777885923783, "critic_loss": 1.3232311010360718, "ae_transition_loss": 1.584012468655904, "ae_encoder_loss": 0.5493002136548361, "actor_loss": -2.312150557835897, "actor_target_entropy": -2.0, "actor_entropy": -0.6825967828432719, "alpha_loss": 0.0023051255848258734, "alpha_value": 0.009988529144959324, "duration": 7.602157831192017, "step": 84509}
{"episode_reward": 2.21640876877468, "episode": 2648.0, "batch_reward": 0.02846423862501979, "critic_loss": 1.7942239046096802, "ae_transition_loss": 1.7388609051704407, "ae_encoder_loss": 0.6478749811649323, "actor_loss": -2.2048505544662476, "actor_target_entropy": -2.0, "actor_entropy": -0.6092872321605682, "alpha_loss": 0.0021852270292583853, "alpha_value": 0.00997278350665518, "duration": 3.5954840183258057, "step": 84526}
{"episode_reward": -2.1427604491514307, "episode": 2649.0, "batch_reward": -0.06049527352054914, "critic_loss": 1.5665727456410725, "ae_transition_loss": 1.8827894926071167, "ae_encoder_loss": 0.6339648564656576, "actor_loss": -1.962143898010254, "actor_target_entropy": -2.0, "actor_entropy": -0.728049099445343, "alpha_loss": -0.0001527826728609701, "alpha_value": 0.009956834094513463, "duration": 5.855302333831787, "step": 84554}
{"episode_reward": 2.868455265502267, "episode": 2650.0, "batch_reward": -0.013052988797426224, "critic_loss": 1.7721438109874725, "ae_transition_loss": 1.8110749423503876, "ae_encoder_loss": 0.8789718747138977, "actor_loss": -1.9934265911579132, "actor_target_entropy": -2.0, "actor_entropy": -0.6292077451944351, "alpha_loss": 0.0015220193163258955, "alpha_value": 0.009939958240293624, "duration": 8.519935607910156, "step": 84594}
{"episode_reward": 7.023944328568534, "episode": 2651.0, "batch_reward": -0.08466712757945061, "critic_loss": 1.6333187818527222, "ae_transition_loss": 1.7210923433303833, "ae_encoder_loss": 0.8886002004146576, "actor_loss": -1.5170713663101196, "actor_target_entropy": -2.0, "actor_entropy": -0.5289488434791565, "alpha_loss": 0.0003992125566583127, "alpha_value": 0.009926667290680962, "duration": 42.560364961624146, "step": 84620}
{"episode_reward": 2.885074311730309, "episode": 2652.0, "batch_reward": -0.017335383221507072, "critic_loss": 1.6408969163894653, "ae_transition_loss": 1.7915407419204712, "ae_encoder_loss": 0.8653056621551514, "actor_loss": -2.087739944458008, "actor_target_entropy": -2.0, "actor_entropy": -0.43442302942276, "alpha_loss": 1.472202711738646e-05, "alpha_value": 0.009920490349764522, "duration": 0.5537548065185547, "step": 84621}
{"episode_reward": 0.8236542803315218, "episode": 2653.0, "batch_reward": 0.027700144797563553, "critic_loss": 1.1009624004364014, "ae_transition_loss": 1.6240390539169312, "ae_encoder_loss": 0.737077534198761, "actor_loss": -2.2047280073165894, "actor_target_entropy": -2.0, "actor_entropy": -0.413520410656929, "alpha_loss": 0.0038135377690196037, "alpha_value": 0.009915000192276847, "duration": 4.413042068481445, "step": 84643}
{"episode_reward": 2.757468295932868, "episode": 2654.0, "batch_reward": 0.01715725939720869, "critic_loss": 1.7577260732650757, "ae_transition_loss": 1.643395721912384, "ae_encoder_loss": 0.7806959450244904, "actor_loss": -1.9900820851325989, "actor_target_entropy": -2.0, "actor_entropy": -0.5429453551769257, "alpha_loss": 0.0015748112346045673, "alpha_value": 0.00990555210476799, "duration": 5.324514627456665, "step": 84669}
{"episode_reward": 1.5251817791945883, "episode": 2655.0, "duration": 0.22364473342895508, "step": 84670}
{"episode_reward": -10.247540980566326, "episode": 2656.0, "batch_reward": -0.04010578617453575, "critic_loss": 1.9679909348487854, "ae_transition_loss": 1.8473071455955505, "ae_encoder_loss": 0.6578074395656586, "actor_loss": -1.7438318133354187, "actor_target_entropy": -2.0, "actor_entropy": -0.5898450613021851, "alpha_loss": 0.004304590635001659, "alpha_value": 0.009895226146569444, "duration": 3.6999471187591553, "step": 84688}
{"episode_reward": -0.625696975106994, "episode": 2657.0, "duration": 0.2197575569152832, "step": 84689}
{"episode_reward": -1.0136444463497214, "episode": 2658.0, "batch_reward": -0.03148643299937248, "critic_loss": 1.364898443222046, "ae_transition_loss": 1.7917568683624268, "ae_encoder_loss": 0.5854634940624237, "actor_loss": -2.283043146133423, "actor_target_entropy": -2.0, "actor_entropy": -0.6734462380409241, "alpha_loss": 0.002458423259668052, "alpha_value": 0.009882763729739287, "duration": 4.171886682510376, "step": 84710}
{"episode_reward": 2.1743850878909066, "episode": 2659.0, "batch_reward": -0.01711701958750685, "critic_loss": 1.9112648765246074, "ae_transition_loss": 1.794450541337331, "ae_encoder_loss": 0.519204393029213, "actor_loss": -2.3684882322947183, "actor_target_entropy": -2.0, "actor_entropy": -0.7391981184482574, "alpha_loss": 0.0016483079719667633, "alpha_value": 0.009856704556557216, "duration": 10.505016088485718, "step": 84762}
{"episode_reward": 12.870693219006874, "episode": 2660.0, "batch_reward": 0.0006512802094221116, "critic_loss": 1.5507384538650513, "ae_transition_loss": 1.7250810384750366, "ae_encoder_loss": 0.48401638865470886, "actor_loss": -2.2186352729797365, "actor_target_entropy": -2.0, "actor_entropy": -0.6687446713447571, "alpha_loss": 0.0004829092184081674, "alpha_value": 0.0098268238363662, "duration": 10.526649951934814, "step": 84815}
{"episode_reward": 10.274009683928432, "episode": 2661.0, "batch_reward": -0.11347149685025215, "critic_loss": 1.7840899229049683, "ae_transition_loss": 2.1849923729896545, "ae_encoder_loss": 0.4879036098718643, "actor_loss": -1.3514209985733032, "actor_target_entropy": -2.0, "actor_entropy": -0.6004719734191895, "alpha_loss": 0.0013701971038244665, "alpha_value": 0.009812163314749444, "duration": 148.18017029762268, "step": 84836}
{"episode_reward": 1.2709945198232855, "episode": 2662.0, "batch_reward": 0.03545964285731316, "critic_loss": 1.9153430461883545, "ae_transition_loss": 1.8130815982818604, "ae_encoder_loss": 0.9807230114936829, "actor_loss": -2.4741591691970823, "actor_target_entropy": -2.0, "actor_entropy": -0.6204357028007508, "alpha_loss": 0.0018600639188662172, "alpha_value": 0.009796578228306948, "duration": 10.639539241790771, "step": 84885}
{"episode_reward": 12.790847030603606, "episode": 2663.0, "batch_reward": -0.01496485065269683, "critic_loss": 2.1383738773209706, "ae_transition_loss": 1.6632103409085954, "ae_encoder_loss": 0.9728389212063381, "actor_loss": -2.055091381072998, "actor_target_entropy": -2.0, "actor_entropy": -0.5812174933297294, "alpha_loss": 0.0011930886123861586, "alpha_value": 0.00975286609989045, "duration": 28.4985990524292, "step": 85021}
{"episode_reward": 22.49693471938385, "episode": 2664.0, "batch_reward": 0.025485077872872353, "critic_loss": 1.7489986717700958, "ae_transition_loss": 1.4957143068313599, "ae_encoder_loss": 0.6875911355018616, "actor_loss": -2.426335334777832, "actor_target_entropy": -2.0, "actor_entropy": -0.5106666684150696, "alpha_loss": 0.0003241986851207912, "alpha_value": 0.00972223637562299, "duration": 4.989025115966797, "step": 85045}
{"episode_reward": 3.511924230557785, "episode": 2665.0, "batch_reward": 0.021717502735555172, "critic_loss": 1.75168377161026, "ae_transition_loss": 1.4368646740913391, "ae_encoder_loss": 0.5081451758742332, "actor_loss": -2.6419424414634705, "actor_target_entropy": -2.0, "actor_entropy": -0.5279740244150162, "alpha_loss": 0.0002708883839659393, "alpha_value": 0.009714226826056842, "duration": 8.99693250656128, "step": 85089}
{"episode_reward": 1.950054613065463, "episode": 2666.0, "duration": 0.2345123291015625, "step": 85090}
{"episode_reward": -0.27184156439628254, "episode": 2667.0, "batch_reward": -0.06855975463986397, "critic_loss": 1.7916546662648518, "ae_transition_loss": 1.6772373517354329, "ae_encoder_loss": 0.430131196975708, "actor_loss": -2.1367607911427817, "actor_target_entropy": -2.0, "actor_entropy": -0.5672947764396667, "alpha_loss": 0.001383659119407336, "alpha_value": 0.009705963651427138, "duration": 5.671956300735474, "step": 85117}
{"episode_reward": 1.1049844016570705, "episode": 2668.0, "batch_reward": -0.0049786921590566635, "critic_loss": 1.5137979984283447, "ae_transition_loss": 1.6044895946979523, "ae_encoder_loss": 0.5694263502955437, "actor_loss": -2.1231067776679993, "actor_target_entropy": -2.0, "actor_entropy": -0.5869076102972031, "alpha_loss": 0.0008378469356102869, "alpha_value": 0.009696504475572142, "duration": 7.395538330078125, "step": 85151}
{"episode_reward": 4.534026101552036, "episode": 2669.0, "batch_reward": 0.000843571126461029, "critic_loss": 1.5293198347091674, "ae_transition_loss": 1.718571090698242, "ae_encoder_loss": 0.49252397418022154, "actor_loss": -1.9721829891204834, "actor_target_entropy": -2.0, "actor_entropy": -0.6334643959999084, "alpha_loss": 0.0004247930133715272, "alpha_value": 0.00968480158279176, "duration": 11.076040029525757, "step": 85207}
{"episode_reward": 11.898339984262385, "episode": 2670.0, "batch_reward": -0.05104132741689682, "critic_loss": 0.5502239465713501, "ae_transition_loss": 1.3164029121398926, "ae_encoder_loss": 0.6631783843040466, "actor_loss": -2.418412208557129, "actor_target_entropy": -2.0, "actor_entropy": -0.6492698192596436, "alpha_loss": -0.0033564046025276184, "alpha_value": 0.00967824211970672, "duration": 1.91562819480896, "step": 85216}
{"episode_reward": -3.4328952787108333, "episode": 2671.0, "batch_reward": -0.005966947159983895, "critic_loss": 1.2732452587647871, "ae_transition_loss": 1.577453992583535, "ae_encoder_loss": 0.5612727877768603, "actor_loss": -2.068026672710072, "actor_target_entropy": -2.0, "actor_entropy": -0.631519843231548, "alpha_loss": 7.329683285206556e-05, "alpha_value": 0.00967314567657366, "duration": 123.9758460521698, "step": 85329}
{"episode_reward": 34.85176670643207, "episode": 2672.0, "batch_reward": -0.0011838643501202266, "critic_loss": 1.5247369309266408, "ae_transition_loss": 1.6443698207537334, "ae_encoder_loss": 0.6944100558757782, "actor_loss": -2.3144432504971824, "actor_target_entropy": -2.0, "actor_entropy": -0.6013992925484976, "alpha_loss": 0.000790672961253828, "alpha_value": 0.009662861655705337, "duration": 23.95574927330017, "step": 85450}
{"episode_reward": 47.85716184166554, "episode": 2673.0, "batch_reward": -0.0019700396806001663, "critic_loss": 1.3357269962628682, "ae_transition_loss": 1.5727188189824421, "ae_encoder_loss": 0.5814896573623022, "actor_loss": -2.5090729792912803, "actor_target_entropy": -2.0, "actor_entropy": -0.5619052797555923, "alpha_loss": 0.002153390960302204, "alpha_value": 0.009648746213945172, "duration": 11.431881666183472, "step": 85507}
{"episode_reward": 15.000741968465075, "episode": 2674.0, "batch_reward": 0.006488848105072975, "critic_loss": 1.1588148117065429, "ae_transition_loss": 1.4662460088729858, "ae_encoder_loss": 0.4922866702079773, "actor_loss": -2.4376578330993652, "actor_target_entropy": -2.0, "actor_entropy": -0.5823392987251281, "alpha_loss": 0.0011368019273504614, "alpha_value": 0.009631554738066844, "duration": 9.17168378829956, "step": 85552}
{"episode_reward": 17.089544347534563, "episode": 2675.0, "batch_reward": -0.009245552180800587, "critic_loss": 1.2473088204860687, "ae_transition_loss": 1.9841019958257675, "ae_encoder_loss": 0.4739653766155243, "actor_loss": -2.0431468188762665, "actor_target_entropy": -2.0, "actor_entropy": -0.5573715791106224, "alpha_loss": 0.000789612990047317, "alpha_value": 0.00960979473962626, "duration": 16.716968297958374, "step": 85635}
{"episode_reward": 57.240717356869354, "episode": 2676.0, "batch_reward": -0.019140438952793676, "critic_loss": 1.5741465836763382, "ae_transition_loss": 1.7625570793946583, "ae_encoder_loss": 0.7728406215707461, "actor_loss": -2.331119487682978, "actor_target_entropy": -2.0, "actor_entropy": -0.7514379918575287, "alpha_loss": -0.000700747114024125, "alpha_value": 0.009582950287461117, "duration": 24.742762088775635, "step": 85756}
{"episode_reward": 35.69777713386745, "episode": 2677.0, "batch_reward": -0.03210633620619774, "critic_loss": 1.6765684882799785, "ae_transition_loss": 1.6854204535484314, "ae_encoder_loss": 0.5942418177922567, "actor_loss": -2.1880735754966736, "actor_target_entropy": -2.0, "actor_entropy": -0.7740723590056101, "alpha_loss": -0.001082639772600184, "alpha_value": 0.009585733078579357, "duration": 13.17874789237976, "step": 85820}
{"episode_reward": 14.823393235581388, "episode": 2678.0, "batch_reward": -0.055265110731124875, "critic_loss": 1.55691659450531, "ae_transition_loss": 1.7051906347274781, "ae_encoder_loss": 0.5082590818405152, "actor_loss": -1.7434463977813721, "actor_target_entropy": -2.0, "actor_entropy": -0.7762051820755005, "alpha_loss": -0.00059693114599213, "alpha_value": 0.009596742034797618, "duration": 9.804810285568237, "step": 85867}
{"episode_reward": 14.26855447510531, "episode": 2679.0, "batch_reward": -0.02011731266975403, "critic_loss": 1.73326575756073, "ae_transition_loss": 1.8083372513453166, "ae_encoder_loss": 0.36861775318781537, "actor_loss": -2.3636250495910645, "actor_target_entropy": -2.0, "actor_entropy": -0.8081797560056051, "alpha_loss": -0.001673675704902659, "alpha_value": 0.009604810960706549, "duration": 6.759689092636108, "step": 85900}
{"episode_reward": 11.820660124091361, "episode": 2680.0, "batch_reward": 0.015733636915683746, "critic_loss": 1.1437569856643677, "ae_transition_loss": 1.516114056110382, "ae_encoder_loss": 0.5003256797790527, "actor_loss": -2.403473436832428, "actor_target_entropy": -2.0, "actor_entropy": -0.8460743129253387, "alpha_loss": -0.0011487314623082057, "alpha_value": 0.009614236329113296, "duration": 6.955179691314697, "step": 85933}
{"episode_reward": 7.335199303392532, "episode": 2681.0, "batch_reward": 0.04039228036999702, "critic_loss": 1.4122434973716735, "ae_transition_loss": 1.5266244649887084, "ae_encoder_loss": 0.3621822834014893, "actor_loss": -2.6169474124908447, "actor_target_entropy": -2.0, "actor_entropy": -0.9137395620346069, "alpha_loss": -0.002414187556132674, "alpha_value": 0.009628151125214713, "duration": 48.30352854728699, "step": 85982}
{"episode_reward": 3.810459608309265, "episode": 2682.0, "batch_reward": -0.022041770396754146, "critic_loss": 1.016347974538803, "ae_transition_loss": 1.4605461955070496, "ae_encoder_loss": 0.45138607174158096, "actor_loss": -2.230674088001251, "actor_target_entropy": -2.0, "actor_entropy": -0.8851626664400101, "alpha_loss": -0.004151073517277837, "alpha_value": 0.00964978359852897, "duration": 8.624781131744385, "step": 86023}
{"episode_reward": 16.312020743884144, "episode": 2683.0, "batch_reward": -0.022118753354464258, "critic_loss": 1.2414369583129883, "ae_transition_loss": 1.7323677710124425, "ae_encoder_loss": 0.5377062218529838, "actor_loss": -2.125398942402431, "actor_target_entropy": -2.0, "actor_entropy": -0.7451720152582441, "alpha_loss": -0.004371276956849864, "alpha_value": 0.009692437961937842, "duration": 14.369535684585571, "step": 86094}
{"episode_reward": 41.57640744843663, "episode": 2684.0, "duration": 1.0220861434936523, "step": 86098}
{"episode_reward": -2.122030495096582, "episode": 2685.0, "batch_reward": -0.009095933521166444, "critic_loss": 1.2505105932553608, "ae_transition_loss": 1.5577300488948822, "ae_encoder_loss": 0.5578318561116854, "actor_loss": -2.1228178441524506, "actor_target_entropy": -2.0, "actor_entropy": -0.8387036770582199, "alpha_loss": -0.0009936332232124794, "alpha_value": 0.009781736692089668, "duration": 23.63728976249695, "step": 86212}
{"episode_reward": 47.89094084183581, "episode": 2686.0, "batch_reward": -0.018205951200798154, "critic_loss": 1.3251835107803345, "ae_transition_loss": 1.7254407703876495, "ae_encoder_loss": 0.938850000500679, "actor_loss": -1.9580267369747162, "actor_target_entropy": -2.0, "actor_entropy": -0.9331962764263153, "alpha_loss": 0.00012492250971263275, "alpha_value": 0.00982877227374879, "duration": 8.418871641159058, "step": 86253}
{"episode_reward": 6.3757300382670925, "episode": 2687.0, "batch_reward": -0.0010936145360271137, "critic_loss": 0.8504449725151062, "ae_transition_loss": 1.4570053815841675, "ae_encoder_loss": 0.7033864061037699, "actor_loss": -2.1913779576619468, "actor_target_entropy": -2.0, "actor_entropy": -0.9550106922785441, "alpha_loss": -0.0001225970530261596, "alpha_value": 0.009838393434815044, "duration": 7.547328948974609, "step": 86289}
{"episode_reward": 4.2683052340442025, "episode": 2688.0, "batch_reward": -0.05602877959609032, "critic_loss": 0.9491070508956909, "ae_transition_loss": 1.5177984237670898, "ae_encoder_loss": 0.6600028276443481, "actor_loss": -2.1871836185455322, "actor_target_entropy": -2.0, "actor_entropy": -0.7743539810180664, "alpha_loss": 0.00071993243182078, "alpha_value": 0.009842779618207226, "duration": 1.775421380996704, "step": 86297}
{"episode_reward": -2.7107025769252764, "episode": 2689.0, "batch_reward": -0.03131269500590861, "critic_loss": 1.409936174750328, "ae_transition_loss": 1.5203836858272552, "ae_encoder_loss": 0.5699914172291756, "actor_loss": -2.3673714995384216, "actor_target_entropy": -2.0, "actor_entropy": -0.7363487184047699, "alpha_loss": 0.0015870266070123762, "alpha_value": 0.009845345008692923, "duration": 8.604166507720947, "step": 86340}
{"episode_reward": 2.0521001449740432, "episode": 2690.0, "batch_reward": -0.013314200192689895, "critic_loss": 1.918908452987671, "ae_transition_loss": 1.6652686595916748, "ae_encoder_loss": 0.6347223341464996, "actor_loss": -2.204802083969116, "actor_target_entropy": -2.0, "actor_entropy": -0.522613936662674, "alpha_loss": 0.0026938726427033544, "alpha_value": 0.00984217172203333, "duration": 9.82370662689209, "step": 86389}
{"episode_reward": 3.798538300271199, "episode": 2691.0, "duration": 135.16361832618713, "step": 86390}
{"episode_reward": -0.5973114536107101, "episode": 2692.0, "batch_reward": 0.0024776682257652283, "critic_loss": 0.75560462474823, "ae_transition_loss": 1.3309555053710938, "ae_encoder_loss": 0.6056202054023743, "actor_loss": -2.419440269470215, "actor_target_entropy": -2.0, "actor_entropy": -0.34343135356903076, "alpha_loss": 0.0022280244156718254, "alpha_value": 0.009833508013794111, "duration": 0.5629472732543945, "step": 86391}
{"episode_reward": -0.7755054576010167, "episode": 2693.0, "batch_reward": -0.02732028178870678, "critic_loss": 1.4963645935058594, "ae_transition_loss": 1.5841326713562012, "ae_encoder_loss": 0.5108719348907471, "actor_loss": -2.042825436592102, "actor_target_entropy": -2.0, "actor_entropy": -0.43967190384864807, "alpha_loss": 0.0021036298479884864, "alpha_value": 0.009821105001329107, "duration": 10.17526125907898, "step": 86441}
{"episode_reward": 5.907956402496903, "episode": 2694.0, "batch_reward": -0.07054208219051361, "critic_loss": 1.3773721694946288, "ae_transition_loss": 1.6658193588256835, "ae_encoder_loss": 0.5194799661636352, "actor_loss": -1.980118703842163, "actor_target_entropy": -2.0, "actor_entropy": -0.6009219527244568, "alpha_loss": 0.001115941081661731, "alpha_value": 0.009799211487517277, "duration": 11.497313499450684, "step": 86500}
{"episode_reward": 15.21080130659892, "episode": 2695.0, "batch_reward": -0.04605913069099188, "critic_loss": 1.2507617870966594, "ae_transition_loss": 1.5643584926923115, "ae_encoder_loss": 0.4784829765558243, "actor_loss": -2.034794569015503, "actor_target_entropy": -2.0, "actor_entropy": -0.7561931113402048, "alpha_loss": 7.331457648736735e-05, "alpha_value": 0.00977464633779277, "duration": 11.94782042503357, "step": 86560}
{"episode_reward": 13.936520077859022, "episode": 2696.0, "batch_reward": -0.000689522922039032, "critic_loss": 1.2773471236228944, "ae_transition_loss": 1.6925036191940308, "ae_encoder_loss": 0.46743825674057005, "actor_loss": -2.336700773239136, "actor_target_entropy": -2.0, "actor_entropy": -0.6341994404792786, "alpha_loss": -0.0006483904784545302, "alpha_value": 0.00976002892701082, "duration": 10.083728551864624, "step": 86610}
{"episode_reward": 12.93148953549137, "episode": 2697.0, "batch_reward": -0.07706982269883156, "critic_loss": 1.478172481060028, "ae_transition_loss": 1.7240546345710754, "ae_encoder_loss": 0.46387410163879395, "actor_loss": -1.5450328588485718, "actor_target_entropy": -2.0, "actor_entropy": -0.5388852059841156, "alpha_loss": 0.0006383466679835692, "alpha_value": 0.009756133111660608, "duration": 2.961411476135254, "step": 86624}
{"episode_reward": -0.8980065256852466, "episode": 2698.0, "batch_reward": 0.02167552092578262, "critic_loss": 1.684884637594223, "ae_transition_loss": 1.5276733934879303, "ae_encoder_loss": 0.5401637405157089, "actor_loss": -2.4175933599472046, "actor_target_entropy": -2.0, "actor_entropy": -0.5069432109594345, "alpha_loss": -0.0012665637477766722, "alpha_value": 0.009755248259930772, "duration": 8.051142454147339, "step": 86664}
{"episode_reward": 8.694229708862592, "episode": 2699.0, "duration": 0.24912738800048828, "step": 86665}
{"episode_reward": 0.10296765129201468, "episode": 2700.0, "batch_reward": -0.020745869260281324, "critic_loss": 1.1495677530765533, "ae_transition_loss": 1.8553372025489807, "ae_encoder_loss": 0.6080237478017807, "actor_loss": -2.6070175766944885, "actor_target_entropy": -2.0, "actor_entropy": -0.32015518844127655, "alpha_loss": 0.00043565896339714527, "alpha_value": 0.009757774536603335, "duration": 7.917629957199097, "step": 86703}
{"episode_reward": 4.0778663378219395, "episode": 2701.0, "batch_reward": 0.0041464803119500475, "critic_loss": 1.5282633304595947, "ae_transition_loss": 1.8132762511571248, "ae_encoder_loss": 0.7729638417561849, "actor_loss": -2.0995126565297446, "actor_target_entropy": -2.0, "actor_entropy": -0.3305221696694692, "alpha_loss": 0.0009630193429378172, "alpha_value": 0.009758579395962962, "duration": 44.66366100311279, "step": 86736}
{"episode_reward": 5.398624619539826, "episode": 2702.0, "duration": 0.23157453536987305, "step": 86737}
{"episode_reward": -0.12035821916461376, "episode": 2703.0, "batch_reward": 0.03843342512845993, "critic_loss": 1.302851716677348, "ae_transition_loss": 1.712222655614217, "ae_encoder_loss": 0.9556076526641846, "actor_loss": -2.2029501597086587, "actor_target_entropy": -2.0, "actor_entropy": -0.4170963962872823, "alpha_loss": 8.416503745441635e-05, "alpha_value": 0.009757131775132455, "duration": 5.956097602844238, "step": 86766}
{"episode_reward": 7.888768527002433, "episode": 2704.0, "batch_reward": -0.03204834796488285, "critic_loss": 1.3735305547714234, "ae_transition_loss": 1.6321947574615479, "ae_encoder_loss": 1.4241209983825684, "actor_loss": -2.3855214595794676, "actor_target_entropy": -2.0, "actor_entropy": -0.502885776758194, "alpha_loss": 0.00028538929764181374, "alpha_value": 0.00975425529236306, "duration": 10.375663042068481, "step": 86816}
{"episode_reward": 6.706242322533183, "episode": 2705.0, "batch_reward": 0.0013637039810419083, "critic_loss": 1.4229254325230916, "ae_transition_loss": 1.6009207963943481, "ae_encoder_loss": 1.274503191312154, "actor_loss": -2.0871441761652627, "actor_target_entropy": -2.0, "actor_entropy": -0.5614067117373148, "alpha_loss": 0.0013979159411974251, "alpha_value": 0.009750184614944913, "duration": 6.523934602737427, "step": 86849}
{"episode_reward": 5.805334181514178, "episode": 2706.0, "batch_reward": -0.01795410132035613, "critic_loss": 1.175079271197319, "ae_transition_loss": 1.6058829426765442, "ae_encoder_loss": 0.8397525697946548, "actor_loss": -2.1572417616844177, "actor_target_entropy": -2.0, "actor_entropy": -0.6181668490171432, "alpha_loss": -7.07350845914334e-05, "alpha_value": 0.009744309610355002, "duration": 7.775720834732056, "step": 86886}
{"episode_reward": 8.55182777015327, "episode": 2707.0, "batch_reward": -0.018154813442379236, "critic_loss": 1.171107828617096, "ae_transition_loss": 1.4682733416557312, "ae_encoder_loss": 0.574834406375885, "actor_loss": -2.3538466691970825, "actor_target_entropy": -2.0, "actor_entropy": -0.6799696087837219, "alpha_loss": -0.0006707054853904992, "alpha_value": 0.009740819368095543, "duration": 4.127820730209351, "step": 86905}
{"episode_reward": 0.712757739222958, "episode": 2708.0, "batch_reward": 0.0035726710754845825, "critic_loss": 1.2092653044632502, "ae_transition_loss": 1.5135138205119543, "ae_encoder_loss": 0.4917769432067871, "actor_loss": -2.4186594571386064, "actor_target_entropy": -2.0, "actor_entropy": -0.6008547672203609, "alpha_loss": 0.0014477380235413356, "alpha_value": 0.009723536537350117, "duration": 28.86778998374939, "step": 87046}
{"episode_reward": 64.30715246858433, "episode": 2709.0, "batch_reward": -0.0009784636398156483, "critic_loss": 1.0803268750508626, "ae_transition_loss": 1.410754640897115, "ae_encoder_loss": 0.5514821410179138, "actor_loss": -2.1847976446151733, "actor_target_entropy": -2.0, "actor_entropy": -0.5951100985209147, "alpha_loss": -0.000919739754560093, "alpha_value": 0.00970047775552329, "duration": 5.8269031047821045, "step": 87073}
{"episode_reward": -0.6096607898110793, "episode": 2710.0, "batch_reward": 0.014268162660300732, "critic_loss": 1.1629911661148071, "ae_transition_loss": 1.5671075582504272, "ae_encoder_loss": 0.5329458713531494, "actor_loss": -2.438885807991028, "actor_target_entropy": -2.0, "actor_entropy": -0.7155483961105347, "alpha_loss": 0.00016077935288194567, "alpha_value": 0.009696403235686758, "duration": 4.362584590911865, "step": 87093}
{"episode_reward": 0.38163424691929043, "episode": 2711.0, "batch_reward": 0.05425423849374056, "critic_loss": 1.194439172744751, "ae_transition_loss": 1.640217363834381, "ae_encoder_loss": 0.5304359495639801, "actor_loss": -2.991024971008301, "actor_target_entropy": -2.0, "actor_entropy": -0.7580720782279968, "alpha_loss": -0.0016092678415589035, "alpha_value": 0.009693856564285449, "duration": 37.956185817718506, "step": 87116}
{"episode_reward": 0.887709897257432, "episode": 2712.0, "batch_reward": -0.009316256269812584, "critic_loss": 1.3134754498799641, "ae_transition_loss": 1.5275816917419434, "ae_encoder_loss": 0.4286854763825734, "actor_loss": -2.262061278025309, "actor_target_entropy": -2.0, "actor_entropy": -0.7311345537503561, "alpha_loss": -0.0008781257978019615, "alpha_value": 0.009693341955109793, "duration": 6.037274122238159, "step": 87144}
{"episode_reward": 1.1999061453924151, "episode": 2713.0, "batch_reward": -0.019453543704003096, "critic_loss": 1.3026656359434128, "ae_transition_loss": 1.5129720568656921, "ae_encoder_loss": 0.5064425989985466, "actor_loss": -2.5460108518600464, "actor_target_entropy": -2.0, "actor_entropy": -0.7512462139129639, "alpha_loss": -0.0005841655656695366, "alpha_value": 0.009694766195296137, "duration": 7.873235702514648, "step": 87181}
{"episode_reward": 3.8561126290788215, "episode": 2714.0, "batch_reward": -0.03550320118665695, "critic_loss": 0.8758509159088135, "ae_transition_loss": 1.4322961568832397, "ae_encoder_loss": 0.38501274585723877, "actor_loss": -2.391148090362549, "actor_target_entropy": -2.0, "actor_entropy": -0.770248532295227, "alpha_loss": -0.0001844613580033183, "alpha_value": 0.009697331452073462, "duration": 3.174605131149292, "step": 87197}
{"episode_reward": -1.7324442425893485, "episode": 2715.0, "batch_reward": -0.02596433580453907, "critic_loss": 1.625070529324668, "ae_transition_loss": 1.6123157909938268, "ae_encoder_loss": 0.4183494320937565, "actor_loss": -2.278902905327933, "actor_target_entropy": -2.0, "actor_entropy": -0.722684953893934, "alpha_loss": -0.00023705844900437763, "alpha_value": 0.009698632821768747, "duration": 13.993483543395996, "step": 87264}
{"episode_reward": 8.598325590928, "episode": 2716.0, "batch_reward": -0.014491884037852287, "critic_loss": 1.7060446739196777, "ae_transition_loss": 1.6715369820594788, "ae_encoder_loss": 0.48004698753356934, "actor_loss": -2.49764746427536, "actor_target_entropy": -2.0, "actor_entropy": -0.6939126253128052, "alpha_loss": -0.0006257723580347374, "alpha_value": 0.009701327423362898, "duration": 4.961026906967163, "step": 87288}
{"episode_reward": -0.07944248447384278, "episode": 2717.0, "batch_reward": 0.02892779614776373, "critic_loss": 1.2459143280982972, "ae_transition_loss": 1.6377969980239868, "ae_encoder_loss": 0.4171711325645447, "actor_loss": -2.801358699798584, "actor_target_entropy": -2.0, "actor_entropy": -0.6530094265937805, "alpha_loss": 0.0003800721635343507, "alpha_value": 0.009705277220174434, "duration": 9.479482173919678, "step": 87333}
{"episode_reward": 7.975054446080701, "episode": 2718.0, "batch_reward": -0.001687302254140377, "critic_loss": 1.5639681220054626, "ae_transition_loss": 1.4961133301258087, "ae_encoder_loss": 0.5592145994305611, "actor_loss": -2.474166989326477, "actor_target_entropy": -2.0, "actor_entropy": -0.5138020887970924, "alpha_loss": -0.0019176350033376366, "alpha_value": 0.009708715402043735, "duration": 8.83725094795227, "step": 87375}
{"episode_reward": 8.526665625166647, "episode": 2719.0, "batch_reward": -7.074489258229733e-05, "critic_loss": 1.451454445719719, "ae_transition_loss": 1.5726232826709747, "ae_encoder_loss": 0.8141592144966125, "actor_loss": -2.381058007478714, "actor_target_entropy": -2.0, "actor_entropy": -0.4734170511364937, "alpha_loss": -0.000743236843845807, "alpha_value": 0.009717071091905716, "duration": 8.70000410079956, "step": 87419}
{"episode_reward": 17.133578558778453, "episode": 2720.0, "batch_reward": 0.02664610417559743, "critic_loss": 1.0476353913545609, "ae_transition_loss": 1.4813214242458344, "ae_encoder_loss": 0.5228329002857208, "actor_loss": -2.8919763565063477, "actor_target_entropy": -2.0, "actor_entropy": -0.5896673798561096, "alpha_loss": -0.0014886221324559301, "alpha_value": 0.009727169967145696, "duration": 7.991436004638672, "step": 87458}
{"episode_reward": 9.392635477990305, "episode": 2721.0, "batch_reward": 0.005746135953813791, "critic_loss": 1.1021202504634857, "ae_transition_loss": 1.496615707874298, "ae_encoder_loss": 0.508112758398056, "actor_loss": -2.554332137107849, "actor_target_entropy": -2.0, "actor_entropy": -0.575061209499836, "alpha_loss": -0.001068353929440491, "alpha_value": 0.009739634844888491, "duration": 53.584373474121094, "step": 87498}
{"episode_reward": 5.526635260369215, "episode": 2722.0, "batch_reward": -0.012103099996844927, "critic_loss": 1.5690261920293171, "ae_transition_loss": 1.6306346257527669, "ae_encoder_loss": 0.5773684581120809, "actor_loss": -2.406189521153768, "actor_target_entropy": -2.0, "actor_entropy": -0.6617673635482788, "alpha_loss": 5.9063274723788105e-05, "alpha_value": 0.009752197477625677, "duration": 11.411336660385132, "step": 87555}
{"episode_reward": 21.784599870751563, "episode": 2723.0, "batch_reward": -0.003229161724448204, "critic_loss": 0.8060068041086197, "ae_transition_loss": 1.5343618392944336, "ae_encoder_loss": 0.7136114537715912, "actor_loss": -2.648811459541321, "actor_target_entropy": -2.0, "actor_entropy": -0.6858400404453278, "alpha_loss": -0.00019434650312177837, "alpha_value": 0.00976058950186865, "duration": 8.211501359939575, "step": 87593}
{"episode_reward": 10.164986154715772, "episode": 2724.0, "batch_reward": 0.04352977313101292, "critic_loss": 0.7200820744037628, "ae_transition_loss": 1.4835696816444397, "ae_encoder_loss": 0.7183000445365906, "actor_loss": -2.917945623397827, "actor_target_entropy": -2.0, "actor_entropy": -0.7185513973236084, "alpha_loss": 0.00026516822981648147, "alpha_value": 0.009764901269329353, "duration": 4.2131359577178955, "step": 87614}
{"episode_reward": 7.718663363896768, "episode": 2725.0, "duration": 0.21062445640563965, "step": 87615}
{"episode_reward": -0.2905779723998727, "episode": 2726.0, "batch_reward": 0.04175479244440794, "critic_loss": 2.1150276899337768, "ae_transition_loss": 1.5284822702407836, "ae_encoder_loss": 0.6250422835350037, "actor_loss": -2.5850242614746093, "actor_target_entropy": -2.0, "actor_entropy": -0.6638207316398621, "alpha_loss": -0.0005997303349431604, "alpha_value": 0.009768994380602112, "duration": 10.892122268676758, "step": 87670}
{"episode_reward": 6.319949642486713, "episode": 2727.0, "batch_reward": 0.008621249347925186, "critic_loss": 2.312446355819702, "ae_transition_loss": 2.2447126507759094, "ae_encoder_loss": 0.5669131278991699, "actor_loss": -2.4555532932281494, "actor_target_entropy": -2.0, "actor_entropy": -0.773949533700943, "alpha_loss": -0.0012900331639684737, "alpha_value": 0.009774493238502891, "duration": 4.063719034194946, "step": 87690}
{"episode_reward": -1.1985718272375436, "episode": 2728.0, "batch_reward": -0.013972196417550245, "critic_loss": 1.3062366048494976, "ae_transition_loss": 1.7541398406028748, "ae_encoder_loss": 0.6584270497163137, "actor_loss": -2.4614145755767822, "actor_target_entropy": -2.0, "actor_entropy": -0.7205385764439901, "alpha_loss": 0.0008681601320859045, "alpha_value": 0.00977873511504919, "duration": 11.160328149795532, "step": 87744}
{"episode_reward": 16.78648404687861, "episode": 2729.0, "batch_reward": 0.012511661276221275, "critic_loss": 0.9989037215709686, "ae_transition_loss": 1.6441890597343445, "ae_encoder_loss": 0.536765843629837, "actor_loss": -2.6828482151031494, "actor_target_entropy": -2.0, "actor_entropy": -0.7063373327255249, "alpha_loss": 0.004538679262623191, "alpha_value": 0.009778137855846934, "duration": 4.166549205780029, "step": 87765}
{"episode_reward": -0.009359768516594202, "episode": 2730.0, "batch_reward": -0.004133365546854643, "critic_loss": 1.5418233596361601, "ae_transition_loss": 1.829165632908161, "ae_encoder_loss": 0.605192808004526, "actor_loss": -2.5575638000781717, "actor_target_entropy": -2.0, "actor_entropy": -0.6665392701442425, "alpha_loss": 0.001082827151269437, "alpha_value": 0.00975875035830251, "duration": 25.76932668685913, "step": 87892}
{"episode_reward": 45.435623197002556, "episode": 2731.0, "batch_reward": 0.004065923765301705, "critic_loss": 1.3901803731918334, "ae_transition_loss": 1.6533150911331176, "ae_encoder_loss": 0.7521977901458741, "actor_loss": -2.4590571880340577, "actor_target_entropy": -2.0, "actor_entropy": -0.5359176993370056, "alpha_loss": 0.0012437036843039096, "alpha_value": 0.009729013325620612, "duration": 150.03490829467773, "step": 87945}
{"episode_reward": 2.885902283845082, "episode": 2732.0, "batch_reward": -0.032880015671253204, "critic_loss": 1.8367748260498047, "ae_transition_loss": 1.533769965171814, "ae_encoder_loss": 0.7924508452415466, "actor_loss": -2.5073459148406982, "actor_target_entropy": -2.0, "actor_entropy": -0.5397220849990845, "alpha_loss": 0.002890478353947401, "alpha_value": 0.009718417306233932, "duration": 2.7876968383789062, "step": 87958}
{"episode_reward": -2.2727493850580127, "episode": 2733.0, "batch_reward": -0.01251699635758996, "critic_loss": 1.3089040890336037, "ae_transition_loss": 1.679586961865425, "ae_encoder_loss": 0.5939078293740749, "actor_loss": -2.551174893975258, "actor_target_entropy": -2.0, "actor_entropy": -0.5839413218200207, "alpha_loss": -0.00020150075943092816, "alpha_value": 0.009701287558170256, "duration": 15.78388261795044, "step": 88035}
{"episode_reward": 30.675273680154366, "episode": 2734.0, "batch_reward": -0.01307889586314559, "critic_loss": 2.1050718903541563, "ae_transition_loss": 1.8423942446708679, "ae_encoder_loss": 1.0882984340190887, "actor_loss": -2.580415225028992, "actor_target_entropy": -2.0, "actor_entropy": -0.8343217968940735, "alpha_loss": -0.0013742368901148438, "alpha_value": 0.009692346368451205, "duration": 20.378227472305298, "step": 88134}
{"episode_reward": 2.2422536624536717, "episode": 2735.0, "batch_reward": -0.036389368689722486, "critic_loss": 1.8289287487665813, "ae_transition_loss": 1.7585357295142279, "ae_encoder_loss": 0.8522315488921272, "actor_loss": -2.4608967304229736, "actor_target_entropy": -2.0, "actor_entropy": -0.8306569986873202, "alpha_loss": -0.0011092124364545776, "alpha_value": 0.009713484232926846, "duration": 18.213512659072876, "step": 88224}
{"episode_reward": 26.2733457851211, "episode": 2736.0, "batch_reward": 0.0006831770555840598, "critic_loss": 1.2691644032796223, "ae_transition_loss": 1.6573024988174438, "ae_encoder_loss": 0.5068425900406308, "actor_loss": -2.335330327351888, "actor_target_entropy": -2.0, "actor_entropy": -0.8142514096366035, "alpha_loss": -0.00140437805869927, "alpha_value": 0.009745068391790802, "duration": 17.95636248588562, "step": 88311}
{"episode_reward": 43.11604981275539, "episode": 2737.0, "batch_reward": 0.030202511698007584, "critic_loss": 1.6489633917808533, "ae_transition_loss": 1.9205852448940277, "ae_encoder_loss": 0.6315372735261917, "actor_loss": -2.6025930047035217, "actor_target_entropy": -2.0, "actor_entropy": -0.6950009018182755, "alpha_loss": -5.7159995776601136e-06, "alpha_value": 0.009767387237550981, "duration": 8.7258882522583, "step": 88354}
{"episode_reward": 11.752263254647422, "episode": 2738.0, "batch_reward": 0.04526709392666817, "critic_loss": 1.9914413293202717, "ae_transition_loss": 1.453945279121399, "ae_encoder_loss": 0.4746362864971161, "actor_loss": -2.9838496843973794, "actor_target_entropy": -2.0, "actor_entropy": -0.5979009668032328, "alpha_loss": 0.0016046333281944196, "alpha_value": 0.00977536778679273, "duration": 6.78493857383728, "step": 88388}
{"episode_reward": 5.049032497548349, "episode": 2739.0, "batch_reward": -0.0011517051607370377, "critic_loss": 2.220203220844269, "ae_transition_loss": 1.842041293780009, "ae_encoder_loss": 0.6246892213821411, "actor_loss": -2.630232652028402, "actor_target_entropy": -2.0, "actor_entropy": -0.5012208223342896, "alpha_loss": 0.0019428902305662632, "alpha_value": 0.009776867516591856, "duration": 6.075883150100708, "step": 88418}
{"episode_reward": -1.5666644763641562, "episode": 2740.0, "batch_reward": -0.014721578607956568, "critic_loss": 1.337425688902537, "ae_transition_loss": 1.8318918546040852, "ae_encoder_loss": 0.6360959808031718, "actor_loss": -2.705474058787028, "actor_target_entropy": -2.0, "actor_entropy": -0.45998261372248334, "alpha_loss": 0.0036558251983175674, "alpha_value": 0.00977236283068751, "duration": 5.72768235206604, "step": 88446}
{"episode_reward": 3.609434893814243, "episode": 2741.0, "duration": 57.78750658035278, "step": 88447}
{"episode_reward": -0.7197096873387868, "episode": 2742.0, "batch_reward": -0.041400433983653784, "critic_loss": 1.5561898946762085, "ae_transition_loss": 1.6356064677238464, "ae_encoder_loss": 0.6510114818811417, "actor_loss": -2.5466529428958893, "actor_target_entropy": -2.0, "actor_entropy": -0.43953174352645874, "alpha_loss": 0.0022782707528676838, "alpha_value": 0.009757274885206594, "duration": 8.133066892623901, "step": 88485}
{"episode_reward": 3.7679533574116992, "episode": 2743.0, "duration": 0.27881717681884766, "step": 88486}
{"episode_reward": -0.5289349541382633, "episode": 2744.0, "batch_reward": -0.023512446011106174, "critic_loss": 1.9029667774836223, "ae_transition_loss": 2.1519449949264526, "ae_encoder_loss": 0.6263976494471232, "actor_loss": -2.09392511844635, "actor_target_entropy": -2.0, "actor_entropy": -0.4282056788603465, "alpha_loss": 0.0015913368357966344, "alpha_value": 0.009739087520105202, "duration": 6.123972654342651, "step": 88515}
{"episode_reward": 1.67415346812887, "episode": 2745.0, "batch_reward": -0.021213604602962732, "critic_loss": 1.7341580986976624, "ae_transition_loss": 1.6284410059452057, "ae_encoder_loss": 0.5938690602779388, "actor_loss": -2.5028222501277924, "actor_target_entropy": -2.0, "actor_entropy": -0.42452413588762283, "alpha_loss": 0.0013450779224513099, "alpha_value": 0.009720529657437964, "duration": 8.01215934753418, "step": 88552}
{"episode_reward": 2.32277963959888, "episode": 2746.0, "duration": 0.21693849563598633, "step": 88553}
{"episode_reward": -0.015876917642894617, "episode": 2747.0, "batch_reward": 0.006562411552295089, "critic_loss": 1.3284530639648438, "ae_transition_loss": 1.6561916768550873, "ae_encoder_loss": 0.41320663690567017, "actor_loss": -2.792336881160736, "actor_target_entropy": -2.0, "actor_entropy": -0.6075571626424789, "alpha_loss": 0.0017399800999555737, "alpha_value": 0.00969988462710637, "duration": 9.440229892730713, "step": 88598}
{"episode_reward": 5.9926624685382714, "episode": 2748.0, "batch_reward": 0.02017894573509693, "critic_loss": 1.3121432065963745, "ae_transition_loss": 1.5689926147460938, "ae_encoder_loss": 0.492287814617157, "actor_loss": -2.8466875553131104, "actor_target_entropy": -2.0, "actor_entropy": -0.629025936126709, "alpha_loss": 0.004487522412091494, "alpha_value": 0.009687295629177773, "duration": 1.85355806350708, "step": 88606}
{"episode_reward": -0.2235564099585297, "episode": 2749.0, "batch_reward": -0.00250215083360672, "critic_loss": 1.4813627401987712, "ae_transition_loss": 1.6470853090286255, "ae_encoder_loss": 0.5707235336303711, "actor_loss": -2.912684440612793, "actor_target_entropy": -2.0, "actor_entropy": -0.6156081557273865, "alpha_loss": 0.0014100431775053341, "alpha_value": 0.009674758097925435, "duration": 5.65792989730835, "step": 88633}
{"episode_reward": 3.872681305361694, "episode": 2750.0, "batch_reward": 0.015046407601663045, "critic_loss": 1.398544796875545, "ae_transition_loss": 1.8450665984834944, "ae_encoder_loss": 0.7124872377940586, "actor_loss": -2.768830026899065, "actor_target_entropy": -2.0, "actor_entropy": -0.6768584421702794, "alpha_loss": 0.0001749608782120049, "alpha_value": 0.009649421126917959, "duration": 14.736299276351929, "step": 88702}
{"episode_reward": 9.93126784463436, "episode": 2751.0, "duration": 58.97097301483154, "step": 88703}
{"episode_reward": -0.04783266543801769, "episode": 2752.0, "batch_reward": -8.06385651230812e-06, "critic_loss": 1.4588351845741272, "ae_transition_loss": 1.6318157315254211, "ae_encoder_loss": 0.7151395976543427, "actor_loss": -2.1430763602256775, "actor_target_entropy": -2.0, "actor_entropy": -0.6305769085884094, "alpha_loss": 0.0020323036005720496, "alpha_value": 0.009633898127742603, "duration": 4.841902017593384, "step": 88727}
{"episode_reward": 0.9272746709323693, "episode": 2753.0, "batch_reward": 0.009031071638067564, "critic_loss": 1.3586694598197937, "ae_transition_loss": 1.6936821738878887, "ae_encoder_loss": 0.563702846566836, "actor_loss": -2.38263609011968, "actor_target_entropy": -2.0, "actor_entropy": -0.691902627547582, "alpha_loss": 0.0014418138404532026, "alpha_value": 0.009620240993340965, "duration": 11.771867036819458, "step": 88786}
{"episode_reward": 10.196723040216902, "episode": 2754.0, "batch_reward": 0.008760062791407109, "critic_loss": 1.2133488535881043, "ae_transition_loss": 1.747914469242096, "ae_encoder_loss": 0.6011459112167359, "actor_loss": -2.5420801401138307, "actor_target_entropy": -2.0, "actor_entropy": -0.7009309828281403, "alpha_loss": -0.0008418318902840838, "alpha_value": 0.009598379516153535, "duration": 20.49582266807556, "step": 88885}
{"episode_reward": 24.02386446641689, "episode": 2755.0, "batch_reward": 0.03236286217967669, "critic_loss": 1.1115796566009521, "ae_transition_loss": 1.675732413927714, "ae_encoder_loss": 0.7193445265293121, "actor_loss": -3.0565106868743896, "actor_target_entropy": -2.0, "actor_entropy": -0.643257220586141, "alpha_loss": -0.002180969536614915, "alpha_value": 0.009596331933226884, "duration": 6.1521995067596436, "step": 88914}
{"episode_reward": 7.455966276001474, "episode": 2756.0, "batch_reward": -0.01215480174869299, "critic_loss": 1.2005997747182846, "ae_transition_loss": 1.7030131220817566, "ae_encoder_loss": 0.853502169251442, "actor_loss": -2.605203688144684, "actor_target_entropy": -2.0, "actor_entropy": -0.6270550191402435, "alpha_loss": 0.0011127784673590213, "alpha_value": 0.00960201345563189, "duration": 9.06748342514038, "step": 88958}
{"episode_reward": 9.764850075855163, "episode": 2757.0, "duration": 0.23178410530090332, "step": 88959}
{"episode_reward": 0.37633778096057907, "episode": 2758.0, "batch_reward": -0.016618654705010928, "critic_loss": 1.7635352519842296, "ae_transition_loss": 1.8159197293795073, "ae_encoder_loss": 0.8341929683318505, "actor_loss": -2.459223536344675, "actor_target_entropy": -2.0, "actor_entropy": -0.5865441652444693, "alpha_loss": 0.0008796778890357998, "alpha_value": 0.009596053148878975, "duration": 25.818848371505737, "step": 89084}
{"episode_reward": 60.662332102799475, "episode": 2759.0, "batch_reward": -0.0400089497367541, "critic_loss": 1.9134722550710042, "ae_transition_loss": 1.7338430285453796, "ae_encoder_loss": 0.8891664246718088, "actor_loss": -2.429016947746277, "actor_target_entropy": -2.0, "actor_entropy": -0.579152524471283, "alpha_loss": 0.0008552688668714836, "alpha_value": 0.009579470473732973, "duration": 12.904842615127563, "step": 89147}
{"episode_reward": 12.8662840680151, "episode": 2760.0, "batch_reward": -0.009391850233078003, "critic_loss": 1.989682498574257, "ae_transition_loss": 1.6695177555084229, "ae_encoder_loss": 0.8473012313246727, "actor_loss": -2.4801391661167145, "actor_target_entropy": -2.0, "actor_entropy": -0.5334545522928238, "alpha_loss": 0.002203435245610308, "alpha_value": 0.009531722848386864, "duration": 40.59315586090088, "step": 89341}
{"episode_reward": 63.73766374272884, "episode": 2761.0, "batch_reward": -0.06020459719002247, "critic_loss": 1.4052141904830933, "ae_transition_loss": 1.6570740938186646, "ae_encoder_loss": 0.4718181788921356, "actor_loss": -2.4011592864990234, "actor_target_entropy": -2.0, "actor_entropy": -0.5487108528614044, "alpha_loss": 0.003597572911530733, "alpha_value": 0.009469196465805838, "duration": 46.69842600822449, "step": 89366}
{"episode_reward": 0.480009642172587, "episode": 2762.0, "batch_reward": 0.031707845628261566, "critic_loss": 1.745759916305542, "ae_transition_loss": 1.5683016061782837, "ae_encoder_loss": 0.5490004658699036, "actor_loss": -2.42289023399353, "actor_target_entropy": -2.0, "actor_entropy": -0.557037740945816, "alpha_loss": 0.002339731506071985, "alpha_value": 0.009442454969122209, "duration": 10.495736360549927, "step": 89415}
{"episode_reward": 9.602249988026495, "episode": 2763.0, "batch_reward": -0.023739888643225033, "critic_loss": 1.7879444758097331, "ae_transition_loss": 1.7416350841522217, "ae_encoder_loss": 0.6704170902570089, "actor_loss": -2.218958775202433, "actor_target_entropy": -2.0, "actor_entropy": -0.4743978480497996, "alpha_loss": 0.0025666658766567707, "alpha_value": 0.009411862799239687, "duration": 6.201529026031494, "step": 89443}
{"episode_reward": 1.065004988508785, "episode": 2764.0, "batch_reward": 0.004743826575577259, "critic_loss": 0.9586316347122192, "ae_transition_loss": 1.7965590953826904, "ae_encoder_loss": 0.6826770901679993, "actor_loss": -2.4800647497177124, "actor_target_entropy": -2.0, "actor_entropy": -0.49396343529224396, "alpha_loss": 0.00013756286352872849, "alpha_value": 0.009392308394593367, "duration": 4.118682384490967, "step": 89461}
{"episode_reward": -1.2049664335231252, "episode": 2765.0, "batch_reward": 0.03889842424541712, "critic_loss": 1.8197437077760696, "ae_transition_loss": 1.6197853088378906, "ae_encoder_loss": 0.6765330135822296, "actor_loss": -2.750004470348358, "actor_target_entropy": -2.0, "actor_entropy": -0.48066453635692596, "alpha_loss": 0.001567095285281539, "alpha_value": 0.009372407952724093, "duration": 9.855099439620972, "step": 89509}
{"episode_reward": -0.7322004432342796, "episode": 2766.0, "batch_reward": 0.04253845723966757, "critic_loss": 1.3874793648719788, "ae_transition_loss": 1.6991475423177083, "ae_encoder_loss": 0.8082811236381531, "actor_loss": -2.8597185611724854, "actor_target_entropy": -2.0, "actor_entropy": -0.5758360028266907, "alpha_loss": 0.0016761783820887406, "alpha_value": 0.009351307296518738, "duration": 5.459925651550293, "step": 89535}
{"episode_reward": 3.0538747802749304, "episode": 2767.0, "batch_reward": -0.02089450368657708, "critic_loss": 1.228051021695137, "ae_transition_loss": 1.7193554043769836, "ae_encoder_loss": 0.8085551112890244, "actor_loss": -2.5892383456230164, "actor_target_entropy": -2.0, "actor_entropy": -0.5738118290901184, "alpha_loss": 0.002330580842681229, "alpha_value": 0.00933044571690729, "duration": 8.563697576522827, "step": 89576}
{"episode_reward": 6.284564167029052, "episode": 2768.0, "batch_reward": -0.038356299279257655, "critic_loss": 1.3216383059819539, "ae_transition_loss": 1.7102123498916626, "ae_encoder_loss": 0.5522452592849731, "actor_loss": -2.4647162755330405, "actor_target_entropy": -2.0, "actor_entropy": -0.636598269144694, "alpha_loss": 0.001248751252812023, "alpha_value": 0.009298583892989045, "duration": 12.691760063171387, "step": 89640}
{"episode_reward": 15.85517296740927, "episode": 2769.0, "batch_reward": 0.043395309088130794, "critic_loss": 1.4916908939679463, "ae_transition_loss": 1.5906575123469036, "ae_encoder_loss": 0.5880133708318075, "actor_loss": -2.7517762184143066, "actor_target_entropy": -2.0, "actor_entropy": -0.6846220095952352, "alpha_loss": 0.0009566660349567732, "alpha_value": 0.009273436640646206, "duration": 5.463841676712036, "step": 89667}
{"episode_reward": 4.028764052063693, "episode": 2770.0, "batch_reward": 0.012539091520011425, "critic_loss": 1.723142348229885, "ae_transition_loss": 1.5649585872888565, "ae_encoder_loss": 0.579065591096878, "actor_loss": -2.89202880859375, "actor_target_entropy": -2.0, "actor_entropy": -0.6805793792009354, "alpha_loss": 0.00032926828498602845, "alpha_value": 0.009251799235799262, "duration": 15.183518648147583, "step": 89741}
{"episode_reward": 1.8458789727552722, "episode": 2771.0, "batch_reward": -0.025198711548000574, "critic_loss": 1.62818044424057, "ae_transition_loss": 1.7329523265361786, "ae_encoder_loss": 0.5394694805145264, "actor_loss": -2.6297138333320618, "actor_target_entropy": -2.0, "actor_entropy": -0.5565953403711319, "alpha_loss": 0.0017234877741429955, "alpha_value": 0.009233841318292541, "duration": 106.09212112426758, "step": 89790}
{"episode_reward": 8.788686901954089, "episode": 2772.0, "batch_reward": -0.12519168853759766, "critic_loss": 1.6157495975494385, "ae_transition_loss": 1.6753493547439575, "ae_encoder_loss": 0.49110090732574463, "actor_loss": -1.8063013553619385, "actor_target_entropy": -2.0, "actor_entropy": -0.2631457448005676, "alpha_loss": 0.0033873887732625008, "alpha_value": 0.009225624347555203, "duration": 0.5235073566436768, "step": 89791}
{"episode_reward": -0.09078869773656838, "episode": 2773.0, "batch_reward": 0.031122436746954918, "critic_loss": 1.9009122848510742, "ae_transition_loss": 1.756821095943451, "ae_encoder_loss": 0.5721205472946167, "actor_loss": -2.556489586830139, "actor_target_entropy": -2.0, "actor_entropy": -0.3760923221707344, "alpha_loss": 0.0027939934516325593, "alpha_value": 0.009219822132971053, "duration": 5.415961980819702, "step": 89819}
{"episode_reward": 5.282617896672376, "episode": 2774.0, "batch_reward": -0.032979901880025864, "critic_loss": 0.5365873972574869, "ae_transition_loss": 1.4298410415649414, "ae_encoder_loss": 0.6309316257635752, "actor_loss": -2.4319610595703125, "actor_target_entropy": -2.0, "actor_entropy": -0.42896626393000287, "alpha_loss": 0.0004484099141942958, "alpha_value": 0.009208474255493936, "duration": 4.906601905822754, "step": 89842}
{"episode_reward": 2.329169205958968, "episode": 2775.0, "batch_reward": 0.00021762214601039886, "critic_loss": 1.803481240272522, "ae_transition_loss": 1.8967087745666504, "ae_encoder_loss": 1.8419259464740754, "actor_loss": -2.6802651500701904, "actor_target_entropy": -2.0, "actor_entropy": -0.4657263433933258, "alpha_loss": 0.0012830832385225222, "alpha_value": 0.009156499055148952, "duration": 54.87958765029907, "step": 90091}
{"episode_reward": 150.13887262832756, "episode": 2776.0, "batch_reward": 0.0016917598744233449, "critic_loss": 2.081477403640747, "ae_transition_loss": 1.889201323191325, "ae_encoder_loss": 1.3414310812950134, "actor_loss": -3.2137181758880615, "actor_target_entropy": -2.0, "actor_entropy": -0.5533488790194193, "alpha_loss": 0.001204075359661753, "alpha_value": 0.009100392250839407, "duration": 6.477946043014526, "step": 90122}
{"episode_reward": 7.787514088479088, "episode": 2777.0, "batch_reward": 0.001563585673769315, "critic_loss": 1.9965041478474934, "ae_transition_loss": 1.7745271523793538, "ae_encoder_loss": 0.9618646999200186, "actor_loss": -2.5857810179392495, "actor_target_entropy": -2.0, "actor_entropy": -0.6359386444091797, "alpha_loss": 0.00022589102930699786, "alpha_value": 0.009081510762599512, "duration": 13.935322523117065, "step": 90189}
{"episode_reward": 15.431649579470609, "episode": 2778.0, "batch_reward": -0.00013114498662097112, "critic_loss": 2.3459359237125943, "ae_transition_loss": 1.5906973736626762, "ae_encoder_loss": 0.7661943478243691, "actor_loss": -2.3970116547175815, "actor_target_entropy": -2.0, "actor_entropy": -0.6963200313704354, "alpha_loss": -0.0003066103173685925, "alpha_value": 0.009064741777766961, "duration": 13.278762578964233, "step": 90253}
{"episode_reward": 15.723809171277459, "episode": 2779.0, "batch_reward": -0.0620940700173378, "critic_loss": 2.3375959396362305, "ae_transition_loss": 1.6535543203353882, "ae_encoder_loss": 0.7923145890235901, "actor_loss": -2.420194149017334, "actor_target_entropy": -2.0, "actor_entropy": -0.690981388092041, "alpha_loss": 6.0447840951383114e-05, "alpha_value": 0.009061015751993296, "duration": 2.6770691871643066, "step": 90265}
{"episode_reward": -1.1658423776003324, "episode": 2780.0, "batch_reward": -0.0058544861773649854, "critic_loss": 1.7052464485168457, "ae_transition_loss": 1.3367859522501628, "ae_encoder_loss": 0.5556839108467102, "actor_loss": -2.611086924870809, "actor_target_entropy": -2.0, "actor_entropy": -0.7181904117266337, "alpha_loss": -0.002108713611960411, "alpha_value": 0.009060744927129062, "duration": 5.918658256530762, "step": 90292}
{"episode_reward": 3.515186227974728, "episode": 2781.0, "batch_reward": 0.06903956830501556, "critic_loss": 3.373880624771118, "ae_transition_loss": 1.172890543937683, "ae_encoder_loss": 0.6510724425315857, "actor_loss": -2.9589881896972656, "actor_target_entropy": -2.0, "actor_entropy": -0.6071119904518127, "alpha_loss": -0.0021501637529581785, "alpha_value": 0.009062695941084088, "duration": 90.43546867370605, "step": 90302}
{"episode_reward": -2.2247146248710385, "episode": 2782.0, "batch_reward": 0.016319261863827705, "critic_loss": 1.8941314220428467, "ae_transition_loss": 1.340875506401062, "ae_encoder_loss": 0.7328399419784546, "actor_loss": -3.288094997406006, "actor_target_entropy": -2.0, "actor_entropy": -0.6834235787391663, "alpha_loss": -0.003504018532112241, "alpha_value": 0.00906448987578199, "duration": 3.332667589187622, "step": 90319}
{"episode_reward": -1.881552933667951, "episode": 2783.0, "batch_reward": 0.010950498282909393, "critic_loss": 1.948651870091756, "ae_transition_loss": 1.4063448111216228, "ae_encoder_loss": 0.8573433756828308, "actor_loss": -2.749699831008911, "actor_target_entropy": -2.0, "actor_entropy": -0.6357308626174927, "alpha_loss": -0.0002920857708280285, "alpha_value": 0.00906923874428725, "duration": 5.242804527282715, "step": 90345}
{"episode_reward": 2.433371322277096, "episode": 2784.0, "batch_reward": 0.017849411194523174, "critic_loss": 1.2948535283406575, "ae_transition_loss": 1.3053398132324219, "ae_encoder_loss": 1.2399080991744995, "actor_loss": -2.4093618392944336, "actor_target_entropy": -2.0, "actor_entropy": -0.5991027156511942, "alpha_loss": -0.0013454200622315209, "alpha_value": 0.00907591302632329, "duration": 5.534783124923706, "step": 90371}
{"episode_reward": 3.019765503594608, "episode": 2785.0, "duration": 0.18314313888549805, "step": 90372}
{"episode_reward": -0.9373259925722608, "episode": 2786.0, "batch_reward": 0.019858751446008682, "critic_loss": 1.9432491858800252, "ae_transition_loss": 1.4947330554326375, "ae_encoder_loss": 1.020012875398, "actor_loss": -2.444045384724935, "actor_target_entropy": -2.0, "actor_entropy": -0.5510891278584799, "alpha_loss": -0.0013723827432841063, "alpha_value": 0.00908424754202364, "duration": 7.018437623977661, "step": 90408}
{"episode_reward": 2.439718500376731, "episode": 2787.0, "batch_reward": 0.012675655074417591, "critic_loss": 2.9457786083221436, "ae_transition_loss": 1.4773632884025574, "ae_encoder_loss": 0.8501422703266144, "actor_loss": -2.4033617973327637, "actor_target_entropy": -2.0, "actor_entropy": -0.5800430178642273, "alpha_loss": -0.00042876999941654503, "alpha_value": 0.009092113846345572, "duration": 3.1970105171203613, "step": 90422}
{"episode_reward": -1.0655599559473998, "episode": 2788.0, "batch_reward": 0.13762404024600983, "critic_loss": 1.5868613719940186, "ae_transition_loss": 1.5954891443252563, "ae_encoder_loss": 0.7468906044960022, "actor_loss": -3.587564468383789, "actor_target_entropy": -2.0, "actor_entropy": -0.5871106386184692, "alpha_loss": 0.0014098670799285173, "alpha_value": 0.009096649287410408, "duration": 2.1619203090667725, "step": 90431}
{"episode_reward": -1.1138290592845697, "episode": 2789.0, "batch_reward": -0.041638877242803574, "critic_loss": 2.9355216026306152, "ae_transition_loss": 2.0122973918914795, "ae_encoder_loss": 1.1360633373260498, "actor_loss": -2.4797784090042114, "actor_target_entropy": -2.0, "actor_entropy": -0.44257524609565735, "alpha_loss": 0.0015033190429676324, "alpha_value": 0.009099760645382168, "duration": 5.38066554069519, "step": 90457}
{"episode_reward": 1.8189863850170471, "episode": 2790.0, "batch_reward": 0.001302957224349181, "critic_loss": 1.950784722963969, "ae_transition_loss": 1.5832020441691081, "ae_encoder_loss": 0.8894898295402527, "actor_loss": -3.394320011138916, "actor_target_entropy": -2.0, "actor_entropy": -0.3929097255071004, "alpha_loss": 3.8025114918127656e-05, "alpha_value": 0.009101740893753192, "duration": 5.3444905281066895, "step": 90483}
{"episode_reward": 2.5570200468911004, "episode": 2791.0, "batch_reward": 0.0244651697576046, "critic_loss": 2.427540421485901, "ae_transition_loss": 1.6770934462547302, "ae_encoder_loss": 0.6479304730892181, "actor_loss": -2.4616611003875732, "actor_target_entropy": -2.0, "actor_entropy": -0.2821721285581589, "alpha_loss": -0.0008268835372291505, "alpha_value": 0.009103022616589358, "duration": 42.23895335197449, "step": 90506}
{"episode_reward": -0.8215464218662225, "episode": 2792.0, "batch_reward": -0.04900818504393101, "critic_loss": 2.788333535194397, "ae_transition_loss": 1.9017423391342163, "ae_encoder_loss": 0.6899445354938507, "actor_loss": -2.3675990104675293, "actor_target_entropy": -2.0, "actor_entropy": -0.07567960396409035, "alpha_loss": -0.000264535570750013, "alpha_value": 0.009105018402208571, "duration": 4.575667381286621, "step": 90528}
{"episode_reward": 1.4797702281362257, "episode": 2793.0, "duration": 0.2277238368988037, "step": 90529}
{"episode_reward": -0.23804153302339132, "episode": 2794.0, "batch_reward": 0.018652021884918213, "critic_loss": 1.6080258786678314, "ae_transition_loss": 1.7010651528835297, "ae_encoder_loss": 0.5510556846857071, "actor_loss": -2.9466460943222046, "actor_target_entropy": -2.0, "actor_entropy": -0.02213781699538231, "alpha_loss": 0.0013364259211812168, "alpha_value": 0.009107145012796808, "duration": 7.0102927684783936, "step": 90562}
{"episode_reward": 0.6469204325341219, "episode": 2795.0, "batch_reward": -0.03652761280536652, "critic_loss": 2.5706087589263915, "ae_transition_loss": 1.6589756250381469, "ae_encoder_loss": 0.7229250073432922, "actor_loss": -2.1274871587753297, "actor_target_entropy": -2.0, "actor_entropy": -0.19075102508068084, "alpha_loss": 0.003004030347801745, "alpha_value": 0.00910174607150212, "duration": 10.425387859344482, "step": 90612}
{"episode_reward": -0.5467010623308531, "episode": 2796.0, "batch_reward": 0.0075525278225541115, "critic_loss": 2.3410136699676514, "ae_transition_loss": 2.1025781333446503, "ae_encoder_loss": 0.6530917435884476, "actor_loss": -2.7323278188705444, "actor_target_entropy": -2.0, "actor_entropy": -0.43933072686195374, "alpha_loss": 0.0028749905177392066, "alpha_value": 0.009083474266166057, "duration": 9.227864265441895, "step": 90658}
{"episode_reward": 6.0370068083563, "episode": 2797.0, "batch_reward": -0.055640194565057755, "critic_loss": 2.007129192352295, "ae_transition_loss": 2.195481777191162, "ae_encoder_loss": 0.7723520994186401, "actor_loss": -2.519502639770508, "actor_target_entropy": -2.0, "actor_entropy": -0.3644990026950836, "alpha_loss": 0.0030611802358180285, "alpha_value": 0.009069160754918867, "duration": 2.1381185054779053, "step": 90667}
{"episode_reward": -1.753938869728678, "episode": 2798.0, "batch_reward": 0.05836127698421478, "critic_loss": 1.9519097805023193, "ae_transition_loss": 1.5628767311573029, "ae_encoder_loss": 0.6052169948816299, "actor_loss": -3.0292139053344727, "actor_target_entropy": -2.0, "actor_entropy": -0.5049565881490707, "alpha_loss": 0.003066999721340835, "alpha_value": 0.009052598066865522, "duration": 8.441651582717896, "step": 90708}
{"episode_reward": 4.82024493366279, "episode": 2799.0, "batch_reward": 0.02157573972363025, "critic_loss": 1.706654205918312, "ae_transition_loss": 1.7793645858764648, "ae_encoder_loss": 0.5104763209819794, "actor_loss": -2.700972080230713, "actor_target_entropy": -2.0, "actor_entropy": -0.3020689431577921, "alpha_loss": 0.004406854917760938, "alpha_value": 0.009002971730339449, "duration": 15.73827075958252, "step": 90783}
{"episode_reward": 11.483657473917111, "episode": 2800.0, "batch_reward": -0.0404949439689517, "critic_loss": 1.9374703168869019, "ae_transition_loss": 1.7207841277122498, "ae_encoder_loss": 0.5794031322002411, "actor_loss": -1.9010953903198242, "actor_target_entropy": -2.0, "actor_entropy": -0.19447124749422073, "alpha_loss": 0.004180919611826539, "alpha_value": 0.008951787612339144, "duration": 4.14888858795166, "step": 90802}
{"episode_reward": -1.0843964531098527, "episode": 2801.0, "batch_reward": 0.025935248205704347, "critic_loss": 1.8891390221459525, "ae_transition_loss": 1.6236787693841117, "ae_encoder_loss": 0.46702326621328083, "actor_loss": -2.879179988588606, "actor_target_entropy": -2.0, "actor_entropy": -0.6259750383240836, "alpha_loss": 0.0030372837458604147, "alpha_value": 0.00890154637422586, "duration": 112.2978127002716, "step": 90871}
{"episode_reward": -0.049131267779563975, "episode": 2802.0, "batch_reward": 0.00483722680558761, "critic_loss": 1.9858407179514568, "ae_transition_loss": 1.9895615736643473, "ae_encoder_loss": 1.113227947552999, "actor_loss": -2.763623809814453, "actor_target_entropy": -2.0, "actor_entropy": -0.6614150633414586, "alpha_loss": 0.003812569100409746, "alpha_value": 0.008776908304442443, "duration": 32.04617214202881, "step": 91030}
{"episode_reward": 51.679632579686306, "episode": 2803.0, "batch_reward": -0.00045343488454818726, "critic_loss": 1.4487761855125427, "ae_transition_loss": 1.9687785506248474, "ae_encoder_loss": 1.602253258228302, "actor_loss": -2.863956928253174, "actor_target_entropy": -2.0, "actor_entropy": -0.6421425938606262, "alpha_loss": 0.002200098941102624, "alpha_value": 0.008681237927011223, "duration": 4.051793098449707, "step": 91049}
{"episode_reward": -0.9316944497222571, "episode": 2804.0, "duration": 0.23934721946716309, "step": 91050}
{"episode_reward": 0.9915824450107424, "episode": 2805.0, "batch_reward": 0.040028028190135956, "critic_loss": 3.9721925258636475, "ae_transition_loss": 3.5208818912506104, "ae_encoder_loss": 2.077075719833374, "actor_loss": -3.1228365898132324, "actor_target_entropy": -2.0, "actor_entropy": -0.6041321158409119, "alpha_loss": 0.0006837755208835006, "alpha_value": 0.00866713736917183, "duration": 0.5653104782104492, "step": 91051}
{"episode_reward": -0.36614916385151786, "episode": 2806.0, "batch_reward": -0.016073213269313175, "critic_loss": 2.121739387512207, "ae_transition_loss": 2.066480835278829, "ae_encoder_loss": 1.3011489311854045, "actor_loss": -3.2544449170430503, "actor_target_entropy": -2.0, "actor_entropy": -0.5696869889895121, "alpha_loss": 0.004377396854882439, "alpha_value": 0.008649689480981942, "duration": 7.1985414028167725, "step": 91086}
{"episode_reward": 3.716763111096023, "episode": 2807.0, "batch_reward": -0.0048768771812319756, "critic_loss": 2.2765716910362244, "ae_transition_loss": 2.0467005372047424, "ae_encoder_loss": 0.8006612658500671, "actor_loss": -2.9244980812072754, "actor_target_entropy": -2.0, "actor_entropy": -0.4845997095108032, "alpha_loss": 0.005045538768172264, "alpha_value": 0.008614483727152029, "duration": 8.19366717338562, "step": 91123}
{"episode_reward": 1.47308566822409, "episode": 2808.0, "batch_reward": -0.028378011658787727, "critic_loss": 1.659592827161153, "ae_transition_loss": 2.011695901552836, "ae_encoder_loss": 0.9958626826604208, "actor_loss": -2.3268226782480874, "actor_target_entropy": -2.0, "actor_entropy": -0.603407214085261, "alpha_loss": 0.0023592469903330007, "alpha_value": 0.008575925402083642, "duration": 6.48427414894104, "step": 91153}
{"episode_reward": 6.564529136561147, "episode": 2809.0, "batch_reward": 0.004528019732485215, "critic_loss": 1.8946620623270671, "ae_transition_loss": 1.9021848440170288, "ae_encoder_loss": 1.114763855934143, "actor_loss": -2.426419258117676, "actor_target_entropy": -2.0, "actor_entropy": -0.6200832525889078, "alpha_loss": 0.0006460254468644658, "alpha_value": 0.008546322494895679, "duration": 6.725552797317505, "step": 91186}
{"episode_reward": 6.061185907406308, "episode": 2810.0, "batch_reward": 0.025605703238397837, "critic_loss": 2.8912099301815033, "ae_transition_loss": 1.952140748500824, "ae_encoder_loss": 1.1554080694913864, "actor_loss": -2.829681873321533, "actor_target_entropy": -2.0, "actor_entropy": -0.5469469651579857, "alpha_loss": 0.001840278840973042, "alpha_value": 0.008519268274622842, "duration": 8.3078031539917, "step": 91226}
{"episode_reward": 5.4294175530098805, "episode": 2811.0, "batch_reward": 0.00459888515373071, "critic_loss": 2.5689404805501304, "ae_transition_loss": 1.9395688374837239, "ae_encoder_loss": 1.6966311931610107, "actor_loss": -2.160355567932129, "actor_target_entropy": -2.0, "actor_entropy": -0.34620586037635803, "alpha_loss": 0.002601475571282208, "alpha_value": 0.00849491196285799, "duration": 74.87573504447937, "step": 91256}
{"episode_reward": 5.260847545718432, "episode": 2812.0, "duration": 0.23182225227355957, "step": 91257}
{"episode_reward": 0.026988634238103215, "episode": 2813.0, "batch_reward": 0.0006256962660700083, "critic_loss": 2.602830946445465, "ae_transition_loss": 1.7710060775279999, "ae_encoder_loss": 1.502612680196762, "actor_loss": -2.887933373451233, "actor_target_entropy": -2.0, "actor_entropy": -0.411205418407917, "alpha_loss": 0.003303757490357384, "alpha_value": 0.00846956947459825, "duration": 7.3857526779174805, "step": 91292}
{"episode_reward": 5.924080241511693, "episode": 2814.0, "batch_reward": 0.036952934538324676, "critic_loss": 1.9588183760643005, "ae_transition_loss": 1.6132132212320964, "ae_encoder_loss": 1.848122199376424, "actor_loss": -2.8380077679951987, "actor_target_entropy": -2.0, "actor_entropy": -0.417873740196228, "alpha_loss": 0.0021689134252180033, "alpha_value": 0.008441377146324178, "duration": 7.5057878494262695, "step": 91328}
{"episode_reward": 5.958555691674742, "episode": 2815.0, "batch_reward": 0.02376955437163512, "critic_loss": 2.3677972157796225, "ae_transition_loss": 1.6127694050470989, "ae_encoder_loss": 2.001630107561747, "actor_loss": -2.845001141230265, "actor_target_entropy": -2.0, "actor_entropy": -0.4925612012545268, "alpha_loss": 0.0001921175280585885, "alpha_value": 0.00841885369622025, "duration": 5.5638604164123535, "step": 91353}
{"episode_reward": 1.4180332754042833, "episode": 2816.0, "duration": 0.22262287139892578, "step": 91354}
{"episode_reward": -0.21143680253083003, "episode": 2817.0, "batch_reward": 0.004966267850250006, "critic_loss": 2.366824984550476, "ae_transition_loss": 1.7559726238250732, "ae_encoder_loss": 1.837939202785492, "actor_loss": -2.6592410802841187, "actor_target_entropy": -2.0, "actor_entropy": -0.5359492748975754, "alpha_loss": 0.0009722396462166216, "alpha_value": 0.008399403491355251, "duration": 9.337193250656128, "step": 91400}
{"episode_reward": 7.351855696906067, "episode": 2818.0, "batch_reward": 0.03316581870118777, "critic_loss": 3.2695822715759277, "ae_transition_loss": 1.6286108096440632, "ae_encoder_loss": 1.9199236631393433, "actor_loss": -2.7619481086730957, "actor_target_entropy": -2.0, "actor_entropy": -0.5408779780069987, "alpha_loss": 0.0013783442554995418, "alpha_value": 0.008383116441048522, "duration": 5.5635826587677, "step": 91427}
{"episode_reward": 4.36020047692242, "episode": 2819.0, "batch_reward": -0.025745175778865814, "critic_loss": 4.099562644958496, "ae_transition_loss": 2.2868086099624634, "ae_encoder_loss": 2.3699498176574707, "actor_loss": -2.01324325799942, "actor_target_entropy": -2.0, "actor_entropy": -0.43891823291778564, "alpha_loss": 0.004122263984754682, "alpha_value": 0.008371745125959375, "duration": 4.2517170906066895, "step": 91448}
{"episode_reward": 0.06593818927526485, "episode": 2820.0, "batch_reward": 0.025762973974148434, "critic_loss": 3.053058465321859, "ae_transition_loss": 1.9743986924489338, "ae_encoder_loss": 1.5253787438074748, "actor_loss": -2.8951543966929116, "actor_target_entropy": -2.0, "actor_entropy": -0.4863707522551219, "alpha_loss": 0.0013449078736205895, "alpha_value": 0.008357918949957922, "duration": 5.687660217285156, "step": 91476}
{"episode_reward": 6.61454971272457, "episode": 2821.0, "duration": 72.70382070541382, "step": 91477}
{"episode_reward": -0.26089122891426086, "episode": 2822.0, "batch_reward": 0.006725162666823182, "critic_loss": 2.4242927857807706, "ae_transition_loss": 1.9609332254954748, "ae_encoder_loss": 1.0549454603876387, "actor_loss": -2.7771055698394775, "actor_target_entropy": -2.0, "actor_entropy": -0.48055109807423185, "alpha_loss": 0.0015234165392549975, "alpha_value": 0.008331260515168032, "duration": 13.201522588729858, "step": 91541}
{"episode_reward": 12.978377736259812, "episode": 2823.0, "batch_reward": 0.010381164960563183, "critic_loss": 2.126195549964905, "ae_transition_loss": 1.9718326330184937, "ae_encoder_loss": 0.7394869029521942, "actor_loss": -2.8958730697631836, "actor_target_entropy": -2.0, "actor_entropy": -0.46862365305423737, "alpha_loss": -0.00024103408213704824, "alpha_value": 0.008308445558204265, "duration": 4.974417686462402, "step": 91567}
{"episode_reward": 5.01602055685824, "episode": 2824.0, "batch_reward": -0.09976913779973984, "critic_loss": 1.2690373659133911, "ae_transition_loss": 1.9387943744659424, "ae_encoder_loss": 0.8621240258216858, "actor_loss": -2.1797595024108887, "actor_target_entropy": -2.0, "actor_entropy": -0.4033827781677246, "alpha_loss": 0.003239579498767853, "alpha_value": 0.00830264169681329, "duration": 2.203477382659912, "step": 91578}
{"episode_reward": -1.5102183593873655, "episode": 2825.0, "batch_reward": 0.04820948218305906, "critic_loss": 2.2737446228663125, "ae_transition_loss": 1.9793712298075359, "ae_encoder_loss": 0.7559760411580404, "actor_loss": -3.2154390811920166, "actor_target_entropy": -2.0, "actor_entropy": -0.49276115496953327, "alpha_loss": 0.000621557691677784, "alpha_value": 0.00829485779684737, "duration": 4.928718090057373, "step": 91601}
{"episode_reward": 1.7515416073297105, "episode": 2826.0, "duration": 0.9025571346282959, "step": 91606}
{"episode_reward": -1.0574532284908678, "episode": 2827.0, "batch_reward": -0.02306690951809287, "critic_loss": 1.9964925050735474, "ae_transition_loss": 1.9101872742176056, "ae_encoder_loss": 0.7778160572052002, "actor_loss": -2.6344733238220215, "actor_target_entropy": -2.0, "actor_entropy": -0.42740652710199356, "alpha_loss": 0.0008985633030533791, "alpha_value": 0.008282705047467741, "duration": 8.460273027420044, "step": 91647}
{"episode_reward": 7.357369397218263, "episode": 2828.0, "batch_reward": -0.0438925102353096, "critic_loss": 1.8218807578086853, "ae_transition_loss": 1.8058616816997528, "ae_encoder_loss": 0.8418296575546265, "actor_loss": -2.717991441488266, "actor_target_entropy": -2.0, "actor_entropy": -0.4408561736345291, "alpha_loss": 0.001803143706638366, "alpha_value": 0.00826887982902813, "duration": 7.427016258239746, "step": 91682}
{"episode_reward": 6.21667856418827, "episode": 2829.0, "batch_reward": -0.07389172166585922, "critic_loss": 3.88596773147583, "ae_transition_loss": 1.928741693496704, "ae_encoder_loss": 0.6046467423439026, "actor_loss": -3.1088154315948486, "actor_target_entropy": -2.0, "actor_entropy": -0.5233631134033203, "alpha_loss": 0.0007717755506746471, "alpha_value": 0.008259374539580798, "duration": 2.494951009750366, "step": 91694}
{"episode_reward": -6.1712834225821664, "episode": 2830.0, "batch_reward": 0.0037503689527511597, "critic_loss": 5.5634143352508545, "ae_transition_loss": 1.776081919670105, "ae_encoder_loss": 0.6263704895973206, "actor_loss": -2.838180720806122, "actor_target_entropy": -2.0, "actor_entropy": -0.4281695634126663, "alpha_loss": 0.001105727074900642, "alpha_value": 0.008253836657929295, "duration": 5.157580852508545, "step": 91720}
{"episode_reward": 2.692584671150597, "episode": 2831.0, "batch_reward": 0.013257605023682117, "critic_loss": 2.4839731454849243, "ae_transition_loss": 1.7023280560970306, "ae_encoder_loss": 0.5636692494153976, "actor_loss": -3.111680746078491, "actor_target_entropy": -2.0, "actor_entropy": -0.4714256152510643, "alpha_loss": 0.0002177494898205623, "alpha_value": 0.008243670798462489, "duration": 51.08369159698486, "step": 91755}
{"episode_reward": 5.744749339625299, "episode": 2832.0, "batch_reward": -0.026206867769360542, "critic_loss": 1.9380279183387756, "ae_transition_loss": 1.5220245718955994, "ae_encoder_loss": 0.5228390395641327, "actor_loss": -2.636508584022522, "actor_target_entropy": -2.0, "actor_entropy": -0.4088422656059265, "alpha_loss": 0.0009807418682612479, "alpha_value": 0.008235101292760713, "duration": 4.383745908737183, "step": 91776}
{"episode_reward": 1.6594199689070117, "episode": 2833.0, "batch_reward": 0.019574770083030064, "critic_loss": 1.5636295477549236, "ae_transition_loss": 1.5771173238754272, "ae_encoder_loss": 0.6075433095296224, "actor_loss": -3.136117935180664, "actor_target_entropy": -2.0, "actor_entropy": -0.42850972215334576, "alpha_loss": -0.0005310180179852372, "alpha_value": 0.008229280267247069, "duration": 6.231901407241821, "step": 91807}
{"episode_reward": 5.068197763156625, "episode": 2834.0, "batch_reward": 0.03594130976125598, "critic_loss": 2.161323845386505, "ae_transition_loss": 1.4769490957260132, "ae_encoder_loss": 0.3547508493065834, "actor_loss": -2.82451069355011, "actor_target_entropy": -2.0, "actor_entropy": -0.38784946501255035, "alpha_loss": 3.4470031096134335e-05, "alpha_value": 0.008223694748269098, "duration": 7.4197633266448975, "step": 91843}
{"episode_reward": 3.6861534788865504, "episode": 2835.0, "batch_reward": 0.010878405533730984, "critic_loss": 1.4854198694229126, "ae_transition_loss": 1.6813893079757691, "ae_encoder_loss": 0.34863736629486086, "actor_loss": -3.1566100120544434, "actor_target_entropy": -2.0, "actor_entropy": -0.470806759595871, "alpha_loss": -0.00012849324848502875, "alpha_value": 0.008218327400388642, "duration": 10.751798152923584, "step": 91896}
{"episode_reward": 11.63662278146846, "episode": 2836.0, "batch_reward": 0.01634794962592423, "critic_loss": 1.9356972873210907, "ae_transition_loss": 1.564732402563095, "ae_encoder_loss": 0.3394004851579666, "actor_loss": -2.93420946598053, "actor_target_entropy": -2.0, "actor_entropy": -0.467319555580616, "alpha_loss": -0.000109103973954916, "alpha_value": 0.008215627404391008, "duration": 7.264695167541504, "step": 91931}
{"episode_reward": 5.6011857736336275, "episode": 2837.0, "batch_reward": 0.06331782508641481, "critic_loss": 1.658387839794159, "ae_transition_loss": 1.5203488767147064, "ae_encoder_loss": 0.3286963105201721, "actor_loss": -3.4173848032951355, "actor_target_entropy": -2.0, "actor_entropy": -0.5865298062562943, "alpha_loss": -0.0013710112834814936, "alpha_value": 0.008216006809870191, "duration": 9.706795454025269, "step": 91977}
{"episode_reward": -5.064971270915605, "episode": 2838.0, "batch_reward": -0.00031886249780654907, "critic_loss": 3.402033805847168, "ae_transition_loss": 1.5721299648284912, "ae_encoder_loss": 0.3958251029253006, "actor_loss": -3.2731693983078003, "actor_target_entropy": -2.0, "actor_entropy": -0.5474576354026794, "alpha_loss": -3.3941410947591066e-05, "alpha_value": 0.00821962578480519, "duration": 3.2534360885620117, "step": 91991}
{"episode_reward": -1.9048783763459731, "episode": 2839.0, "batch_reward": 0.021942390128970146, "critic_loss": 1.2028025388717651, "ae_transition_loss": 1.3481333255767822, "ae_encoder_loss": 0.4427753984928131, "actor_loss": -3.0937037467956543, "actor_target_entropy": -2.0, "actor_entropy": -0.5683111250400543, "alpha_loss": -0.0011011377209797502, "alpha_value": 0.008222351612274133, "duration": 5.154391288757324, "step": 92015}
{"episode_reward": -0.27133964517069814, "episode": 2840.0, "duration": 0.19491243362426758, "step": 92016}
{"episode_reward": -0.6459230780601501, "episode": 2841.0, "batch_reward": 0.014833477791398764, "critic_loss": 2.050675928592682, "ae_transition_loss": 1.468851000070572, "ae_encoder_loss": 0.4737217202782631, "actor_loss": -3.001598536968231, "actor_target_entropy": -2.0, "actor_entropy": -0.608945682644844, "alpha_loss": 7.586751598864794e-05, "alpha_value": 0.008225973212927102, "duration": 76.99710583686829, "step": 92053}
{"episode_reward": 4.771086523562819, "episode": 2842.0, "batch_reward": -0.019814254716038704, "critic_loss": 2.2255207697550454, "ae_transition_loss": 1.6421444018681843, "ae_encoder_loss": 0.5840734044710795, "actor_loss": -2.988632599512736, "actor_target_entropy": -2.0, "actor_entropy": -0.6109459002812704, "alpha_loss": -0.00047713950819646317, "alpha_value": 0.008229314493823102, "duration": 6.60621190071106, "step": 92085}
{"episode_reward": 6.350822763181917, "episode": 2843.0, "batch_reward": -0.008052811026573181, "critic_loss": 2.3601532697677614, "ae_transition_loss": 1.5477450370788575, "ae_encoder_loss": 0.5452952265739441, "actor_loss": -2.917392063140869, "actor_target_entropy": -2.0, "actor_entropy": -0.6231155455112457, "alpha_loss": -0.001205665501765907, "alpha_value": 0.008234852797614841, "duration": 11.124600410461426, "step": 92138}
{"episode_reward": 11.985671976409483, "episode": 2844.0, "batch_reward": 0.01348076673457399, "critic_loss": 1.7414545789361, "ae_transition_loss": 1.6235476732254028, "ae_encoder_loss": 0.38305606693029404, "actor_loss": -3.0580483973026276, "actor_target_entropy": -2.0, "actor_entropy": -0.680414117872715, "alpha_loss": -0.0005595335969701409, "alpha_value": 0.008246312137691152, "duration": 16.015954732894897, "step": 92217}
{"episode_reward": 15.561531350555565, "episode": 2845.0, "batch_reward": -0.03172019235789776, "critic_loss": 1.351177442073822, "ae_transition_loss": 1.5191213369369507, "ae_encoder_loss": 0.48106215596199037, "actor_loss": -2.6479462146759034, "actor_target_entropy": -2.0, "actor_entropy": -0.5349574983119965, "alpha_loss": 0.0002314490091521293, "alpha_value": 0.00825624055542996, "duration": 9.667187452316284, "step": 92265}
{"episode_reward": 11.400554122749547, "episode": 2846.0, "batch_reward": 0.022790687391534448, "critic_loss": 1.7708452343940735, "ae_transition_loss": 1.4963885247707367, "ae_encoder_loss": 0.6145311295986176, "actor_loss": -3.2591439485549927, "actor_target_entropy": -2.0, "actor_entropy": -0.655015155673027, "alpha_loss": -0.001344790965958964, "alpha_value": 0.008261409792898269, "duration": 8.65625548362732, "step": 92307}
{"episode_reward": 10.409212388301665, "episode": 2847.0, "batch_reward": 0.05167630687355995, "critic_loss": 1.6740326086680095, "ae_transition_loss": 1.6801143487294514, "ae_encoder_loss": 0.7142298221588135, "actor_loss": -3.3516820271809897, "actor_target_entropy": -2.0, "actor_entropy": -0.7405047218004862, "alpha_loss": -0.001541560748592019, "alpha_value": 0.008268612502703295, "duration": 5.927831172943115, "step": 92336}
{"episode_reward": 6.254881794083003, "episode": 2848.0, "batch_reward": 0.023148188367486, "critic_loss": 1.4935128390789032, "ae_transition_loss": 1.540748417377472, "ae_encoder_loss": 0.43646804988384247, "actor_loss": -3.294260799884796, "actor_target_entropy": -2.0, "actor_entropy": -0.7540404796600342, "alpha_loss": -0.0013561783271143213, "alpha_value": 0.008277569874768274, "duration": 8.826282024383545, "step": 92380}
{"episode_reward": 5.6500965554678295, "episode": 2849.0, "batch_reward": 0.005053667972485225, "critic_loss": 2.2691965103149414, "ae_transition_loss": 1.5602553288141887, "ae_encoder_loss": 0.5113938748836517, "actor_loss": -3.252915541330973, "actor_target_entropy": -2.0, "actor_entropy": -0.7603120803833008, "alpha_loss": -0.0015873995337945719, "alpha_value": 0.008288696817958368, "duration": 5.104584217071533, "step": 92405}
{"episode_reward": 1.1859060882090173, "episode": 2850.0, "duration": 0.24439549446105957, "step": 92406}
{"episode_reward": 0.7716523135155038, "episode": 2851.0, "duration": 59.435672760009766, "step": 92407}
{"episode_reward": -0.8132202211737419, "episode": 2852.0, "batch_reward": 0.01276083430275321, "critic_loss": 2.0312182307243347, "ae_transition_loss": 1.9848119914531708, "ae_encoder_loss": 0.5531496554613113, "actor_loss": -2.7895068526268005, "actor_target_entropy": -2.0, "actor_entropy": -0.6395915672183037, "alpha_loss": -0.002070557849947363, "alpha_value": 0.008301666561916223, "duration": 8.116098880767822, "step": 92447}
{"episode_reward": 5.714544224248692, "episode": 2853.0, "batch_reward": 0.02064762699107329, "critic_loss": 2.5996575951576233, "ae_transition_loss": 1.7886974811553955, "ae_encoder_loss": 1.2127633094787598, "actor_loss": -3.295451800028483, "actor_target_entropy": -2.0, "actor_entropy": -0.8005921641985575, "alpha_loss": -0.0019294722781827052, "alpha_value": 0.008317031567433046, "duration": 5.344791889190674, "step": 92472}
{"episode_reward": 1.2138360509665842, "episode": 2854.0, "batch_reward": 0.057934947311878204, "critic_loss": 2.3281588554382324, "ae_transition_loss": 1.8196728229522705, "ae_encoder_loss": 1.2756236791610718, "actor_loss": -3.0395474433898926, "actor_target_entropy": -2.0, "actor_entropy": -0.716691792011261, "alpha_loss": -0.00038144917925819755, "alpha_value": 0.00832677084854401, "duration": 2.4263381958007812, "step": 92483}
{"episode_reward": -1.938961649698266, "episode": 2855.0, "duration": 0.17795753479003906, "step": 92484}
{"episode_reward": -0.2236258667362322, "episode": 2856.0, "duration": 0.2697620391845703, "step": 92485}
{"episode_reward": -0.008336503387149065, "episode": 2857.0, "duration": 0.22396206855773926, "step": 92486}
{"episode_reward": -0.5755579471588135, "episode": 2858.0, "batch_reward": 0.024463974591344594, "critic_loss": 1.9501930236816407, "ae_transition_loss": 1.7350242137908936, "ae_encoder_loss": 1.023447048664093, "actor_loss": -3.1429949760437013, "actor_target_entropy": -2.0, "actor_entropy": -0.7695919036865234, "alpha_loss": -0.0017247351817786694, "alpha_value": 0.008339563732347014, "duration": 9.429033994674683, "step": 92531}
{"episode_reward": 11.088171554166452, "episode": 2859.0, "duration": 0.20225286483764648, "step": 92532}
{"episode_reward": 0.17971556974486586, "episode": 2860.0, "batch_reward": -0.008923700079321861, "critic_loss": 2.326026439666748, "ae_transition_loss": 1.7653005719184875, "ae_encoder_loss": 0.6976270973682404, "actor_loss": -3.2393327951431274, "actor_target_entropy": -2.0, "actor_entropy": -0.7527176141738892, "alpha_loss": -0.0020156491664238274, "alpha_value": 0.008355854942408304, "duration": 4.455913782119751, "step": 92553}
{"episode_reward": 0.7718206635280697, "episode": 2861.0, "batch_reward": -0.023664115307231743, "critic_loss": 2.289850572745005, "ae_transition_loss": 1.8844474355379741, "ae_encoder_loss": 0.6085358907779058, "actor_loss": -2.764857808748881, "actor_target_entropy": -2.0, "actor_entropy": -0.7407390375932058, "alpha_loss": -0.0017339159627833094, "alpha_value": 0.008376349159904884, "duration": 83.4274070262909, "step": 92613}
{"episode_reward": 13.943165513906251, "episode": 2862.0, "batch_reward": 0.0067507892847061155, "critic_loss": 2.2296488285064697, "ae_transition_loss": 1.6620481252670287, "ae_encoder_loss": 0.5784835815429688, "actor_loss": -3.0044670581817625, "actor_target_entropy": -2.0, "actor_entropy": -0.7145885586738586, "alpha_loss": -0.00044548691948875785, "alpha_value": 0.008403016316680978, "duration": 10.086013793945312, "step": 92662}
{"episode_reward": 16.930521179727652, "episode": 2863.0, "duration": 0.22716498374938965, "step": 92663}
{"episode_reward": -0.7815774506420103, "episode": 2864.0, "duration": 0.2046067714691162, "step": 92664}
{"episode_reward": -0.5140995227941849, "episode": 2865.0, "duration": 0.2303011417388916, "step": 92665}
{"episode_reward": -0.607659867590685, "episode": 2866.0, "duration": 0.22369885444641113, "step": 92666}
{"episode_reward": -0.7367174059436712, "episode": 2867.0, "batch_reward": 0.057003230322152376, "critic_loss": 1.4621812105178833, "ae_transition_loss": 1.7371323108673096, "ae_encoder_loss": 0.4929364547133446, "actor_loss": -3.3674970865249634, "actor_target_entropy": -2.0, "actor_entropy": -0.7558435499668121, "alpha_loss": -0.0020154024750809185, "alpha_value": 0.008421205333653996, "duration": 7.908700466156006, "step": 92704}
{"episode_reward": 9.90238495768558, "episode": 2868.0, "batch_reward": 0.017080259198943775, "critic_loss": 2.6639068126678467, "ae_transition_loss": 1.584323247273763, "ae_encoder_loss": 0.45748374859491986, "actor_loss": -2.9082162380218506, "actor_target_entropy": -2.0, "actor_entropy": -0.7335702578226725, "alpha_loss": -0.0011187758451948564, "alpha_value": 0.00843581710159412, "duration": 6.1794352531433105, "step": 92733}
{"episode_reward": 4.450072527787197, "episode": 2869.0, "batch_reward": 0.022668934427201748, "critic_loss": 2.068752884864807, "ae_transition_loss": 1.4667575359344482, "ae_encoder_loss": 0.45184750109910965, "actor_loss": -2.9851448833942413, "actor_target_entropy": -2.0, "actor_entropy": -0.7284765169024467, "alpha_loss": -0.0014976206002756953, "alpha_value": 0.008460564506362758, "duration": 16.891420125961304, "step": 92815}
{"episode_reward": 4.485031940887639, "episode": 2870.0, "batch_reward": 0.00874650850892067, "critic_loss": 1.5723736763000489, "ae_transition_loss": 1.5731806755065918, "ae_encoder_loss": 0.42497528791427613, "actor_loss": -3.000186538696289, "actor_target_entropy": -2.0, "actor_entropy": -0.5509609937667846, "alpha_loss": 0.00032235344406217337, "alpha_value": 0.00848832171577813, "duration": 10.543748617172241, "step": 92867}
{"episode_reward": 9.984448916606556, "episode": 2871.0, "duration": 58.58767080307007, "step": 92868}
{"episode_reward": -0.33946762542058423, "episode": 2872.0, "batch_reward": -0.010357257910072803, "critic_loss": 1.7977465987205505, "ae_transition_loss": 1.558236837387085, "ae_encoder_loss": 0.4402964264154434, "actor_loss": -2.755692422389984, "actor_target_entropy": -2.0, "actor_entropy": -0.5203903168439865, "alpha_loss": 0.001161219654022716, "alpha_value": 0.008496424409127715, "duration": 7.526693820953369, "step": 92905}
{"episode_reward": 7.177790823122487, "episode": 2873.0, "batch_reward": 0.027028437331318857, "critic_loss": 1.5388309955596924, "ae_transition_loss": 1.5829058408737182, "ae_encoder_loss": 0.4333401322364807, "actor_loss": -2.9464252948760987, "actor_target_entropy": -2.0, "actor_entropy": -0.6227784156799316, "alpha_loss": -0.000633551471401006, "alpha_value": 0.008497487420142506, "duration": 9.872886419296265, "step": 92951}
{"episode_reward": 5.801471699262549, "episode": 2874.0, "batch_reward": -0.01701432839035988, "critic_loss": 1.7007303833961487, "ae_transition_loss": 1.6355146765708923, "ae_encoder_loss": 0.41328297555446625, "actor_loss": -2.5390844345092773, "actor_target_entropy": -2.0, "actor_entropy": -0.5868190824985504, "alpha_loss": 0.0001436268212273717, "alpha_value": 0.008499991794393657, "duration": 5.432352304458618, "step": 92978}
{"episode_reward": 4.48601023320945, "episode": 2875.0, "batch_reward": 0.03577512502670288, "critic_loss": 1.5668413639068604, "ae_transition_loss": 1.6159296035766602, "ae_encoder_loss": 0.4230363816022873, "actor_loss": -3.083162546157837, "actor_target_entropy": -2.0, "actor_entropy": -0.5267873704433441, "alpha_loss": -0.0018094539118465036, "alpha_value": 0.008501815526961137, "duration": 3.3027281761169434, "step": 92993}
{"episode_reward": -0.07242675953391568, "episode": 2876.0, "batch_reward": 0.0213270615786314, "critic_loss": 1.4539127349853516, "ae_transition_loss": 1.8059442043304443, "ae_encoder_loss": 0.28318241238594055, "actor_loss": -3.3409929275512695, "actor_target_entropy": -2.0, "actor_entropy": -0.5938006639480591, "alpha_loss": -0.004483052995055914, "alpha_value": 0.008503823899568212, "duration": 2.8242669105529785, "step": 93006}
{"episode_reward": 0.20317773581354728, "episode": 2877.0, "duration": 0.22771239280700684, "step": 93007}
{"episode_reward": 0.1546215392886528, "episode": 2878.0, "batch_reward": -0.04135294444859028, "critic_loss": 1.4617446064949036, "ae_transition_loss": 1.67428457736969, "ae_encoder_loss": 0.585180918375651, "actor_loss": -2.9142375389734902, "actor_target_entropy": -2.0, "actor_entropy": -0.5910519063472748, "alpha_loss": -0.0016748073976486921, "alpha_value": 0.008514477716184915, "duration": 12.439475536346436, "step": 93068}
{"episode_reward": -1.2984592207742849, "episode": 2879.0, "batch_reward": 0.0018737837672233582, "critic_loss": 0.9751633405685425, "ae_transition_loss": 1.4992791414260864, "ae_encoder_loss": 0.4910493493080139, "actor_loss": -3.2572808265686035, "actor_target_entropy": -2.0, "actor_entropy": -0.6695157885551453, "alpha_loss": -0.002736212220042944, "alpha_value": 0.008526915395158227, "duration": 1.304086446762085, "step": 93073}
{"episode_reward": -2.5226277712586525, "episode": 2880.0, "batch_reward": 0.04575573420152068, "critic_loss": 1.938670814037323, "ae_transition_loss": 1.653472512960434, "ae_encoder_loss": 0.5041895285248756, "actor_loss": -2.777361273765564, "actor_target_entropy": -2.0, "actor_entropy": -0.6953482925891876, "alpha_loss": -0.0010265005694236606, "alpha_value": 0.0085370372052079, "duration": 8.645447731018066, "step": 93116}
{"episode_reward": 7.808541548603523, "episode": 2881.0, "batch_reward": 0.04144639025131861, "critic_loss": 1.5832020441691081, "ae_transition_loss": 1.6578220129013062, "ae_encoder_loss": 0.5527333617210388, "actor_loss": -3.3937199910481772, "actor_target_entropy": -2.0, "actor_entropy": -0.8351596792538961, "alpha_loss": -0.0016865471843630075, "alpha_value": 0.00855163984471099, "duration": 52.9144241809845, "step": 93146}
{"episode_reward": 2.8468358421636393, "episode": 2882.0, "batch_reward": 0.03397323563694954, "critic_loss": 1.8088491360346477, "ae_transition_loss": 1.6945154269536336, "ae_encoder_loss": 0.7440908551216125, "actor_loss": -3.412172794342041, "actor_target_entropy": -2.0, "actor_entropy": -0.8308908541997274, "alpha_loss": -0.0010184212781799336, "alpha_value": 0.008564987381489664, "duration": 6.487725734710693, "step": 93177}
{"episode_reward": 6.623676483153826, "episode": 2883.0, "batch_reward": 0.1050453782081604, "critic_loss": 3.93381404876709, "ae_transition_loss": 1.8670806884765625, "ae_encoder_loss": 0.34966346621513367, "actor_loss": -2.7963674068450928, "actor_target_entropy": -2.0, "actor_entropy": -0.8149100542068481, "alpha_loss": -0.0015244369860738516, "alpha_value": 0.008573313812679955, "duration": 2.0480308532714844, "step": 93186}
{"episode_reward": -3.172435087292323, "episode": 2884.0, "batch_reward": 0.03205579239875078, "critic_loss": 1.6691742539405823, "ae_transition_loss": 1.6608149409294128, "ae_encoder_loss": 0.530643917620182, "actor_loss": -3.5620678067207336, "actor_target_entropy": -2.0, "actor_entropy": -0.8063960075378418, "alpha_loss": -0.0020452463504625484, "alpha_value": 0.008584094524341241, "duration": 8.012921571731567, "step": 93225}
{"episode_reward": 5.5637136782961445, "episode": 2885.0, "batch_reward": 0.04193591636916002, "critic_loss": 1.9837794701258342, "ae_transition_loss": 1.6013133923212688, "ae_encoder_loss": 0.5257620612780253, "actor_loss": -3.3871191342671714, "actor_target_entropy": -2.0, "actor_entropy": -0.6678939660390218, "alpha_loss": -0.000734270375687629, "alpha_value": 0.008600696719816574, "duration": 5.845438718795776, "step": 93252}
{"episode_reward": 4.879688640960165, "episode": 2886.0, "duration": 0.18556547164916992, "step": 93253}
{"episode_reward": -0.08841082520136823, "episode": 2887.0, "duration": 0.1951618194580078, "step": 93254}
{"episode_reward": -0.19708828628063202, "episode": 2888.0, "batch_reward": -0.0038443319499492645, "critic_loss": 3.325917959213257, "ae_transition_loss": 1.6828145583470662, "ae_encoder_loss": 0.46830304463704425, "actor_loss": -2.7641902764638266, "actor_target_entropy": -2.0, "actor_entropy": -0.6605082750320435, "alpha_loss": -0.001534693146822974, "alpha_value": 0.008613833223515291, "duration": 7.343615770339966, "step": 93290}
{"episode_reward": 7.66703426999772, "episode": 2889.0, "batch_reward": 0.087226003408432, "critic_loss": 1.4421888589859009, "ae_transition_loss": 1.808276891708374, "ae_encoder_loss": 0.36553749442100525, "actor_loss": -3.6114413738250732, "actor_target_entropy": -2.0, "actor_entropy": -0.7578376531600952, "alpha_loss": -0.0012871057260781527, "alpha_value": 0.008622218945343815, "duration": 0.5393710136413574, "step": 93291}
{"episode_reward": -0.15468643605709076, "episode": 2890.0, "batch_reward": 0.08699874579906464, "critic_loss": 1.6183618903160095, "ae_transition_loss": 1.4538932243982952, "ae_encoder_loss": 0.429528405268987, "actor_loss": -3.95394237836202, "actor_target_entropy": -2.0, "actor_entropy": -0.7650163173675537, "alpha_loss": -0.0020118383690714836, "alpha_value": 0.008631350064222526, "duration": 6.972288131713867, "step": 93327}
{"episode_reward": 4.94881680727028, "episode": 2891.0, "batch_reward": 0.013901109993457793, "critic_loss": 2.2853403091430664, "ae_transition_loss": 1.6632032155990601, "ae_encoder_loss": 0.4392163395881653, "actor_loss": -3.211578893661499, "actor_target_entropy": -2.0, "actor_entropy": -0.6833526968955994, "alpha_loss": -0.000821285555139184, "alpha_value": 0.008649889805067099, "duration": 60.91969919204712, "step": 93373}
{"episode_reward": 10.070295800267395, "episode": 2892.0, "batch_reward": 0.010070610791444778, "critic_loss": 1.897688627243042, "ae_transition_loss": 1.9977428317070007, "ae_encoder_loss": 0.4923994839191437, "actor_loss": -2.6587538719177246, "actor_target_entropy": -2.0, "actor_entropy": -0.7087309062480927, "alpha_loss": -0.0011055447976104915, "alpha_value": 0.008664019730791828, "duration": 4.031973123550415, "step": 93392}
{"episode_reward": 0.5899257751252525, "episode": 2893.0, "batch_reward": 0.031092886999249458, "critic_loss": 1.539646077156067, "ae_transition_loss": 1.5327462673187255, "ae_encoder_loss": 0.4375866293907166, "actor_loss": -3.2482563495635985, "actor_target_entropy": -2.0, "actor_entropy": -0.7685836911201477, "alpha_loss": -0.0022207222529686986, "alpha_value": 0.008677439208909317, "duration": 11.14775037765503, "step": 93447}
{"episode_reward": 9.734419411076649, "episode": 2894.0, "batch_reward": 0.05212757810950279, "critic_loss": 1.859027087688446, "ae_transition_loss": 1.6554566383361817, "ae_encoder_loss": 0.5112375825643539, "actor_loss": -3.2810197830200196, "actor_target_entropy": -2.0, "actor_entropy": -0.8265928030014038, "alpha_loss": -0.0022976366628427057, "alpha_value": 0.008718887874970585, "duration": 19.695802211761475, "step": 93548}
{"episode_reward": 54.991724818846286, "episode": 2895.0, "batch_reward": 0.020072724670171738, "critic_loss": 1.1877023577690125, "ae_transition_loss": 1.6049671173095703, "ae_encoder_loss": 0.4282105565071106, "actor_loss": -3.4322614669799805, "actor_target_entropy": -2.0, "actor_entropy": -0.7919443845748901, "alpha_loss": -0.0014648963115178049, "alpha_value": 0.008758102866287677, "duration": 4.159806251525879, "step": 93569}
{"episode_reward": -1.6845817355458879, "episode": 2896.0, "batch_reward": 0.02674466785457399, "critic_loss": 1.4314613342285156, "ae_transition_loss": 1.7076907025443182, "ae_encoder_loss": 0.6520432465606265, "actor_loss": -3.4457447793748646, "actor_target_entropy": -2.0, "actor_entropy": -0.774019201596578, "alpha_loss": -0.0016695923792819183, "alpha_value": 0.008792807664238927, "duration": 17.86774253845215, "step": 93658}
{"episode_reward": 33.43348677782254, "episode": 2897.0, "batch_reward": 0.06694498285651207, "critic_loss": 2.9478225708007812, "ae_transition_loss": 1.6777868866920471, "ae_encoder_loss": 0.7041092216968536, "actor_loss": -3.468932271003723, "actor_target_entropy": -2.0, "actor_entropy": -0.8034868836402893, "alpha_loss": -0.0014346193056553602, "alpha_value": 0.008823872908374317, "duration": 4.37955117225647, "step": 93680}
{"episode_reward": -0.844025812755215, "episode": 2898.0, "batch_reward": 0.1152016893029213, "critic_loss": 1.3951947689056396, "ae_transition_loss": 1.5651934146881104, "ae_encoder_loss": 0.741502046585083, "actor_loss": -3.8656845092773438, "actor_target_entropy": -2.0, "actor_entropy": -0.8589563369750977, "alpha_loss": 0.0006660296930931509, "alpha_value": 0.008831960144168635, "duration": 0.6009120941162109, "step": 93681}
{"episode_reward": -0.7408330165294247, "episode": 2899.0, "batch_reward": 0.019401883240789175, "critic_loss": 2.2993092834949493, "ae_transition_loss": 1.731815904378891, "ae_encoder_loss": 1.4414280951023102, "actor_loss": -3.0225313901901245, "actor_target_entropy": -2.0, "actor_entropy": -0.7568443417549133, "alpha_loss": -0.0016630821337457746, "alpha_value": 0.008843930335953203, "duration": 8.59481692314148, "step": 93725}
{"episode_reward": 9.615138792721076, "episode": 2900.0, "batch_reward": 0.004179821535944939, "critic_loss": 1.5579846382141114, "ae_transition_loss": 1.648556160926819, "ae_encoder_loss": 0.7372945189476013, "actor_loss": -3.3508129119873047, "actor_target_entropy": -2.0, "actor_entropy": -0.7577105164527893, "alpha_loss": -0.002048325526993722, "alpha_value": 0.008865611084122585, "duration": 9.795375347137451, "step": 93775}
{"episode_reward": 6.019610357031465, "episode": 2901.0, "batch_reward": 0.0517828402419885, "critic_loss": 2.4767414927482605, "ae_transition_loss": 1.7875450054804485, "ae_encoder_loss": 1.3299781878789265, "actor_loss": -3.347147305806478, "actor_target_entropy": -2.0, "actor_entropy": -0.7417007188002268, "alpha_loss": -0.0024026491543433317, "alpha_value": 0.00889598534487924, "duration": 84.35615110397339, "step": 93833}
{"episode_reward": 8.727294314721457, "episode": 2902.0, "batch_reward": 0.04591049626469612, "critic_loss": 1.2012179692586262, "ae_transition_loss": 1.6792004903157551, "ae_encoder_loss": 0.7005892097949982, "actor_loss": -3.4434004624684653, "actor_target_entropy": -2.0, "actor_entropy": -0.7101402878761292, "alpha_loss": -0.0031689477618783712, "alpha_value": 0.008925564961974322, "duration": 6.71178674697876, "step": 93865}
{"episode_reward": 7.303678286955051, "episode": 2903.0, "batch_reward": 0.03561664496858915, "critic_loss": 3.1193705797195435, "ae_transition_loss": 1.6782863140106201, "ae_encoder_loss": 0.7889714241027832, "actor_loss": -3.460873285929362, "actor_target_entropy": -2.0, "actor_entropy": -0.501308818658193, "alpha_loss": -0.0034321065759286284, "alpha_value": 0.008949472484102189, "duration": 6.8510425090789795, "step": 93898}
{"episode_reward": -1.9160190923226825, "episode": 2904.0, "batch_reward": 0.03757700324058533, "critic_loss": 2.79426372051239, "ae_transition_loss": 1.7688494324684143, "ae_encoder_loss": 0.6721071004867554, "actor_loss": -3.4947104454040527, "actor_target_entropy": -2.0, "actor_entropy": -0.4098834693431854, "alpha_loss": -0.005218937527388334, "alpha_value": 0.008971790970407527, "duration": 3.650099277496338, "step": 93915}
{"episode_reward": -3.4935170198527734, "episode": 2905.0, "batch_reward": -0.069209985435009, "critic_loss": 2.251324415206909, "ae_transition_loss": 1.7418899536132812, "ae_encoder_loss": 1.0650274753570557, "actor_loss": -3.4503026008605957, "actor_target_entropy": -2.0, "actor_entropy": -0.4470435380935669, "alpha_loss": -0.00283298222348094, "alpha_value": 0.008986875662927302, "duration": 1.9502360820770264, "step": 93924}
{"episode_reward": -2.2557827083637694, "episode": 2906.0, "batch_reward": 0.11576605588197708, "critic_loss": 1.27503901720047, "ae_transition_loss": 1.4746139645576477, "ae_encoder_loss": 1.1089689135551453, "actor_loss": -3.641438603401184, "actor_target_entropy": -2.0, "actor_entropy": -0.5032522231340408, "alpha_loss": -0.004414782742969692, "alpha_value": 0.009002097198808307, "duration": 4.9957802295684814, "step": 93948}
{"episode_reward": 0.7715661555314878, "episode": 2907.0, "batch_reward": 0.005051223561167717, "critic_loss": 2.0925285816192627, "ae_transition_loss": 1.840763807296753, "ae_encoder_loss": 0.9655492305755615, "actor_loss": -2.773653507232666, "actor_target_entropy": -2.0, "actor_entropy": -0.6206279098987579, "alpha_loss": -0.0016335295513272285, "alpha_value": 0.00902330168523621, "duration": 3.6976020336151123, "step": 93964}
{"episode_reward": -2.3292102633823357, "episode": 2908.0, "batch_reward": -0.04308284632861614, "critic_loss": 2.944504737854004, "ae_transition_loss": 2.1171284317970276, "ae_encoder_loss": 0.8217515349388123, "actor_loss": -2.18433940410614, "actor_target_entropy": -2.0, "actor_entropy": -0.755073606967926, "alpha_loss": -0.0021550278179347515, "alpha_value": 0.009043231092281504, "duration": 3.967365026473999, "step": 93982}
{"episode_reward": 4.183865667106048, "episode": 2909.0, "batch_reward": 0.004046677611768246, "critic_loss": 2.300449848175049, "ae_transition_loss": 1.7811404466629028, "ae_encoder_loss": 1.460517704486847, "actor_loss": -2.58017897605896, "actor_target_entropy": -2.0, "actor_entropy": -0.8720955550670624, "alpha_loss": -0.00017960683908313513, "alpha_value": 0.009061863329513437, "duration": 4.273495674133301, "step": 94002}
{"episode_reward": 0.8188981945992494, "episode": 2910.0, "batch_reward": 0.03505111783742905, "critic_loss": 2.2552038192749024, "ae_transition_loss": 1.909871768951416, "ae_encoder_loss": 1.76667720079422, "actor_loss": -3.537493276596069, "actor_target_entropy": -2.0, "actor_entropy": -0.9969209432601929, "alpha_loss": -0.0009637457085773348, "alpha_value": 0.009086366609786775, "duration": 11.216723680496216, "step": 94056}
{"episode_reward": 6.374668341165216, "episode": 2911.0, "batch_reward": 0.022661466524004935, "critic_loss": 3.3170333385467528, "ae_transition_loss": 1.6778487682342529, "ae_encoder_loss": 0.7561048150062561, "actor_loss": -3.2250372409820556, "actor_target_entropy": -2.0, "actor_entropy": -1.0162281751632691, "alpha_loss": -0.0012800982454791664, "alpha_value": 0.009117279668442686, "duration": 63.27672839164734, "step": 94101}
{"episode_reward": 7.701416547706387, "episode": 2912.0, "batch_reward": 0.01116493670269847, "critic_loss": 2.1632282733917236, "ae_transition_loss": 1.8779655694961548, "ae_encoder_loss": 0.7412169128656387, "actor_loss": -3.177098333835602, "actor_target_entropy": -2.0, "actor_entropy": -1.0429634153842926, "alpha_loss": -0.0011144570598844439, "alpha_value": 0.009141643856863627, "duration": 9.435007572174072, "step": 94148}
{"episode_reward": 5.281158392241166, "episode": 2913.0, "batch_reward": 0.01662644762545824, "critic_loss": 2.6949576139450073, "ae_transition_loss": 1.7276391506195068, "ae_encoder_loss": 0.5895474135875702, "actor_loss": -2.7850685119628906, "actor_target_entropy": -2.0, "actor_entropy": -0.879926884174347, "alpha_loss": -0.0024645462282933293, "alpha_value": 0.009164614891238276, "duration": 10.223925590515137, "step": 94199}
{"episode_reward": 9.98798561772636, "episode": 2914.0, "batch_reward": 0.05167062021791935, "critic_loss": 1.9975625276565552, "ae_transition_loss": 1.904891550540924, "ae_encoder_loss": 0.7078381180763245, "actor_loss": -3.1066914796829224, "actor_target_entropy": -2.0, "actor_entropy": -0.5716083943843842, "alpha_loss": -0.0026202384615316987, "alpha_value": 0.00918634059197999, "duration": 2.9498493671417236, "step": 94211}
{"episode_reward": -0.09889524954126902, "episode": 2915.0, "batch_reward": 0.03735137855013212, "critic_loss": 2.13148832321167, "ae_transition_loss": 1.5394431948661804, "ae_encoder_loss": 0.512033611536026, "actor_loss": -3.5362109343210855, "actor_target_entropy": -2.0, "actor_entropy": -0.7189310888449351, "alpha_loss": 0.0007867837460556378, "alpha_value": 0.00920805432429204, "duration": 12.713768243789673, "step": 94276}
{"episode_reward": 17.207563542378853, "episode": 2916.0, "batch_reward": 0.02752005957067013, "critic_loss": 2.1730444717407225, "ae_transition_loss": 1.6872070980072023, "ae_encoder_loss": 0.5575638103485108, "actor_loss": -3.206833629608154, "actor_target_entropy": -2.0, "actor_entropy": -0.5197141647338868, "alpha_loss": 0.0017673014441970736, "alpha_value": 0.009191272108774622, "duration": 50.015658378601074, "step": 94525}
{"episode_reward": 135.5376245259773, "episode": 2917.0, "batch_reward": 0.015062685745457808, "critic_loss": 1.4241831302642822, "ae_transition_loss": 1.6027280886967976, "ae_encoder_loss": 0.3751264015833537, "actor_loss": -3.5066216786702475, "actor_target_entropy": -2.0, "actor_entropy": -0.5708678563435873, "alpha_loss": -0.0006415021295348803, "alpha_value": 0.009122899526451596, "duration": 6.595685243606567, "step": 94558}
{"episode_reward": 2.372966467045439, "episode": 2918.0, "batch_reward": 0.07208573166280985, "critic_loss": 1.3270610719919205, "ae_transition_loss": 1.5936813652515411, "ae_encoder_loss": 0.3481423482298851, "actor_loss": -3.7805416584014893, "actor_target_entropy": -2.0, "actor_entropy": -0.5947577208280563, "alpha_loss": -0.0019790161750279367, "alpha_value": 0.009117818137597315, "duration": 8.543770551681519, "step": 94600}
{"episode_reward": 14.443347201078776, "episode": 2919.0, "batch_reward": 0.06538987532258034, "critic_loss": 2.0464391112327576, "ae_transition_loss": 1.5438016057014465, "ae_encoder_loss": 0.367473267018795, "actor_loss": -3.5968695878982544, "actor_target_entropy": -2.0, "actor_entropy": -0.43969007581472397, "alpha_loss": 0.00019281718414276838, "alpha_value": 0.009121005867350384, "duration": 7.595791339874268, "step": 94637}
{"episode_reward": 9.92956283438983, "episode": 2920.0, "batch_reward": 0.04423206485807896, "critic_loss": 2.0317638516426086, "ae_transition_loss": 1.5511924922466278, "ae_encoder_loss": 0.4084792360663414, "actor_loss": -3.363356113433838, "actor_target_entropy": -2.0, "actor_entropy": -0.4557414874434471, "alpha_loss": -0.0003531134861987084, "alpha_value": 0.009122062683098231, "duration": 8.04368543624878, "step": 94675}
{"episode_reward": 12.564499635044584, "episode": 2921.0, "batch_reward": 0.04894974076887593, "critic_loss": 2.2565959692001343, "ae_transition_loss": 1.8418146222829819, "ae_encoder_loss": 0.8099397271871567, "actor_loss": -3.3581976890563965, "actor_target_entropy": -2.0, "actor_entropy": -0.7064282149076462, "alpha_loss": -0.0016011688130674884, "alpha_value": 0.009138533309808322, "duration": 84.49197673797607, "step": 94840}
{"episode_reward": 32.19544733154626, "episode": 2922.0, "batch_reward": 0.004952642600983381, "critic_loss": 1.6882891058921814, "ae_transition_loss": 1.678607016801834, "ae_encoder_loss": 0.7132149338722229, "actor_loss": -3.1935209035873413, "actor_target_entropy": -2.0, "actor_entropy": -0.5869932770729065, "alpha_loss": 6.059779479983263e-05, "alpha_value": 0.009172856799963613, "duration": 7.547550201416016, "step": 94876}
{"episode_reward": 6.629285750365834, "episode": 2923.0, "batch_reward": 0.034075155233343445, "critic_loss": 1.9778191248575847, "ae_transition_loss": 1.6427560249964397, "ae_encoder_loss": 0.5567002793153127, "actor_loss": -3.1829354763031006, "actor_target_entropy": -2.0, "actor_entropy": -0.6257907350858053, "alpha_loss": -0.0013802849571220577, "alpha_value": 0.009184738797031022, "duration": 6.591914415359497, "step": 94908}
{"episode_reward": -0.3204743275545533, "episode": 2924.0, "duration": 0.22754549980163574, "step": 94909}
{"episode_reward": -0.14019165933132172, "episode": 2925.0, "batch_reward": 0.05846677099665006, "critic_loss": 2.6223698059717813, "ae_transition_loss": 1.5333995819091797, "ae_encoder_loss": 0.5363595287005106, "actor_loss": -3.4596681594848633, "actor_target_entropy": -2.0, "actor_entropy": -0.6610895792643229, "alpha_loss": -0.0017992379531885188, "alpha_value": 0.009195764912008594, "duration": 5.181614637374878, "step": 94932}
{"episode_reward": 1.227731474668944, "episode": 2926.0, "batch_reward": 0.0580093365162611, "critic_loss": 2.282594680786133, "ae_transition_loss": 1.6565807580947876, "ae_encoder_loss": 0.6165369212627411, "actor_loss": -3.9300797462463377, "actor_target_entropy": -2.0, "actor_entropy": -0.6684963941574097, "alpha_loss": -0.0021251451689749956, "alpha_value": 0.009214961605878428, "duration": 10.42365288734436, "step": 94981}
{"episode_reward": -5.804944424965662, "episode": 2927.0, "batch_reward": 0.016676798462867737, "critic_loss": 1.7523095607757568, "ae_transition_loss": 1.383998990058899, "ae_encoder_loss": 0.7352254986763, "actor_loss": -3.425943613052368, "actor_target_entropy": -2.0, "actor_entropy": -0.631170928478241, "alpha_loss": -0.0022259284742176533, "alpha_value": 0.009232102170050407, "duration": 2.898362636566162, "step": 94996}
{"episode_reward": -0.9543363009695796, "episode": 2928.0, "batch_reward": 0.06552228145301342, "critic_loss": 1.5648784637451172, "ae_transition_loss": 1.4643417596817017, "ae_encoder_loss": 0.6989212334156036, "actor_loss": -3.868061065673828, "actor_target_entropy": -2.0, "actor_entropy": -0.5758211016654968, "alpha_loss": -0.0018589536775834858, "alpha_value": 0.009240590696297403, "duration": 4.743811130523682, "step": 95019}
{"episode_reward": 1.9844083446954626, "episode": 2929.0, "batch_reward": 0.03964438196271658, "critic_loss": 1.7544272541999817, "ae_transition_loss": 1.7231557667255402, "ae_encoder_loss": 0.5039763301610947, "actor_loss": -3.36123263835907, "actor_target_entropy": -2.0, "actor_entropy": -0.4593677446246147, "alpha_loss": 0.0006179165211506188, "alpha_value": 0.009256317648178244, "duration": 7.104348659515381, "step": 95052}
{"episode_reward": 8.633038479634887, "episode": 2930.0, "batch_reward": 0.02836798969656229, "critic_loss": 3.0848352909088135, "ae_transition_loss": 1.6894968350728352, "ae_encoder_loss": 0.46854538718859357, "actor_loss": -3.1877690156300864, "actor_target_entropy": -2.0, "actor_entropy": -0.3622191548347473, "alpha_loss": -9.568702080287039e-05, "alpha_value": 0.00926838815273587, "duration": 6.811282396316528, "step": 95087}
{"episode_reward": 6.818168785564661, "episode": 2931.0, "batch_reward": 0.048811963914583124, "critic_loss": 2.6293266216913858, "ae_transition_loss": 1.7426768740018208, "ae_encoder_loss": 0.4516357680161794, "actor_loss": -3.5408220688501992, "actor_target_entropy": -2.0, "actor_entropy": -0.28338277836640674, "alpha_loss": 0.001964844996109605, "alpha_value": 0.009274661115511154, "duration": 56.11186742782593, "step": 95142}
{"episode_reward": 13.571458810487474, "episode": 2932.0, "batch_reward": 0.02314087748527527, "critic_loss": 1.5620293617248535, "ae_transition_loss": 1.7276147603988647, "ae_encoder_loss": 0.6954221725463867, "actor_loss": -3.622238278388977, "actor_target_entropy": -2.0, "actor_entropy": -0.33562085032463074, "alpha_loss": 0.0014879573573125526, "alpha_value": 0.009270513224291184, "duration": 4.3721067905426025, "step": 95162}
{"episode_reward": 1.8972812942224868, "episode": 2933.0, "batch_reward": 0.06039847806096077, "critic_loss": 2.393981409072876, "ae_transition_loss": 1.7555344581604004, "ae_encoder_loss": 0.633981990814209, "actor_loss": -3.640729570388794, "actor_target_entropy": -2.0, "actor_entropy": -0.3409022629261017, "alpha_loss": -0.0004211985738947988, "alpha_value": 0.009263273945570891, "duration": 9.897464990615845, "step": 95211}
{"episode_reward": 15.571104247995757, "episode": 2934.0, "batch_reward": 0.051594686694443226, "critic_loss": 1.5857585271199544, "ae_transition_loss": 1.6070289611816406, "ae_encoder_loss": 0.5631351123253504, "actor_loss": -3.5144485235214233, "actor_target_entropy": -2.0, "actor_entropy": -0.2159384861588478, "alpha_loss": -0.00020781566854566336, "alpha_value": 0.009259907251986006, "duration": 13.613695859909058, "step": 95278}
{"episode_reward": 16.57119961406268, "episode": 2935.0, "batch_reward": 0.03249134992559751, "critic_loss": 2.383595069249471, "ae_transition_loss": 1.7579121589660645, "ae_encoder_loss": 0.6674212217330933, "actor_loss": -3.264446417490641, "actor_target_entropy": -2.0, "actor_entropy": -0.07567289471626282, "alpha_loss": 0.0027860230135653787, "alpha_value": 0.00925867703026626, "duration": 5.739722728729248, "step": 95306}
{"episode_reward": -3.483637854923314, "episode": 2936.0, "batch_reward": 0.050381824374198914, "critic_loss": 2.3804786337746515, "ae_transition_loss": 1.5813066826926336, "ae_encoder_loss": 0.5150093138217926, "actor_loss": -3.5418337980906167, "actor_target_entropy": -2.0, "actor_entropy": -0.2787229162123468, "alpha_loss": 0.0014640333021007893, "alpha_value": 0.009234797282658693, "duration": 18.51176643371582, "step": 95397}
{"episode_reward": 10.059271543263948, "episode": 2937.0, "batch_reward": 0.01920863116780917, "critic_loss": 2.5506507953008017, "ae_transition_loss": 1.5319630304972331, "ae_encoder_loss": 0.5186289250850677, "actor_loss": -3.542001406351725, "actor_target_entropy": -2.0, "actor_entropy": -0.5591106712818146, "alpha_loss": 0.000663623766740784, "alpha_value": 0.009208486347017418, "duration": 5.56423282623291, "step": 95424}
{"episode_reward": 5.329659558678013, "episode": 2938.0, "batch_reward": 0.01086119469255209, "critic_loss": 2.634537100791931, "ae_transition_loss": 1.6439487934112549, "ae_encoder_loss": 0.3837500810623169, "actor_loss": -2.896988868713379, "actor_target_entropy": -2.0, "actor_entropy": -0.6753024160861969, "alpha_loss": 3.308267332613468e-05, "alpha_value": 0.009200544663772823, "duration": 4.19005823135376, "step": 95444}
{"episode_reward": 2.818714868799198, "episode": 2939.0, "duration": 0.2331857681274414, "step": 95445}
{"episode_reward": -0.031160101294517517, "episode": 2940.0, "batch_reward": 0.0029740433674305677, "critic_loss": 1.8388653546571732, "ae_transition_loss": 1.637407660484314, "ae_encoder_loss": 0.6130432710051537, "actor_loss": -3.0864073634147644, "actor_target_entropy": -2.0, "actor_entropy": -0.7729085385799408, "alpha_loss": -0.0014886240096529946, "alpha_value": 0.009194800285717007, "duration": 7.977297306060791, "step": 95482}
{"episode_reward": 7.997843034415575, "episode": 2941.0, "batch_reward": 0.03970125764608383, "critic_loss": 2.153368282318115, "ae_transition_loss": 1.3829341650009155, "ae_encoder_loss": 0.7664515614509583, "actor_loss": -3.6779329776763916, "actor_target_entropy": -2.0, "actor_entropy": -0.8275416374206543, "alpha_loss": -0.0024382951436564327, "alpha_value": 0.009197556573580994, "duration": 63.7705979347229, "step": 95539}
{"episode_reward": 18.510835400543996, "episode": 2942.0, "batch_reward": 0.004423270747065544, "critic_loss": 1.6009637355804442, "ae_transition_loss": 1.4725387573242188, "ae_encoder_loss": 0.5656115293502808, "actor_loss": -3.7112170696258544, "actor_target_entropy": -2.0, "actor_entropy": -0.8878387451171875, "alpha_loss": -0.0033981376327574253, "alpha_value": 0.00921605830671505, "duration": 9.443384170532227, "step": 95586}
{"episode_reward": 15.417509862080063, "episode": 2943.0, "batch_reward": 0.048020912683568895, "critic_loss": 2.7927651703357697, "ae_transition_loss": 1.4591150283813477, "ae_encoder_loss": 0.4311618506908417, "actor_loss": -3.262527108192444, "actor_target_entropy": -2.0, "actor_entropy": -0.94489586353302, "alpha_loss": -0.0037219595978967845, "alpha_value": 0.009245283702024296, "duration": 8.927787065505981, "step": 95630}
{"episode_reward": 15.084041360558711, "episode": 2944.0, "batch_reward": 0.0510110342875123, "critic_loss": 1.4883873164653778, "ae_transition_loss": 1.5300359725952148, "ae_encoder_loss": 0.37183989584445953, "actor_loss": -3.645597219467163, "actor_target_entropy": -2.0, "actor_entropy": -0.964721292257309, "alpha_loss": -0.004192160326056182, "alpha_value": 0.009281051976933404, "duration": 7.726542711257935, "step": 95669}
{"episode_reward": 14.51158568187088, "episode": 2945.0, "batch_reward": 0.023926126770675182, "critic_loss": 2.144353464245796, "ae_transition_loss": 1.6816651821136475, "ae_encoder_loss": 0.3833925426006317, "actor_loss": -3.5566669702529907, "actor_target_entropy": -2.0, "actor_entropy": -0.9875407069921494, "alpha_loss": -0.005287234205752611, "alpha_value": 0.00932558145247223, "duration": 7.026057958602905, "step": 95703}
{"episode_reward": 14.992097427488346, "episode": 2946.0, "batch_reward": 0.048592282459139824, "critic_loss": 2.4966251611709596, "ae_transition_loss": 1.5379873275756837, "ae_encoder_loss": 0.5401326835155487, "actor_loss": -3.5631146907806395, "actor_target_entropy": -2.0, "actor_entropy": -0.9227209568023682, "alpha_loss": -0.00510658398270607, "alpha_value": 0.009385105402266775, "duration": 11.54277229309082, "step": 95760}
{"episode_reward": 5.966157324376831, "episode": 2947.0, "batch_reward": 0.007169489376246929, "critic_loss": 2.7124805450439453, "ae_transition_loss": 1.5868481636047362, "ae_encoder_loss": 0.6002704262733459, "actor_loss": -3.277269172668457, "actor_target_entropy": -2.0, "actor_entropy": -0.8801037788391113, "alpha_loss": -0.005131463892757893, "alpha_value": 0.009461986701676365, "duration": 9.939836025238037, "step": 95810}
{"episode_reward": 11.609509966634148, "episode": 2948.0, "batch_reward": 0.06803025901317597, "critic_loss": 1.8071868419647217, "ae_transition_loss": 1.5297026634216309, "ae_encoder_loss": 0.4644126892089844, "actor_loss": -3.718789052963257, "actor_target_entropy": -2.0, "actor_entropy": -0.8436460018157959, "alpha_loss": -0.005447798129171133, "alpha_value": 0.009544315457824373, "duration": 9.52375078201294, "step": 95857}
{"episode_reward": 14.936617090725672, "episode": 2949.0, "batch_reward": 0.033972653249899544, "critic_loss": 1.9147086938222249, "ae_transition_loss": 1.4262819687525432, "ae_encoder_loss": 0.5691651701927185, "actor_loss": -3.637601613998413, "actor_target_entropy": -2.0, "actor_entropy": -0.7756130496660868, "alpha_loss": -0.007289991248399019, "alpha_value": 0.009612570130531089, "duration": 6.007777214050293, "step": 95886}
{"episode_reward": 8.56219312290937, "episode": 2950.0, "batch_reward": 0.025966598341862362, "critic_loss": 2.2096431255340576, "ae_transition_loss": 1.4222257534662883, "ae_encoder_loss": 0.607197105884552, "actor_loss": -3.4595510959625244, "actor_target_entropy": -2.0, "actor_entropy": -0.6419679323832194, "alpha_loss": -0.007167026711006959, "alpha_value": 0.009669798390357545, "duration": 5.693669319152832, "step": 95913}
{"episode_reward": 2.4471080453838736, "episode": 2951.0, "batch_reward": 0.009291276335716248, "critic_loss": 1.3765218257904053, "ae_transition_loss": 1.623340368270874, "ae_encoder_loss": 0.44666144251823425, "actor_loss": -3.0673975944519043, "actor_target_entropy": -2.0, "actor_entropy": -0.5380271673202515, "alpha_loss": -0.005910013802349567, "alpha_value": 0.009710659359559637, "duration": 70.5939793586731, "step": 95930}
{"episode_reward": 0.27650861198466803, "episode": 2952.0, "batch_reward": 0.09996858984231949, "critic_loss": 1.5081647038459778, "ae_transition_loss": 1.346596598625183, "ae_encoder_loss": 0.30527089536190033, "actor_loss": -3.394157648086548, "actor_target_entropy": -2.0, "actor_entropy": -0.5782696604728699, "alpha_loss": -0.00650451984256506, "alpha_value": 0.009740811942880338, "duration": 3.0514135360717773, "step": 95944}
{"episode_reward": -1.853430608872967, "episode": 2953.0, "batch_reward": 0.10813495144248009, "critic_loss": 2.2220533887545266, "ae_transition_loss": 1.5144104957580566, "ae_encoder_loss": 0.3903941810131073, "actor_loss": -3.8043367862701416, "actor_target_entropy": -2.0, "actor_entropy": -0.5574474632740021, "alpha_loss": -0.004614994783575336, "alpha_value": 0.009791586238363644, "duration": 7.540249586105347, "step": 95980}
{"episode_reward": 11.85235247053655, "episode": 2954.0, "batch_reward": 0.03527672961354256, "critic_loss": 2.0888638496398926, "ae_transition_loss": 1.7583538055419923, "ae_encoder_loss": 0.3906156897544861, "actor_loss": -3.6475656986236573, "actor_target_entropy": -2.0, "actor_entropy": -0.5537683248519898, "alpha_loss": -0.0008492088003549725, "alpha_value": 0.009865188136458713, "duration": 9.499616622924805, "step": 96026}
{"episode_reward": 15.993425652184378, "episode": 2955.0, "batch_reward": 0.0908644525334239, "critic_loss": 2.2032064497470856, "ae_transition_loss": 1.6247356235980988, "ae_encoder_loss": 0.4011247009038925, "actor_loss": -3.7520461082458496, "actor_target_entropy": -2.0, "actor_entropy": -0.5062988698482513, "alpha_loss": 0.00018354978237766773, "alpha_value": 0.009925654922035038, "duration": 8.347847700119019, "step": 96066}
{"episode_reward": 11.733689492050043, "episode": 2956.0, "batch_reward": 0.016374403983354567, "critic_loss": 1.5629546880722045, "ae_transition_loss": 1.5645926237106322, "ae_encoder_loss": 0.47934279441833494, "actor_loss": -3.6661893367767333, "actor_target_entropy": -2.0, "actor_entropy": -0.6948788523674011, "alpha_loss": -0.00012195836752653122, "alpha_value": 0.009961773622619501, "duration": 10.639775037765503, "step": 96118}
{"episode_reward": 15.04504044515457, "episode": 2957.0, "batch_reward": 0.05910492851398885, "critic_loss": 2.1531185805797577, "ae_transition_loss": 1.6176941692829132, "ae_encoder_loss": 0.6283847242593765, "actor_loss": -3.219033896923065, "actor_target_entropy": -2.0, "actor_entropy": -0.7378735393285751, "alpha_loss": -0.002231051796115935, "alpha_value": 0.0099861834392598, "duration": 7.700048923492432, "step": 96156}
{"episode_reward": 12.58984987676848, "episode": 2958.0, "batch_reward": 0.06841052696108818, "critic_loss": 2.020234783490499, "ae_transition_loss": 1.5226739247639973, "ae_encoder_loss": 0.4378446141878764, "actor_loss": -3.974616368611654, "actor_target_entropy": -2.0, "actor_entropy": -0.6751171151796976, "alpha_loss": -0.0015045015995080273, "alpha_value": 0.010006215917414579, "duration": 6.099573135375977, "step": 96185}
{"episode_reward": 5.123388039200397, "episode": 2959.0, "batch_reward": 0.10362400114536285, "critic_loss": 0.8561843633651733, "ae_transition_loss": 1.2932183742523193, "ae_encoder_loss": 0.7147307395935059, "actor_loss": -4.108099937438965, "actor_target_entropy": -2.0, "actor_entropy": -0.7003324031829834, "alpha_loss": -0.004116635769605637, "alpha_value": 0.010017640824824807, "duration": 3.0759408473968506, "step": 96200}
{"episode_reward": 0.2569431350601259, "episode": 2960.0, "batch_reward": 0.06183289363980293, "critic_loss": 2.115741729736328, "ae_transition_loss": 1.6809806823730469, "ae_encoder_loss": 0.42715877294540405, "actor_loss": -3.4242398738861084, "actor_target_entropy": -2.0, "actor_entropy": -0.7191720008850098, "alpha_loss": -0.0017342758364975452, "alpha_value": 0.010024442723888282, "duration": 1.4063587188720703, "step": 96206}
{"episode_reward": -1.1682602951467294, "episode": 2961.0, "batch_reward": 0.05763176456093788, "critic_loss": 1.4491012692451477, "ae_transition_loss": 1.5599603652954102, "ae_encoder_loss": 0.5466938316822052, "actor_loss": -3.577746629714966, "actor_target_entropy": -2.0, "actor_entropy": -0.7345013320446014, "alpha_loss": -0.003094627521932125, "alpha_value": 0.010034888824965022, "duration": 52.89242911338806, "step": 96222}
{"episode_reward": -0.5468493315888201, "episode": 2962.0, "batch_reward": 0.054009509086608884, "critic_loss": 1.6043203830718995, "ae_transition_loss": 1.7036820888519286, "ae_encoder_loss": 0.5916773557662964, "actor_loss": -3.5609262943267823, "actor_target_entropy": -2.0, "actor_entropy": -0.7875304579734802, "alpha_loss": -0.0038373051211237907, "alpha_value": 0.010062956539080707, "duration": 10.586019515991211, "step": 96272}
{"episode_reward": 10.893467846736712, "episode": 2963.0, "batch_reward": 0.08574628680944443, "critic_loss": 1.249474573135376, "ae_transition_loss": 1.543217420578003, "ae_encoder_loss": 0.5611541211605072, "actor_loss": -4.048950052261352, "actor_target_entropy": -2.0, "actor_entropy": -0.8212065935134888, "alpha_loss": -0.00462324321269989, "alpha_value": 0.010113348765841725, "duration": 10.706389665603638, "step": 96326}
{"episode_reward": 12.484423093374755, "episode": 2964.0, "batch_reward": 0.10054124146699905, "critic_loss": 1.1804320812225342, "ae_transition_loss": 1.515169620513916, "ae_encoder_loss": 0.5985378623008728, "actor_loss": -4.34190559387207, "actor_target_entropy": -2.0, "actor_entropy": -0.7711188793182373, "alpha_loss": -0.004068270325660706, "alpha_value": 0.010150145702452392, "duration": 2.247549057006836, "step": 96336}
{"episode_reward": -1.7804846614718817, "episode": 2965.0, "batch_reward": 0.03574683299909035, "critic_loss": 1.7519179781277974, "ae_transition_loss": 1.5318408608436584, "ae_encoder_loss": 0.4701111267010371, "actor_loss": -3.675228397051493, "actor_target_entropy": -2.0, "actor_entropy": -0.7477524876594543, "alpha_loss": -0.004168452840531245, "alpha_value": 0.010193679064206583, "duration": 11.838033437728882, "step": 96393}
{"episode_reward": 10.933409997646482, "episode": 2966.0, "duration": 0.19774770736694336, "step": 96394}
{"episode_reward": -0.6445167660713196, "episode": 2967.0, "batch_reward": 0.054253856651484966, "critic_loss": 1.6580718010663986, "ae_transition_loss": 1.450313687324524, "ae_encoder_loss": 0.3837134838104248, "actor_loss": -3.9020971059799194, "actor_target_entropy": -2.0, "actor_entropy": -0.7486320734024048, "alpha_loss": -0.004445413243956864, "alpha_value": 0.010261154722928533, "duration": 8.112159013748169, "step": 96434}
{"episode_reward": 11.76785097562478, "episode": 2968.0, "batch_reward": 0.04678307212889195, "critic_loss": 1.823900818824768, "ae_transition_loss": 1.683849310874939, "ae_encoder_loss": 0.39887864589691163, "actor_loss": -3.829783248901367, "actor_target_entropy": -2.0, "actor_entropy": -0.7842776060104371, "alpha_loss": -0.004197792708873748, "alpha_value": 0.01032761365225195, "duration": 10.600728988647461, "step": 96484}
{"episode_reward": 16.724136091577243, "episode": 2969.0, "batch_reward": 0.06253572786226869, "critic_loss": 1.916031002998352, "ae_transition_loss": 1.3875616788864136, "ae_encoder_loss": 0.40844903141260147, "actor_loss": -3.9440407156944275, "actor_target_entropy": -2.0, "actor_entropy": -0.7232615053653717, "alpha_loss": -0.004413585760630667, "alpha_value": 0.010394780680761427, "duration": 7.840246915817261, "step": 96522}
{"episode_reward": 8.712309007452438, "episode": 2970.0, "batch_reward": 0.024983187019824982, "critic_loss": 1.8872154712677003, "ae_transition_loss": 1.4350744485855103, "ae_encoder_loss": 0.3858367681503296, "actor_loss": -3.636567544937134, "actor_target_entropy": -2.0, "actor_entropy": -0.7225815415382385, "alpha_loss": -0.003718887362629175, "alpha_value": 0.010462013249492214, "duration": 10.759338140487671, "step": 96575}
{"episode_reward": 10.563307461330337, "episode": 2971.0, "batch_reward": 0.08347954228520393, "critic_loss": 2.1857051849365234, "ae_transition_loss": 1.5233879486719768, "ae_encoder_loss": 0.3896465053160985, "actor_loss": -3.687807559967041, "actor_target_entropy": -2.0, "actor_entropy": -0.7068650821844736, "alpha_loss": -0.0019999331852886826, "alpha_value": 0.010538434204087439, "duration": 101.54601407051086, "step": 96634}
{"episode_reward": 16.514071439727655, "episode": 2972.0, "batch_reward": 0.06576852081343532, "critic_loss": 1.6641688495874405, "ae_transition_loss": 1.59734645485878, "ae_encoder_loss": 0.29920293390750885, "actor_loss": -3.9201366901397705, "actor_target_entropy": -2.0, "actor_entropy": -0.7082344442605972, "alpha_loss": -0.0037981719942763448, "alpha_value": 0.010597554949753844, "duration": 9.055999517440796, "step": 96679}
{"episode_reward": 12.803312169657273, "episode": 2973.0, "batch_reward": 0.04589396268129349, "critic_loss": 1.8130935192108155, "ae_transition_loss": 1.5266526222229004, "ae_encoder_loss": 0.43684629797935487, "actor_loss": -3.776919937133789, "actor_target_entropy": -2.0, "actor_entropy": -0.6968430519104004, "alpha_loss": -0.00217882163124159, "alpha_value": 0.010649440649468246, "duration": 9.126978874206543, "step": 96722}
{"episode_reward": 13.263370194506825, "episode": 2974.0, "duration": 0.20017147064208984, "step": 96723}
{"episode_reward": -0.33392021513680337, "episode": 2975.0, "batch_reward": 0.07712266687303782, "critic_loss": 1.5707474648952484, "ae_transition_loss": 1.4013231992721558, "ae_encoder_loss": 0.47280339896678925, "actor_loss": -3.687528610229492, "actor_target_entropy": -2.0, "actor_entropy": -0.6618277579545975, "alpha_loss": -0.0039060534327290952, "alpha_value": 0.01069991204223008, "duration": 8.740600824356079, "step": 96766}
{"episode_reward": 14.465076660338095, "episode": 2976.0, "batch_reward": 0.05678343240703855, "critic_loss": 2.475315945489066, "ae_transition_loss": 1.5554634843553816, "ae_encoder_loss": 0.565934453691755, "actor_loss": -3.838484627859933, "actor_target_entropy": -2.0, "actor_entropy": -0.5651547057288033, "alpha_loss": -0.0020368144531468196, "alpha_value": 0.010762216419317225, "duration": 14.303507328033447, "step": 96835}
{"episode_reward": 34.42609992610042, "episode": 2977.0, "batch_reward": 0.07170427838961284, "critic_loss": 2.2486764987309775, "ae_transition_loss": 1.4177507956822712, "ae_encoder_loss": 0.4254511793454488, "actor_loss": -3.901972452799479, "actor_target_entropy": -2.0, "actor_entropy": -0.47017637888590497, "alpha_loss": -0.00022798008285462856, "alpha_value": 0.010811350280466718, "duration": 6.527975797653198, "step": 96866}
{"episode_reward": 4.039623775954921, "episode": 2978.0, "batch_reward": 0.0702636893838644, "critic_loss": 1.8230294585227966, "ae_transition_loss": 1.612650732199351, "ae_encoder_loss": 0.4778737078110377, "actor_loss": -3.872049331665039, "actor_target_entropy": -2.0, "actor_entropy": -0.37805641690889996, "alpha_loss": -0.00011967237029845516, "alpha_value": 0.010842133739995131, "duration": 12.903622388839722, "step": 96929}
{"episode_reward": 14.166819975635734, "episode": 2979.0, "batch_reward": 0.021909904045363266, "critic_loss": 2.3865697582562766, "ae_transition_loss": 2.029856582482656, "ae_encoder_loss": 0.5118231723705927, "actor_loss": -3.367305636405945, "actor_target_entropy": -2.0, "actor_entropy": -0.45559584101041156, "alpha_loss": -0.0019757850580693534, "alpha_value": 0.010868159249366864, "duration": 12.260018587112427, "step": 96989}
{"episode_reward": 14.417749074331418, "episode": 2980.0, "batch_reward": 0.08349007709572713, "critic_loss": 2.2483343482017517, "ae_transition_loss": 1.729710837205251, "ae_encoder_loss": 1.065764566262563, "actor_loss": -3.8945826292037964, "actor_target_entropy": -2.0, "actor_entropy": -0.6212820510069529, "alpha_loss": -0.0016907233803067356, "alpha_value": 0.010899091103260046, "duration": 12.067507982254028, "step": 97049}
{"episode_reward": 23.724592950540856, "episode": 2981.0, "batch_reward": 0.04043559022247791, "critic_loss": 2.3307329654693603, "ae_transition_loss": 1.7009737253189088, "ae_encoder_loss": 0.816753751039505, "actor_loss": -3.9560315132141115, "actor_target_entropy": -2.0, "actor_entropy": -0.6482905745506287, "alpha_loss": -0.0018077261978760363, "alpha_value": 0.010930364510545307, "duration": 131.7638874053955, "step": 97097}
{"episode_reward": 17.617796869233175, "episode": 2982.0, "batch_reward": 0.052265102842024395, "critic_loss": 2.1329992030348097, "ae_transition_loss": 1.4263036676815577, "ae_encoder_loss": 0.4156967444079263, "actor_loss": -3.845704742840358, "actor_target_entropy": -2.0, "actor_entropy": -0.7236455721514565, "alpha_loss": -0.0021724109122130486, "alpha_value": 0.010987237907893329, "duration": 27.271331071853638, "step": 97232}
{"episode_reward": 32.36890945326438, "episode": 2983.0, "batch_reward": 0.04422128200531006, "critic_loss": 1.8767168919245403, "ae_transition_loss": 1.2275461355845134, "ae_encoder_loss": 0.510254313548406, "actor_loss": -4.208646456400554, "actor_target_entropy": -2.0, "actor_entropy": -0.7673497001330057, "alpha_loss": -0.004608950267235438, "alpha_value": 0.011053482727754986, "duration": 6.6338067054748535, "step": 97264}
{"episode_reward": 9.413331870797247, "episode": 2984.0, "batch_reward": 0.07435488700866699, "critic_loss": 2.7647929986317954, "ae_transition_loss": 1.5280932982762654, "ae_encoder_loss": 0.49514995018641156, "actor_loss": -3.819185177485148, "actor_target_entropy": -2.0, "actor_entropy": -0.7034611900647482, "alpha_loss": -0.003433196417366465, "alpha_value": 0.011085968326966594, "duration": 5.863130331039429, "step": 97292}
{"episode_reward": 1.121302373196549, "episode": 2985.0, "batch_reward": 0.07016409561038017, "critic_loss": 2.6321053504943848, "ae_transition_loss": 2.262720823287964, "ae_encoder_loss": 0.7888574699560801, "actor_loss": -3.90181835492452, "actor_target_entropy": -2.0, "actor_entropy": -0.6881003975868225, "alpha_loss": -0.003380474401637912, "alpha_value": 0.011121238640602894, "duration": 6.0703558921813965, "step": 97321}
{"episode_reward": 6.512224953032519, "episode": 2986.0, "batch_reward": 0.08275164348574784, "critic_loss": 2.7514655681756826, "ae_transition_loss": 1.6383342742919922, "ae_encoder_loss": 0.8517398329881521, "actor_loss": -3.8459646151616025, "actor_target_entropy": -2.0, "actor_entropy": -0.7074873493267939, "alpha_loss": -0.0021966782425386975, "alpha_value": 0.01120933734416847, "duration": 26.417468070983887, "step": 97452}
{"episode_reward": -7.803122061129808, "episode": 2987.0, "batch_reward": 0.07548560202121735, "critic_loss": 1.6714880168437958, "ae_transition_loss": 1.6376419067382812, "ae_encoder_loss": 0.5138587355613708, "actor_loss": -4.331148266792297, "actor_target_entropy": -2.0, "actor_entropy": -0.7063628435134888, "alpha_loss": -0.002211465616710484, "alpha_value": 0.011286514025456896, "duration": 4.406906366348267, "step": 97472}
{"episode_reward": -1.7074883118122428, "episode": 2988.0, "batch_reward": 0.08087568636983633, "critic_loss": 2.8281248807907104, "ae_transition_loss": 1.709834724664688, "ae_encoder_loss": 0.7367907911539078, "actor_loss": -3.733886241912842, "actor_target_entropy": -2.0, "actor_entropy": -0.6888637989759445, "alpha_loss": -0.0017044190171873197, "alpha_value": 0.011312354809639923, "duration": 8.269884824752808, "step": 97511}
{"episode_reward": 6.748318079785046, "episode": 2989.0, "batch_reward": 0.05207222141325474, "critic_loss": 2.473093569278717, "ae_transition_loss": 1.3948367238044739, "ae_encoder_loss": 0.5129900276660919, "actor_loss": -3.9048635959625244, "actor_target_entropy": -2.0, "actor_entropy": -0.6315974295139313, "alpha_loss": -0.0008402037201449275, "alpha_value": 0.011336811431799902, "duration": 4.388649940490723, "step": 97532}
{"episode_reward": -0.8039215591513259, "episode": 2990.0, "batch_reward": 0.07782437652349472, "critic_loss": 1.208426058292389, "ae_transition_loss": 1.3179829716682434, "ae_encoder_loss": 0.4561786502599716, "actor_loss": -3.4504328966140747, "actor_target_entropy": -2.0, "actor_entropy": -0.5757167041301727, "alpha_loss": -0.000831320125143975, "alpha_value": 0.011352067154103824, "duration": 4.493509531021118, "step": 97555}
{"episode_reward": -0.4590324332611152, "episode": 2991.0, "batch_reward": 0.06946711863080661, "critic_loss": 2.5996549129486084, "ae_transition_loss": 1.2291241486867268, "ae_encoder_loss": 0.42212597529093426, "actor_loss": -4.401859442392985, "actor_target_entropy": -2.0, "actor_entropy": -0.6474560697873434, "alpha_loss": 4.784237050140897e-05, "alpha_value": 0.011368266211760394, "duration": 51.660130977630615, "step": 97582}
{"episode_reward": 0.9487982081412674, "episode": 2992.0, "batch_reward": 0.09115228429436684, "critic_loss": 1.9605331204154275, "ae_transition_loss": 1.2885696671225808, "ae_encoder_loss": 0.47865859215909784, "actor_loss": -3.9410729625008325, "actor_target_entropy": -2.0, "actor_entropy": -0.6246175874363292, "alpha_loss": -0.0005830362060805783, "alpha_value": 0.01139507702425372, "duration": 25.822400331497192, "step": 97700}
{"episode_reward": 32.13883676494943, "episode": 2993.0, "batch_reward": -0.01538906991481781, "critic_loss": 2.1931532621383667, "ae_transition_loss": 1.4020056128501892, "ae_encoder_loss": 1.1153032779693604, "actor_loss": -3.4568833112716675, "actor_target_entropy": -2.0, "actor_entropy": -0.5408058166503906, "alpha_loss": 0.0014550922205671668, "alpha_value": 0.011412532619006622, "duration": 3.1621222496032715, "step": 97714}
{"episode_reward": -0.4908327553817985, "episode": 2994.0, "batch_reward": 0.08103852942585946, "critic_loss": 2.240783417224884, "ae_transition_loss": 1.358931303024292, "ae_encoder_loss": 0.5950236618518829, "actor_loss": -3.8293757915496824, "actor_target_entropy": -2.0, "actor_entropy": -0.5622345328330993, "alpha_loss": -0.0012087717739632353, "alpha_value": 0.01142284756787592, "duration": 11.277542114257812, "step": 97767}
{"episode_reward": -3.520988865568739, "episode": 2995.0, "batch_reward": 0.042112420126795766, "critic_loss": 2.3009313106536866, "ae_transition_loss": 1.498192811012268, "ae_encoder_loss": 0.5491869688034058, "actor_loss": -3.879202365875244, "actor_target_entropy": -2.0, "actor_entropy": -0.525507140159607, "alpha_loss": -0.0016253206878900528, "alpha_value": 0.011440507947608933, "duration": 10.319748640060425, "step": 97817}
{"episode_reward": 12.103842854900392, "episode": 2996.0, "batch_reward": 0.11508457309433393, "critic_loss": 2.1584469079971313, "ae_transition_loss": 1.5029971429279871, "ae_encoder_loss": 0.5121132986886161, "actor_loss": -4.220945256096976, "actor_target_entropy": -2.0, "actor_entropy": -0.5162884848458427, "alpha_loss": -0.0023474461382388006, "alpha_value": 0.011471124217076393, "duration": 13.493066310882568, "step": 97881}
{"episode_reward": 16.406570545494557, "episode": 2997.0, "batch_reward": 0.125642541795969, "critic_loss": 2.343975305557251, "ae_transition_loss": 1.6577172577381134, "ae_encoder_loss": 0.3908715397119522, "actor_loss": -4.319930136203766, "actor_target_entropy": -2.0, "actor_entropy": -0.49344881623983383, "alpha_loss": 0.0001801003236323595, "alpha_value": 0.011504249521769089, "duration": 8.398480653762817, "step": 97921}
{"episode_reward": 15.499020603839286, "episode": 2998.0, "duration": 0.1862938404083252, "step": 97922}
{"episode_reward": -0.4242178617687805, "episode": 2999.0, "batch_reward": 0.04946553707122803, "critic_loss": 2.089753746986389, "ae_transition_loss": 1.6347770690917969, "ae_encoder_loss": 0.43986351788043976, "actor_loss": -4.009524464607239, "actor_target_entropy": -2.0, "actor_entropy": -0.41055382788181305, "alpha_loss": 0.0008840121445246041, "alpha_value": 0.011520442957317967, "duration": 8.329488515853882, "step": 97962}
{"episode_reward": 12.33989705877218, "episode": 3000.0, "batch_reward": 0.05255269072949886, "critic_loss": 1.6150177001953125, "ae_transition_loss": 1.5968193292617798, "ae_encoder_loss": 0.3971772432327271, "actor_loss": -3.8626843452453614, "actor_target_entropy": -2.0, "actor_entropy": -0.3518947124481201, "alpha_loss": 0.0007453677710145712, "alpha_value": 0.011528111036876072, "duration": 10.033262968063354, "step": 98011}
{"episode_reward": 16.966607550502623, "episode": 3001.0, "duration": 117.28595566749573, "step": 98012}
{"episode_reward": -0.2922832991673558, "episode": 3002.0, "batch_reward": 0.06804520264267921, "critic_loss": 2.579868793487549, "ae_transition_loss": 1.7928632497787476, "ae_encoder_loss": 0.4171768128871918, "actor_loss": -3.971573233604431, "actor_target_entropy": -2.0, "actor_entropy": -0.28249405324459076, "alpha_loss": 0.0006055596750229597, "alpha_value": 0.011527785940044905, "duration": 4.45666241645813, "step": 98032}
{"episode_reward": 0.7492851273626582, "episode": 3003.0, "batch_reward": 0.0821441042769168, "critic_loss": 1.985214935881751, "ae_transition_loss": 1.5775959236281258, "ae_encoder_loss": 0.42416622383253916, "actor_loss": -4.159626160349164, "actor_target_entropy": -2.0, "actor_entropy": -0.2682832713638033, "alpha_loss": 0.0018862331469011093, "alpha_value": 0.011503107455762397, "duration": 30.518487691879272, "step": 98174}
{"episode_reward": 34.282906443326596, "episode": 3004.0, "batch_reward": 0.05740304039791226, "critic_loss": 2.152276110649109, "ae_transition_loss": 1.4857887744903564, "ae_encoder_loss": 0.6130217671394348, "actor_loss": -4.233803844451904, "actor_target_entropy": -2.0, "actor_entropy": -0.3720823794603348, "alpha_loss": -0.0007876550313085318, "alpha_value": 0.011455973407701738, "duration": 11.024502754211426, "step": 98225}
{"episode_reward": 15.968304206650117, "episode": 3005.0, "batch_reward": 0.04094713181257248, "critic_loss": 2.307778835296631, "ae_transition_loss": 1.918911337852478, "ae_encoder_loss": 0.7919134497642517, "actor_loss": -4.243490695953369, "actor_target_entropy": -2.0, "actor_entropy": -0.48533686995506287, "alpha_loss": -0.0011663584737107158, "alpha_value": 0.011448272635790768, "duration": 2.139716863632202, "step": 98235}
{"episode_reward": -2.130076369658031, "episode": 3006.0, "batch_reward": 0.08396539775033791, "critic_loss": 1.5749839544296265, "ae_transition_loss": 1.574060281117757, "ae_encoder_loss": 0.6000328560670217, "actor_loss": -4.000420133272807, "actor_target_entropy": -2.0, "actor_entropy": -0.5116715431213379, "alpha_loss": -0.00031510145830300945, "alpha_value": 0.011444650949744999, "duration": 11.768774509429932, "step": 98291}
{"episode_reward": 9.709577072211314, "episode": 3007.0, "batch_reward": 0.08034191466867924, "critic_loss": 1.771480878194173, "ae_transition_loss": 1.5274718602498372, "ae_encoder_loss": 0.6482288340727488, "actor_loss": -4.042153278986613, "actor_target_entropy": -2.0, "actor_entropy": -0.526584525903066, "alpha_loss": 0.00021909272375827035, "alpha_value": 0.011445337462422598, "duration": 13.702820539474487, "step": 98359}
{"episode_reward": 14.421514298926919, "episode": 3008.0, "batch_reward": 0.12018519826233387, "critic_loss": 3.5491890907287598, "ae_transition_loss": 1.6927780508995056, "ae_encoder_loss": 0.7311387062072754, "actor_loss": -4.457005023956299, "actor_target_entropy": -2.0, "actor_entropy": -0.5491313338279724, "alpha_loss": -0.0013952726731076837, "alpha_value": 0.011445026637509204, "duration": 3.065361738204956, "step": 98373}
{"episode_reward": -1.2826896786183255, "episode": 3009.0, "batch_reward": 0.045125159248709676, "critic_loss": 2.5861636877059935, "ae_transition_loss": 1.5422150373458863, "ae_encoder_loss": 0.36125014424324037, "actor_loss": -4.044426822662354, "actor_target_entropy": -2.0, "actor_entropy": -0.557813036441803, "alpha_loss": -0.0015382860612589866, "alpha_value": 0.01144962112258558, "duration": 10.524183750152588, "step": 98424}
{"episode_reward": 5.896506348883373, "episode": 3010.0, "batch_reward": 0.11223790794610977, "critic_loss": 0.8267596960067749, "ae_transition_loss": 1.2646677494049072, "ae_encoder_loss": 0.4828062355518341, "actor_loss": -4.477792739868164, "actor_target_entropy": -2.0, "actor_entropy": -0.5471110343933105, "alpha_loss": 0.001204105792567134, "alpha_value": 0.01145619469536934, "duration": 3.229996681213379, "step": 98440}
{"episode_reward": 0.8911122882716945, "episode": 3011.0, "batch_reward": 0.08687971417720501, "critic_loss": 2.6623526444801917, "ae_transition_loss": 1.7085912135931163, "ae_encoder_loss": 0.5829293200602899, "actor_loss": -4.014765831140371, "actor_target_entropy": -2.0, "actor_entropy": -0.5257872870335212, "alpha_loss": 0.0005875692787902573, "alpha_value": 0.011461191705485334, "duration": 75.37323784828186, "step": 98562}
{"episode_reward": 38.37879874167555, "episode": 3012.0, "batch_reward": 0.0709235280752182, "critic_loss": 2.2450984001159666, "ae_transition_loss": 1.6188910245895385, "ae_encoder_loss": 0.5286373019218444, "actor_loss": -3.7213485717773436, "actor_target_entropy": -2.0, "actor_entropy": -0.4759076416492462, "alpha_loss": 0.0005843749502673745, "alpha_value": 0.011451030797604353, "duration": 10.432218313217163, "step": 98612}
{"episode_reward": 14.59134602369396, "episode": 3013.0, "batch_reward": 0.06710791885852814, "critic_loss": 1.9881906986236573, "ae_transition_loss": 1.788652276992798, "ae_encoder_loss": 0.414040207862854, "actor_loss": -4.023919725418091, "actor_target_entropy": -2.0, "actor_entropy": -0.5355964422225952, "alpha_loss": 0.00023474256740882993, "alpha_value": 0.011439930593123102, "duration": 20.58860969543457, "step": 98711}
{"episode_reward": 32.23266561388228, "episode": 3014.0, "batch_reward": 0.06152741704136133, "critic_loss": 1.949068009853363, "ae_transition_loss": 1.6614595254262288, "ae_encoder_loss": 0.4348543832699458, "actor_loss": -3.88203497727712, "actor_target_entropy": -2.0, "actor_entropy": -0.5431849857171377, "alpha_loss": 0.0016078617773018777, "alpha_value": 0.011428364283013174, "duration": 13.024985074996948, "step": 98775}
{"episode_reward": 31.09514009579352, "episode": 3015.0, "batch_reward": 0.08749693507949512, "critic_loss": 1.967951496442159, "ae_transition_loss": 1.6553614735603333, "ae_encoder_loss": 0.40748541553815204, "actor_loss": -4.077518065770467, "actor_target_entropy": -2.0, "actor_entropy": -0.5585625171661377, "alpha_loss": -0.0009913319760623078, "alpha_value": 0.011413264603056694, "duration": 11.593754768371582, "step": 98832}
{"episode_reward": 14.399485891226442, "episode": 3016.0, "batch_reward": 0.09768441319465637, "critic_loss": 0.804712176322937, "ae_transition_loss": 1.3765841722488403, "ae_encoder_loss": 0.4405273199081421, "actor_loss": -3.9574103355407715, "actor_target_entropy": -2.0, "actor_entropy": -0.5515085458755493, "alpha_loss": -0.0019479974871501327, "alpha_value": 0.011409310810065684, "duration": 2.8859364986419678, "step": 98847}
{"episode_reward": -1.3897526016718573, "episode": 3017.0, "batch_reward": 0.09033743691231523, "critic_loss": 1.8120674320629664, "ae_transition_loss": 1.5012682165418352, "ae_encoder_loss": 0.5965949126652309, "actor_loss": -4.180670704160418, "actor_target_entropy": -2.0, "actor_entropy": -0.5293199249676296, "alpha_loss": 0.0007798210322757118, "alpha_value": 0.011409329818963141, "duration": 14.611751794815063, "step": 98918}
{"episode_reward": 15.541600716657214, "episode": 3018.0, "batch_reward": 0.05660566017031669, "critic_loss": 3.353383922576904, "ae_transition_loss": 2.7280489206314087, "ae_encoder_loss": 1.3304759860038757, "actor_loss": -4.064895820617676, "actor_target_entropy": -2.0, "actor_entropy": -0.4863803803920746, "alpha_loss": 0.001668555790092796, "alpha_value": 0.011398974624514283, "duration": 10.419649839401245, "step": 98969}
{"episode_reward": 20.912296207803116, "episode": 3019.0, "batch_reward": 0.08417538553476334, "critic_loss": 2.4610700607299805, "ae_transition_loss": 1.9241377115249634, "ae_encoder_loss": 2.9205830097198486, "actor_loss": -4.617732286453247, "actor_target_entropy": -2.0, "actor_entropy": -0.4686598479747772, "alpha_loss": 0.0010146158747375011, "alpha_value": 0.011387887966592417, "duration": 3.5333032608032227, "step": 98985}
{"episode_reward": -1.8350446335895008, "episode": 3020.0, "batch_reward": 0.08631955566150802, "critic_loss": 3.68320437840053, "ae_transition_loss": 2.0513664994921004, "ae_encoder_loss": 2.1875408547265187, "actor_loss": -4.401677472250802, "actor_target_entropy": -2.0, "actor_entropy": -0.5292761666434151, "alpha_loss": -0.001154517921219979, "alpha_value": 0.011379520871754407, "duration": 14.806509494781494, "step": 99057}
{"episode_reward": 11.10585881938618, "episode": 3021.0, "batch_reward": 0.067573472391814, "critic_loss": 2.8625009059906006, "ae_transition_loss": 1.9428753852844238, "ae_encoder_loss": 1.7758288383483887, "actor_loss": -3.9884663820266724, "actor_target_entropy": -2.0, "actor_entropy": -0.49299824237823486, "alpha_loss": -0.0002331889554625377, "alpha_value": 0.01138079181419647, "duration": 83.49586653709412, "step": 99097}
{"episode_reward": 9.706252572839556, "episode": 3022.0, "batch_reward": 0.07368153227227074, "critic_loss": 2.7635221651622226, "ae_transition_loss": 1.837965420314244, "ae_encoder_loss": 0.8121990774359021, "actor_loss": -4.142689228057861, "actor_target_entropy": -2.0, "actor_entropy": -0.4641482446874891, "alpha_loss": 0.000696406583301723, "alpha_value": 0.011383976072009819, "duration": 13.247347831726074, "step": 99161}
{"episode_reward": 22.30475109331261, "episode": 3023.0, "batch_reward": 0.042527195842315756, "critic_loss": 2.622676452000936, "ae_transition_loss": 1.6922734181086223, "ae_encoder_loss": 0.485637108484904, "actor_loss": -3.928029457728068, "actor_target_entropy": -2.0, "actor_entropy": -0.383687824010849, "alpha_loss": 0.0006351689614045123, "alpha_value": 0.01138134792452712, "duration": 7.6560821533203125, "step": 99199}
{"episode_reward": 8.483414043953214, "episode": 3024.0, "batch_reward": 0.0729787473877271, "critic_loss": 2.9399105111757913, "ae_transition_loss": 1.498063067595164, "ae_encoder_loss": 0.5729886045058569, "actor_loss": -3.9284847180048623, "actor_target_entropy": -2.0, "actor_entropy": -0.32677027583122253, "alpha_loss": 0.0017436237928147118, "alpha_value": 0.011370201460568463, "duration": 12.571808099746704, "step": 99260}
{"episode_reward": 17.758632778392904, "episode": 3025.0, "batch_reward": 0.10887836664915085, "critic_loss": 2.8649796644846597, "ae_transition_loss": 1.410645882288615, "ae_encoder_loss": 0.5749559203783671, "actor_loss": -4.725597540537517, "actor_target_entropy": -2.0, "actor_entropy": -0.2561844289302826, "alpha_loss": 0.0027516589810450873, "alpha_value": 0.01135171408198248, "duration": 5.788198709487915, "step": 99287}
{"episode_reward": 5.093750292492666, "episode": 3026.0, "batch_reward": 0.04577940087765455, "critic_loss": 2.9914090156555178, "ae_transition_loss": 1.2855138540267945, "ae_encoder_loss": 0.6219821214675904, "actor_loss": -3.639161396026611, "actor_target_entropy": -2.0, "actor_entropy": -0.1985167771577835, "alpha_loss": 0.0023820292204618453, "alpha_value": 0.011325658457996384, "duration": 9.60986065864563, "step": 99333}
{"episode_reward": 9.111705466192888, "episode": 3027.0, "batch_reward": 0.1021781638264656, "critic_loss": 2.462181051572164, "ae_transition_loss": 1.0709157983462017, "ae_encoder_loss": 0.7062137226263682, "actor_loss": -4.142712990442912, "actor_target_entropy": -2.0, "actor_entropy": -0.30327680706977844, "alpha_loss": 0.00020283109430844584, "alpha_value": 0.011297125350346817, "duration": 6.565340280532837, "step": 99366}
{"episode_reward": 6.73010463136243, "episode": 3028.0, "batch_reward": 0.09402577827374141, "critic_loss": 2.4724427461624146, "ae_transition_loss": 1.7057135303815205, "ae_encoder_loss": 0.8996662894884745, "actor_loss": -4.33316175142924, "actor_target_entropy": -2.0, "actor_entropy": -0.33520221213499707, "alpha_loss": 0.0010138637298950925, "alpha_value": 0.011269432848927723, "duration": 11.79042387008667, "step": 99424}
{"episode_reward": 14.675379790306605, "episode": 3029.0, "batch_reward": 0.0701293908059597, "critic_loss": 2.3465293645858765, "ae_transition_loss": 1.3468177914619446, "ae_encoder_loss": 0.6487248539924622, "actor_loss": -3.633883237838745, "actor_target_entropy": -2.0, "actor_entropy": -0.3184908330440521, "alpha_loss": -0.0006555631407536566, "alpha_value": 0.011248409631980824, "duration": 4.42392110824585, "step": 99445}
{"episode_reward": 1.0446963504621376, "episode": 3030.0, "batch_reward": 0.07299497226874034, "critic_loss": 2.881507456302643, "ae_transition_loss": 1.52791694800059, "ae_encoder_loss": 0.4765019913514455, "actor_loss": -4.404641310373942, "actor_target_entropy": -2.0, "actor_entropy": -0.3137787828842799, "alpha_loss": -8.028982362399499e-05, "alpha_value": 0.011234403784852747, "duration": 11.901917695999146, "step": 99502}
{"episode_reward": 22.806561408061715, "episode": 3031.0, "duration": 75.55098724365234, "step": 99508}
{"episode_reward": -1.1549267261285454, "episode": 3032.0, "batch_reward": 0.1256468343947615, "critic_loss": 2.436586720602853, "ae_transition_loss": 1.6523911271776472, "ae_encoder_loss": 0.3857281378337315, "actor_loss": -4.493988582066128, "actor_target_entropy": -2.0, "actor_entropy": -0.3100493252277374, "alpha_loss": 0.0013723938858934811, "alpha_value": 0.011221807211381026, "duration": 13.667205095291138, "step": 99573}
{"episode_reward": 31.603336863824357, "episode": 3033.0, "batch_reward": 0.08038643561303616, "critic_loss": 1.760070264339447, "ae_transition_loss": 1.5929436683654785, "ae_encoder_loss": 0.33610835671424866, "actor_loss": -4.149149596691132, "actor_target_entropy": -2.0, "actor_entropy": -0.2762672156095505, "alpha_loss": 0.002405220366199501, "alpha_value": 0.011203611758783732, "duration": 8.804391145706177, "step": 99615}
{"episode_reward": 12.697469350631136, "episode": 3034.0, "batch_reward": 0.12928616255521774, "critic_loss": 1.1481385231018066, "ae_transition_loss": 1.4059272408485413, "ae_encoder_loss": 0.3062107264995575, "actor_loss": -4.634792804718018, "actor_target_entropy": -2.0, "actor_entropy": -0.33261100947856903, "alpha_loss": 0.001732419419568032, "alpha_value": 0.011186678817043761, "duration": 4.599609375, "step": 99636}
{"episode_reward": 1.842142453303833, "episode": 3035.0, "batch_reward": 0.09826754778623581, "critic_loss": 1.7768207490444183, "ae_transition_loss": 1.4541437327861786, "ae_encoder_loss": 0.30071642249822617, "actor_loss": -4.1564531326293945, "actor_target_entropy": -2.0, "actor_entropy": -0.26383159309625626, "alpha_loss": 0.002445079997414723, "alpha_value": 0.011169186922286438, "duration": 9.10400390625, "step": 99680}
{"episode_reward": 16.456868084131962, "episode": 3036.0, "batch_reward": 0.08268435299396515, "critic_loss": 0.6718844771385193, "ae_transition_loss": 1.1415055990219116, "ae_encoder_loss": 0.5736090540885925, "actor_loss": -4.255492687225342, "actor_target_entropy": -2.0, "actor_entropy": -0.2857484519481659, "alpha_loss": 0.0023997672833502293, "alpha_value": 0.011152717106811053, "duration": 2.131798028945923, "step": 99690}
{"episode_reward": -2.2654714296453746, "episode": 3037.0, "batch_reward": 0.06510091349482536, "critic_loss": 2.181499481201172, "ae_transition_loss": 1.4084163188934327, "ae_encoder_loss": 0.4791278958320618, "actor_loss": -4.132999229431152, "actor_target_entropy": -2.0, "actor_entropy": -0.2958021402359009, "alpha_loss": 0.002325657056644559, "alpha_value": 0.011132584357225254, "duration": 9.495968103408813, "step": 99735}
{"episode_reward": 15.245691747026553, "episode": 3038.0, "batch_reward": 0.11988946422934532, "critic_loss": 2.155572474002838, "ae_transition_loss": 1.3703817427158356, "ae_encoder_loss": 0.3769151121377945, "actor_loss": -4.192680895328522, "actor_target_entropy": -2.0, "actor_entropy": -0.3709001913666725, "alpha_loss": 0.0030852695927023888, "alpha_value": 0.011096004233534632, "duration": 7.771647930145264, "step": 99771}
{"episode_reward": 9.759405591216488, "episode": 3039.0, "batch_reward": 0.07525537659724553, "critic_loss": 1.766162673632304, "ae_transition_loss": 1.1154764493306477, "ae_encoder_loss": 0.3506358166535695, "actor_loss": -4.210952281951904, "actor_target_entropy": -2.0, "actor_entropy": -0.40287625789642334, "alpha_loss": -0.0004008901499522229, "alpha_value": 0.011063584907537003, "duration": 7.223681926727295, "step": 99805}
{"episode_reward": 9.118842865632741, "episode": 3040.0, "batch_reward": 0.1057188254263666, "critic_loss": 1.4768409066730075, "ae_transition_loss": 1.326542125807868, "ae_encoder_loss": 0.4371071325408088, "actor_loss": -4.266423755221897, "actor_target_entropy": -2.0, "actor_entropy": -0.4833367665608724, "alpha_loss": 0.00106120455570312, "alpha_value": 0.01102626670517136, "duration": 19.423760652542114, "step": 99900}
{"episode_reward": 24.235830440982305, "episode": 3041.0, "batch_reward": 0.10934614166617393, "critic_loss": 1.4587340116500855, "ae_transition_loss": 1.3080546855926514, "ae_encoder_loss": 0.36565580368041994, "actor_loss": -4.3150733470916744, "actor_target_entropy": -2.0, "actor_entropy": -0.4888073027133942, "alpha_loss": 0.0008497589849866926, "alpha_value": 0.010988937572499174, "duration": 106.33156728744507, "step": 99942}
{"episode_reward": 16.799900147674833, "episode": 3042.0, "duration": 0.22171354293823242, "step": 99943}
{"episode_reward": -0.09053456044427746, "episode": 3043.0, "batch_reward": 0.07411473244428635, "critic_loss": 1.6673247337341308, "ae_transition_loss": 1.3490836858749389, "ae_encoder_loss": 0.5634637951850892, "actor_loss": -4.105584335327149, "actor_target_entropy": -2.0, "actor_entropy": -0.4679151654243469, "alpha_loss": -0.0003121592802926898, "alpha_value": 0.010969360043190499, "duration": 10.637797832489014, "step": 99995}
{"episode_reward": 19.533904426199815, "episode": 3044.0, "duration": 0.2601613998413086, "step": 99996}
